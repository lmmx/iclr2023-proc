id	number	title	keywords	TL;DR	area	paperhash	pdf
jU-AXLS2bl	2	Hedge Your Actions: Flexible Reinforcement Learning for Complex Action Spaces	['Efficient Reinforcement Learning', 'Large Action Space', 'Listwise Action Retrieval']	Flexible reinforcement learning under complex innumerable action spaces via listwise action retrieval	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|hedge_your_actions_flexible_reinforcement_learning_for_complex_action_spaces	/pdf/90135ebabd29ea6e3584f07ffc6455d88d709710.pdf
ED2Jjms9A4H	3	Efficient Exploration via Fragmentation and Recall	['fragmentation', 'recall', 'exploration', 'cognitive science', 'neuroscience', 'curiosity', 'reinforcement learning', 'spatial navigation']	We propose a novel framework for exploration based on fragmentation-and-recall.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|efficient_exploration_via_fragmentation_and_recall	/pdf/510179473164f96c015db231c1981ccfc1d73d56.pdf
KjKZaJ5Gbv	5	Efficient Multi-Task Reinforcement Learning via Selective Behavior Sharing	['Reinforcement Learning', 'Multitask Reinforcement Learning']	Sharing behaviors between tasks to improve exploration for multitask reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|efficient_multitask_reinforcement_learning_via_selective_behavior_sharing	/pdf/bb66e0cdbc71ccd6e7ff5693c3199f8950416b9a.pdf
4XMAzZasId	6	Model-agnostic Measure of Generalization Difficulty	['generalization', 'inductive bias', 'information theory', 'manifold', 'complexity']	We propose a model-agnostic measure of the generalization difficulty of a task.	General Machine Learning (ie none of the above)	anonymous|modelagnostic_measure_of_generalization_difficulty	/pdf/d7f05dd50d630daf84ed1f34b5e5c837e639476a.pdf
IJwhRE510b	8	ELODI: Ensemble Logit Difference Inhibition for Positive-Congruent Training	['positive-congruent training', 'negative flip', 'ensemble learning']		Deep Learning and representational learning	anonymous|elodi_ensemble_logit_difference_inhibition_for_positivecongruent_training	/pdf/743ee19c40b0a25cd97c924439b4b14ba4526bfc.pdf
P5Z-Zl9XJ7	9	Continuous-Discrete Convolution for (3+1)D Geometry-Sequence Modeling in Proteins	['Protein representation learning', '3D geometry modeling', '1D sequence modeling', 'continuous convolution', 'discrete convolution.']	This paper proposes a Continuous-Discrete Convolution (CDConv) for the (3+1)D geometry-sequence strutuere modeling in proteins.	Deep Learning and representational learning	anonymous|continuousdiscrete_convolution_for_31d_geometrysequence_modeling_in_proteins	/pdf/f041e2da01fb3b9c5408eb12ff50e8842a992280.pdf
E9_04otJ62	10	Winograd Structured Pruning for Fast Winograd Convolution 	['Winograd convolution', 'structured pruning', 'GPU', 'parallel processor']	We propose a novel Winograd structured pruning method, which prunes the weights in the Winograd-domain in a structured form with optimized pruning unit size for fast Winograd convolution on parallel processors.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|winograd_structured_pruning_for_fast_winograd_convolution	/pdf/8462b77a8fbbeb316df6e75e8928c29a3a2bfcc3.pdf
10R_bcjFwJ	11	Patch-Level Contrasting without Patch Correspondence for Accurate and Dense Contrastive Representation Learning	['self supervised learning', 'contrastive learning']	We propose a new self-supervised leanring method to learn both spatial-sensitive and global-discriminative information	Deep Learning and representational learning	anonymous|patchlevel_contrasting_without_patch_correspondence_for_accurate_and_dense_contrastive_representation_learning	/pdf/710c0f5d04987c4be74d1b353bda278fa8f731ec.pdf
A3sgyt4HWp	12	Contextual Image Masking Modeling via Synergized Contrasting without View Augmentation for Faster and Better Visual Pretraining	['Mask Image Modeling', 'Self-supervised learning']	We propose a novel framework for synergizing MIM and contrastive learning in a close-loop.	Deep Learning and representational learning	anonymous|contextual_image_masking_modeling_via_synergized_contrasting_without_view_augmentation_for_faster_and_better_visual_pretraining	/pdf/cf3a0fb6b22391e42bff5eec71a4c9b6ed85e684.pdf
e1u9PVnwNr	17	BiBench: Benchmarking and Analyzing Network Binarization	['Model Binarization', 'Network Compression', 'Deep Learning']	We present BiBench, aiming to rigorously benchmark and analyze network binarization.	Deep Learning and representational learning	anonymous|bibench_benchmarking_and_analyzing_network_binarization	/pdf/3f92a578a9b837fe41b0c47aecf979db41d87d4c.pdf
VJjtgKzrmj	18	Understanding the Training Dynamics in Federated Deep Learning via Aggregation Weight Optimization	['Federated learning', 'deep learning', 'weighted aggregation', 'training dynamics', 'optimization', 'neural network.']	We provide new understandings about the training dynamics of federated learning with neural network and devise a practical tool for aggregation weight optimization, improving global model generalization.	Deep Learning and representational learning	anonymous|understanding_the_training_dynamics_in_federated_deep_learning_via_aggregation_weight_optimization	/pdf/9f157cab39f1f9f6ae259532d0f3b1b503568e88.pdf
7hdmA0qtr5	20	scFormer: a universal representation learning approach for single-cell data using transformers	['single-cell genomics', 'self-supervised learning', 'transformer']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|scformer_a_universal_representation_learning_approach_for_singlecell_data_using_transformers	/pdf/90b19e6e57e7a21e7fca2ffba1e99e7841808af2.pdf
nId8ZtIXub	23	Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking	['multi-object tracking']		Applications (eg, speech processing, computer vision, NLP)	anonymous|observationcentric_sort_rethinking_sort_for_robust_multiobject_tracking	/pdf/ed735e31186cc54585f7392a0c5cdf1c90d09fa5.pdf
IzI055GrvG	24	Object Tracking by Hierarchical Part-Whole Attention	['multi-object tracking', 'transformer', 'visual representation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|object_tracking_by_hierarchical_partwhole_attention	/pdf/3f9aa1a182eda3368b7468675c3864cb9ad1c75a.pdf
TJjaQEOK8a	25	In the ZONE: Measuring difficulty and progression in curriculum generation	['curriculum learning', 'multiagent', 'Bayesian']	This work proposes a Bayesian computational framework to operationalize ``the zone of proximal development'' and to improve existing curriculum generation algorithms.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|in_the_zone_measuring_difficulty_and_progression_in_curriculum_generation	/pdf/5c23d058fe444b3e2e3ee8adbb2b033fdb8175e8.pdf
9JjGZsDvHb	29	Metro: Memory-Enhanced Transformer for Retrosynthetic Planning via Reaction Tree	['Retrosynthetic Planning', 'Transformer', 'Memory Network', 'Reaction Database', 'Reaction tree']	We use reaction database to search the retrosynthetic routes and introduce a memory network to learn the context information of the route.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|metro_memoryenhanced_transformer_for_retrosynthetic_planning_via_reaction_tree	/pdf/ed940fd48acfe1503d6d90213d42297a74b79c4f.pdf
P45P8xfL_n	30	A MULTI-SCALE STRUCTURE-PRESERVING HETEROLOGOUS IMAGE TRANSFORMATION ALGORITHM BASED ON CONDITIONAL ADVERSARIAL NETWORK LEARNING	['Heterologous Image Transformation', 'Multi-scale feature encoding', 'Generative Adversarial Networks']	Proposed new model structure and two loss functions reduce distortion and blur in generated heterogenous images		anonymous|a_multiscale_structurepreserving_heterologous_image_transformation_algorithm_based_on_conditional_adversarial_network_learning	/pdf/6c1d17f4f7736e3dba7aa2d05029ba3845f3b29b.pdf
oQjWltREeRA	31	Generalized Category Discovery via Adaptive GMMs without Knowing the Class Number	['generalized category discovery', 'transfer learning', 'clustering', 'deep learning']		Deep Learning and representational learning	anonymous|generalized_category_discovery_via_adaptive_gmms_without_knowing_the_class_number	/pdf/687961319914c32eb8ca969a0aa36952985a2fe6.pdf
jgmuRzM-sb6	33	DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks	['GNN', 'Interpretability']		General Machine Learning (ie none of the above)	anonymous|dag_matters_gflownets_enhanced_explainer_for_graph_neural_networks	/pdf/3e1c0890887721a04ff9e57ae213aabcd152aacc.pdf
OZG9yDOz0b	35	Do Spiking Neural Networks Learn Similar Representation with Artificial Neural Networks? A Pilot Study on SNN Representation	['Spiking Neural Networks', 'Artificial Neural Network', 'Representation Similarity Analysis']	Systematic study on the representation difference between ANNs and SNNs are conducted in this work. 	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|do_spiking_neural_networks_learn_similar_representation_with_artificial_neural_networks_a_pilot_study_on_snn_representation	/pdf/907075194b6674841849afa95a48dd6a9e82338f.pdf
GN6cm7uSjV	41	Masked Surfel Prediction for Self-Supervised Point Cloud Learning	['Self-supervised point cloud learning', 'surfel representation', 'masked auto-encoding']	Considering the local geometry information explicitly into the masked auto-encoding	Unsupervised and Self-supervised learning	anonymous|masked_surfel_prediction_for_selfsupervised_point_cloud_learning	/pdf/0d060a8377606c64fb6d3c121053683e6315dcd8.pdf
07tc5kKRIo	42	Delving into Semantic Scale Imbalance	['Imbalanced Learning', 'Model bias', 'Long-tailed distribution']	Our proposed semantic scale, like the number of samples, is a natural measure of class imbalance and does not depend on the model’s predictions.	Deep Learning and representational learning	anonymous|delving_into_semantic_scale_imbalance	/pdf/dc5de8598548b233bfb1f92bb866895ce642ed63.pdf
UAB7seI4nq	43	Backpropagation Path Search On Adversarial Transferability	['Adversarial Attack', 'Adversarial Transferability', 'Black-box Attack']	We boost adversarial transferability by searching paths in the backpropagation process.	Applications (eg, speech processing, computer vision, NLP)	anonymous|backpropagation_path_search_on_adversarial_transferability	/pdf/2133dec30297175dd82e585517c77d120d6748f4.pdf
Nkd7AS2USRd	45	Protein structure generation via folding diffusion	['Generative modeling of protein backbone structures', 'structural biology', 'diffusion', 'diffusion modeling', 'generative modeling', 'proteins', 'internal coordinates']	Inspired by the protein folding process, we introduce a new diffusion-based generative model that acts on the inter-residue angles in protein backbones and generates diverse, designable protein structures without needing equivariance mechanisms.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|protein_structure_generation_via_folding_diffusion	/pdf/1eeaf56088a4da7f7788c3a7045ecdcb0d49887f.pdf
J13x0dErg1	52	Rethinking Knowledge Distillation via Cross-Entropy	['Knowledge Distillation', 'Image Classification']	A new teacher-based knowledge distillation method and a new teacher-free knowledge distillation method	Deep Learning and representational learning	anonymous|rethinking_knowledge_distillation_via_crossentropy	/pdf/6e7760bcb4e2b86d9ee7f275f3a262768921e730.pdf
Xi8JtRx75B	53	Trust-consistent Visual Semantic Embedding for Image-Text Matching	['visual semantic embedding', 'image-text matching', 'uncertainty learning', 'multi-modal learning']		Deep Learning and representational learning	anonymous|trustconsistent_visual_semantic_embedding_for_imagetext_matching	/pdf/572b3b46fc8ebbc56956d0d5644106dd3260a951.pdf
6kxApT2r2i	54	The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from a Single Image	['Augmentations', 'Single Image Learning', 'Distillation']	We show that it is possible to extrapolate to semantic classes such as those of ImageNet or Kinetics using just a single datum plus heavy augmentations as visual inputs.	Deep Learning and representational learning	anonymous|the_augmented_image_prior_distilling_1000_classes_by_extrapolating_from_a_single_image	/pdf/b09857a3860a80e93d14b5664ed75d6b3d5371d5.pdf
BqrPeZ_e5P	55	SIMPLE: Specialized Model-Sample Matching for Domain Generalization	['domain generalization', 'ensemble learning', 'pretrained model']		Deep Learning and representational learning	anonymous|simple_specialized_modelsample_matching_for_domain_generalization	/pdf/f6ccb2652b7c7bf986b75fe102e6fc5d5c451f3d.pdf
3GDft6lexE	58	Cooperate or Compete: A New Perspective on Training of Generative Networks	['Generative Adversarial Networks', 'Nash Equilibrium', 'Correlated Equilibrium', 'Repeated Games']	Generative networks can perform better and learn faster if training is modeled as an infinitely repeated simultaneous game	Generative models	anonymous|cooperate_or_compete_a_new_perspective_on_training_of_generative_networks	/pdf/7ddb010bd4f0f921d42e445022fff67e455c7b97.pdf
CjTHVo1dvR	61	Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance Matching	['molecule', 'pretraining', 'representation', 'geometry', 'denoising score matching']	We propose GeoSSL, a self-supervised learning method using the denoising distance matching for molecular goemetry pretraining.	Unsupervised and Self-supervised learning	anonymous|molecular_geometry_pretraining_with_se3invariant_denoising_distance_matching	/pdf/42f0bd293c4286146144f8c135453ccf0fa9dae1.pdf
wUcNUTnOvq	62	GraphCG: Unsupervised Discovery of Steerable Factors in Graphs	['graph', 'controllable generation', 'molecular graph', 'point clouds']	We develop an unsupervised graph controllable generation method to steer factors on the molecular graphs and point clouds.	Generative models	anonymous|graphcg_unsupervised_discovery_of_steerable_factors_in_graphs	/pdf/4cb3d06f2df045543e7894fc048f1f3d65300d38.pdf
I_YZANaz5X	70	DualAfford: Learning Collaborative Visual Affordance for Dual-gripper Manipulation	['Visual Actionable Representation for Robotics', 'Visual Understanding of 3D Shapes']	We propose a novel learning framework to learn collaborative affordance for dual-gripper manipulation tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dualafford_learning_collaborative_visual_affordance_for_dualgripper_manipulation	/pdf/dbcfc294bbb0c584f9ba523fceefb4190f98202c.pdf
nVYND1kLOug	77	Example-based Planning via Dual Gradient Fields	['Example-based Planning', 'Score-Matching', 'Path Planning', 'Reinforcement Learning']	We introduce an example-based planning framework via score-matching.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|examplebased_planning_via_dual_gradient_fields	/pdf/c9d483476e5701cad12f7753626bc33f3e54099a.pdf
7uTvSvC7hGO	78	Exploring Visual Interpretability for Contrastive Language-Image Pretraining	['Visual Interpretability', 'Explainability', 'Contrastive Language-Image Pretraining', 'Multimodality']	A visual interpretability work for CLIP. We observe CLIP shows opposite visualization results, and find the reason is semantic shift at pooling layer. Then, we solve this problem with nontrivial improvements.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|exploring_visual_interpretability_for_contrastive_languageimage_pretraining	/pdf/3b0d229053659bcf0009845cadd59385d63c3a16.pdf
TQ5WUwS_4ai	79	On amortizing convex conjugates for optimal transport	['optimal transport', 'wasserstein-2', 'convex conjugate', 'c-transform', 'amortized optimization']	State-of-the art continuous Wasserstein-2 potential learning, and along the way I improved Jax's L-BFGS implementation to run in 3% of the time for solving batches of optimization problems	Optimization (eg, convex and non-convex optimization)	anonymous|on_amortizing_convex_conjugates_for_optimal_transport	/pdf/95eb12fba632158de1b02f413a5a164311d6972d.pdf
qhu9uX4QlP8	80	Meta Optimal Transport	['optimal transport', 'meta learning', 'amortized optimization']	We learn to predict the solution to optimal transport problems	Optimization (eg, convex and non-convex optimization)	anonymous|meta_optimal_transport	/pdf/a12e0242f81d44ddaffa46f8bae46c7982521673.pdf
S1Jgnb7mLfI	82	Neural Attention Memory	['Neuro-symbolic AI', 'Transformer', 'Memory-augmented neural network', 'compositional generalization']	Neural attention memory is a differentiable NN memory architecture based on attention which is efficient and powerful.	Deep Learning and representational learning	anonymous|neural_attention_memory	/pdf/f5b1fc12d0a0009eb37836a1844a2fc9dc654ad8.pdf
UoBJm4V21md	83	Mimic before Reconstruct: Enhance Masked Autoencoders with Feature Mimicking	['Masked Autoencoders', 'Masked Convolution', 'Off-the-shelf pertained model DINO and CLIP']		Unsupervised and Self-supervised learning	anonymous|mimic_before_reconstruct_enhance_masked_autoencoders_with_feature_mimicking	/pdf/a337190a35541f5cde3ab2f210fe9dce5c6ecac1.pdf
a3OY2j9kJc-	84	MaSS: Multi-attribute Selective Suppression	['Multi-attribute', 'GAN', 'Attribute Suppression']	Selectively suppress the attributes while preserving the rest of attributes	Deep Learning and representational learning	anonymous|mass_multiattribute_selective_suppression	/pdf/bf93a3a4c59bfa9d6ee1734d8bf8c139c0cd5a19.pdf
RVTOp3MwT3n	86	Diversify and Disambiguate: Out-of-Distribution Robustness via Disagreement	['Out-of-distribution robustness', 'spurious correlations', 'underspecification', 'ambiguity', 'ensembles']	Given underspecified data, (1) find a diverse set of solutions and (2) choose the best one.	Deep Learning and representational learning	anonymous|diversify_and_disambiguate_outofdistribution_robustness_via_disagreement	/pdf/235b7de34be0df2ffe9c9a19fb7ca35304c11605.pdf
APuPRxjHvZ	88	Surgical Fine-Tuning Improves Adaptation to Distribution Shifts	['Transfer learning', 'fine-tuning', 'parameter freezing', 'distortion of pre-trained models']	Selectively fine-tuning a subset of layers outperforms full fine-tuning when transferring to tasks with various distribution shifts.	Deep Learning and representational learning	anonymous|surgical_finetuning_improves_adaptation_to_distribution_shifts	/pdf/0b8415a0f806e4995989d897775ee21832f72efd.pdf
v6dqNREneyw	89	Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations	['multi-domain long-tailed learning', 'balanced representation augmentation', 'out-of-distribution robustness']	Balanced augmenting disentangled representations benefit the robustness of multi-domain long-tailed learning	Deep Learning and representational learning	anonymous|multidomain_longtailed_learning_by_augmenting_disentangled_representations	/pdf/1cfda5fc4fd80f7c160e9e6d77415aaf4ca0e6ca.pdf
8FroynZv4C	90	Representation Learning for Low-rank General-sum Markov Games	['Reinforcement Learning', 'Multi Agent', 'Representation Learning']	We provide a general representation learning framework for multi-player general-sum Markov games.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|representation_learning_for_lowrank_generalsum_markov_games	/pdf/29a539606f053c7ef053d297c8ce88c7e4738ee6.pdf
WLMaYqspJl	91	Multi-Modal Few-Shot Temporal Action Detection	['action detection', 'video understanding', 'vision language', 'few-shot learning']	Detecting action temporally from very few annotated samples using vision-language	Applications (eg, speech processing, computer vision, NLP)	anonymous|multimodal_fewshot_temporal_action_detection	/pdf/40fc7ed3a0ebbf9f53ec63b772bb087c6457e13f.pdf
ALuRpkAeQP	92	Quasi-Conservative Score-based Generative Models	['Score-based Generative Models', 'Conservativeness']	In this paper, we propose Quasi-Conservative Score-based Generative Models (QCSGMs), which are designed to maintain both the architectural flexibility and the property of conservativeness of score-based generative models.	Generative models	anonymous|quasiconservative_scorebased_generative_models	/pdf/b10a83e71638c0169cd5a3d0416bec4c8e825a01.pdf
AbRe0e_R07	93	TEAS: Exploiting Spiking Activity for Temporal-wise Adaptive Spiking Neural Networks	['Spiking Neural Network']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|teas_exploiting_spiking_activity_for_temporalwise_adaptive_spiking_neural_networks	/pdf/6baf909d21cc41e4eaebe9d1e068b2bcd1781efd.pdf
CqoBqextqY	94	HyperFeel: An Efficient Federated Learning Framework Using Hyperdimensional Computing	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|hyperfeel_an_efficient_federated_learning_framework_using_hyperdimensional_computing	/pdf/f6e0ee9bc0143de2ad02f01acd45e973d4ca1f01.pdf
X55dLasnEcC	96	Evaluating Weakly Supervised Object Localization Methods Right? A Study on Heatmap-based XAI and Neural Backed Decision Tree	['object localization', 'computer vision', 'deep learning', 'deep neural network']	Evaluating object localization using XAI methods on MaxBoxAcc metrics. NBDT is tested too as an extension.	Applications (eg, speech processing, computer vision, NLP)	anonymous|evaluating_weakly_supervised_object_localization_methods_right_a_study_on_heatmapbased_xai_and_neural_backed_decision_tree	/pdf/4de343c88eea70cd9f54cc5b58ac1cbb185e38f7.pdf
xzmqxHdZAwO	97	Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|pushing_the_limits_of_fewshot_anomaly_detection_in_industry_vision_graphcore	/pdf/6bc8f8fe99e536ee637b86d3c2e3ce8fa1f2d977.pdf
E08kaoSiQl0	104	Transcendental Idealism of Planner: Evaluating Perception from Planning Perspective for Autonomous Driving	['Autonomous Driving', 'Utility Maximisation', 'Hilbert Space', 'Planning', 'Perception']	The paper proposes a systematic and principled framework to evaluate the consequence of perception module error from the perspective of autonomous vehicle planning. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|transcendental_idealism_of_planner_evaluating_perception_from_planning_perspective_for_autonomous_driving	/pdf/f39eaf7f87a63588791c1c65c0453be4eddddcd0.pdf
ptbePrczhRt	105	Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|group_detr_fast_detr_training_with_groupwise_onetomany_assignment	/pdf/c979ca4cdb5bfdc4fc339aff176f6349859b9d86.pdf
K5qR1F14qPE	107	Motion-inductive Self-supervised Object Discovery in Videos	['Video Object Segmentation', 'Motion Segmentation', 'Object Discovery']	We propose a motion-inductive model through directly processing consecutive RGB frames to segment the foreground objects and train it by flow reconstruction between pairwise frames, i.e. without any mask annotations.	Unsupervised and Self-supervised learning	anonymous|motioninductive_selfsupervised_object_discovery_in_videos	/pdf/c6741d9bfe8863ad84c8a150ea3c51c9398f0c93.pdf
BM10-kHq8uX	108	Functional Relation Field: A Model-Agnostic Framework for Multivariate Time Series Forecasting	['Functional Relation Field', 'Spatio-Temporal Forecasting', 'Constraint Optimization', 'Multivariate Time Series']	Functional Relation Field: A Model-Agnostic Framework for Multivariate Time Series Forecasting	Deep Learning and representational learning	anonymous|functional_relation_field_a_modelagnostic_framework_for_multivariate_time_series_forecasting	/pdf/a2035e20e410c92bb1d0701909a5eb99601de685.pdf
NRxydtWup1S	113	Sparse and Hierarchical Masked Modeling for Convolutional Representation Learning	['Self-Supervised Learning', 'Masked Autoencoding', 'Masked Pre-training', 'Masked Modeling', 'Convolutional Neural Networks']	This paper presents a simple yet powerful framework to pre-train convolutional network (convnet) with Sparse masKed modeling.	Unsupervised and Self-supervised learning	anonymous|sparse_and_hierarchical_masked_modeling_for_convolutional_representation_learning	/pdf/02d6c6ecc1555267400ff77d7092dc6e02d847f4.pdf
NPfDKT9OUJ3	116	H2RBox: Horizonal Box Annotation is All You Need for Oriented Object Detection	['Oriented Object Detection', 'Rotated Object Detection']		Applications (eg, speech processing, computer vision, NLP)	anonymous|h2rbox_horizonal_box_annotation_is_all_you_need_for_oriented_object_detection	/pdf/a9d055832671360d577095dcd401a964cf3567e2.pdf
hfUJ4ShyDEU	117	Achieve the Minimum Width of Neural Networks for Universal Approximation	['Universal Approximation', 'Feedforward Neural Network', 'Leaky-ReLU']	We prove that the minimum width of FNN for UAP is $w^*_{\min} = \max(d_x,d_y)$ which is achievable.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|achieve_the_minimum_width_of_neural_networks_for_universal_approximation	/pdf/0fcaf33fe94d50d6276e7557211c1027c73586e6.pdf
xl2-MIX2DCD	118	Reward Learning with Trees: Methods and Evaluation	['reinforcement learning', 'reward learning', 'alignment', 'human-agent interaction', 'explainable AI', 'XAI', 'interpretability', 'decision trees']	We show that reward learning with tree models can be competitive with neural networks, and demonstrate some of its interpretability benefits.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|reward_learning_with_trees_methods_and_evaluation	/pdf/eb54e1e65252095906b3062b8ea6461f494d2e45.pdf
r63dkNZj7I5	119	Refining Visual Representation for Generalized Zero-Shot Recognition through Implicit-Semantics-Guided Metric Learning	['generalized zero-shot learning', 'metric learning', 'multi-class classification']		Deep Learning and representational learning	anonymous|refining_visual_representation_for_generalized_zeroshot_recognition_through_implicitsemanticsguided_metric_learning	/pdf/22560ec4d3831a87e5765bb3ed9e68dbd06b6181.pdf
GmjwnzduXzf	120	Grassmannian Class Representation in Deep Learning	['Grassmannian', 'geometric optimization', 'classification', 'feature transfer', 'long-tail']		Deep Learning and representational learning	anonymous|grassmannian_class_representation_in_deep_learning	/pdf/bb0cce87621786b2470b580127ddc93c235d5cb1.pdf
ZLv-8v0Sp_H	122	Communication Efficient Fair Federated Recommender System	['Federated Learning', 'Recommender Systems', 'Bias and Fairness']	A random sampling based Fair Federated Recommender System.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|communication_efficient_fair_federated_recommender_system	/pdf/9a84eb733392c5f448a817df06a1a33e6b1ca2df.pdf
8mWlBArp1qx	125	MaPLe: Multi-modal Prompt Learning	['Vision-language models', 'Prompt learning', 'Generalization', 'Fine-tuning', 'Transfer learning']	Multi-modal prompt learning for improving synergy between learned language and vision representations for fine-tuning CLIP on downstream image recognition tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|maple_multimodal_prompt_learning	/pdf/2fd107cca2f99ace613cbd88626f1d4dba197ce8.pdf
m0R-SYjUpTL	127	Defactorization Transformer: Modeling Long Range Dependency with Local Window Cost	[]		Deep Learning and representational learning	anonymous|defactorization_transformer_modeling_long_range_dependency_with_local_window_cost	/pdf/193e7dd1cae6f3476b753376a3f3f1d2eecee0f5.pdf
CGuvK3U09LH	128	Suppressing the Heterogeneity: A Strong Feature Extractor for Few-shot Segmentation	['deep learning', 'computer vision', 'few-shot learning', 'few-shot semantic segmentation']		Deep Learning and representational learning	anonymous|suppressing_the_heterogeneity_a_strong_feature_extractor_for_fewshot_segmentation	/pdf/afeaa6f2868ae58b12cc51f2ecef2ef8a3e18702.pdf
MLJ5TF5FtXH	129	Interpretable Single/Multi-label Text Classification with Unsupervised Constituent-label alignments	['Interpretability', 'natural language processing', 'text classification', 'unsupervised learning', 'structured language model', 'multiple instance learning', 'recursive neural network']	An inherently interpretable model architecture with explicit unsupervised label to constituent alignments.	Unsupervised and Self-supervised learning	anonymous|interpretable_singlemultilabel_text_classification_with_unsupervised_constituentlabel_alignments	/pdf/8eed576dabf894f3ea7903b2e374068345286ef1.pdf
7PURWDjJCf3	130	Slimmable Networks for Contrastive Self-supervised Learning	['self-supervised learning', 'contrastive learning', 'slimmable networks']		Unsupervised and Self-supervised learning	anonymous|slimmable_networks_for_contrastive_selfsupervised_learning	/pdf/7c338fa23952ab744b6ea20a89c7e47a80880ac9.pdf
UyC1dXUA-n	131	Design of the topology for contrastive visual-textual alignment	[]	We change the topology of embedding space to oblique manifold for better alignment performance.	Deep Learning and representational learning	anonymous|design_of_the_topology_for_contrastive_visualtextual_alignment	/pdf/2e7c0548a2f37a4cbb35298f72e048fa07da6b17.pdf
E2Y_xv8ybf	132	On the Calibration Set Difficulty and Out-of-distribution Calibration	['nerual network calibration', 'out-of-distribution calibration']	Calibration set difficulity impacts out-of-distribution calibration performance	General Machine Learning (ie none of the above)	anonymous|on_the_calibration_set_difficulty_and_outofdistribution_calibration	/pdf/2c8e770f4fa75b695e02c27777c5deaf84773625.pdf
O7gAffL9a0	133	Confidence and Dispersity Speak: Characterising Prediction Matrix for Unsupervised Accuracy Estimation	['Out-of-distribution generalization', 'Unsupervised Accuracy Estimation', 'Prediction DIversity', 'Distribution Shift']	This work proposes a simple but effective method (prediction diversity) to predict how well a model generalize to out-of-distribution datasets	Deep Learning and representational learning	anonymous|confidence_and_dispersity_speak_characterising_prediction_matrix_for_unsupervised_accuracy_estimation	/pdf/d00ed3e79fa0ef2782cc1fba7f16e06752ac47f5.pdf
pHO19kq_yT	135	Universal Unlearnable Examples: Cluster-wise Perturbations without Label-consistency	['pravicy-preserving', 'unlearnable example', 'adversarial attack', 'poisoning attack']	We proposed a novel method called UniversalCP, which is effective in a more practical scenario.	Deep Learning and representational learning	anonymous|universal_unlearnable_examples_clusterwise_perturbations_without_labelconsistency	/pdf/b6bc02ad73fa6decf80ff0424ea6b9db280f17c7.pdf
HdYxZ_OVZG	139	ThinkSum: Probabilistic reasoning over sets using large language models	['NLP', 'language models', 'prompting', 'zero-shot learning']	A wise System 2 for large language models: Think (parallel model call) + Sum (aggregate results to make a prediction).	Applications (eg, speech processing, computer vision, NLP)	anonymous|thinksum_probabilistic_reasoning_over_sets_using_large_language_models	/pdf/95c8d2713aff131ba9374ef9b67ce44e958fc3b1.pdf
gbC0cLDB6X	141	Expanding Datasets With Guided Imagination	['Dataset Expansion', 'Guided Imagination']		Deep Learning and representational learning	anonymous|expanding_datasets_with_guided_imagination	/pdf/93631fecf93ab47af910532be07e0e41b0687294.pdf
-2zfgNS917	143	BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection	['object detection', '3d detection', 'BEV perception']	We leverage LiDAR-based knowledge into multi-view 3d detectors with cross-modal BEV distillation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|bevdistill_crossmodal_bev_distillation_for_multiview_3d_object_detection	/pdf/77c0c60a52de2fecf276ceebac1f3341c272778a.pdf
Fl6bxyqN4W	144	Multiscale Pyramid Representation on Graphs: a Graph Sampling and Filtering Approach	['graph neural networks']	We propose pyramid representation on graphs by a framework that exploits multi-scale on the spatial domain and multi-resolution on the spectral domain simultaneously.	Deep Learning and representational learning	anonymous|multiscale_pyramid_representation_on_graphs_a_graph_sampling_and_filtering_approach	/pdf/86c6733889fa749342a57c5f22087d8aa22162cd.pdf
VNzq9PBFta	145	Succinct Compression: Lossless Compression for Fast and Memory-Efficient Deep Neural Network Inference	['Succinct Data Structures', 'Deep Neural Networks', 'Efficient Inference']	First work to introduce Succinct Data Structures for Fast and Memory-Efficient Computations of Deep Neural Networks	Deep Learning and representational learning	anonymous|succinct_compression_lossless_compression_for_fast_and_memoryefficient_deep_neural_network_inference	/pdf/2b3c362b3db84f2d6f26f758f632afc2930230ca.pdf
WbyWDWoXD3	146	Feint in Multi-Player Games	['Feint', 'Multi-Player Games']	First work to formalize, implement and examine Feint in Multi-Player Games	General Machine Learning (ie none of the above)	anonymous|feint_in_multiplayer_games	/pdf/c59930b341b33a076d05fdca46dfbf9eb23fdaf2.pdf
4JVdg72e7f	148	CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-training	[]		Unsupervised and Self-supervised learning	anonymous|clip2point_transfer_clip_to_point_cloud_classification_with_imagedepth_pretraining	/pdf/0e29e5c95deadc24fae8ae7f4de67fa2bbdf35a3.pdf
mVn2JGzlET	149	Partial transportability for domain generalization	['Causality', 'domain generalization']	"This paper investigates the problem of domain generalization from the perspective of transportability theory. We propose the task of partial transportability and provide solutions that highlight new contrasts with ""invariance learning"" methods."	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|partial_transportability_for_domain_generalization	/pdf/6ef7722129d5825604beb43723278e414d8d3925.pdf
e1e9CGUj-3	150	TT-NF: Tensor Train Neural Fields	['neural fields', 'deep learning', 'tensor train', 'tensor decompositions', 'sampling', 'radiance fields', 'voxels']	We repurpose the tensor train decomposition to learning compressed neural fields via backpropagation through samples.	General Machine Learning (ie none of the above)	anonymous|ttnf_tensor_train_neural_fields	/pdf/632c005709121d36922283a8dc4e37a84c367e76.pdf
f23tQmoxWz-	151	S-SOLVER: Numerically Stable Adaptive Step Size Solver for Neural ODEs	['neural ODEs', 'ODE solvers', 'numerical integration', 'numerical stability']	We propose a neural ODE adaptive step size solver that is more numerically stable thanks to novel, more reliable local truncation error estimation.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|ssolver_numerically_stable_adaptive_step_size_solver_for_neural_odes	/pdf/33e6eff2872a6e3d9071c2ec3fb7b91fed43e9cc.pdf
JdgO-ht1uTN	152	Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning	['Probabilistic Logical Rule Learning', 'Knowledge Graph Completion', 'Logical Representation Learning']	We propose logical entity representation (LERP) to incorporate contextual information of entities into logical rule learning.	Deep Learning and representational learning	anonymous|logical_entity_representation_in_knowledgegraphs_for_differentiable_rule_learning	/pdf/766213f33b3165156c19b594cf40d218cb1d7cc6.pdf
EGx_FtsO1eu	153	MixQuant: A Quantization Bit-width Search that Can Optimize the Performance of your Quantization Method	['neural network quantization', 'rounding error', 'bit-width search']	We propose MixQuant, a search algorithm that finds the optimal custom quantization bit-width for each layer weight based on roundoff error minimization and can be combined with any quantization method as a form of pre-processing optimization.	Deep Learning and representational learning	anonymous|mixquant_a_quantization_bitwidth_search_that_can_optimize_the_performance_of_your_quantization_method	/pdf/fdadfb36943b783eb48185ab3d3a02ff281de702.pdf
W4ub8fyCpED	154	Learning a 3D-Aware Encoder for Style-based Generative Radiance Field	[]		Deep Learning and representational learning	anonymous|learning_a_3daware_encoder_for_stylebased_generative_radiance_field	/pdf/8b733e56ae236fee96cc72d3c0ed12cf9f617f68.pdf
KdAxKVwAmP	155	STViT: Semantic Tokens for Efficient Global and Local Vision Transformers	['token reduction algorithm', 'efficient vision transformer', 'global and local vision transformer', 'downstream tasks']		Deep Learning and representational learning	anonymous|stvit_semantic_tokens_for_efficient_global_and_local_vision_transformers	/pdf/353ebef0baf9b096d578de68801b152a512f9d4a.pdf
zEn1BhaNYsC	156	Minimax Optimal Kernel Operator Learning via Multilevel Training	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|minimax_optimal_kernel_operator_learning_via_multilevel_training	/pdf/f528ce7cc39e75476015c9695133f9275c70ff85.pdf
QHWXmoYNw-Z	158	Boosting Out-of-Distribution Detection with Multiple Pre-trained Models 	['Out-of-Distribution Detection', 'Model Zoo', 'Ensemble']		Deep Learning and representational learning	anonymous|boosting_outofdistribution_detection_with_multiple_pretrained_models	/pdf/aac90deaf78cc76e4a266fee30979b11e91acf65.pdf
kkLRWnh9ST1	159	DOTIN: Dropping Out Task-Irrelevant Nodes for GNNs	['Graph Networks', 'Graph pooling']	We propose a new method to drop task-irrelevant nodes to increase the scalability and efficiency.	General Machine Learning (ie none of the above)	anonymous|dotin_dropping_out_taskirrelevant_nodes_for_gnns	/pdf/8d354ba4e769bfea81b2a5753cf0feab87d0ba8c.pdf
-HHJZlRpGb	160	Learning Domain-Agnostic Representation for Disease Diagnosis	['multi centers disease diagnosis', 'mammogram classification']	We propose a disentanglement model in medical imaging diagnosis, in order to achieve robustness to multi centers.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_domainagnostic_representation_for_disease_diagnosis	/pdf/be54fb46fb4d15c69056a6886f5f8965aebdfb6a.pdf
SUcUqu_X30	161	Attention De-sparsification Matters: Inducing Diversity in Digital Pathology Representation Learning	['Computational pathology', 'Cell segmentation', 'Self supervised learning', 'Vision Transformer', 'Sparse attention']	We introduce Di-SSL, a diversity-inducing self-supervised learning method to enhance the representation learning in Digital Pathology.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|attention_desparsification_matters_inducing_diversity_in_digital_pathology_representation_learning	/pdf/e7f6ec8b8e2f8c106bd9d082fb59ea61394a4245.pdf
jdEXFqGjdh	163	CI-VAE: a Class-Informed Deep Variational Autoencoder for Enhanced Class-Specific Data Interpolation	['Variational Auto Encoder', 'Supervised', 'Latent Space Traversal', 'Data Interpolation', 'Discriminator']	A deep learning framework for interpolations in high-dimensional data	Generative models	anonymous|civae_a_classinformed_deep_variational_autoencoder_for_enhanced_classspecific_data_interpolation	/pdf/624f471b9f14ecb2d4fa00ab4342ef9a3d520854.pdf
D4JQEKlTyG	164	Individual Privacy Accounting for Differentially Private Stochastic Gradient Descent	['individual privacy for DP-SGD', 'fairness in privacy']	We compute individual privacy parameters for DP-SGD and show the privacy guarantee varies across different groups.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|individual_privacy_accounting_for_differentially_private_stochastic_gradient_descent	/pdf/ba8959dfcdfcd869185a7efc0c501f2a1828654a.pdf
aNWiwR2HiOs	166	Measuring Asymmetric Gradient Discrepancy in Parallel Continual Learning	['Multi-Task Learning', 'Continual Learning', 'Gradient Discrepancy']	We propose a Maximum Discrepancy Optimization (MaxDO) strategy to minimize the maximum asymmetric discrepancy among multiple gradients in parallel continual learning.	Deep Learning and representational learning	anonymous|measuring_asymmetric_gradient_discrepancy_in_parallel_continual_learning	/pdf/5aae82b0570acc9ecd418b6aa2d247d5c5050128.pdf
yUcvOAre_7	167	Optimizing Server-side Aggregation For Robust Federated Learning via Subspace Training	['federated learning', 'server-side aggregation', 'subspace training']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|optimizing_serverside_aggregation_for_robust_federated_learning_via_subspace_training	/pdf/0ac841626de6a3721d8069c9e116104245402cdf.pdf
-CwPopPJda	168	TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding	['Multi-task Learning', 'Scene Understanding', 'Computer Vision']	We propose a novel multi-task prompting framework to concurrently learn task-specific and task-generic representations as well as cross-task interaction along spatial and channel dimensions based on transformer for multiple dense predictions tasks.	Deep Learning and representational learning	anonymous|taskprompter_spatialchannel_multitask_prompting_for_dense_scene_understanding	/pdf/a12230dbb06b9bf7fc64d0efdd0942ecd67010ee.pdf
KVljrqehulG	169	Efficient Automatic Machine Learning via Design Graphs	['Automated Machine Learning', 'Sample efficiency', 'Design graph', 'Graph Neural Networks']	We propose FALCON, an efficient AutoML method that searches for the optimal model design on design graphs.	Deep Learning and representational learning	anonymous|efficient_automatic_machine_learning_via_design_graphs	/pdf/c35546dc6cd5cc73e1454f6b67066b5f45217731.pdf
cCFqcrq0d8	174	A Unified Framework of Soft Threshold Pruning	['Network Pruning', 'Network Compression', 'Spiking Neural Networks']		Deep Learning and representational learning	anonymous|a_unified_framework_of_soft_threshold_pruning	/pdf/cadb92fd04813797759981096b411b12914a15c4.pdf
CdU7ApBxICO	175	Self-attentive Rationalization for Graph Contrastive Learning	['Graph Contrastive Learning', 'Self-supervised Learning', 'Transformer', 'Rationalization', 'self-attention']	Graph contrastive learning framework with self-attentive rationalization	Unsupervised and Self-supervised learning	anonymous|selfattentive_rationalization_for_graph_contrastive_learning	/pdf/8ede7cabe33e4bfdf6cc75b8b033c1ab283692ae.pdf
Kn6i2BZW69w	177	DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training	['dropping intermediate tensors', 'dropping activations', 'activation compressed training', 'top-k', 'vision transformer', 'cnn']	DropIT can save memory & improve accuracy, providing a new perspective of dropping in activation compressed training than quantization.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dropit_dropping_intermediate_tensors_for_memoryefficient_dnn_training	/pdf/1ffacdbd0d34fea965a47bfd70413dc33730753b.pdf
UYS38ssi1M	178	Learning GFlowNets from partial episodes for improved convergence and stability	['GFlowNets', 'probabilistic modeling', 'reinforcement learning']	GFlowNet training is made faster and more stable by learning from subtrajectories.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|learning_gflownets_from_partial_episodes_for_improved_convergence_and_stability	/pdf/3ee45e48480f450c9972ddc424ea8898294918ec.pdf
LPwlqyrnwg	179	On Stability and Generalization of Bilevel Optimization Problems	['bilevel optimization', 'generalization', 'stability']	Generalization bounds in different settings for single-timescale gradient-based method 	Optimization (eg, convex and non-convex optimization)	anonymous|on_stability_and_generalization_of_bilevel_optimization_problems	/pdf/7606a71868e054d40995b37d9aa8ae50e87ed04d.pdf
boNyg20-JDm	181	Harnessing Out-Of-Distribution Examples via Augmenting Content and Style	['out-of-distribution', 'open-set learning']	Harnessing OOD examples through data augmentation that changes the content and style. 	Deep Learning and representational learning	anonymous|harnessing_outofdistribution_examples_via_augmenting_content_and_style	/pdf/84fdc95a9663320bc27d2d3853243a1ae87fcdb8.pdf
vPvy4x-0H52	182	Robust Generalization against Corruptions via Worst-Case Sharpness Minimization	['distributionally robust optimization', 'out-of-distribution generalization']	Mitigating sharpness of the worst-case distributions for robust generalization against corruptions.	General Machine Learning (ie none of the above)	anonymous|robust_generalization_against_corruptions_via_worstcase_sharpness_minimization	/pdf/21fec0278a4f4cdc9b7121e1848b16a686d5883a.pdf
IAy-lKeb3z	183	Sharpness-aware Quantization for Deep Neural Networks	['Sharpness-aware Minimization', 'Quantization', 'CNNs', 'Transformers']	We propose a novel method, dubbed Sharpness-Aware Quantization (SAQ), to smooth the loss landscape and improve the generalization performance of the quantized models.	Deep Learning and representational learning	anonymous|sharpnessaware_quantization_for_deep_neural_networks	/pdf/86f993ded5667f9137285bf0191838e74dd814f2.pdf
YWZ90TiPBM	187	Improving Corruption Robustness with Adversarial Feature Alignment Transformers	['Corruption Robustness', 'Attention Stability', 'Feature Alignment']	We improve the robustness of transformers by enhancing the stability of the self-attention mechanism.	Deep Learning and representational learning	anonymous|improving_corruption_robustness_with_adversarial_feature_alignment_transformers	/pdf/933599ec288c5b2d88ed932140e8e97217b7f0fa.pdf
anFy7Tb1zW	189	Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program	['Multimodal Learning', 'Generative Models', 'Representation Learning']	We proposed Neural Shape Compiler to translate between three hierarchical shape abstractions: Point Cloud, Shape Program, and Text.	Generative models	anonymous|neural_shape_compiler_a_unified_framework_for_transforming_between_text_point_cloud_and_program	/pdf/5f032a0fb0e4bf8f2bc644ef4d775582aff41e22.pdf
k8nG8lWMMjn	192	Semantic Grouping Network for Audio Source Separation	['audio souce separation', 'audio-visual separation']	We propose a novel Semantic Grouping Network, termed as SGN, that can disentangle sound representations and extract high-level semantic info for each source to guide separation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|semantic_grouping_network_for_audio_source_separation	/pdf/db902417b1d784a01c3921c0c0b6f392dec3da4a.pdf
D-zfUK7BR6c	193	DrML: Diagnosing and Rectifying Vision Models using Language	['model diagnosis', 'multi-modal contrastive learning', 'vision and language']	Our work highlights a distinct advantage of multi-modal embedding space: the ability to diagnose vision classifiers through natural language.	Applications (eg, speech processing, computer vision, NLP)	anonymous|drml_diagnosing_and_rectifying_vision_models_using_language	/pdf/a362786b7a4ab318d24788aefcde5c21d7719e56.pdf
CvfiXFOW2n	195	ClusTR: Exploring Efficient Self-attention via Clustering for Vision Transformers	['Vision Transformer', 'Clustering', 'Multi-scale', 'Efficient']		Applications (eg, speech processing, computer vision, NLP)	anonymous|clustr_exploring_efficient_selfattention_via_clustering_for_vision_transformers	/pdf/7f75885a11912bc53eeb5e8180a0abc5cf865840.pdf
P_O91UpSX0M	197	On the Dynamics under the Averaged Sample Margin Loss and Beyond	['Implicit bias', 'neural collapse', 'gradient descent']	We investigate the dynamics of the averaged sample margin loss and provide some insights for improvements.	Deep Learning and representational learning	anonymous|on_the_dynamics_under_the_averaged_sample_margin_loss_and_beyond	/pdf/e7a909efd0659408d1ce989cf45bd06d639dbd6b.pdf
OUMNXSAek8	198	Learning Implicit Scale Conditioned Memory Compensation for Talking Head Generation	['Talking Head Generation']	We propose a novel implicit scale conditioned memory compensation network (MCNet) for high-fidelity talking head generation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_implicit_scale_conditioned_memory_compensation_for_talking_head_generation	/pdf/5c52e89c86f95bcc941b920be0c7cee8fe90dbec.pdf
SWUGykek_T	200	Robustness Exploration of Semantic Information in Adversarial Training	['Adversarial training', 'Semantic information', 'Adversarial robustness']		Deep Learning and representational learning	anonymous|robustness_exploration_of_semantic_information_in_adversarial_training	/pdf/c403f653ccb06fe17dfea1198b696308e39e2ec7.pdf
gurtzTlw6Q	203	Rotation Invariant Quantization for Model Compression	['Neural Network', 'Model compression', 'Rate-distortion', 'Quantization']	In this study, we investigate the theoretical limits of post-training NN model compression rates using the rate-distortion theory, proving that the highest compression rate is attained by a simple single-letter (scalar) rotation-invariant solution.	Optimization (eg, convex and non-convex optimization)	anonymous|rotation_invariant_quantization_for_model_compression	/pdf/8e61f689c755c0408d49650d093458ddc7ed20b5.pdf
AZFvpnnewr	204	Trainability Preserving Neural Pruning	['neural network structured pruning', 'trainability', 'kernel orthogonalization']	We present a new filter pruning approach that effectively preserves trainability during pruning with encouraging performance. 	Deep Learning and representational learning	anonymous|trainability_preserving_neural_pruning	/pdf/97269ae80bf3c9716f2ce4517921a8f49dda2f68.pdf
VsqE7E-lWB	206	Distilling Text-Image Foundation Models	['foundation models', 'CLIP', 'knowledge distillation', 'capacity gap']	We focus on image classification task, and investigate the capasity gap resistance of CLIP in knowledge distillation. 	Deep Learning and representational learning	anonymous|distilling_textimage_foundation_models	/pdf/a8f9b8a534fa8b127d5f6ab15346b5ba982885c3.pdf
SFyOjfEOJO	207	Hybrid Neuro-Symbolic Reasoning based on Multimodal Fusion	['Neural Networks', 'Deep Learning', 'Symbolic Reasoning', 'Multimodal Fusion', 'Word Embedding', 'Rule-based Reasoning']	A hybrid neural/symbolic modeling to enhance complex image classifications using commonsense knowledge.	General Machine Learning (ie none of the above)	anonymous|hybrid_neurosymbolic_reasoning_based_on_multimodal_fusion	/pdf/9374f8281e7fdf83eea919810912cdffa49f48a2.pdf
4Udi4sd8qz9	208	Sparse Misinformation Detector	['Misinformation detection', 'fake news detection', 'sparse training', 'network pruning']	We present an efficient sparse misinformation detector based on a special sparsity pattern (CircuSparsity), with very encouraging performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sparse_misinformation_detector	/pdf/fb827c89dfa90b3bd09fe6edf73d467605f6da2d.pdf
DFaFg1u7UT	209	Examining the Value of Neural Filter Pruning -- Retrospect and Prospect	['Neural network filter pruning', 'value of pruning', 'trainability', 'dynamical isometry']	"We study the ""value of filter pruning"" issue and show it might be inaccurate due to suboptimal LR setups, more insights provided to explain the reason behind."	Deep Learning and representational learning	anonymous|examining_the_value_of_neural_filter_pruning_retrospect_and_prospect	/pdf/86e47bbbe86b511116e7265fbdca85b08ada9b2d.pdf
awnvqZja69	210	Image as Set of Points	['Clustering', 'Image Processing', 'Context Cluster', 'Representation']	We introduce Context Cluster, a new paradigm that considers an image as a set of point and employs clustering method for feature extraction.	Deep Learning and representational learning	anonymous|image_as_set_of_points	/pdf/058f003a1fb2a8eec37f7a146a455b1f5cc042d9.pdf
-0tPmzgXS5	211	Probing into Overfitting for Video Recognition	['Action Recognition', 'Data Augmentation', 'Overfitting']	We propose a data augmentation tailored for action recognition which shows consistent improvement over various models and datasets.	Applications (eg, speech processing, computer vision, NLP)	anonymous|probing_into_overfitting_for_video_recognition	/pdf/9bb7a2e02bc8d83c82b2d9c227236d9216bc4219.pdf
b553eG8Wkb	212	(LA)YER-NEIGH(BOR) SAMPLING: DEFUSING NEIGHBORHOOD EXPLOSION	['Graph Neural Networks. Sampling']	Paper presents a new sampling algorithm combining layer and neighbor sampling methods	Deep Learning and representational learning	anonymous|layerneighbor_sampling_defusing_neighborhood_explosion	/pdf/845afbeda45c3272a6548c86bf000300487188be.pdf
k7p_YAO7yE	214	MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction	['Autonomous Driving', 'Online Vectorized HD Map Construction', 'End-to-End']	We present a structured end-to-end framework for efficient online vectorized HD map construction.	Applications (eg, speech processing, computer vision, NLP)	anonymous|maptr_structured_modeling_and_learning_for_online_vectorized_hd_map_construction	/pdf/561f8c1c09f08bdcba41718d0c6069331bc73cea.pdf
ConT6H7MWL	216	IDEAL: Query-Efficient Data-Free Learning from Black-Box Models	['black-box model', 'knowledge distillation']	query-efficiently learn from black-box model APIs to train a good student without any real data	Deep Learning and representational learning	anonymous|ideal_queryefficient_datafree_learning_from_blackbox_models	/pdf/3c4bf5b181abc0914ca6e5aedf93f531a216e49a.pdf
KWSPJ1tuYX	217	Correcting the Sub-optimal Bit Allocation	['neural video compression', 'semi-amortized variational auto-encoder']	Correcting the bit allocation in neural video compression by extending semi-amortized variational inference to non-factorized latent.	Generative models	anonymous|correcting_the_suboptimal_bit_allocation	/pdf/ada86f7a6f7b423039232c8427337e032f90a090.pdf
nQai_B1Zrt	218	 Decompose to Generalize: Species-Generalized Animal Pose Estimation	['Pose Estimation', 'Domain Generalization', 'Transfer Learning']		Deep Learning and representational learning	anonymous|decompose_to_generalize_speciesgeneralized_animal_pose_estimation	/pdf/cb144b9ac3a868cd3d6ee8a0c23efde37d52b33c.pdf
FeWvD0L_a4	219	Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection	['Deep Reinforcement Learning', 'The Arcade Learning Environment', 'Human World Records', 'Behavioral Control']	We have constructed a general framework to control the behaviors in RL  and achieved SOTA performance in Atari 1B benchmark.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learnable_behavior_control_breaking_atari_human_world_records_via_sampleefficient_behavior_selection	/pdf/e5fb66b69c1c19fb059a83726781267f051a3f9b.pdf
nUmCcZ5RKF	220	IS SYNTHETIC DATA FROM GENERATIVE MODELS READY FOR IMAGE RECOGNITION?	['data generation', 'image recognition', 'text-to-image synthesis']	We present the first study on the state-of-the-art text-to-image generation models for image recognition.	Applications (eg, speech processing, computer vision, NLP)	anonymous|is_synthetic_data_from_generative_models_ready_for_image_recognition	/pdf/01ecd42ebd8aaa5ccb5fe894cc13999ca94b992f.pdf
k1lWBmJuyf	221	Normalized Activation Function: Toward Better Convergence	['normalization', 'activation function', 'initialization']	Normalizing gradient variance by simply constructing an affine transformation after each activation function.	Deep Learning and representational learning	anonymous|normalized_activation_function_toward_better_convergence	/pdf/97496e29c792e4599ab83e78d0212a08b77fdcff.pdf
BSww-NrOzJ	222	Steering Prototypes with Prompt Tuning for Rehearsal-free Continual Learning	['Continual Learning', 'Prompt Tuning', 'Prototype', 'Contrastive Learning']		Deep Learning and representational learning	anonymous|steering_prototypes_with_prompt_tuning_for_rehearsalfree_continual_learning	/pdf/fca365a6e2dca7be32f704687455e97b46671adc.pdf
x5mtJD2ovc	224	KNN-Diffusion: Image Generation via Large-Scale Retrieval	[]		Generative models	anonymous|knndiffusion_image_generation_via_largescale_retrieval	/pdf/16cd71030ccef3d94c8059fc7ae2b7bd3a6f1731.pdf
QDE5hzxVpS	225	Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features	['positional information', 'position encoding', 'padding', 'CNN']	We demonstrate a more accurate paradigm in quantifying the strength of positional information in CNN models	Deep Learning and representational learning	anonymous|unveiling_the_mask_of_positioninformation_pattern_through_the_mist_of_image_features	/pdf/93e7fb3fcd2eacbf7048f0130743de4e08d023bd.pdf
S9GpoS2TmN	226	Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization	['Trajectory Translation', 'One-Shot Generalization', 'Long-Horizon Task', 'Reinforcement Learning']	We tackle the problem of one-shot generalization for long-horizon tasks by learning a model to translate an abstract trajectory to an executable trajectory.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|abstracttoexecutable_trajectory_translation_for_oneshot_task_generalization	/pdf/dbee86fa4f6f2005fd437c18b806d67289a00ebf.pdf
YUDiZcZTI8	227	Bit-Pruning: A Sparse Multiplication-Less Dot-Product	['pruning', 'non-uniform quantization', 'power of two', '2bit']	Mult-less dot-product comprised of add and shift; add is pruned during training to reduce energy 	Deep Learning and representational learning	anonymous|bitpruning_a_sparse_multiplicationless_dotproduct	/pdf/e3c21d2c34dcc9f4276a61877367e781ca9ca5e8.pdf
eGm22rqG93	228	DELTA: DEBIASED FULLY TEST-TIME ADAPTATION	[]		Deep Learning and representational learning	anonymous|delta_debiased_fully_testtime_adaptation	/pdf/627dd38646d58b06f6b6b5231874829bb346c190.pdf
ZaOG6ci_IP7	231	kaBEDONN: posthoc eXplainable Artificial Intelligence with Data Ordered Neural Network	['Explainable Artificial Intelligence', 'Neural Network', 'instance-based learning']	A posthoc method for providing explanation to blackbox algorithms by querying similar data	Deep Learning and representational learning	anonymous|kabedonn_posthoc_explainable_artificial_intelligence_with_data_ordered_neural_network	/pdf/6ddd43b10273051df57f3e3dc5432f702511d616.pdf
Kn-HA8DFik	233	Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot Classification	['cross-domain few-shot classification', 'cross-level distillation', 'feature denoising']	We design a cross-level distillation and a feature denoising operation for handling cross-domain few-shot classification. Our approach can surpass the SOTA method by 5.44% on 1-shot and 1.37% on 5-shot classification tasks in the BSCD-FSL benchmark.	Deep Learning and representational learning	anonymous|crosslevel_distillation_and_feature_denoising_for_crossdomain_fewshot_classification	/pdf/f126aab43ab1407f3b666ab45d338cccaa8a2737.pdf
XGT4bsvI6y	234	Module-wise Training of Residual Networks via the Minimizing Movement Scheme	['Deep learning', 'Layer-wise training', 'Optimal transport', 'Locking problems', 'Parallelism']	We introduce a regularization inspired by the minimizing movement scheme for gradient flows in distribution space for layer-wise training of neural networks. 	Deep Learning and representational learning	anonymous|modulewise_training_of_residual_networks_via_the_minimizing_movement_scheme	/pdf/09b729d39cc12c03fa191d89edba5c40c2f202cf.pdf
lTb1kzFA84J	235	Parameterized projected Bellman operator	['reinforcement learning', 'bellman operator', 'operator learning', 'approximate value iteration']	A novel reinforcement learning approach that obtains an approximation of the Bellman operator to overcome the limitations of the regular Bellman operator.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|parameterized_projected_bellman_operator	/pdf/7821da51313bd3bbc7e236782486686fd71264ef.pdf
Liuo-Bk-beq	236	The Biased Artist: Exploiting Cultural Biases via Homoglyphs in Text-Guided Image Generation Models	['Text-Guided Image Generation Models', 'Bias', 'DALL-E 2', 'Security']	Inducing cultural biases into text-conditional image generation models by replacing single characters in the text prompts with homoglyphs.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|the_biased_artist_exploiting_cultural_biases_via_homoglyphs_in_textguided_image_generation_models	/pdf/9463607bcf528f240f6e2207a93baa77d5641685.pdf
2xNKMFGPJU5	237	Unsupervised Learning of Causal Relationships from Unstructured Data	['causality', 'deep learning', 'causal representation learning', 'unsupervised', 'VAE']	We propose a modification to the VAE that learns variables and causal relationships between them in an unsupervised way.	Deep Learning and representational learning	anonymous|unsupervised_learning_of_causal_relationships_from_unstructured_data	/pdf/5d50a3dbf5671675793093509b4407e93d94ff58.pdf
3leZITnUE9r	245	An Empirical Study of Metrics to Measure Representational Harms in Pre-Trained Language Models	['Natural Language Processing', 'Fairness', 'Safety']	Measuring implicit hate in pretrained language models	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|an_empirical_study_of_metrics_to_measure_representational_harms_in_pretrained_language_models	/pdf/05b61236e415955a1db17de5aa371074e01c2d07.pdf
FPdDFUVYVPl	246	Is Self-Supervised Contrastive Learning More Robust Than Supervised Learning?	[]		Unsupervised and Self-supervised learning	anonymous|is_selfsupervised_contrastive_learning_more_robust_than_supervised_learning	/pdf/c145f2206cb2b38889c7665aa2db65576402cdf6.pdf
LmNckrTpTBo	249	Training A Multi-stage Deep Classifier with Feedback Signals	['multi-stage classification', 'training framework']		Applications (eg, speech processing, computer vision, NLP)	anonymous|training_a_multistage_deep_classifier_with_feedback_signals	/pdf/a702f8999783a0635c671e03ebac2cb1819ea5d6.pdf
OzHFdcvucgb	250	QCRS: Improve Randomized Smoothing using Quasi-Concave Optimization	['Randomized Smoothing', 'Robustness']	Improve traditional randomized smoothing using Quasi-Concave Optimization	General Machine Learning (ie none of the above)	anonymous|qcrs_improve_randomized_smoothing_using_quasiconcave_optimization	/pdf/ad2928d1f7f42d1fe7250de06537fb34f3c0727b.pdf
csARsNPKgVi	252	AutoSKDBERT: Learn to Stochastically Distill BERT	['Categorical distribution optimization', 'Stochastic knowledge distillation', 'BERT compression', 'GLUE']	AutoSKDBERT stochastically selects a teacher model from a predefined teacher team to distill student model in each iteration with a learnable categorical distribution.	Applications (eg, speech processing, computer vision, NLP)	anonymous|autoskdbert_learn_to_stochastically_distill_bert	/pdf/a8b41b0ea8400453ef46e6978671e04366cf169c.pdf
uPPbSJcMBXf	253	Domain Generalization via Independent Regularization from Early-branching Networks	['domain generalization', 'representational learning']	We find an early-branching structure is essential when using independent regularization for DG, and with a new augmentation strategy, our method can outperform most existing SOTA.	Deep Learning and representational learning	anonymous|domain_generalization_via_independent_regularization_from_earlybranching_networks	/pdf/63413f18f9b3656078d6483809e0ec5f679b2f45.pdf
PmP_sf3JkrH	254	Real-Time Image Demoir$\acute{e}$ing on Mobile Devices	['Image Demoireing', 'Network Acceleration']	This paper presents a dynamic demoireing acceleration method towards a real-time image demoireing on mobile devices.	Applications (eg, speech processing, computer vision, NLP)	anonymous|realtime_image_demoir\acuteeing_on_mobile_devices	/pdf/b09a6e7932ef1610139ce5f9805cd72d9e0ca70e.pdf
jT1HcWv6PgO	255	Towards Sustainable Self-supervised Learning	['sustainable', 'self-supervised learning', 'vision transformer']	This paper proposes a new method towards the sustainable self-supervised learning goal.	Unsupervised and Self-supervised learning	anonymous|towards_sustainable_selfsupervised_learning	/pdf/79ef199cbbce4ac7f9fbb45e823f6c51c5bfdc95.pdf
CxPw6TeByX4	257	SoundNeRirF: Receiver-to-Receiver Sound Neural Room Impulse Response Field	['Sound Neural Rendering Field', 'Sound Prediction', 'Representation Learning', 'Receiver-to-Receiver Modelling']	Propose a receiver-to-receiver sound neural room acoustics rendering field	Applications (eg, speech processing, computer vision, NLP)	anonymous|soundnerirf_receivertoreceiver_sound_neural_room_impulse_response_field	/pdf/73474fb7e5c921305bd712b12cefb4954230a3bc.pdf
53T6FlFulCV	258	SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition Neural Network	['Sound Crowd Count', 'Dyadic Decomposition Network', 'Learnable Filters', 'Acoustic Crowd Counting']	A novel and general framework for sound crowd counting from sound raw waveform	Applications (eg, speech processing, computer vision, NLP)	anonymous|soundcount_sound_counting_from_raw_audio_with_dyadic_decomposition_neural_network	/pdf/fecb03b3f970085458e37bc0dc118426bf83d447.pdf
AB4xZG9uzGl	259	Active Topological Mapping by Metric-Free Exploration via Task and Motion Imitation	['Topological Mapping', 'Feature-Space Task and Motion Planning', 'Visual Navigation', 'Deeply-Supervised Learning']	A novel framework of building metric-free topological map for exploration and navigation	Applications (eg, speech processing, computer vision, NLP)	anonymous|active_topological_mapping_by_metricfree_exploration_via_task_and_motion_imitation	/pdf/069617a67324f24ea266ff659f87d48c5da63a34.pdf
qtVUTPpTNq	260	Object Localization helps Action Recognition Models Adapt to New Environments	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|object_localization_helps_action_recognition_models_adapt_to_new_environments	/pdf/efc5e69a2fbbec09bfb73bee0c2bfe6b14cacd51.pdf
1ROAstc9jv	261	ChiroDiff: Modelling chirographic data with Diffusion Models	['chirographic data', 'continuous-time', 'diffusion model', 'generative model']	Learning diffusion model for continuous-time chirographic data (e.g. handwriting, sketch etc.)	Generative models	anonymous|chirodiff_modelling_chirographic_data_with_diffusion_models	/pdf/8583052b7b1f21fabbbbe4c725d7326e1f01ae6e.pdf
m7rFrsO0YWb	264	Neural-Symbolic Recursive Machine for Systematic Generalization	['Systematic Generalization', 'Compositional Generalization', 'Neural-symbolic']	We present Neural-Symbolic Recursive Machine for systematic generalization which achieves state-of-the-art performance on SCAN, PCFG, and HINT.	General Machine Learning (ie none of the above)	anonymous|neuralsymbolic_recursive_machine_for_systematic_generalization	/pdf/eb098a679218565dd52a980f5f51b875f5c36245.pdf
ejQVau3Z-QQ	265	WaGI: Wavelet-based GAN Inversion for Preserving High-Frequency Image Details	['GAN inversion', 'wavelet transform']		Generative models	anonymous|wagi_waveletbased_gan_inversion_for_preserving_highfrequency_image_details	/pdf/c452867e35a389d286e2baa7c3f6064a2baeaddb.pdf
WuDCu0aZXO0	266	Global Prototype Encoding for Incremental Video Highlights Detection	['Video highlights detection', 'Incremental learning', 'Newly released dataset']		Applications (eg, speech processing, computer vision, NLP)	anonymous|global_prototype_encoding_for_incremental_video_highlights_detection	/pdf/8a30bc7adbc4e935c79af423434a312b0d6f2a03.pdf
t9Zd7Oi5JPl	267	PatchDCT: Patch Refinement for High Quality Instance Segmentation	['Instance Segmentation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|patchdct_patch_refinement_for_high_quality_instance_segmentation	/pdf/241bfc9312bd5d37eb1328cda689c3ee0a7abcd5.pdf
Q3-1vRh3HOA	268	Dilated convolution with learnable spacings	['deep learning', 'convolution', 'dilated convolution', 'receptive field']	Dilated convolution with learnable spacings: a new method that improves the accuracy of state-of-the-art CNNs	Deep Learning and representational learning	anonymous|dilated_convolution_with_learnable_spacings	/pdf/17bc3623d0a21a5f14dc9bc4004716a023a796f7.pdf
_k0CnK5V7F	273	"Faster Neural Architecture ""Search"" for Deep Image Prior"	['Deep Image Prior', 'Image Denoising', 'Self-Supervised Learning']	We develop a faster and training-free architecture design strategy to estimate the required architecture for each image in advance.	Unsupervised and Self-supervised learning	anonymous|faster_neural_architecture_search_for_deep_image_prior	/pdf/598f38ef0c5608bb9af9bdbbea19becab653227e.pdf
_X9Yl1K2mD	274	Rotamer Density Estimators are Unsupervised Learners of the Effect of Mutations on Protein-Protein Interaction	['effect of mutations', 'protein-protein interaction', 'unsupervised learning']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|rotamer_density_estimators_are_unsupervised_learners_of_the_effect_of_mutations_on_proteinprotein_interaction	/pdf/e550cd173f42d7ac3e61014fd68b33535a30fb49.pdf
BSUoWl5yfv	275	Training Instability and Disharmony Between ReLU and Batch Normalization	['Deep learning', 'Gradient Exploding', 'ReLU', 'Batch normalization', 'Training instability', 'LARS', 'WarmUp']	We mathematically show how the disharmony between ReLU and BN causes temporal gradient explosion and training instability. We also propose a better solution of the problem.	Deep Learning and representational learning	anonymous|training_instability_and_disharmony_between_relu_and_batch_normalization	/pdf/add1bea91fa94adb7878a8aea09779013996f6f2.pdf
woa783QMul	276	Fairness-aware Contrastive Learning with Partially Annotated Sensitive Attributes	['Fair Representation Learning', 'Semi-supervised Learning', 'Contrastive Learning', 'Data Augmentation']	Proposing a new problem of fair unsupervised representation learning with limited annotated sensitive attributes and a fairness-aware contrastive learning framework.	Deep Learning and representational learning	anonymous|fairnessaware_contrastive_learning_with_partially_annotated_sensitive_attributes	/pdf/8f27290bd3d20f4800751afddd5f911c2a6863af.pdf
RuLGBgoonoM	277	ViTKD: Practical Guidelines for ViT Feature Knowledge Distillation	['Knowledge Distillation', 'Vision Transformer', 'Image Classification']	A feature-based knowledge distillation method for ViT	Deep Learning and representational learning	anonymous|vitkd_practical_guidelines_for_vit_feature_knowledge_distillation	/pdf/d3a5f52da9e717b6a1f85196273495db65697256.pdf
Mof47lISH6N	279	DifFace: Blind Face Restoration with Diffused Error Contraction	['Face Restoration', 'Diffusion Model', 'Super-resolution']	We propose a new blind face restoration method that consists of an error compressor and a Markov chain partially borrowed from a pre-trained diffusion model.  	Applications (eg, speech processing, computer vision, NLP)	anonymous|difface_blind_face_restoration_with_diffused_error_contraction	/pdf/abf4dadf9c30bbe2b31ea776a5779f3b5b4446db.pdf
kTBTu1XxvFC	281	FreeSeg: Free Mask from Interpretable Contrastive Language-Image Pretraining for Semantic Segmentation	['Semantic Segmentation', 'Open-vocabulary', 'Zero-shot', 'Contrastive Language-Image Pretraining', 'Interpretability']	We use natural language as supervision for open world segmentation, via freely available mask from raw feature map of pretraining model, which is striaght forward and effective.	Applications (eg, speech processing, computer vision, NLP)	anonymous|freeseg_free_mask_from_interpretable_contrastive_languageimage_pretraining_for_semantic_segmentation	/pdf/e5551a7d1ce5c642b2892396239dc064abf29859.pdf
aPQRSQCDF2-	283	Hardware-restriction-aware training (HRAT) for memristor neural networks	['Neuromorphic computing', 'Memristor', 'Neural network training', 'Hardware restrictions']		General Machine Learning (ie none of the above)	anonymous|hardwarerestrictionaware_training_hrat_for_memristor_neural_networks	/pdf/e3d05b61f28245c5bfd094687e14b42cc151ed76.pdf
Xecc-oeRzMr	284	Bayesian Robust Graph Contrastive Learning	['Graph Neural Networks', 'Contrastive Learning', 'Bayesian Nonparametric Learning', 'Noise']		Deep Learning and representational learning	anonymous|bayesian_robust_graph_contrastive_learning	/pdf/3bc3a34990ff3bbfdc716bda96273034d557117e.pdf
wmMUAg_l4Qk	285	Double dynamic sparse training for GANs	['empirical deep learning', 'neural network pruning', 'dynamic sparse training']	We propose a quantity named balance ratio to investigate and improve dynamic sparse training for GANs.	Deep Learning and representational learning	anonymous|double_dynamic_sparse_training_for_gans	/pdf/90e1ffc6c07779930714986295b3593bf6ae0b18.pdf
QfLU7FtXDUn	286	SpQAT: A Sparse Quantization-Aware Training Method	['efficient training', 'quantization-aware training', 'network quantization']	We develop an efficient sparse QAT method, dubbed SpQAT, based on the partly scratch-off lottery ticket phenomenon we observed.	Applications (eg, speech processing, computer vision, NLP)	anonymous|spqat_a_sparse_quantizationaware_training_method	/pdf/cbefb4912ebd891fcba9318b893c9c451384462d.pdf
A85gMNB01t1	287	HRDFuse: Monocular 360$^\circ$ Depth Estimation by Collaboratively Learning Holistic-with-Regional Depth Distributions	['3D Computer Vision', 'Scene Analysis and Understanding', 'Depth distribution classification', 'Feature representation learning']	This paper proposed a novel solution for monocular 360$^\circ$ depth estimation, which predicts an ERP format depth map by collaboratively learning the holistic-with-regional information from the ERP image and its TP patches.	Applications (eg, speech processing, computer vision, NLP)	anonymous|hrdfuse_monocular_360^\circ_depth_estimation_by_collaboratively_learning_holisticwithregional_depth_distributions	/pdf/fe4067b0d2dc7144967cfffcc53860190e665d5a.pdf
hVVUY7p64WL	288	Learnable Topological Features For Phylogenetic Inference via Graph Neural Networks	['phylogenetic inference', 'learnable topological features', 'graph neural network', 'density estimation', 'variational inference']	Novel phylogenetic inference methods based on learnable topological features via graph neural networks	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learnable_topological_features_for_phylogenetic_inference_via_graph_neural_networks	/pdf/5f8a2cbc0213b53ee4968a024c37d63d33229d99.pdf
qaJj2vTwrG5	289	EyeDAS: Securing Perception of Autonomous Cars Against the Stereoblindness Syndrome	[]			anonymous|eyedas_securing_perception_of_autonomous_cars_against_the_stereoblindness_syndrome	/pdf/9eed14bf17cd5921b121f5edf0f06e91c7f3c5b2.pdf
D9WJEsALpI1	290	SegNeRF: 3D Part Segmentation with Neural Radiance Fields	[]	We perform 3D part segmentation on novel objects using only images by leveraging volume rendering.	Applications (eg, speech processing, computer vision, NLP)	anonymous|segnerf_3d_part_segmentation_with_neural_radiance_fields	/pdf/c43f531266628ba1be01a63d09993788b1a8ad46.pdf
VfAUPNStOS_	291	CD-Depth: Unsupervised Domain Adaptation for Depth Estimation via Cross Domain Integration	['monocular depth estimation', 'unsupervised domain adaptation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|cddepth_unsupervised_domain_adaptation_for_depth_estimation_via_cross_domain_integration	/pdf/336e101e9b0f2de29be90a2870ccfc4acdc2cd64.pdf
eW2zCT1gm3	294	A Simple and Provable Method to Adapt Pre-trained Model across Domains with Few Samples	['Cross-domain few-shot learning', 'PAC-Bayesian framework', 'dimensionality reduction', 'ensemble']	This paper proposes a Simple and Provable method to quickly adapt a given pre-trained model across domains with few samples.	Deep Learning and representational learning	anonymous|a_simple_and_provable_method_to_adapt_pretrained_model_across_domains_with_few_samples	/pdf/58bcb08fa6b9cdf9d790556bf018207f86e51c8d.pdf
YjFvx8VBl1	296	BoxTeacher: Exploring High-Quality Pseudo Labels for Weakly Supervised Instance Segmentation	['Weakly supervised instance segmentation', 'instance segmentation', 'object detection']	This paper presents an end-to-end training framework named BoxTeacher to boost the performance of weakly supervised instance segmentation with high-quality pseudo labels. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|boxteacher_exploring_highquality_pseudo_labels_for_weakly_supervised_instance_segmentation	/pdf/988a133d1dc240654d45823d02fb38c691b6c577.pdf
1FxRPKrH8bw	301	MCAL: Minimum Cost Human-Machine Active Labeling	['Active Labeling', 'Groundtruth Annotation', 'Dataset Labeling']	A framework to address the prohibitive data labeling cost challenge using hybrid human-machine labeling.		anonymous|mcal_minimum_cost_humanmachine_active_labeling	/pdf/3262e5c2b7935c8b67e1569cfe3d246edd125445.pdf
yc9xen7EAzd	305	Approximated Anomalous Diffusion: Gaussian Mixture Score-based Generative Models	[]		Generative models	anonymous|approximated_anomalous_diffusion_gaussian_mixture_scorebased_generative_models	/pdf/05d7b640728b432a25db67671e32ef0d396b41d1.pdf
xLr0I_xYGAs	307	The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|the_devil_is_in_the_wronglyclassified_samples_towards_unified_openset_recognition	/pdf/ebe7c692112fa136570a29f5ecbb4cc2e1e9f6bf.pdf
Qsbh0IgVG_8	308	Domain Specific Denoising Diffusion Probabilistic Models for Brain Dynamics	['Denoising Diffusion Probalistic Models', 'EEG Signal', 'Domain Variance Generation', 'Subject Difference', 'Deep Learning']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|domain_specific_denoising_diffusion_probabilistic_models_for_brain_dynamics	/pdf/a508acfea978eaf7f26bfd95edbc93aa6e015d42.pdf
OiLPUTbiic5Y	309	Multi-User Reinforcement Learning with Low Rank Rewards	['Low Rank Matrix Estimation', 'Collaborative Reinforcement Learning']	A statistically efficient method for learning policies collaboratively across multiple users with same state-space transitions but low-rank reward matrix. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|multiuser_reinforcement_learning_with_low_rank_rewards	/pdf/078e953d28e33acaccf7d9997f3a8755cf73e7f1.pdf
pgHNOcxEdRI	311	Function-Consistent Feature Distillation	['knowledge distillation', 'feature distillation', 'function consistency']		Deep Learning and representational learning	anonymous|functionconsistent_feature_distillation	/pdf/58108a57c3724d5091fe64ccb7a2320d0655859e.pdf
SNzzt94tGzP	313	Learn to Know Unknowns: A Bionic Memory Network for Unsupervised Anomaly Detection	['Unsupervised learning', 'Anomaly detection', 'Memory bank']	We proposed a biomimetic neural network for unsupervised anomaly detection inspired by the hippocampus-cortex cascade, enabling the model to know the unknowns.	General Machine Learning (ie none of the above)	anonymous|learn_to_know_unknowns_a_bionic_memory_network_for_unsupervised_anomaly_detection	/pdf/5fa0c9f6037e3eebb93cca61cf9177c16fcfd332.pdf
zlwBI2gQL3K	315	Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion	['few-shot learning', 'knowledge graph completion']		Deep Learning and representational learning	anonymous|hierarchical_relational_learning_for_fewshot_knowledge_graph_completion	/pdf/e7e4c1bae60e31e0944741b25ca9506063d9e9c4.pdf
6BO4lP8K1N1	316	Cutting Long Gradient Flows: Decoupling End-to-End Backpropagation Based on Supervised Contrastive Learning	[]	We cut long gradient flows into multiple shorter ones and maintain comparable test accuracy.	Deep Learning and representational learning	anonymous|cutting_long_gradient_flows_decoupling_endtoend_backpropagation_based_on_supervised_contrastive_learning	/pdf/d87754168084d12e249d18aeda0f5d0dc2388c76.pdf
NAQvF08TcyG	317	An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion	['Personalized generation', 'text-to-image', 'inversion']	We present the task of personalized text-to-image generation, and introduce an inversion-based method that allows us to synthesize novel scenes of user-provided visual concepts, guided by natural language instructions.	Generative models	anonymous|an_image_is_worth_one_word_personalizing_texttoimage_generation_using_textual_inversion	/pdf/4cd5dc35e2369be9db927fae04e0abdc78969376.pdf
D1Iqfm7WTkk	318	Neural ePDOs: Spatially Adaptive Equivariant Partial Differential Operator Based  Networks	['Equivariance', 'Partial differential operators']	We propose a novel spatial adaptive equivariant PDOs-based network which achieves superior performance than previous works. 	Deep Learning and representational learning	anonymous|neural_epdos_spatially_adaptive_equivariant_partial_differential_operator_based_networks	/pdf/3adc8d86d3920db1728e86532318317c57e89c98.pdf
ep_8uwxouZO	319	DeepSAT: An EDA-Driven Learning Framework for SAT	[]		Deep Learning and representational learning	anonymous|deepsat_an_edadriven_learning_framework_for_sat	/pdf/a57df8286576ac30ff532b96f63cc48bba8f3216.pdf
WbxHAzkeQcn	320	Neural Networks and the Chomsky Hierarchy	['length generalization', 'memory-augmented neural networks', 'recurrent neural networks']	Large-scale empirical study to determine the computational complexity class of a number of neural network architectures, which allows forecasting limitations on generalization capabilities.	Deep Learning and representational learning	anonymous|neural_networks_and_the_chomsky_hierarchy	/pdf/be63a0c4c30268d79391d43048dfbc388164ecec.pdf
uKiE0VIluA-	321	GFlowNets and variational inference	['variational inference', 'GFlowNets', 'probabilistic modeling', 'weighted importance sampling']	We theoretically and empirically compare and contrast GFlowNets with hierarchical variational inference.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|gflownets_and_variational_inference	/pdf/36d341670fd5f02ac6a564e671aa77bad3391dad.pdf
EVrz7UM-ZDm	322	Volumetric Optimal Transportation by Fast Fourier Transform	['Optimal transport', 'Monge-Ampere equation', 'Elliptic PDE', 'Fast Fourier transform']	Optimal transport, Monge-Amp\`ere equation, Elliptic PDE, Fast Fourier transform	General Machine Learning (ie none of the above)	anonymous|volumetric_optimal_transportation_by_fast_fourier_transform	/pdf/5fde374d03336d9dc2985ff70ca8e35b156757b3.pdf
og1UqadquNk	323	Variational Autoencoders with Decremental Information Bottleneck for Disentanglement	['disentanglement', 'variational autoencoders']	We present a novel decremental variational autoencoder with disentanglement-invariant transformations, termed DeVAE, for balancing disentanglement and reconstruction fidelity.	Deep Learning and representational learning	anonymous|variational_autoencoders_with_decremental_information_bottleneck_for_disentanglement	/pdf/c5fd55d30e4c08f1edda17606f99d4d82333e266.pdf
usa87QW3_r9	324	Everyone's Preference Changes Differently: Weighted Multi-Interest Retrieval Model	['recommendation system', 'sequential models', 'temporal dynamics', 'user behavior modeling', 'multi-interest representation']	A joint-modeling of unbiased multiple user interests and the interest weights.	Deep Learning and representational learning	anonymous|everyones_preference_changes_differently_weighted_multiinterest_retrieval_model	/pdf/5a218e8bb9dd746c56e4a2ef6c53e23fcece11af.pdf
ti6fH3EhFkv	326	Towards a Unified View on Visual Parameter-Efficient Transfer Learning	['Parameter Efficient', 'Transfer Learning', 'Domain Adaption']	This paper investigates the positional importance of trainable parameter for adapting a large model to downstream tasks.	Deep Learning and representational learning	anonymous|towards_a_unified_view_on_visual_parameterefficient_transfer_learning	/pdf/f1fe53e4523780af0bfa24b74f6e5d1c3916336a.pdf
_uR2KmSfU8g	328	Generaling Multimodal Variational Methods to Sets	['multimodal variational auto encoder', 'self attention', 'unupervised learning', 'set representation learning']	This paper presents a novel variational method on sets called the Set Multimodal VAE (SMVAE) for learning the joint-modality posterior directly while handling the missing modality problem. 	Deep Learning and representational learning	anonymous|generaling_multimodal_variational_methods_to_sets	/pdf/215a0c9226dc751243f7b2f7b008eb95d23f65c2.pdf
3m_awcLrg8E	329	Token Turing Machines	['memory', 'Neural Turing Machine', 'robot learning', 'sequence']	Token Turing Machines (TTM) is a sequential, autoregressive transformer model with memory for real-world sequential decision making, modernizing Neural Turing Machines.	Deep Learning and representational learning	anonymous|token_turing_machines	/pdf/db96d0089190366d72f8214399b69104b46f936d.pdf
COrdS9G6TJ8	331	AQUILA: Communication Efficient Federated Learning with Adaptive Quantization of Lazily-Aggregated Gradients	['Federated Learning', 'communication efficiency', 'adaptive quantization']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|aquila_communication_efficient_federated_learning_with_adaptive_quantization_of_lazilyaggregated_gradients	/pdf/6abe815c0faee599b4b9b7ad0276fce3115b877b.pdf
4lGL_ruf--t	332	OhMG: Zero-shot Open-vocabulary Human Motion Generation	['foundation model', 'contrastive language-image pretraining', 'human motion generation', 'zero-shot', 'open-vocabulary']	We propose a zero-shot open-vocabulary human motion generation framework, with guidance from the large foundation model (i.e., CLIP)	Unsupervised and Self-supervised learning	anonymous|ohmg_zeroshot_openvocabulary_human_motion_generation	/pdf/4ae9aeec3a0bb918c6602626486024933d1e79d3.pdf
vVbUB9oWUup	333	Decoupling Concept Bottleneck Model	['Interpretability', 'Concept-based Model']	We analyze the concept/label trade-off for Concept Bottleneck Model (CBM) and propose a new interactive and interpretable AI system to alleviate this issue.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|decoupling_concept_bottleneck_model	/pdf/ba840edc0548c96c3bcb9b13241d5fd54ec654c4.pdf
OpzV3lp3IMC	336	Self-conditioned Embedding Diffusion for Text Generation	['language models', 'diffusion models', 'generative models']	Our continuous diffusion framework operates on word embeddings, enabling flexible and scalable diffusion models for text generation.	Generative models	anonymous|selfconditioned_embedding_diffusion_for_text_generation	/pdf/11ef7dddb6afa574c5155ad2ab939d2003119399.pdf
y5W8tpojhtJ	337	Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-Incremental Learning	['few-shot class-incremental learning', 'neural collapse']	An interpretable solution inspired by neural collapse for few-shot class-incremental learning	Deep Learning and representational learning	anonymous|neural_collapse_inspired_featureclassifier_alignment_for_fewshot_classincremental_learning	/pdf/d137761b84be637eda298eaba2b6ecea38bc8abd.pdf
luEG3j9LW5-	338	Bidirectional Learning for Offline Model-based Biological Sequence Design	['offline model-based optimization', 'meta learning', 'biological sequence design.']	We adapt bidirectional learning to biological sequence design and propose Adaptive-$\eta$ to tune learning rates for gradient-based algorithms on offline model-based optimization. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|bidirectional_learning_for_offline_modelbased_biological_sequence_design	/pdf/cc0c60cfad798c87f7a578c5413087804c1ef472.pdf
lU5R_e4zXza	339	Self-supervised Video Representation Learning with Motion-Aware Masked Autoencoders	['Masked autoencoders', 'Self-supervised spatiotemporal representation learning']	We propose a motion-aware MAE method, MotionMAE, for self-supervised spatiotemporal representation learning from unlabeled videos.	Unsupervised and Self-supervised learning	anonymous|selfsupervised_video_representation_learning_with_motionaware_masked_autoencoders	/pdf/3cfb14e2fa8e41edb013299ec38e4f752461c57c.pdf
MxvHVNukama	340	On The Inadequacy of Optimizing Alignment and Uniformity in Contrastive Learning of Sentence Representations	['Sentence representation learning', 'Contrastive learning', 'Alignment', 'Uniformity']		Deep Learning and representational learning	anonymous|on_the_inadequacy_of_optimizing_alignment_and_uniformity_in_contrastive_learning_of_sentence_representations	/pdf/194d24a520edbd45df1109a282135464b5c233b1.pdf
qmV_tOHp7B9	341	CAN: A simple, efficient and scalable contrastive masked autoencoder framework for learning visual representations	['Self supervised learning', 'contrastive learning', 'masked autoencoders']	We propose a minimal and conceptually clean synthesis of (C) contrastive learning, (A) masked autoencoders, and (N) the noise prediction for self-supervised learning on images	Unsupervised and Self-supervised learning	anonymous|can_a_simple_efficient_and_scalable_contrastive_masked_autoencoder_framework_for_learning_visual_representations	/pdf/6f89386065f1517d0fb97749e9d6c9a2b86ca744.pdf
VqDrqeQ8-C4	344	Smooth-Reduce: Leveraging Patches for Improved Certified Robustness	['Adversarial defenses', 'Certifiable defenses', 'Randomized Smoothing', 'Ensemble Models', 'Robust Video Classifiers']	We present a novel, patch based approach to simulate ensembles that improve randomized smoothing performance.	Deep Learning and representational learning	anonymous|smoothreduce_leveraging_patches_for_improved_certified_robustness	/pdf/2de2e9383038b18fae25c0b2070eef6f11f0803d.pdf
esRySujigfO	345	CLIP-FLOW: CONTRASTIVE LEARNING WITH ITERATIVE PSEUDO LABELING FOR OPTICAL FLOW	['Optical Flow', 'Contrastvie Learning', 'Semi-supervised Learning']	A semi-supervised framework for optical flow with iterative pseudo labeling and contrastive flow loss to facilitate representation learning with unlabeled data	Unsupervised and Self-supervised learning	anonymous|clipflow_contrastive_learning_with_iterative_pseudo_labeling_for_optical_flow	/pdf/8152a088508561f0551c25e761d3d5581b8e4565.pdf
3nM5uhPlfv6	346	Stochastic Differentially Private and Fair Learning	['algorithmic fairness', 'differential privacy', 'private fair learning', 'stochastic optimization']	The first efficient differentially private fair learning algorithm that is guaranteed to converge, even when stochastic minibatches of data are used in each iteration of training. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|stochastic_differentially_private_and_fair_learning	/pdf/d3bfd720413d266763e6f4d6050e233e22d97053.pdf
9x3CO0ZU9LR	349	Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Networks	['RL theory', 'deep off-policy evaluation', 'neural network function approximation', 'manifold data']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|sample_complexity_of_nonparametric_offpolicy_evaluation_on_lowdimensional_manifolds_using_deep_networks	/pdf/04216b0096531f9cfd576e2cf46cb719c81d3829.pdf
g1GnnCI1OrC	350	E-CRF: Embedded Conditional Random Field for Boundary-caused Class Weights Confusion in Semantic Segmentation	[]			anonymous|ecrf_embedded_conditional_random_field_for_boundarycaused_class_weights_confusion_in_semantic_segmentation	/pdf/3940feceda72634230b8705a5fbe6740cea90238.pdf
3tYvDb4dwab	352	Understanding Self-Supervised Pretraining with Part-Aware Representation Learning	['Part-aware representation', 'Self-supervised learning', 'Masked image modeling', 'Contrastive learning']	We study the capability of learning part-aware representations of self-supervised pretraining methods, including contrastive learning and masked image modeling.	Unsupervised and Self-supervised learning	anonymous|understanding_selfsupervised_pretraining_with_partaware_representation_learning	/pdf/c0175c563fa075f176f82b1076b55b07f12c1443.pdf
hTWqB327Oay	353	Calibrating Multimodal Learning	[]		Deep Learning and representational learning	anonymous|calibrating_multimodal_learning	/pdf/52dffc022f11dad5e8986b4841f8e400345ecb47.pdf
t-hNmA0cVSW	354	Semi-supervised Counting via Pixel-by-pixel Density Distribution Modelling	['Computer Vision', 'Crowd Counting', 'Semi-Supervised Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|semisupervised_counting_via_pixelbypixel_density_distribution_modelling	/pdf/bd5faa6f736a49c899a88657a7ca7c731dfb7779.pdf
1QQnYd02etI	355	Unified Vision and Language Prompt Learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|unified_vision_and_language_prompt_learning	/pdf/e0d1fb8102bac283cfd0072ae6762821cb23af93.pdf
Pza24zf9FpS	356	Neural Groundplans: Persistent Neural Scene Representations from a Single Image	['Neural scene representations', '3D', 'nerf', 'scene understanding', 'neural rendering', 'object-centric representations']	We train a self-supervised model that learns to map a single image to a 3D representation of the scene, with separate components for the immovable and movable 3D regions.	Unsupervised and Self-supervised learning	anonymous|neural_groundplans_persistent_neural_scene_representations_from_a_single_image	/pdf/608d79198a0ca1d88ee224d65ea9c5c959a948e9.pdf
cMAjKYftNwx	357	Extracting Robust Models with Uncertain Examples	[]		Deep Learning and representational learning	anonymous|extracting_robust_models_with_uncertain_examples	/pdf/427a5b87baab59f04cc98493210b249421cd629f.pdf
U_BPCe6yKb9	358	Re-balancing Adversarial Training Over Unbalanced Datasets	[]		Deep Learning and representational learning	anonymous|rebalancing_adversarial_training_over_unbalanced_datasets	/pdf/6480e4c282e49b0c7ca58b148e76d705a906e7c0.pdf
LGbzYw_pnsc	359	Nearing or Surpassing: Overall Evaluation of Human-Machine Dynamic Vision Ability	['Dynamic Visual Ability', 'Machine Intelligence Evaluation', 'Single Object Tracking']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|nearing_or_surpassing_overall_evaluation_of_humanmachine_dynamic_vision_ability	/pdf/e937747023bc84cf033343b50ff72ec56fa2b864.pdf
BqxE86ufTzq	361	Gradient Estimation for Unseen Domain Risk Minimization with Pre-Trained Models	['domain generalization', 'gradient estimation', 'pre-trained models']	Gradient Estimation for Unseen Domain Risk Minimization with Pre-Trained Models	Deep Learning and representational learning	anonymous|gradient_estimation_for_unseen_domain_risk_minimization_with_pretrained_models	/pdf/ee3357187381de7fec3b52ff958c0b37f7040bff.pdf
NYtq-CsRP3H	362	Parameter Averaging for Feature Ranking	['Parameter averaging', 'feature ranking', 'feature importance', 'robustness', 'interpretability', 'tabular data']	In this work, we introduce a novel method based on parameter averaging to estimate accurate and robust feature importance in tabular data setting, referred as XTab.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|parameter_averaging_for_feature_ranking	/pdf/76fb6b23b4efecd6ca2793702fdcc2abb2d320cf.pdf
hdghx6wbGuD	363	Out-of-distribution Detection with Implicit Outlier Transformation	['out-of-distribution detection']		Deep Learning and representational learning	anonymous|outofdistribution_detection_with_implicit_outlier_transformation	/pdf/d9b6759fda9f48480152ab015be36287a6a996f3.pdf
Ox0ZtZKG9_-	366	Cross-Domain Autonomous Driving Perception using Contrastive Appearance Adaptation	['Domain adaptation', 'Object detection', 'Semantic segmentation', 'Depth estimation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|crossdomain_autonomous_driving_perception_using_contrastive_appearance_adaptation	/pdf/95ea0ba82bb5901a2c5266f31ad8146dd3fac98f.pdf
KKBMz-EL4tD	367	Alternating Differentiation for Optimization Layers	['Alternating differentiation', 'optimization layers', 'unrolling', 'implicit models']	We propose a new implicit differentiation framework (Alt-Diff) that decouples optimization layers in an alternating way to increase the computational speed. We also prove the convergence of Alt-Diff and show the upper bound of truncated error.	Optimization (eg, convex and non-convex optimization)	anonymous|alternating_differentiation_for_optimization_layers	/pdf/4d24631fd5ef2c3dcd9d2d86682ce660b5667dcd.pdf
lZOUQQvwI3q	368	Measuring axiomatic identifiability of counterfactual image models	['Counterfactual inference', 'Generative Models', 'Computer Vision']	We use the axiomatic definition of counterfactual to derive metrics that enable quantifying the correctness of approximate counterfactual inference models.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|measuring_axiomatic_identifiability_of_counterfactual_image_models	/pdf/a71f296cd19bdaa06a702d9825e6249fc8c79112.pdf
C1A2HD6EEGO	369	ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing	['Robustness', 'benchmark', 'attribute']	A new robustness benchmark that can help to evaluate the robustness against different object attributes	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|imagenete_benchmarking_neural_network_robustness_via_attribute_editing	/pdf/6b15ed09e9a413e04f06500abb2d42f6ebfebf4e.pdf
h9ThYkkgSD4	370	Activation Function: Absolute Function,One Function Behaves more Individualized	['activation function', 'absolute function', 'individualization', 'universality', 'over-fitting', 'Z-Score', 'abstract network', 'concrete network，stimulation']	A new activition function		anonymous|activation_function_absolute_functionone_function_behaves_more_individualized	/pdf/8b288128bdb3ea7b772ce046f9742bf34a75cc02.pdf
yQdBtFfleh6	371	Rethinking skip connection model as a learnable Markov chain	['Language translation', 'image classification', 'transformer']	Penal connection only introduces negligible computational burden and can be implemented with one line of code under most popular deep learning frameworks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|rethinking_skip_connection_model_as_a_learnable_markov_chain	/pdf/db421feac4a2a98f17e323e393f1748e2b992289.pdf
SNgLnzFQeiD	373	Revisiting the Entropy Semiring for Neural Speech Recognition	['semiring', 'asr', 'ctc', 'rnn-t', 'entropy', 'regularization', 'distillation', 'streaming', 'speech recognition']	A numerically stable open-source implementation of the entropy semiring for CTC and RNN-T; obtained SOTA on Librispeech streaming.	Applications (eg, speech processing, computer vision, NLP)	anonymous|revisiting_the_entropy_semiring_for_neural_speech_recognition	/pdf/988deabe7c14ec223fbdd84b560aa6a99e8e6889.pdf
wYIKh2Z7bI8	376	WeightRelay: Efficient Heterogenous Federated Learning on Time Series	['Federated learning', 'Heterogeneous models', 'Time series classification']	To train multiple models on a smaller budget, we don't need to train everyone from the stretch. We could initialize some of those models by the trained weight from the others for fast convergence.	General Machine Learning (ie none of the above)	anonymous|weightrelay_efficient_heterogenous_federated_learning_on_time_series	/pdf/c83563da68efc08df8a39820f01b584d8743003e.pdf
EQiRSnqUYOh	377	Demystifying the Optimization and Generalization of Deep PAC-Bayesian Learning	['PAC-Bayes', 'Probabilistic Neural Netowrks', 'Neural Tangent Kernel']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|demystifying_the_optimization_and_generalization_of_deep_pacbayesian_learning	/pdf/06629b4c13a123c773a29dd7b4da239bc6a4d6e7.pdf
jNpvW1ozbj3	378	Multiple output samples for each input in a single-output Gaussian process	['Gaussian process', 'multiple outputs', 'subjective', 'uncertainty', 'spoken language assessment']	This paper proposes to extend the Gaussian process framework to allow for multiple output samples for each input from the same task in the training set.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|multiple_output_samples_for_each_input_in_a_singleoutput_gaussian_process	/pdf/c081e5b42cb75638ee16257e5710f34f96849be9.pdf
uFZt0ZJi8BX	379	GANet: Graph-Aware Network for Point Cloud Completion with Displacement-Aware Point Augmentor	['Point cloud completion', 'Graph-aware network', 'Displacements-aware point augmentor']	Our proposed GANet effectively learns from contour information of partial point clouds, and it delivers state-of-the-art results on multiple benchmarks and exhibits impressive efficiency.	Applications (eg, speech processing, computer vision, NLP)	anonymous|ganet_graphaware_network_for_point_cloud_completion_with_displacementaware_point_augmentor	/pdf/3152c644704de347d8ddd5ba03864099dbac34cc.pdf
7ZaJfk915b1	382	Shared Knowledge Lifelong Learning	[]		Deep Learning and representational learning	anonymous|shared_knowledge_lifelong_learning	/pdf/738ab86b31dbec8b3413355ceda45871fc547c85.pdf
wralRReGNHi	383	Multiplane NeRF-Supervised Disentanglement of Depth and Camera Pose from Videos	['Multiple Image Plane', 'Disentanglement from Video']		Unsupervised and Self-supervised learning	anonymous|multiplane_nerfsupervised_disentanglement_of_depth_and_camera_pose_from_videos	/pdf/eac3ae4f747473c5f9e6a82e8f00e08c85f62234.pdf
Q_Jexl8-qDi	384	De Novo Molecular Generation via Connection-aware Motif Mining	['Molecular generation', 'Graph generation', 'Motifs mining']	We propose a fragment-based model for molecular generation. It first mines connection-aware motifs from the molecule library and then leverage a connection-aware generator to generate novel drug candidates.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|de_novo_molecular_generation_via_connectionaware_motif_mining	/pdf/50412c49f0d034055ae9c5f1da0f00257c891cb3.pdf
h8RIDPvVubq	385	An Analysis of Information Bottlenecks	[]		Deep Learning and representational learning	anonymous|an_analysis_of_information_bottlenecks	/pdf/83ea866e7420c14c7665f526f74abea0e9d4b114.pdf
RBNk9cpT1AW	386	MS3: A Multimodal Supervised Pretrained Model for Semantic Segmentation	['multi-dataset', 'multi-modal', 'semantic segmentation']	This paper proposes a multi-dataset pretraining model with multimodal supervision for semantic segmentation and outperforms ImageNet pretraining under both standard fine-tuning and some rapid deployment scenarios.	Deep Learning and representational learning	anonymous|ms3_a_multimodal_supervised_pretrained_model_for_semantic_segmentation	/pdf/c409ef712b072cad7038d4c56229c00200741cbd.pdf
l0mX03b3UZv	388	Provable Adaptivity in Adam	['Benefit of Adam', 'convergence', 'SGD', 'optimization']	We explain why Adam is faster than SGD through convergence analysis.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|provable_adaptivity_in_adam	/pdf/953430635445551cedbe8df753c54eb023654920.pdf
LxEfHeknf4z	389	CompletionFormer: Depth Completion with Convolutions and Vision Transformers	['Depth', 'Depth Completion', 'Vision Transformer', 'Computer Vision']		Applications (eg, speech processing, computer vision, NLP)	anonymous|completionformer_depth_completion_with_convolutions_and_vision_transformers	/pdf/02df003d9b979b255ade065c03622cd06dabe69c.pdf
anRa-qu7ZjQ	390	TiDAL: Learning Training Dynamics for Active Learning	['active learning', 'training dynamics']	TiDAL: Learning Training Dynamics for Active Learning	Applications (eg, speech processing, computer vision, NLP)	anonymous|tidal_learning_training_dynamics_for_active_learning	/pdf/babe8c3fc75027fcd328b3544c47f50a4048cce2.pdf
JroZRaRw7Eu	391	Token Merging: Your ViT But Faster	['token merging', 'token pruning', 'inference speed', 'training speed', 'throughput', 'off-the-shelf', 'fine tuning']	We merge tokens in a ViT at runtime using a fast custom matching algorithm. Our method, ToMe, can increase training and inference speed, lower training memory, and can be applied with and without training.	Deep Learning and representational learning	anonymous|token_merging_your_vit_but_faster	/pdf/5cec72df6c1dc489f3437415514e87bc52ac54dc.pdf
z4eslwuymzQ	392	Gradient Norm Regularizer Seeks Flat Minima and Improves Generalization	[]		Deep Learning and representational learning	anonymous|gradient_norm_regularizer_seeks_flat_minima_and_improves_generalization	/pdf/6f9cf3bd38841f21a061984cc6a8a72fb3965501.pdf
q08xeIw1HA1	393	NICO++: Towards Better Benchmarking for Domain Generalization	[]		Deep Learning and representational learning	anonymous|nico_towards_better_benchmarking_for_domain_generalization	/pdf/90ae6288c0f9077cd784649ae5282e52cda6c168.pdf
9OEW_t2uO4u	394	CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable and Controllable Text-Guided Image Manipulation	['computer vision', 'text-guided image manipulation', 'latent manipulation']	We propose a novel approach to enforce better disentanglement, interpretability and controllability for text-guided image manipulation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|clippae_projectionaugmentation_embedding_to_extract_relevant_features_for_a_disentangled_interpretable_and_controllable_textguided_image_manipulation	/pdf/d8e79ba66b723b95d100c42a41062a2aec4e4564.pdf
zRCEbtS646c	395	Lossless Dataset Compression Via Dataset Quantization	['Dataset distillation', 'coreset selection']		Applications (eg, speech processing, computer vision, NLP)	anonymous|lossless_dataset_compression_via_dataset_quantization	/pdf/eded157830f6f93c529b4993368c3c822c4cf327.pdf
6Pv8AMSylux	396	DIVISION: Memory Efficient Training via Dual Activation Precision	['DNN training', 'activation compressed training', 'memory efficient training', 'frequency domain']	A simple and transparent framework to reduce the memory cost of DNN training.	Deep Learning and representational learning	anonymous|division_memory_efficient_training_via_dual_activation_precision	/pdf/564e4a080f91343360c2f9c756919e6cda023f92.pdf
DAxQXzdq8SF	397	SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series	['Contrastive Predictive Coding', 'Self-Organizing Maps', 'Time series', 'Dimensionality Reduction']	This work proposes SOM-CPC, an unsupervised model for interpretable 2D representation learning of high-rate time series.		anonymous|somcpc_unsupervised_contrastive_learning_with_selforganizing_maps_for_structured_representations_of_highrate_time_series	/pdf/defbb849d8a32af757272c9fffe384b862b81725.pdf
h2ktOJbrT_4	398	MiSAL: Active Learning for Every Budget	['Deep Active learning', 'Low budget', 'High budget', 'Deep learning']	Different budget sizes call for different active learning strategies; we introduce a practical method to determine in advance which strategy should be used and when.	Deep Learning and representational learning	anonymous|misal_active_learning_for_every_budget	/pdf/e7db27ffc793cf8a98a66db12ed505848cff8ea2.pdf
XqcQhVUr2h0	400	Limitless Stability for Graph Convolutional Networks 	['Graph Convolutional Networks', 'Graph Neural Networks', 'Stability', 'Transferability', 'Spectral Graph Theory', 'Rigorous Proofs']	We develop a general and novel stability theory for graph convolutional networks able to deal with undirected graphs as well as topology-changing perturbations	Deep Learning and representational learning	anonymous|limitless_stability_for_graph_convolutional_networks	/pdf/4a1613d37e7e61b38c5e2e4364f019aebdf9e08b.pdf
qQz1UKDCiy7	401	Momentum in Momentum for Adaptive Optimization	[]		Deep Learning and representational learning	anonymous|momentum_in_momentum_for_adaptive_optimization	/pdf/2fcd06470a20b8a82ef7891f897024955a7764c4.pdf
mfIX4QpsARJ	402	EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers	['Learning Fluid Mechanics', 'Simulation', 'Graph networks']	We introduce a new large-scale dataset for learning non-steady fluid mechanics and a method based on self-attention on graphs	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|eagle_largescale_learning_of_turbulent_fluid_dynamics_with_mesh_transformers	/pdf/1f967e23e445b175985eb55b12e56d2120bfcfe6.pdf
8l5GjEqGiRG	403	A Close Look at Token Mixer: From Attention to Convolution	['Convolution', 'Attention', 'Visual Representation']	We take a close look at two classical token-mixers, convolution and attention. Detailed comparison and visual analysis motivate us to present a novel fully convolutional vision transformer, which achieves promising performance on several benchmarks.	Deep Learning and representational learning	anonymous|a_close_look_at_token_mixer_from_attention_to_convolution	/pdf/5d1ae3ea738e5ca72ca6aadd0c1d2c8a3267d092.pdf
yi4vd8VqROx	404	Exploring Neural Network Representational Similarity using Filter Subspaces	[]		Deep Learning and representational learning	anonymous|exploring_neural_network_representational_similarity_using_filter_subspaces	/pdf/ce1b5699a4d46197d99eabbd432add81528c29ef.pdf
ylMq8MBnAp	408	Topology-aware robust optimization	['out-of-distribution generalization', 'distributionally robust optimization']	We propose a new principled optimization method that seamlessly integrates topological information to develop strong OOD resilience	Deep Learning and representational learning	anonymous|topologyaware_robust_optimization	/pdf/14494c159329c3729af72a32dc86c4c6201edb07.pdf
1C_kSW1-k0	409	STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK	['natural language understanding', 'question answering', 'structured explanations', 'soft reasoning', 'dataset']	We introduce STREET, a unified multi-task and multi-domain natural language reasoning and explanation benchmark.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|street_a_multitask_structured_reasoning_and_explanation_benchmark	/pdf/0a9cbdd5f6012483a7bb2b473e4b14cf5a782bf3.pdf
maT89nOQi9i	410	AdPE: Adversarial Positional Embeddings for Pretraining Vision Transformers via MAE+	['Self-Supervised Learning', 'Adversarial Pre-training', 'Positional Embedding']	We propose an Adversarial Positional Embedding (AdPE) approach for self-supervised learning.	Unsupervised and Self-supervised learning	anonymous|adpe_adversarial_positional_embeddings_for_pretraining_vision_transformers_via_mae	/pdf/f3ab030bb18a445f143e52933d6ba0bff56e3dc7.pdf
D6gktu1C7C_	411	Voting from Nearest Tasks: Meta-Vote Pruning of Pretrained Models for Downstream Tasks	[]		Deep Learning and representational learning	anonymous|voting_from_nearest_tasks_metavote_pruning_of_pretrained_models_for_downstream_tasks	/pdf/e106616eb38156beba3ddae07839a5b68e7bb711.pdf
gPWtHmCaBiY	412	Does Continual Learning Equally Forget All Parameters?	[]		Deep Learning and representational learning	anonymous|does_continual_learning_equally_forget_all_parameters	/pdf/ec484e785288a19b8efc6025420e0b9c217ef654.pdf
9U-cIq9P2p4	413	Learning Antidote Data to Individual Unfairness	['Individual Fairness', 'Antidote Data', 'Machine Learning Fairness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_antidote_data_to_individual_unfairness	/pdf/8451ce29ee20c6d1f61bd2a5d56323678a3c4cd1.pdf
wcNtbEtcGIC	415	Robust and Controllable Object-Centric Learning through Energy-based Models	[]		Deep Learning and representational learning	anonymous|robust_and_controllable_objectcentric_learning_through_energybased_models	/pdf/c68b261f8270c6e4aca91f0dbdd14614f9369fef.pdf
GMRodZ8OlVr	420	ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation	['Text', '3D shape', 'CLIP', 'differentiable rendering']	An efficient text-guided 3D shape generation framework without needing paired text and shape. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|iss_image_as_stepping_stone_for_textguided_3d_shape_generation	/pdf/2ea1427ac9af36e46bfe743b5df59ffd2e0ac86e.pdf
eySeuMAqICL	422	$1\times1$ Convolution is All You Need for Image Super-Resolution	['Single Image Super-Resolution', 'Lightweight Single Image Super-Resolution']	We exploit and demonstrate the effectiveness of the $1\times1$ convolution with spatial-shift  in SR task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|1\times1_convolution_is_all_you_need_for_image_superresolution	/pdf/378fdea419ac01ba638600889340de097461f52e.pdf
GLOtO2QbNp	423	Uncertainty Calibration via Knowledge Flow under Long-tailed Distribution	['Long-tailed', 'Calibration']	We propose a novel method to realize the calibration under long-tailed distribution	Deep Learning and representational learning	anonymous|uncertainty_calibration_via_knowledge_flow_under_longtailed_distribution	/pdf/2d8492bb3b300dbc8eb28fad9558f261f7d45653.pdf
NJENsJ37sQ	424	Empowering Networks With Scale and Rotation Equivariance Using A Similarity Convolution	['Representation Learning']		Deep Learning and representational learning	anonymous|empowering_networks_with_scale_and_rotation_equivariance_using_a_similarity_convolution	/pdf/89e10459c8ba897da6d16a46731b1903826ea89f.pdf
YhzSxtB3LNk	426	Contrastive Continuity on Augmentation Stability Rehearsal for Continual Self-Supervised Learning	['continual learning', 'self-supervised learning', 'continual self-supervised learning']	This paper proposes C$^2$ ASR to address catastrophic forgetting in continual self-supervised learning	Unsupervised and Self-supervised learning	anonymous|contrastive_continuity_on_augmentation_stability_rehearsal_for_continual_selfsupervised_learning	/pdf/4744b19a826ed1757796951aaf21e277bf45f4bc.pdf
8sqKEkAO3jv	427	A simple but effective and efficient global modeling paradigm for image restoration	['image restoration', 'image de-raining', 'image de-hazing', 'image enhancement']	This is the first attempt to propose a theoretically feasible, simple but effective global modeling paradigm for image restoration.	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_simple_but_effective_and_efficient_global_modeling_paradigm_for_image_restoration	/pdf/a91e45465d6f5a5b9d89e6dfe8e81448b11d0216.pdf
R8GW1hR1kE	428	Guide Detectors in Pixel Space with Global Positioning and Abductive Matching	['Object Detection', 'Abductive DETR']		Applications (eg, speech processing, computer vision, NLP)	anonymous|guide_detectors_in_pixel_space_with_global_positioning_and_abductive_matching	/pdf/0b1a91a770a8408fa806192088a18f99bba13459.pdf
KbYevcLjnc	429	PEER: A Collaborative Language Model	['Language Models', 'Controllability', 'Prompting', 'Zero-Shot Learning', 'Editing']	We introduce PEER, a language model trained to mimic the collaborative editing process by which humans often write text.	Applications (eg, speech processing, computer vision, NLP)	anonymous|peer_a_collaborative_language_model	/pdf/d6af055a3b417023ca21de7a9c5cf7da7b9bd040.pdf
sL8mQ4L_5L	430	FlexPose: Pose Distribution Adaptation with Few-shot Guidance	['Pose Adapation', 'Human Pose Detection', 'Few-shot']	We transfer a human pose distribution to another one with only few-shot guidance and apply it to multiple pose-based tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|flexpose_pose_distribution_adaptation_with_fewshot_guidance	/pdf/92b8a0d5de1797286e313f977e21089ee49588c3.pdf
dyr1wSqCZC	431	Structure-Sensitive Graph Dictionary Embedding for Graph Classification	['graph classification', 'variational inference', 'attention', 'mutual information']		Deep Learning and representational learning	anonymous|structuresensitive_graph_dictionary_embedding_for_graph_classification	/pdf/2a02a33a48d97360417650d15179b7aff4a72f4e.pdf
RecZ9nB9Q4	432	Sparse Mixture-of-Experts are Domain Generalizable Learners	['domain generalization', 'mixture-of-experts', 'algorithmic alignment', 'visual attributes']	We theoretically investigate the impact of backbone architecture on DG. We propose a novel SOTA model Generalizable Mixture-of-Experts (GMoE) for DG.	Deep Learning and representational learning	anonymous|sparse_mixtureofexperts_are_domain_generalizable_learners	/pdf/9926a30c93c6bfbe8b0235b9a28457f9b9ae384e.pdf
WmOF--p0PP	433	Efficient Covariance Estimation for Sparsified Functional Data	['functional data', 'covariance estimation', 'spatial correlation', 'convergence rate']	Novel sparsification schemes for functional data are proposed and the covariance estimation is shown to be asymptotically equivalent to sample covariance computed without sparsification.	General Machine Learning (ie none of the above)	anonymous|efficient_covariance_estimation_for_sparsified_functional_data	/pdf/0cc6d79d76d1604ea0ec93aec3a6f35fdee42728.pdf
oPYySRqti-	434	SWORD: Demystify the Secrets of Open-world Instance Recognition	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|sword_demystify_the_secrets_of_openworld_instance_recognition	/pdf/24a21bfa5b8691c20ad8098065f3b31080e6c8e8.pdf
gvMAooaEi3	436	Revisiting Higher-Order Gradient Methods for Multi-Agent Reinforcement Learning	['Multi-agent reinforcement learning', 'Higher-order gradient-based optimization']	We revisit the use of higher-order gradient information in multi-agent reinforcement learning, identify its limitations, and introduce novel approaches that extend its application scope to a broader range of problems.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|revisiting_higherorder_gradient_methods_for_multiagent_reinforcement_learning	/pdf/c13925d1f51b1263be94b3cd8ff77dbc38e94a0f.pdf
w1w4dGJ4qV	437	The Benefits of Model-Based Generalization in Reinforcement Learning	['model-based reinforcement learning', 'generalization']	We show how algorithms that generate experience with a learned parametric model can generalize in a way that is inherently more powerful than relying on value-function generalization and experience replay.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_benefits_of_modelbased_generalization_in_reinforcement_learning	/pdf/a08716c485dee902214f4a04aeb3a57c705c579d.pdf
IDJx97BC38	438	SQA3D: Situated Question Answering in 3D Scenes	['3D vision', 'scene understanding', 'visual question answering', 'embodied AI']	We introduce a grand challenge for embodied agents to understand situations and reason about 3D scenes accordingly.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|sqa3d_situated_question_answering_in_3d_scenes	/pdf/d16107fad28272b8ba0adffc5f604e87ab086af7.pdf
S8-A2FXnIh	439	Learning to Compose Soft Prompts for Compositional Zero-Shot Learning	['compositional zero-shot learning', 'prompts', 'foundation models']	We introduce compositional soft prompting (CSP), a parameter-efficient learning technique to improve the zero-shot compositionality of large-scale pretrained vision-language models (VLMs).	Deep Learning and representational learning	anonymous|learning_to_compose_soft_prompts_for_compositional_zeroshot_learning	/pdf/b8b063352e55eb5d29e602800a55b17a83721eb6.pdf
lZKBhpedXk	441	MultiWave: Multiresolution Deep Architectures through Wavelet Decomposition for Multivariate Timeseries Forecasting and Prediction	['Time series', 'Wavelets', 'Wavelet decomposition', 'Recurrent Neural Networks', 'Deep Learning']	In multivariate time-series datasets changes in signals occurs in different frequencies. MultiWave decomposes signals into different frequencies removes the irrelevant frequencies and models each group using a model component.	Deep Learning and representational learning	anonymous|multiwave_multiresolution_deep_architectures_through_wavelet_decomposition_for_multivariate_timeseries_forecasting_and_prediction	/pdf/e8ccd3496e72d4a226d4b4bd59ea2c8d8aca263f.pdf
9MniHf5dmH	443	Label Distribution Learning via Implicit Distribution Representation	['label distribution learning', 'implicit distribution', 'Gaussian distribution', 'self-attention algorithm']		Deep Learning and representational learning	anonymous|label_distribution_learning_via_implicit_distribution_representation	/pdf/f069b37b4da8ba3d3f0103293cab9ec7afe519d9.pdf
coMWK6WGkBP	444	3D-Scene-Entities: Using Phrase-to-3D-Object Correspondences for Richer Visio-Linguistic Models in 3D Scenes	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|3dsceneentities_using_phraseto3dobject_correspondences_for_richer_visiolinguistic_models_in_3d_scenes	/pdf/c4444f3bb616d5f8b06c7a08002f26178884ff30.pdf
pAcoOcnF__U	445	Token-Label Alignment for Vision Transformers	['Vision transformer', 'data mixing.']	We propose a token-label alignment method to improve the performance of vision transformers.	Deep Learning and representational learning	anonymous|tokenlabel_alignment_for_vision_transformers	/pdf/ddbb7cad3a93a5a2072fe57aec22101f31cbb4f0.pdf
LUdVQkS2CK	446	Gamma Sampling: Fine-grained Controlling Language Models without Training	['guided-decoding', 'fine-grained control', 'data-free', 'fast generation speed']	We propose a new simple guided decoding method which does not require any training data to achieve fine-grained controllable text generation while maintaining a fast generation speed.	Applications (eg, speech processing, computer vision, NLP)	anonymous|gamma_sampling_finegrained_controlling_language_models_without_training	/pdf/03c120e5f1733fb6d05feb6cd992080c25e1d4b3.pdf
lRgEbHxowq	447	Time Series are Images: Vision Transformer for Irregularly Sampled Time Series	['irregularly sampled time series', 'vision transformer']	We propose an approach that transforms time series data into line graph images and utilizes vision transformer to perform time series classification task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|time_series_are_images_vision_transformer_for_irregularly_sampled_time_series	/pdf/e4fcea99f1f46b5068df800f326eb1c84a626409.pdf
WumysvcMvV6	448	Mind the Gap: Offline Policy Optimizaiton for Imperfect Rewards	['offline policy optimization', 'imperfect rewards', 'reward gap']	This paper proposes an offline policy optimization approach for imperfect rewards.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|mind_the_gap_offline_policy_optimizaiton_for_imperfect_rewards	/pdf/89331d4889fb081d61cf3b35b2ca9d76a35cc92e.pdf
UkU05GOH7_6	449	Generating Diverse Cooperative Agents by Learning Incompatible Policies	['multi-agent systems', 'cooperation', 'collaboration', 'reinforcement learning', 'diversity', 'robustness']	We show that incompatible poclies are not similar. LIPO generates diverse cooperative partners by learning a population of incompatible policies.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|generating_diverse_cooperative_agents_by_learning_incompatible_policies	/pdf/2d65f2f1682f033a86aafcf00b8cdf163dfb63ba.pdf
Lv3MfAEgvVv	451	Hyperbolic Binary Neural Network	['Neural network quantization', 'Hyperbolic geometry', 'Riemannian manifold']	We propose a Hyperbolic Binary Neural Network that updates the parameters in hyperbolic space.	Deep Learning and representational learning	anonymous|hyperbolic_binary_neural_network	/pdf/a2c77a3a47fe5f9dd8148cbd930535592cba6a7e.pdf
vZTp1oPV3PC	452	One Transformer Can Understand Both 2D & 3D Molecular Data	['Transformer', 'general-purpose molecular model', '2D molecular representation', '3D molecular representation']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|one_transformer_can_understand_both_2d_3d_molecular_data	/pdf/2f4c0d4349fb0e8c076bb90e9e14bcfde7e6ad49.pdf
r9hNv76KoT3	453	Rethinking the Expressive Power of GNNs via Graph Biconnectivity	['Graph Neural Networks', 'Expressive Power', 'Weisfeiler-Lehman test', 'Graph Transformer', 'Biconnectivity']		Deep Learning and representational learning	anonymous|rethinking_the_expressive_power_of_gnns_via_graph_biconnectivity	/pdf/f15c22084aef6564f79f0b36d080a3843d99aa5d.pdf
oWbTcqr8g7	458	Selective Classification Via Neural Network Training Dynamics	['selective classification', 'example difficulty', 'reject option', 'training dynamics', 'optimization']	We propose a novel selective classification algorithm in which we derive a score based on the label disagreement of intermediate models obtained during training.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|selective_classification_via_neural_network_training_dynamics	/pdf/0b566006d6dea2d8dcdea42d22ebdce5e7e2299c.pdf
BLBulxMHuOp	459	Decomposing Texture and Semantics for Out-of-distribution Detection	['Out-of-distribution detection', 'Fourier analysis', 'Normailzing flow model']	We propose a novel OOD detection framework that decomposes the definition of the in-distribution as texture and semantics. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|decomposing_texture_and_semantics_for_outofdistribution_detection	/pdf/1d5a7af3692533469a9e6d4ddf4f17a6cd13c192.pdf
g4PH7bjVZWC	460	Convergence of the mini-batch SIHT algorithm	['mini-batch gradient', 'sparse optimization', 'iterative hard thresholding', 'IHT', 'SIHT', 'mini-batch']	This paper provides stochastic convergence analysis of the mini-batch stochastic hard thresholding algorithm	Optimization (eg, convex and non-convex optimization)	anonymous|convergence_of_the_minibatch_siht_algorithm	/pdf/92f1930671092abf03fd1f5b0d58ef1f4253e5e7.pdf
nZ5_rXpikfK	461	Hierarchical Prompting Improves Visual Recognition On Accuracy, Data Efficiency and Explainability	['hierarchical prompting', 'visual recognition', 'vision transformer']	Hierarchical prompting improves visual recognition on accuracy, data efficiency and explainability.	Applications (eg, speech processing, computer vision, NLP)	anonymous|hierarchical_prompting_improves_visual_recognition_on_accuracy_data_efficiency_and_explainability	/pdf/892bb9f9b093712518b9c5bdff2d17076e8ff42c.pdf
QjQibO3scV_	462	Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching	['Graph Matching', 'Reinforcement Learning', 'Quadratic Assignment', 'Affinity Regularization', 'Combinatorial Optimization.']		Applications (eg, speech processing, computer vision, NLP)	anonymous|revocable_deep_reinforcement_learning_with_affinity_regularization_for_outlierrobust_graph_matching	/pdf/e9cee12a15d452dfb1fd3724dca1da60cbd07852.pdf
U2WjB9xxZ9q	463	3D generation on ImageNet	['3d-generation', 'gans', 'generative adversarial networks', 'knowledge distillation', 'nerf', 'stylegan', 'radiance fields', 'volume rendering']	3D generation on ImageNet	Generative models	anonymous|3d_generation_on_imagenet	/pdf/804888c7ef6e169dc16fd9f2e402f48dbb9e1e9b.pdf
RKiWwhocuiU	464	Domain Generalization with Small Data	['domain generalization', 'small data', 'healthcare', 'medical image']	 A novel domain generalization method in the context of insufficient data is proposed in this work	Applications (eg, speech processing, computer vision, NLP)	anonymous|domain_generalization_with_small_data	/pdf/fd454641e8dc88b7f3facee9154312bcbb85d8fc.pdf
ZytN-E8vZk	466	Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution	['Curriculum RL', 'Morphology Evolution']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|curriculum_reinforcement_learning_via_morphologyenvironment_coevolution	/pdf/526541eb8de95e1491a4ad6c997c9e24c76a05b9.pdf
pG9RSmBrY3	467	Formulating and Proving the Trend of DNNs Learning Simple Concepts	['representation complexity', 'deep neural network']	We theoretically prove and empirically verify that DNNs mainly learn simple interactive concepts.	Deep Learning and representational learning	anonymous|formulating_and_proving_the_trend_of_dnns_learning_simple_concepts	/pdf/d1455d987b54e020bafb5493be0f317adf498c0d.pdf
S3D9NLzjnQ5	469	Distilling Cognitive Backdoor within an Image	['Backdoor sample detection', 'Backdoor defence']	A novel method effectively and robustly detect backdoor samples in the dataset. 	Deep Learning and representational learning	anonymous|distilling_cognitive_backdoor_within_an_image	/pdf/71827e5ce9102a49bd37635fdc0b5cdc04a95e1c.pdf
oPnpibcro8	470	An information-theoretic approach to unsupervised keypoint representation learning	['representation learning', 'keypoint discovery', 'unsupervised learning']	A novel information-theoretic approach to unsupervised keypoint representation learning from videos leveraging local entropy coverage and information transportation maximization.	Unsupervised and Self-supervised learning	anonymous|an_informationtheoretic_approach_to_unsupervised_keypoint_representation_learning	/pdf/9f0b1aa98f757407a46d42801e8af0a9083d4f89.pdf
Qx8lUU8CzQ	471	VectorMapNet: End-to-end Vectorized HD Map Learning	['Autonomous Driving', 'Map Learning', 'Transformer']	We proposed an end-to-end method that directly generate vectorized map from sensor data.	Applications (eg, speech processing, computer vision, NLP)	anonymous|vectormapnet_endtoend_vectorized_hd_map_learning	/pdf/f518ae500a2da010ba533bc000508384385b9c10.pdf
2OETPKmG4S0	473	On the Lower Bound of Minimizing Polyak-Łojasiewicz functions	['Polyak-Łojasiewicz Condition', 'First-order Algorithms', 'Lower Bound', 'Complexity']	We show that any first-order algorithm requires at least  $\tilde{\Omega}\left((L/\mu)^{1-\alpha} \right)$  gradient costs to find an $\epsilon$-approximate optimal solution for a general $L$-smooth, $\mu$-PL function for any $\alpha>0$ .	Optimization (eg, convex and non-convex optimization)	anonymous|on_the_lower_bound_of_minimizing_polyakojasiewicz_functions	/pdf/e733d9d23da29336fec0b11cb0db419828c6f0b6.pdf
LoJ6oXzc_P3	474	Stealing and Defending Transformer-based Encoders	['model stealing', 'model extraction', 'defenses against model extraction', 'transformers', 'encoders', 'self-supervised learning']	We perform attacks against transformer-based encoders and propose a new defense against extraction of vision transformers that combines watermarking with dataset inference.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|stealing_and_defending_transformerbased_encoders	/pdf/6f7f3fd43d48ca71b920196504b7bb87262ee0d5.pdf
65XDF_nwI61	476	ModelAngelo: Automated Model Building for Cryo-EM Maps	['cryo-em', 'model building', 'graph neural networks', 'attention networks', 'proteins']	Using graph neural networks to automatically build atomic models in cryo-EM maps	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|modelangelo_automated_model_building_for_cryoem_maps	/pdf/d700700cf11359beb36d72ad456e524d457c4635.pdf
L8iZdgeKmI6	477	Twofer: Tackling Continual Domain Shift with Simultaneous Domain Generalization and Adaptation	['Domain Generalization', 'Domain Adaptation']	To tackle continual domain shift in real-world applications, this work proposes a novel framework for achieving target domain generalization, target domain adaptation, and forgetting compensation at the same time.	Deep Learning and representational learning	anonymous|twofer_tackling_continual_domain_shift_with_simultaneous_domain_generalization_and_adaptation	/pdf/f91d2f88593e226aa0e2728c5c8f390050229531.pdf
vv6siYLQJqS	478	Neural Sorting Networks with Error-Free Differentiable Swap Functions	[]		Deep Learning and representational learning	anonymous|neural_sorting_networks_with_errorfree_differentiable_swap_functions	/pdf/5563a5c50ae8bf059399d24665159296a5fc9bcc.pdf
SZBy3XeXQvd	479	LSAP: Rethinking Inversion Fidelity, Perception and Editability in GAN Latent Space	[]		Generative models	anonymous|lsap_rethinking_inversion_fidelity_perception_and_editability_in_gan_latent_space	/pdf/7176018840610ad7caca858ec13ab67ea2e9dc3e.pdf
b_CQDy9vrD1	480	ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills	['object manipulation', 'benchmark', 'computer vision', 'robotics', 'reinforcement learning']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|maniskill2_a_unified_benchmark_for_generalizable_manipulation_skills	/pdf/af9d3468d7a56221ffb6d17541e082c94ba336a4.pdf
IajGRJuM7D3	483	Stable, Efficient, and Flexible Monotone Operator Implicit Graph Neural Networks	['implicit graph neural networks', 'monotone operator', 'accelerated operator splitting', 'orthogonal parameterization']	We propose stable, efficient, and flexible implicit graph neural networks leveraging monotone operator theory	Deep Learning and representational learning	anonymous|stable_efficient_and_flexible_monotone_operator_implicit_graph_neural_networks	/pdf/2ab78414e1bdbd42a63b93f5a5d4b912f4fc6559.pdf
BgMo9ofIQi6	484	GENERALIZED MATRIX LOCAL LOW RANK REPRESENTATION BY RANDOM PROJECTION AND SUBMATRIX PROPAGATION	['Matrix decomposition', 'Local Low Rank matrix detection', 'Representation learning', 'Subspace learning']	We developed a sub-matrix propagation based approach to solve the fundamental mathematical problem of matrix local low rank representation.	General Machine Learning (ie none of the above)	anonymous|generalized_matrix_local_low_rank_representation_by_random_projection_and_submatrix_propagation	/pdf/b0f398213087ced361c7136cd33800f94b074f47.pdf
Q2WE65ToiLT	485	A Fairness Analysis on Differentially Private Aggregation of Teacher Ensembles	['Differential Privacy', 'Fairness', 'Semisupervised learning']	This paper analyzes the causes of the disparate impacts arising in a popular teacher ensemble model used for differentially private learning tasks	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_fairness_analysis_on_differentially_private_aggregation_of_teacher_ensembles	/pdf/e7043c7f7f22d64db7c930d737da5aa94b6c1e63.pdf
tHsu1olr9ZcQ	486	Variational Reparametrized Policy Learning with Differentiable Physics	['Differentiable Physics Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|variational_reparametrized_policy_learning_with_differentiable_physics	/pdf/2d329efdc5c95d2a5fe4df607ad54ac428aff694.pdf
3KWnuT-R1bh	488	Conditional Positional Encodings for Vision Transformers	['Vision Transformer']	A conditional positional encoding scheme for vision transformers	Deep Learning and representational learning	anonymous|conditional_positional_encodings_for_vision_transformers	/pdf/74f38676d27656cbd82985c3a7be9c35fb22ee03.pdf
zUN76iFTyfi	490	Unfixed Bias Iterator: A New Iterative Format	['Partial differential equations', 'iterators', 'deep learning']	A deep learning-based unfixed bias iterator for solving partial differential equations.		anonymous|unfixed_bias_iterator_a_new_iterative_format	/pdf/45569275199e0fe3a67f23cf21d2656b4046201a.pdf
LdQUvGLk7yU	492	Tree Structure LSTM for Chinese Named Entity Recognition	['LSTM', 'NER', 'dependency parsing', 'tree structure', 'Chinese']			anonymous|tree_structure_lstm_for_chinese_named_entity_recognition	/pdf/8d6082834c5023dc2fd2748ad9f310cf863f79a7.pdf
bds4tm-XK2I	493	Graph Contrastive Learning with Personalized Augmentation	[]		Unsupervised and Self-supervised learning	anonymous|graph_contrastive_learning_with_personalized_augmentation	/pdf/7aee81efa5d3dd6f90bd4e543cbd7e86a4ccd505.pdf
DSy8tP4WctmZ	495	Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction	['Surface Reconstruction', 'Neural Radiance Field']	We present Voxurf, a voxel-based approach for efficient and accurate neural surface reconstruction.	Deep Learning and representational learning	anonymous|voxurf_voxelbased_efficient_and_accurate_neural_surface_reconstruction	/pdf/e6e27478d38991eb6c4eba2ef18096ab9805bc00.pdf
1NAzMofMnWl	496	Benchmarking Deformable Object Manipulation with Differentiable Physics	['deformable object manipulation', 'differentiable physics', 'benchmark']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|benchmarking_deformable_object_manipulation_with_differentiable_physics	/pdf/562352723a1ac29b68d8d56e8394ecb4a3ea2ff6.pdf
HG0SwOmlaEo	498	Clustering Structure Identification With Ordering Graph	[]		Unsupervised and Self-supervised learning	anonymous|clustering_structure_identification_with_ordering_graph	/pdf/57ecd793799f92b05ce216e098d0bda9546ee157.pdf
88Z7kxbZLL3	499	Semi-Supervised Semantic Segmentation via Boosting Uncertainty on Unlabeled Data	['Semantic Segmentation', 'Semi-supervised Learning', 'Uncertainty in Deep Learning']	We theoretically analyze and experimentally prove that appropriately boosting uncertainty on unlabeled data can help minimize the distribution gap in semi-supervised semantic segmentation.	Deep Learning and representational learning	anonymous|semisupervised_semantic_segmentation_via_boosting_uncertainty_on_unlabeled_data	/pdf/6e6917b035e00ea624b0b75f463949008733850e.pdf
UP_GHHPw7rP	500	Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game	['RL theory']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|nearly_minimax_optimal_offline_reinforcement_learning_with_linear_function_approximation_singleagent_mdp_and_markov_game	/pdf/70739541210cf7e6133281a864362e3269922b2a.pdf
0sjwFxqLHw3	501	Spurious Local Minima Provably Exist for Deep Convolutional Neural Networks	['theoretical issues in deep learning']	We prove that a general class of spurious local minima exist in the loss landscape of deep convolutional neural networks with squared loss or cross-entropy loss.	Optimization (eg, convex and non-convex optimization)	anonymous|spurious_local_minima_provably_exist_for_deep_convolutional_neural_networks	/pdf/8fc10f3aab4f46e520b95053b81c03d483fa829e.pdf
g7U9jD_2CUr	503	EVA3D: Compositional 3D Human Generation from 2D Image Collections	['3D Human Generation', 'Human NeRF', 'Inverse Graphics']	We propose EVA3D, a high-quality unconditional 3D human generative model learned from 2D image collections.	Generative models	anonymous|eva3d_compositional_3d_human_generation_from_2d_image_collections	/pdf/234b2468a5453a578f2d806d5ceb6af9ff12220e.pdf
9HFobmKAmGv	504	A Class-Aware Representation Refinement Framework for Graph Classification	['Graph Neural Network', 'Representation Learning', 'Graph Classification']	CARE computes simple yet powerful class representations and injects them to steer the learning of graph representations towards better class separability	Deep Learning and representational learning	anonymous|a_classaware_representation_refinement_framework_for_graph_classification	/pdf/2a431f13815c8ae53f5688dba2461dd8939649c6.pdf
4vGwQqviud5	505	DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models	['diffusion probabilistic models', 'score-based generative models', 'fast sampling', 'guided sampling']	We propose a fast ODE solver for guided sampling of diffusion probabilistic models in around 15 to 20 steps.	Generative models	anonymous|dpmsolver_fast_solver_for_guided_sampling_of_diffusion_probabilistic_models	/pdf/e374e8107ca47790d1594345d28a6253df02261d.pdf
gwizseh-Iam	506	Learning Axis-Aligned Decision Trees with Gradient Descent	['Decision Trees', 'Gradient Descent']	A novel approach to learn univariate, axis-aligned decision trees with gradient descent using a dense tree representation and an adjusted backpropagation algorithm.	General Machine Learning (ie none of the above)	anonymous|learning_axisaligned_decision_trees_with_gradient_descent	/pdf/b440df836a60318577aaed7725dc3d4465046ba5.pdf
vE93gf9kYkf	507	Active Learning with Controllable Augmentation Induced Acquisition	['active learning', 'data augmentation', 'strength']		General Machine Learning (ie none of the above)	anonymous|active_learning_with_controllable_augmentation_induced_acquisition	/pdf/e57de4b5ec1894350938355de509591f0351a33b.pdf
-z9hdsyUwVQ	508	Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies	['Discounted Markov decision process', 'natural policy gradient', 'policy mirror descent', 'log-linear policy', 'sample complexity']	We show linear convergence of natural policy gradient methods with log-linear policies without any regularization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|linear_convergence_of_natural_policy_gradient_methods_with_loglinear_policies	/pdf/042a0667c116407c2ae1be672db3b4e34868ee1b.pdf
3Y5Uhf5KgGK	510	No Reason for No Supervision: Improved Generalization in Supervised Models	['supervised learning', 'transfer learning', 'representation learning']		Deep Learning and representational learning	anonymous|no_reason_for_no_supervision_improved_generalization_in_supervised_models	/pdf/8cb27427f364c016551d66020fe24e298a8a9918.pdf
Khh7jHEJJFX	511	Uncertainty-Driven Active Vision for Implicit Scene Reconstruction	['Neural Rendering', '3D Reconstruction', 'Scene Reconstruction', 'Next Best View', 'Uncertainty Estimation']	We use neural rendering to approximate the observable uncertainty of an occupancy based scene reconstruction model, which we use to select camera parameters for a next-best-view task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|uncertaintydriven_active_vision_for_implicit_scene_reconstruction	/pdf/76afc4fd5235c3bfdbb4a16673161f191cc0771a.pdf
V3GQRhBzEi	512	Generalizability of Adversarial Robustness Under Distribution Shifts	['domain generalization', 'adversarial robustness']	We study the generalizability of empirical and certified robustness to unseen domains.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|generalizability_of_adversarial_robustness_under_distribution_shifts	/pdf/6488063e15fee85d722382ae7fb116019cc8617c.pdf
WcSm-iommPR	513	Prompt-driven efficient Open-set Semi-supervised Learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|promptdriven_efficient_openset_semisupervised_learning	/pdf/e87c9ff824565e306a1a01086433aa0191fd7af3.pdf
a3-QYAgcDBl	514	 Topologically faithful image segmentation via induced matching of persistence barcodes	['Topology', 'Segmentation', 'Machine Learning']	In this work, we propose the first topologically and feature-wise, spatially accurate metric and loss function for supervised image segmentation.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|topologically_faithful_image_segmentation_via_induced_matching_of_persistence_barcodes	/pdf/ddd32aaa6bd7a64b32f1bb563f5cc684f13ac689.pdf
UVKwsWsXTt	515	Learning Lightweight Object Detectors via Progressive Knowledge Distillation	['object detection', 'knowledge distillation']	We propose a progressive approach to distill knowledge from multiple teacher detectors into a lightweight student.	Deep Learning and representational learning	anonymous|learning_lightweight_object_detectors_via_progressive_knowledge_distillation	/pdf/b7bddf30ee55052cd8cb5cb1a490c4ead65bfc53.pdf
HTbp9Y7g9P	516	Hard Regularization to Prevent Collapse in Online Deep Clustering without Data Augmentation	['deep learning', 'clustering', 'online']	regularizing hard cluster assignments with a Bayesian optimization problem to prevent collapse in online deep clustering without data augmentaiton	Unsupervised and Self-supervised learning	anonymous|hard_regularization_to_prevent_collapse_in_online_deep_clustering_without_data_augmentation	/pdf/12793c92727652f2b54cc2680ab98b9009dfabd8.pdf
3zSn48RUO8M	518	What shapes the loss landscape of self supervised learning?	['loss landscape', 'self-supervised learning', 'collapse']	We analytically solve the loss landscape of self-supervised learning and identify the causes of complete and dimensional collapse	Deep Learning and representational learning	anonymous|what_shapes_the_loss_landscape_of_self_supervised_learning	/pdf/f1ef5c325fcd00f11642a0abfe6b5ed957463294.pdf
lJsr4DwZm1z	525	Set Discrimination Contrastive Learning	['self-supervised learning', 'contrastive learning']	We propose a method that integrates the concept of set representation learning to improve self-supervised visual representation learning	Unsupervised and Self-supervised learning	anonymous|set_discrimination_contrastive_learning	/pdf/e2b841781105f92b32fc87fc371f0961db35a117.pdf
sNKZaNkyi7Q	526	Provable Benefits of Representational Transfer in Reinforcement Learning	['reinforcement learning theory', 'representation learning', 'transfer learning']	We present an algorithm that performs efficient transfer learning in low-rank MDPs, and provide sample complexity bounds under minimal assumptions.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|provable_benefits_of_representational_transfer_in_reinforcement_learning	/pdf/83526355e09b6d26470b1e4aa3966ffea4a726d7.pdf
pkgVPeL9gpX	527	Revisiting Group Robustness: Class-specific Scaling is All You Need	['Group robustness', 'spurious correlation', 'debiasing', 'worst-group accuracy', 'unbiased accuracy', 'performance evaluation']	We propose a simple class-specific scaling strategy to control the trade-off between robust and average accuracies, and based on this, we develop a comprehensive performance evaluation metric and advanced algorithm to improve the trade-off.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revisiting_group_robustness_classspecific_scaling_is_all_you_need	/pdf/fe174045e9fec59bbd0b2c6ce35b6e7a5ab0db2a.pdf
R_OL5mLhsv	528	Interpretability with full complexity by constraining feature information	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|interpretability_with_full_complexity_by_constraining_feature_information	/pdf/b17312a9c5cfb44f6e9c80f8cdf729f01cd53429.pdf
h9yn69de6f	529	Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|metaevolve_continuous_robot_evolution_for_onetomany_policy_transfer	/pdf/d45fbdfb5cf689f21d4e277eb8b677a99a6438e4.pdf
K5si8PjaSy	530	Explainable Artificial Intelligence: Reaping the Fruits of Decision Trees	['Explainable artificial intelligence', 'XAI', 'decision trees', 'explainability', 'neural networks', 'pruning']	This work assessed node weight patterns toward explaining artificial intelligence systems.		anonymous|explainable_artificial_intelligence_reaping_the_fruits_of_decision_trees	/pdf/b5c47b03bb3ce0b14b76739a6f3345743b131aa1.pdf
lfzmAJ12sg	533	SELF-SUPERVISED PRETRAINING FOR DIFFERENTIALLY PRIVATE LEARNING	['differential privacy', 'contrastive learning', 'learned features', 'one image']	We demonstrate self-supervised pretraining is a scalable solution to deep learning with differential privacy regardless of the size of available public datasets in image classification.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|selfsupervised_pretraining_for_differentially_private_learning	/pdf/85f808ba1570d5704028b769ee3417fe7b512658.pdf
_QZlje4dZPu	534	Supervised Contrastive Regression	['regression', 'regression learning']		General Machine Learning (ie none of the above)	anonymous|supervised_contrastive_regression	/pdf/9048c679470c96926fd8d67688e209954bc1515f.pdf
zNq-jISUm7E	535	Q-Match: Self-Supervised Learning For Tabular Data by Matching Distributions Induced by a Queue	['self-supervised learning', 'deep learning for tabular data']	A self-supervised method to train models by minimizing the cross-entropy loss between student-teacher distributions generated using a queue of embeddings. This results in better downstream task performance with less labeled data.	Unsupervised and Self-supervised learning	anonymous|qmatch_selfsupervised_learning_for_tabular_data_by_matching_distributions_induced_by_a_queue	/pdf/5517f2e24de4bc2280a26f8b46c9fce9c72f56ac.pdf
W5U_xEGOaIY	536	Block-level Stiffness Analysis of Residual Networks	['resnets', 'stiffness', 'ordinary differential equations']	In this paper we are the first ones to connect the concepts of stiffness and ResNets via the dynamical systems interpretation to propose that ResNets can be viewed as stiff ODEs.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|blocklevel_stiffness_analysis_of_residual_networks	/pdf/c894feb463ed37d5cc8d162cc536ef32cec703a4.pdf
2QGJXyMNoPz	537	MocoSFL: enabling cross-client collaborative self-supervised learning	['Self-supervised Learning', 'Collaborative Learning', 'Split Federated Learning', 'Momentum Contrast']	Existing collaborative SSL schemes are not suitable for cross-client applications because of their expensive computation and local data requirements. To address these issues, we propose MocoSFL based on Split Federated Learning and MoCo.	Unsupervised and Self-supervised learning	anonymous|mocosfl_enabling_crossclient_collaborative_selfsupervised_learning	/pdf/f8c5942685939627e954b3b8871510b49a07ab65.pdf
N92hjSf5NNh	538	MECTA: Memory-Economic Continual Test-Time Model Adaptation	['continual test-time adaptation', 'memory efficiency']		Unsupervised and Self-supervised learning	anonymous|mecta_memoryeconomic_continual_testtime_model_adaptation	/pdf/bdfca91f5fc7094d9c7a3b0717871a4b25ee6712.pdf
FLMvYXMucWk	539	Temporary feature collapse phenomenon in early learning of MLPs	['Neural Networks', 'Deep Learning Theory', 'Multi-Layer Perceptrons']	In this paper, we focus on a typical two-phase phenomenon in the learning of multi-layer perceptrons (MLPs), and we discover and explain the reason for the feature collapse in the first phase.	Deep Learning and representational learning	anonymous|temporary_feature_collapse_phenomenon_in_early_learning_of_mlps	/pdf/782557808f47d7307f66fe1b583ccc6e24b1f346.pdf
Mwpw3weZrK8	540	GAIN: Enhancing Byzantine Robustness in Federated Learning with Gradient Decomposition	['Federated Learning', 'Byzantine Robustness.']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|gain_enhancing_byzantine_robustness_in_federated_learning_with_gradient_decomposition	/pdf/6d20e45d14a79099814c8421b9455b4900555533.pdf
u6t9zT8h3p5	541	MMCAP: LEARNING TO BROAD-SIGHT NEURAL NETWORKS BY CLASS ATTENTION POOLING	['class attention', 'global average pooling', 'visual recognition', 'over-concentration', 'feature variance']		Deep Learning and representational learning	anonymous|mmcap_learning_to_broadsight_neural_networks_by_class_attention_pooling	/pdf/8b57a5ef34e6b0e6b22d87669f87e5b61eb4a826.pdf
yotPBsMyfTe	542	QFuture: Learning Future Expectations in Multi-Agent Reinforcement Learning	['multi-agent reinforcement learning', 'future expectations learning', 'value decomposition', 'mutual information']	future expectations learning	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|qfuture_learning_future_expectations_in_multiagent_reinforcement_learning	/pdf/2075568c390f7b3604974039b8ff79054175cee0.pdf
NRHajbzg8y0P	544	Multimodal Analogical Reasoning over Knowledge Graphs	['knowledge graph', 'multimodal', 'analogical reasoning', 'prompt learning', 'pre-trained language model']	Multimodal analogical reasoning over knowledge graphs with a new dataset MARS and a new framework MarT.	Applications (eg, speech processing, computer vision, NLP)	anonymous|multimodal_analogical_reasoning_over_knowledge_graphs	/pdf/b99fc4398541c03b5422a6a97ec078d4cde2c641.pdf
Om_QvnjjBL2	545	D2Match: Leveraging Deep Learning and Degeneracy for  Subgraph Matching	[]		Deep Learning and representational learning	anonymous|d2match_leveraging_deep_learning_and_degeneracy_for_subgraph_matching	/pdf/e4ed3416259abb319ef609eeb510a2fb15688341.pdf
YnVpYUjzVHC	546	Consistent and Truthful Interpretation with Fourier Analysis	['AI Interpretability']	We find that the previous attribution methods are not consistent with neighborhood predictions, and introduce a new framework with an efficient algorithm to support consistency. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|consistent_and_truthful_interpretation_with_fourier_analysis	/pdf/d9eb10bcc891ca9b136d37937372b4f88feaa01c.pdf
E67OghNSDMf	547	SepRep-Net: Multi-source Free Domain Adaptation via Model Separation and Reparameterization	['multi-source free domain adaptation', 'generalized domain adaptation']	We introduce a general approach to multi-source free domain adaptation via model separation and reparameterization, which enhances effectiveness, efficiency and generalizability. 	Deep Learning and representational learning	anonymous|seprepnet_multisource_free_domain_adaptation_via_model_separation_and_reparameterization	/pdf/e38a36f76951be9bc65a61566d1926323b6da313.pdf
3TfSOxiRiFH	549	On a Built-in Conflict between Deep Learning and Systematic Generalization	['out-of-distribution generalization', 'systematic generalization', 'compositional generalization']		Deep Learning and representational learning	anonymous|on_a_builtin_conflict_between_deep_learning_and_systematic_generalization	/pdf/89ef0527596aee986cc3e1067739337271fd5a4d.pdf
lL8LF0O8Y2	550	DeSCo: Towards Scalable Deep Subgraph Counting	['subgraph counting', 'graph neural network', 'graph mining']	We propose DeSCo, a neural-based deep subgraph counting framework aims to accurately predict count of query graphs on any given target graph.	Applications (eg, speech processing, computer vision, NLP)	anonymous|desco_towards_scalable_deep_subgraph_counting	/pdf/131e28fb4c9a6099b45bbb4a3f0571c002a46357.pdf
BnznzofWMi	552	Representation Mutual Learning for End-to-End Weakly-Supervised Semantic Segmentation	['Weakly Supervised Semantic Segmentation', 'Representation Mutual Learning', 'End-to-End']	An efficient and decoder-free Representation Mutual Learning (RML) framework for WSSS that combines instance-level, feature-level and pixel-level mutual learning strategies to improve segmentation quality.	Deep Learning and representational learning	anonymous|representation_mutual_learning_for_endtoend_weaklysupervised_semantic_segmentation	/pdf/c2cd8a5a125ef8bec23386eedd168a16a4f0ac87.pdf
frE4fUwz_h	553	Spikformer: When Spiking Neural Network Meets Transformer 	['Transformer', 'Spiking Neural Network']		Deep Learning and representational learning	anonymous|spikformer_when_spiking_neural_network_meets_transformer	/pdf/1c3a638b7ec494cba3602897939b6761b332e83c.pdf
p0MBhpO5wQ	556	Rethinking the Explanation of Graph Neural Network via Non-parametric Subgraph Matching	['Graph Neural Networks', 'Graph Matching', 'Explanation']		Deep Learning and representational learning	anonymous|rethinking_the_explanation_of_graph_neural_network_via_nonparametric_subgraph_matching	/pdf/9d53b55fbc0dadcccdcb198a65f156a5b7d0ca03.pdf
TUhgwGQBtE	557	Do Not Train It: A Linear Neural Architecture Search of Graph Neural Networks	['Neural Architecture Search', 'Graph neural network', 'Automated Machine Learning']		Deep Learning and representational learning	anonymous|do_not_train_it_a_linear_neural_architecture_search_of_graph_neural_networks	/pdf/457f0afafa7222c885c0f6c32407b6f0d006fa72.pdf
gULfK60oYr1	560	Never Revisit: Continuous Exploration in Multi-Agent Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|never_revisit_continuous_exploration_in_multiagent_reinforcement_learning	/pdf/d4d3bae64334090d7f29000fa59ae1af74b1df20.pdf
k2Ml8FGtJZp	563	A Massively Parallel Benchmark for Safe Dexterous Manipulation	['Dexterous Manipulation', 'Safe Reinforcement Learning', 'Robot Learning']	Safety Dexteroushands is the first large-scale task collection focused on safe dexterous manipulation, offering 10+ manipulators and 100+ task combinations.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_massively_parallel_benchmark_for_safe_dexterous_manipulation	/pdf/b8adbc01468a94f3babc72e3a6f3c1509f732171.pdf
5tKhUU5WBi8	564	Out-of-distribution Detection with Diffusion-based Neighborhood	['OOD detection', 'diffusion model']	We design a general strategy to combine a diffusion model and a Resnet to do OOD detection.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|outofdistribution_detection_with_diffusionbased_neighborhood	/pdf/2a4e90d84b4b6b004bbe8d8d5ed40ce6b031acb7.pdf
apZRm_0VClK	565	NASiam: Efficient Representation Learning using Neural Architecture Search for Siamese Networks	['Neural Architecture Search', 'Self-Supervised Learning', 'Representation Learning', 'Siamese Networks', 'Computer Vision']	A novel method improving Siamese Networks architecture using Neural Architecture Search.	Unsupervised and Self-supervised learning	anonymous|nasiam_efficient_representation_learning_using_neural_architecture_search_for_siamese_networks	/pdf/dd3652198e34b1751a2ad347d684fcff5cfb5626.pdf
4inSu6mXdZk	568	Multiscale Neural Operator: Learning Fast and Grid-independent PDE Solvers	['physics-informed machine learning', 'pinns', 'scientific machine learning', 'neural ODEs', 'neural operators', 'machine learning', 'neural networks', 'Matryoshka', 'multiphysics', 'multiscale', 'parametrizations', 'closure', 'subgrid', 'superstructures', 'partial differential equations', 'PDEs', 'differential equations', 'numerical solvers', 'physics', 'hpc', 'surrogate', 'reduced order modeling', 'model reduction', 'uncertainty quantification', 'climate', 'fluid dynamics', 'physics', 'computational physics']	We are the first to embed grid-independent neural operators as closure model or parametrization in physical simulations -- in doing so we created a fast and accurate surrogate of multiscale PDEs.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|multiscale_neural_operator_learning_fast_and_gridindependent_pde_solvers	/pdf/edf1540d5895915e02393174729f4bcaee5c3357.pdf
u_-XxuTcnJ7	572	CoGANs: Collaborative Generative Adversarial Networks	['GANs', 'Multiple generators']	We introduce a new method to train multi-generator GANs which manages to beat the state-of-the-art for MNIST	Generative models	anonymous|cogans_collaborative_generative_adversarial_networks	/pdf/4708805d7761690282c93baa5fd0ec5f4f0a80e5.pdf
5ZLWi--i57	573	BQ-NCO: Bisimulation Quotienting for Generalizable Neural Combinatorial Optimization	[]	A generic formulation of Combinatorial Optimization problems as MDP, and pre-processing steps to improve it, with experiments on routing problems	Deep Learning and representational learning	anonymous|bqnco_bisimulation_quotienting_for_generalizable_neural_combinatorial_optimization	/pdf/215b6b0f50d0153121017c313b255f103b1bc9dd.pdf
15fiz99C8B	574	Look Back When Surprised: Stabilizing Reverse Experience Replay for Neural Approximation	['Experience Replay', 'Reinforcement Learning']	We propose a new experience replay which outperforms previous SOTA on most environments 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|look_back_when_surprised_stabilizing_reverse_experience_replay_for_neural_approximation	/pdf/85d39beca769db1ce9797f8a3b52070d3d224c3a.pdf
xKlCpphHAsg	575	Expected Perturbation Scores for Adversarial Detection	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|expected_perturbation_scores_for_adversarial_detection	/pdf/af08a5c16742445eae2668726ced738b6e962cba.pdf
s4WVupnJjmX	577	Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation	['Multi-person Pose Estimation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|explicit_box_detection_unifies_endtoend_multiperson_pose_estimation	/pdf/8cc84c31e79015a74dcc904da58b30f59ea0d836.pdf
PLUXnnxUdr4	578	Graph Contrastive Learning for Skeleton-based Action Recognition	['Skeleton-based Action Recognition']	For GCN-based methods in skeleton-based action recognition, this work extends the graph learning from using intra-sequence local context to exploring cross-sequence global context.	Applications (eg, speech processing, computer vision, NLP)	anonymous|graph_contrastive_learning_for_skeletonbased_action_recognition	/pdf/1896e5c0d08cd9aa74d46a77de095519df2c637c.pdf
MdiVU9lMmVS	579	Very Large Scale Multi-Agent Reinforcement Learning with Graph Attention Mean Field	['Multi-agent reinforcement learning', 'large-scale problems', 'graph attention', 'mean field']	A multi-agent reinforcement learning method solving very large scale problem by mean-field technique combining graph attention mechanism.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|very_large_scale_multiagent_reinforcement_learning_with_graph_attention_mean_field	/pdf/beb6830c8b16328725a483b96dbef96a1491de65.pdf
Fg3mYW8owg	580	Knowledge Distillation based Degradation Estimation for Blind Super-Resolution	['Image Super-Resolution']	We propose a knowledge distillation based blind super-resolution network, which can generalize to all degradation processes and achieve SOTA performance efficiently.	Applications (eg, speech processing, computer vision, NLP)	anonymous|knowledge_distillation_based_degradation_estimation_for_blind_superresolution	/pdf/ca74c2807ce2ec79da85c66de972b0db44c735f5.pdf
li4GQCQWkv	581	Towards Inferential Reproducibility of Machine Learning Research	['reproducibility', 'variance component analysis', 'reliability', 'significance test']	Methods for inferential reproducibility of machine learning, using signficance testing under meta-parameter variation, variance components,  and reliability coefficients.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_inferential_reproducibility_of_machine_learning_research	/pdf/b7661de98de0838b0109e3df99317b933291e24d.pdf
06mk-epSwZ	582	DiffMimic: Efficient Motion Mimicking with Differentiable Physics	['Physics-based Animation']	Mimic agile skills for physics-based character with differentiable physics simulators.	Applications (eg, speech processing, computer vision, NLP)	anonymous|diffmimic_efficient_motion_mimicking_with_differentiable_physics	/pdf/016eafbac5d5eeeedc7aec0b1c25d5d09c2c2271.pdf
dOxe6utTKC	583	Adversarial Collaborative Learning on Non-IID Features	['Federated Learning', 'Collaborative Learning']	The paper proposes a new collaborative learning framework on non-IID features.	Deep Learning and representational learning	anonymous|adversarial_collaborative_learning_on_noniid_features	/pdf/d23d7a1c954924c8c9c7a08e8abcdb7c80ca3bd2.pdf
B73niNjbPs	584	Continuous PDE Dynamics Forecasting with Implicit Neural Representations	['spatiotemporal forecasting', 'Partial Differential Equations', 'PDEs', 'Implicit Neural Representations', 'INRs', 'continuous models', 'generalization', 'dynamical systems', 'physics']	We propose a continuous-time, continuous-space data-driven PDE forecasting model with extensive spatiotemporal extrapolation capabilities including generalization to unseen sparse meshes and resolutions.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|continuous_pde_dynamics_forecasting_with_implicit_neural_representations	/pdf/7386b04f6ceb76ed912a55543b785dc8f48530cf.pdf
k4p382L0bw	586	Deep Dynamic AutoEncoder for Vision BERT Pretraining	[]		Unsupervised and Self-supervised learning	anonymous|deep_dynamic_autoencoder_for_vision_bert_pretraining	/pdf/6472c277e8b4bd7386efb746bfb79317ce7c76e2.pdf
W918Ora75q	588	Towards Smooth Video Composition	['video generation', 'generative adversarial network']	We develop a simple yet strong baseline for smooth video generation.	Generative models	anonymous|towards_smooth_video_composition	/pdf/8a3f9bc283803aa0aaf467f99d6ac0e0ccfd431c.pdf
HehY2ZX2Cz	589	Sorted eigenvalue comparison $d_{\mathsf{Eig}}$: A simple alternative to $d_{\mathsf{FID}}$	['Distribution shift', 'FID', 'eigenvalue comparison', 'random matrix theory']	We propose to compare sorted eigenvalues as a simple alternative to FID score.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|sorted_eigenvalue_comparison_d_\mathsfeig_a_simple_alternative_to_d_\mathsffid	/pdf/4f2a83999ae673e42f124c6156af1846024558cd.pdf
EdH_fkyhAO	590	Exploring Over-smoothing in Graph Attention Networks from the Markov Chain Perspective	['Graph Attention Networks', 'Over-smoothing', 'Markov Chain']	We give a theoretical analysis on the over-smoothing in GAT under the perspective of Markov Chains and propose a method to solve this problem.	Deep Learning and representational learning	anonymous|exploring_oversmoothing_in_graph_attention_networks_from_the_markov_chain_perspective	/pdf/742a339de50ea063cd7309bb2518ddee55aa5c6e.pdf
g2YraF75Tj	593	Towards Stable Test-time Adaptation in Dynamic Wild World	['Test-time adaptation', 'Roustness']	Propose a Sharpness-aware and Reliable entropy minimization method to make online test-time adaptation stable under wild test scenarios 1) small batch sizes; 2) mixed distribution shifts; 3) imbalanced online label distribution shifts.	Unsupervised and Self-supervised learning	anonymous|towards_stable_testtime_adaptation_in_dynamic_wild_world	/pdf/39e023768c52b7e266a686290382991aff1973d2.pdf
NkJOhtNKX91	594	Digging into Backbone Design on Face Detection	['Face Detection', 'Neural Architecture Search', 'Network Expressivity']	We propose a novel DDSAR score to characterize stage-wise detection ability, based on which, we employ off-the-shelf NAS technology to search FD-friendly backbone architectures.	Applications (eg, speech processing, computer vision, NLP)	anonymous|digging_into_backbone_design_on_face_detection	/pdf/eace2be640369431e669808406dac9a951dab2bc.pdf
GOEpRos3w0L	595	TopoZero: Digging into  Topology Alignment on Zero-Shot Learning	['Zero-Shot Learning', 'Structure Alignment', 'Persistent Homology']	we utilize persistent homology to investigate geometry structure alignment, based on which, we propose a TopoZero framework to achieve multi-dimensional structure alignment.	Applications (eg, speech processing, computer vision, NLP)	anonymous|topozero_digging_into_topology_alignment_on_zeroshot_learning	/pdf/42c9bdb252d9a94f2f6d754abcb290e393829320.pdf
APkMDZtY9HL	596	Interpretable Out-of-Distribution Detection using Pattern Identification	['out-of-distribution detection', 'pattern detection', 'interpretable artificial intelligence', 'confidence', 'metric']	We apply pattern detection to Out-of-Distribution detection on an extensive benchmark. 	Deep Learning and representational learning	anonymous|interpretable_outofdistribution_detection_using_pattern_identification	/pdf/353c19de3b9633483797b2b96a605f6e5f960036.pdf
8pOVAeo8ie	599	LPT: Long-tailed Prompt Tuning  for Image Classification	[]		Deep Learning and representational learning	anonymous|lpt_longtailed_prompt_tuning_for_image_classification	/pdf/55f8c06cd63e6da176591ef78a064bdd260c1c75.pdf
VeEv2NtRhb	600	Lifelong Learning the Task-Parameter Relationships for Knowledge Transfer	['Lifelong learning', 'Continual Learning', 'Transfer Learning']	We propose a heuristic that leverages the similarities between the optimal weight spaces of tasks, to enable knowledge transfer in a lifelong learning setting.	Deep Learning and representational learning	anonymous|lifelong_learning_the_taskparameter_relationships_for_knowledge_transfer	/pdf/ff55b04cdd2933246e0e391217bb0e9bb065b6de.pdf
SI0ON7mZYY	601	Categorial Grammar Induction as a Compositionality Measure for Emergent Languages in Signaling Games	['Emergent Communication', 'Emergent Language', 'Categorial Grammar Induction', 'Syntax', 'Compositionality']	This paper proposes a method for investigating the non-trivially compositional structure of emergent languages using Categorial Grammar Induction.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|categorial_grammar_induction_as_a_compositionality_measure_for_emergent_languages_in_signaling_games	/pdf/bd9db1172a4e803ecace84878fccbc2ef83f31b8.pdf
OT1xF6_56J	602	Rethinking Backdoor Data Poisoning Attacks in the Context of Semi-Supervised Learning	['data poisoning', 'backdoor attacks', 'semi-supervised learning']	We investigate vulnerabilities of semi-supervised learning methods to backdoor data poisoning attacks in unlabeled data and identify characteristics necessary for attack success. 	Deep Learning and representational learning	anonymous|rethinking_backdoor_data_poisoning_attacks_in_the_context_of_semisupervised_learning	/pdf/80ca66e21bda7bfc5bf5d985e818ebd07d4be289.pdf
_AkC4QYxF5	604	Closing the Gap Between SVRG and TD-SVRG with Gradient Splitting	['Temporal Difference learning', 'Reinforcement Learning', 'SVRG', 'Optimization']	We prove a linear convergence time for an SVRG-inspired temporal difference method which is identical to the original convergence time bound of SVRG in the convex setting.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|closing_the_gap_between_svrg_and_tdsvrg_with_gradient_splitting	/pdf/9abb27a227f876acbe3b2a28ab58ce2c798cbed4.pdf
CsKwavjr7A	606	Visual Recognition with Deep Nearest Centroids	['Nearest centroids classifier', 'Cased-base reasoning', 'Image classification', 'Image segmentation', 'Explainable neural networks']		Deep Learning and representational learning	anonymous|visual_recognition_with_deep_nearest_centroids	/pdf/4b6649100fed9ec5bfd9d53c991a9c0e57dabc66.pdf
wshUUnnDjc	607	Benchmarking and Improving Robustness of 3D Point Cloud Recognition against Common Corruptions	['Corruption Robustness Benchmark', 'Point Cloud Classification', 'Data Augmentation']	We propose ModelNet40-C, a novel corruption robustness dataset and benchmark for point cloud recognition with RobustNet and PointCutMixup to further improve the rosbustness.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|benchmarking_and_improving_robustness_of_3d_point_cloud_recognition_against_common_corruptions	/pdf/6a6557cef829152d46c61324dbaa14abf8c897fd.pdf
_MlB0iqfmM	608	Deep Physics-based Deformable Models for Efficient Shape Abstractions	['Deformable models', 'Shape abstraction', 'Deep learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|deep_physicsbased_deformable_models_for_efficient_shape_abstractions	/pdf/29ddcd44d9c551680af8a9290dff57786d1d476c.pdf
293zPCqNqe	609	PointDP: Diffusion-driven Purification against 3D Adversarial Point Clouds	['Adversarial Robustness', 'Point Cloud Classification', 'Diffusion Model']	We propose PointDP, a diffusion-driven purification strategy to defend against adversarial point cloud. PointDP consistently achieves the strongest robustness under various attacks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|pointdp_diffusiondriven_purification_against_3d_adversarial_point_clouds	/pdf/89398a42cecf49798202ae90469f53e00dcedfee.pdf
rSUCajhLsQ	610	Easy Differentially Private Linear Regression	['differential privacy', 'linear regression']	A practical algorithm for differentially private linear regression which does not require data bounds or parameter tuning but is competitive with methods that do.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|easy_differentially_private_linear_regression	/pdf/b0951570c24aeb7ce428a3b2bf27255f3b2b8256.pdf
tPrRs6YB2P	611	Scenario-based Question Answering with Interacting Contextual Properties	['Question Answering']	We proposed a model for scenario-based QA which requires reasoning over multiple contextual properties in user scenarios to find answers that are consistent with the scenarios and to identify necessary information which is missing from the scenarios.	Applications (eg, speech processing, computer vision, NLP)	anonymous|scenariobased_question_answering_with_interacting_contextual_properties	/pdf/646ecf18c72392f17b54c9b11364d159cabed64e.pdf
vQXbQEDJi5	612	MMTSA: Multi-Modal Temporal Segment Attention Network for Efficient Human Activity Recognition	['Multimodal Learning', 'Human Activity Recognition']		Applications (eg, speech processing, computer vision, NLP)	anonymous|mmtsa_multimodal_temporal_segment_attention_network_for_efficient_human_activity_recognition	/pdf/cc7049cef78bf5ce10e4dc874021d969dfb60a05.pdf
z4g0Vpf5Zki	614	Auxiliary task discovery through generate and test	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|auxiliary_task_discovery_through_generate_and_test	/pdf/c440e635f8faa6ec68634bbf9d60962a8bb11e48.pdf
KemSBwOYJC	615	Statistical Inference for Fisher Market Equilibrium	['Fisher market equilibrium', 'first-price auction', 'statistical inference under interference', 'revenue management']	We propose a statistical inference framework for Fisher market equilibrium.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|statistical_inference_for_fisher_market_equilibrium	/pdf/bbf6db47c7bc04727f917b8a49810f0e853af609.pdf
ATWW-bUtxH	618	FEW-SHOT NODE PROMPT TUNING	['node classification', 'few-shot learning', 'graph neural networks']	In this paper, we propose Few-shot Node Prompt Tuning as a effective method to tackle general few-shot node classification tasks.	Deep Learning and representational learning	anonymous|fewshot_node_prompt_tuning	/pdf/cab9cab3466c4038afd521d96de5e038e0b88038.pdf
K9DghwWLWF3	619	Improve the Adaptation Process by Reasoning From Failed and Successful Cases	['case-based reasoning', 'adaptation', 'failed cases', 'artificial potential field']	This work presents a new approach to the adaptation process in the case-based reasoning paradigm	General Machine Learning (ie none of the above)	anonymous|improve_the_adaptation_process_by_reasoning_from_failed_and_successful_cases	/pdf/fd22070671bf731f8b062825838d57ddfda1df33.pdf
MWoZh1gvbxA	620	Hidden Poison: Machine unlearning enables camouflaged poisoning attacks	['Machine Unlearning', 'Poisoning Attack', 'Camouflaging Poisons']	We show that machine unlearning can be used to implement a new type of camouflaged data poisoning attack. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|hidden_poison_machine_unlearning_enables_camouflaged_poisoning_attacks	/pdf/f5e3b96d4371e1179ec00907ffc750c1c7e689a7.pdf
QEmn_Hvh7j8	621	Private GANs, Revisited	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|private_gans_revisited	/pdf/2bad814ca64319d6aaf59d59bbd6921bded08f01.pdf
c0U6KmokuFK	622	GraphPNAS: Learning Distribution of Good Neural Architectures via Deep Graph Generative Models	['Neural Architecture Search', 'Deep Generative Models of Graphs', 'Graph Neural Networks']	Learning Distribution of Good Neural Architectures via Probabilistic Deep Graph Generative Models	Deep Learning and representational learning	anonymous|graphpnas_learning_distribution_of_good_neural_architectures_via_deep_graph_generative_models	/pdf/a0069868ff32de4fea0479520238d69ef7467739.pdf
mNNAjdv3Am	625	An Incremental Learning Approach for Sustainable Regional Isolation and Integration	['Continual Learning', 'Incremental Learning', 'Catastrophic Forgetting', 'Memory Replay', 'Regional Isolation', 'Regional Integration', 'Alleviate Recency Bias']	"Sustainable regional isolation and integration contribute to incremental learning while alleviating ""recency bias""."	Deep Learning and representational learning	anonymous|an_incremental_learning_approach_for_sustainable_regional_isolation_and_integration	/pdf/dda813aeed2a2d71dc4607b61eef0ec58130ca97.pdf
UJ4nGMHZYI	626	Factor Learning Portfolio Optimization Informed by Continuous-Time Finance Models	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|factor_learning_portfolio_optimization_informed_by_continuoustime_finance_models	/pdf/28373a81d9bd1bf67a5a30332a4b8967503a30c2.pdf
PldynS56bN	627	Contextual Convolutional Networks	['Convolutional Neural Networks']	In this paper, we propose to augment potential category memberships as contextual priors in the convolution for contextualized representation learning.	Deep Learning and representational learning	anonymous|contextual_convolutional_networks	/pdf/bbe0808d8890ecd9c292b4bdd19faf064f1d93cc.pdf
9RQh6MOOaD	630	Efficient Hyperdimensional Computing	['Hyperdimensional computing']	Based on a detailed analysis of dimension, accuracy, and orthogonality, this paper proposes a suite of novel techniques that reduce the hypervector dimension significantly while maintaining state-of-art accuracies and efficiency.	General Machine Learning (ie none of the above)	anonymous|efficient_hyperdimensional_computing	/pdf/3da3f19453fd01593eaa45b4b34b690967e05f06.pdf
wxyLBOk-ag	631	Feature Synchronization in Backdoor Attacks	['backdoor attacks', 'model interpretation']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|feature_synchronization_in_backdoor_attacks	/pdf/846d8a53ff56f5072ec29c23b053e1c97cb5785f.pdf
9NzCUqU7i1	637	Learning from Interval-valued Data	['Machine learning', 'Interval-valued data', 'Classification']	Learn a classifier with interval-valued observations using multi-view learning.	General Machine Learning (ie none of the above)	anonymous|learning_from_intervalvalued_data	/pdf/123917bef35561f325dc53b6dedd1da87585a8c7.pdf
MdSGM9PEQ7	640	Admeta: A Novel Double Exponential Moving Average to Adaptive and Non-adaptive Momentum Optimizers with Bidirectional Looking	['optimizer', 'double exponential moving average', 'bidirectional looking', 'Adam', 'SGD']	We propose a bidirectional-looking framework, Admeta, in which a novel double exponential moving average mechanism is proposed to adaptive and non-adaptive momentum optimizers.	Optimization (eg, convex and non-convex optimization)	anonymous|admeta_a_novel_double_exponential_moving_average_to_adaptive_and_nonadaptive_momentum_optimizers_with_bidirectional_looking	/pdf/dc499bdc1667cddd947c009b7a5c9ff202abfb87.pdf
zT5T9gHpGI	641	Adversarial Counterfactual Environment Model Learning	['offline environment model learning', 'reinforcement learning', 'causal inference']	We propose a new environment model learning techniques with better genalization ability on counterfactual data.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adversarial_counterfactual_environment_model_learning	/pdf/852cfe9947954fe483eb27e2bd21c76240394e0d.pdf
MMBILyoRKQ	642	Iterative Relaxing Gradient Projection for Continual Learning	['continual learning', 'gradient projection methods']	We propose a novel gradient projection approach to facilitate forward knowledge transfer within a fixed network capacity by iterative searching and relaxing the critical subspace of the frozen space.	Deep Learning and representational learning	anonymous|iterative_relaxing_gradient_projection_for_continual_learning	/pdf/af65d9ef92367cafef32eaca4343b4eeaf45b7b7.pdf
kj6oK_Hj40	644	Self-Distillation for Further Pre-training of Transformers	['self-distillation', 'adaptation of pre-trained models', 'regularization']	We propose self-distillation in further pre-training to improve effectiveness of adaptation of pre-trained model to target tasks.	Deep Learning and representational learning	anonymous|selfdistillation_for_further_pretraining_of_transformers	/pdf/38cea81f24c1320d9d1f2462abc519f605c4620c.pdf
AP0iZoaRaS	645	Interactive Portrait Harmonization	['harmonization', 'image editing', 'low-level vision']	A new flexible framework that allows users to pick certain regions of the background image and use it to guide the harmonization.		anonymous|interactive_portrait_harmonization	/pdf/54e64d1dc68a6bd5c3bb6efa330a0757fb7de6e2.pdf
bHW9njOSON	646	ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure	['calibration']	We propose a tuning-free calibration obejctive loss Expected Squared Difference (ESD), where we view the calibration error from the perspective of the squared difference between two expectations.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|esd_expected_squared_difference_as_a_tuningfree_trainable_calibration_measure	/pdf/75d343c52253d39c0bfa767e8fa39f4e4003112a.pdf
o8fqVVKN3H	647	Split and Merge Proxy: pre-training protein-protein contact prediction by mining rich information from monomer data	['Protein Bioinformatics', 'Protein-Protein Contact Prediction', 'Pre-training']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|split_and_merge_proxy_pretraining_proteinprotein_contact_prediction_by_mining_rich_information_from_monomer_data	/pdf/4e21f9cf8007158e933dc244767c58b3bd91897c.pdf
PxFpWq6FNiW	648	Prompt-Matched Semantic Segmentation	['foundation model', 'prompt tuning', 'semantic segmentation', 'model generality']	We proposed a generic and effective prompt tuning method for semantic segmentation.	Deep Learning and representational learning	anonymous|promptmatched_semantic_segmentation	/pdf/561e5b9892538a698e0d13a3ec48cf73780a3338.pdf
7bvWopYY1H	650	GeoVeX: Geospatial Vectors with Hexagonal Convolutional Autoencoders	['Representation learning', 'Geospatial Embedding', 'Convolutional Autoencoders on hexagonal grids', 'OpenStreetMap', 'H3 hexagons']	We introduce a new geospatial representation model called GeoVeX to learn global vectors for all geographical locations on Earth land cover (200+ million embeddings). 	Deep Learning and representational learning	anonymous|geovex_geospatial_vectors_with_hexagonal_convolutional_autoencoders	/pdf/52bab91831ca9cb97bcfb99d9a5f9671ec5dd3a0.pdf
EfTN2tSGlF	651	Towards Understanding Convergence and Generalization of AdamW	['deep learning optimization', 'network optimizer']	It theoretically proves the convergence of AdamW, and justifies its generalization superiority over both Adam and its  $\ell_2$-regularized variant. 	Deep Learning and representational learning	anonymous|towards_understanding_convergence_and_generalization_of_adamw	/pdf/c34bd22ce2d373fd0ea49127e13bb7e453f6570f.pdf
Iyi7eb9VIW	652	A Quasi-Bayesian Nonparametric Density Estimator via Autoregressive Predictive Updates	['Bayesian nonparametrics', 'Dirichlet Process Mixture Models', 'Quasi-Bayes']	We introduce a Quasi-Bayesian nonparametric density estimator for moderate-sized data sets that is inspired by an autoregressive Dirichlet Process Mixture Model.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|a_quasibayesian_nonparametric_density_estimator_via_autoregressive_predictive_updates	/pdf/758417a8523675cf4cd6c3e6437423e08418ee18.pdf
CPdc77SQfQ5	653	Win: Weight-Decay-Integrated Nesterov Acceleration for Adaptive Gradient Algorithms	['Optimization acceleration in deep learning', 'network optimizers', 'deep learning optimizer', 'deep learning algorithm']	We  propose a new and general Weight-decay-Integrated Nesterov acceleration for adaptive  algorithms to enhance their convergence speed, and also analyze their convergence  justify their convergence superiority. 	Deep Learning and representational learning	anonymous|win_weightdecayintegrated_nesterov_acceleration_for_adaptive_gradient_algorithms	/pdf/09e7538a1388b57584d51e16152aa39fe0e1e132.pdf
4tsqGWfBb3Q	654	Revisiting Residual Networks for Adversarial Robustness	['Adversarial robustness', 'neural architecture design']	Designing robust convolutional neural networks against adversarial attack. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revisiting_residual_networks_for_adversarial_robustness	/pdf/dda3380eafd6fbc815542ad13bcf7e2e8272ed74.pdf
Uk3zO5A-CSe	655	TIB: Detecting Unknown Objects via Two-Stream Information Bottleneck	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|tib_detecting_unknown_objects_via_twostream_information_bottleneck	/pdf/2d8f7a03d330f679f3cf62c7046b6a0bbf15b7c7.pdf
YjKqWExiy6s	656	Eliminating Catastrophic Overfitting Via Abnormal Adversarial Examples Regularization	[]		Deep Learning and representational learning	anonymous|eliminating_catastrophic_overfitting_via_abnormal_adversarial_examples_regularization	/pdf/f217b56cc3042a91b9f7866a6926ee5650f5b009.pdf
ueYYgo2pSSU	657	Sparse Q-Learning: Offline Reinforcement Learning with Implicit Value Regularization	['Deep Reinforcement Learning', 'Offline Reinforcement Learning', 'Value Regularization', 'Continuous Control']	We show that some form of Implicit Value Regularization (IVR) will result in the In-sample Learning paradigm in offline RL. We also propose a practical algorithm based on the IVR framework, which obtains new SOTA results.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|sparse_qlearning_offline_reinforcement_learning_with_implicit_value_regularization	/pdf/a37291ca09ccc2881659f846334ac1406beeb46e.pdf
szTcqSSc5Vx	658	MIA: A Framework for Certified Robustness of Time-Series Classification and Forecasting Against Temporally-Localized Perturbations	['Certified robustness', 'time series forecasting', 'time series classification']		General Machine Learning (ie none of the above)	anonymous|mia_a_framework_for_certified_robustness_of_timeseries_classification_and_forecasting_against_temporallylocalized_perturbations	/pdf/df9252ca28b1b9f34d044c00eaf54a944d477227.pdf
PFbzoWZyZRX	660	Spike Calibration: Bridging the Gap between ANNs and SNNs in ANN-SNN Conversion 	['Spiking Neural Networks，Spike Calibration，Ultra-low-latency Conversion']	A calibration method based on shifting initial membrane potential is proposed for ANN-SNN conversion to reach the same level of performance as BPTT.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|spike_calibration_bridging_the_gap_between_anns_and_snns_in_annsnn_conversion	/pdf/0acc5e1529bf59b5c7d44d6b3b1e649bb514c505.pdf
UfFXUfAsnPH	661	Big Learning: A Universal Machine Learning Paradigm?	['Foundation models', 'big learning', 'incomplete data', 'GAN']	We propose a new machine learning framework named Big Learning, which exhaustively exploits data information and underlies existing foundation models.	Deep Learning and representational learning	anonymous|big_learning_a_universal_machine_learning_paradigm	/pdf/6285409b9aa1acde337de4906599687441e7afe3.pdf
ZmGrci84heu	664	Understanding and Bridging the Modality Gap for Speech Translation	['neural machine translation', 'speech translation', 'modality gap']	We aim to understand the modality gap for speech translation and propose a simple yet effective Cross-modal Regularization with Scheduled Sampling (Cress) method to bridge this gap.	Applications (eg, speech processing, computer vision, NLP)	anonymous|understanding_and_bridging_the_modality_gap_for_speech_translation	/pdf/541bcfbb1b355774ce0e92a6103e22c77b1bf68b.pdf
At0BdxvACds	666	Curiosity-Driven Unsupervised Data Collection for Offline Reinforcement Learning	['Offline Reinforcement Learning', 'Data Collection', 'Reachability', 'Unsupervised Learning', 'Curiosity-Driven Learning']	We propose a novel adaptive reachability-based method to improve the data collection process in offline reinforcement learning. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|curiositydriven_unsupervised_data_collection_for_offline_reinforcement_learning	/pdf/602fd221f51152c2a69244e9e40ad9964e26d019.pdf
bzaPGEllsjE	667	A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions,  benefit from negative momenta.	['SGD', 'linear models', 'optimization', 'analytic framework', 'NTK']	We have developed an analytic framework for analysis of mini-batch SGD dynamics via generating functions using a novel Spectrally Expressible approximation. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_view_of_minibatch_sgd_via_generating_functions_conditions_of_convergence_phase_transitions_benefit_from_negative_momenta	/pdf/d10b60551d82d80b8f7a544f767c5b5a5df23514.pdf
NZ8Gb5GOrRu	668	Deep Power Laws for Hyperparameter Optimization	['hyperparameter optimization', 'multi-fidelity optimization', 'power laws', 'deep neural networks', 'deep power laws.']	Multi-fidelity hyperparameter optimization with deep power laws that achieves state-of-the-art results across diverse benchmarks.	Deep Learning and representational learning	anonymous|deep_power_laws_for_hyperparameter_optimization	/pdf/217c5c2d1229ee299f81a2b92f7b100bcf204607.pdf
sbWVtxq8-zE	671	Can discrete information extraction prompts generalize across language models?	['prompting', 'prompt analysis', 'language model interfaces', 'prompt generalizations']	"We show that automatically generated prompts can be learned on a language model and used to retrieve information from another. We further provide some preliminary insights on the nature of these ""universal prompts""."	Deep Learning and representational learning	anonymous|can_discrete_information_extraction_prompts_generalize_across_language_models	/pdf/e3085186277602ef933c4c0d1012ec3b3aabb418.pdf
2xQVAXKjLdH	672	Probing into the Fine-grained Manifestation in Multi-modal Image Synthesis	['Multi-modal image synthesis', 'semantic consistency measurement', 'robustness testing']	A new method for evaluating the semantic consistency and robustness of multi-modal image synthesis models	Applications (eg, speech processing, computer vision, NLP)	anonymous|probing_into_the_finegrained_manifestation_in_multimodal_image_synthesis	/pdf/155fb810da897fea2155c490f65288ebe418b61c.pdf
fiB2RjmgwQ6	675	Filter-Recovery Network for Multi-Speaker Audio-Visual Speech Separation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|filterrecovery_network_for_multispeaker_audiovisual_speech_separation	/pdf/6e955b834d7c54dca1bbe80acb723c8ea3c9263d.pdf
DiKT4rrUD9n	676	Friends to Help: Saving Federated Learning from Client Dropout	['Federated Learning', 'Client Dropout', 'Partial Participation']	This paper proposes an algorithm to address client dropout in Federated Learning that discovers the ``friendship'' among clients and uses the friend client's local update as a substitute for the dropout client. 	General Machine Learning (ie none of the above)	anonymous|friends_to_help_saving_federated_learning_from_client_dropout	/pdf/006c0a6703a2c0dbc5153cbc4f9ed466cc88df3f.pdf
Q4B6g_ubd39	678	The Effects of Nonlinearity on Approximation Capacity of Recurrent Neural Networks	['Recurrent Neural Network', 'Approximation Theory', 'Functional Analysis', 'Dynamical System']	The nonlinear recurrent activations do not make the approximation capacity of RNN worse, however also not much better.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|the_effects_of_nonlinearity_on_approximation_capacity_of_recurrent_neural_networks	/pdf/8d0ecd1f0efc986e73a39449a598198d54326f56.pdf
CJl2S0w1mbq	681	A UNIFIED VIEW OF FINDING AND TRANSFORMING WINNING LOTTERY TICKETS	['Lottery Tickets Hypothesis', 'Dual Lottery Tickets Hypothesis', 'Non-linear increased regularization', 'early stopping']	This paper presents a novel paradigm that combines the increased regularization term and early stopping to find or transform winning tickets.	Deep Learning and representational learning	anonymous|a_unified_view_of_finding_and_transforming_winning_lottery_tickets	/pdf/bcd1bd832e5b83da08fcab57c4b9be71415ce9ea.pdf
IiDeZZZ18zi	690	ChemSpacE: Interpretable and Interactive Chemical Space Exploration	['Molecule Generation', 'Molecule Manipulation', 'Human-in-the-loop Molecule Design', 'Chemical Space Exploration']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|chemspace_interpretable_and_interactive_chemical_space_exploration	/pdf/8c3af9571dfeff0d24afbbc3617e8a71824d7e31.pdf
5p4wvBz9xIe	693	HeatDETR: Hardware-Efficient DETR with Device-Adaptive Thinning	[]		Deep Learning and representational learning	anonymous|heatdetr_hardwareefficient_detr_with_deviceadaptive_thinning	/pdf/e9a9b65ddd2eef1a94e103907440112d37e152d4.pdf
AvwF6IvT8et	695	Deep reinforced active learning for multi-class image classification	['Reinforcement learning', 'active learning', 'image classification']			anonymous|deep_reinforced_active_learning_for_multiclass_image_classification	/pdf/29f0755839000763373e02aa811e42e79a0c9e85.pdf
uKmuzIuVl8z	696	Structure-based Drug Design with Equivariant Diffusion Models	['Diffusion Models', 'Equivariant Neural Networks', 'Structure-based Drug Design', 'Molecule Generation', 'Conditional Generation']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|structurebased_drug_design_with_equivariant_diffusion_models	/pdf/76b5b375d0cd197c3e23502600f0a41c80442950.pdf
HHd2OVBoF_-	697	Federated Learning in Non-IID Settings Aided by Differentially Private Synthetic Data	['Federated Learning', 'Representation Learning', 'Differential Privacy']	A novel federated learning framework utilizing data augmentation to improve global accuracy among data-heterogeneous clients	General Machine Learning (ie none of the above)	anonymous|federated_learning_in_noniid_settings_aided_by_differentially_private_synthetic_data	/pdf/c2326070a399ce01fd2f377bb9c2ec09eb270a5e.pdf
SJ1kSyO2jwu	698	Human Motion Diffusion Model	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|human_motion_diffusion_model	/pdf/1bf4b790adb61952b0c43fd7ee3f49bb25358a9c.pdf
naAzVF_v0yA	699	Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data	[]		Deep Learning and representational learning	anonymous|evaluating_natural_language_processing_models_with_generalization_metrics_that_do_not_need_access_to_any_training_or_testing_data	/pdf/18e001508badda0a865141599f859d6450f734e4.pdf
iiRDsy85uXi	700	On the Importance of Architectures and Hyperparameters for Fairness in Face Recognition	['Neural Architecture Search', 'Face Recognition', 'Fairness', 'Hyperparameter Optimization']	We analyze the impact of architectures and hyperparameters on fairness in face recognition and use NAS to design simultaneously fairer and more accurate models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_importance_of_architectures_and_hyperparameters_for_fairness_in_face_recognition	/pdf/865bbc1dafe2f6f17a983b00e9be21bb94e34673.pdf
VHDqQAD4DTU	702	Robust Perception through Equivariance	['Equivariance', 'Adversarial Robustness']	We show equivariance is an effective property to respect at test time to performance robust perception.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robust_perception_through_equivariance	/pdf/4014de1d0aa2e57d2713f1feae13e39e3be34960.pdf
cp5PvcI6w8_	706	TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second	['Tabular Data', 'AutoML', 'Green AI', 'Bayesian prediction', 'Causal Reasoning', 'Real-time Machine Learning']	We present TabPFN, a trained Transformer that learned to solve small tabular data classification problems at SOTA level in less than a second by training on synthetic data generated by integrating principles from causal reasoning and simplicity. 	Deep Learning and representational learning	anonymous|tabpfn_a_transformer_that_solves_small_tabular_classification_problems_in_a_second	/pdf/7921e9df4a3a5ca2697fa92da56855b9c7d3f198.pdf
7ynoX1ojPMt	708	OTOv2: Automatic, Generic, User-Friendly	['Model Compression', 'One Shot', 'Automatic', 'Generic', 'User-Friendly']		Deep Learning and representational learning	anonymous|otov2_automatic_generic_userfriendly	/pdf/01b1b2a6658361a36be63311478311dbcc3dea65.pdf
TT66Tpbus3b	709	DeepPipe: Deep, Modular and Extendable Representations of Machine Learning Pipelines	['Pipeline optimization', 'meta-learning', 'bayesian optimization', 'representation learning']	How to learn Machine Learning pipelines representations to improve their optimization	Deep Learning and representational learning	anonymous|deeppipe_deep_modular_and_extendable_representations_of_machine_learning_pipelines	/pdf/a98dd85cac5c6547a26dcef0eaa4da0b411be10b.pdf
dOM_GHvkO2h	710	HNeRV: A Hybrid Neural Representation  for Videos	['video neural representation', 'implicit neural representation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|hnerv_a_hybrid_neural_representation_for_videos	/pdf/a3d728052b87a0cbfe131608acbed21c2d336eaa.pdf
OTiSSCBm1QD	711	Temporal Relevance Analysis for Video Action Models	['Temporal analysis', 'Frame relevance', 'Video data', 'Action recognition']	The paper provides a deep analysis of the temporal modeling for action recognition.	Applications (eg, speech processing, computer vision, NLP)	anonymous|temporal_relevance_analysis_for_video_action_models	/pdf/a5f1358f37db557a5ae189bfbc06c3abe697e782.pdf
NzrpxT5hTY_	712	FADE: Enabling Large-Scale Federated Adversarial Training on Resource-Constrained Edge Devices	['Federated Learning', 'Adversarial Training']	We propose a novel framework to enable large-scale federated adversarial training on resource-constrained edge devices.	Deep Learning and representational learning	anonymous|fade_enabling_largescale_federated_adversarial_training_on_resourceconstrained_edge_devices	/pdf/a239b4b5ff963d1d5f1c98094ece2a30671358b3.pdf
yDx3GP7Qjfl	713	Language-Guided Artistic Style Transfer Using the Latent Space of DALL-E	['Language-Guided Style Transfer', 'Non-Autoregressive Transformer', 'Deep Reinforcement Learning']	We propose a language-guided style transfer method that manipulates the discrete DALL-E latent space using a non-autoregressive sequence translation approach.	Applications (eg, speech processing, computer vision, NLP)	anonymous|languageguided_artistic_style_transfer_using_the_latent_space_of_dalle	/pdf/f1cc3e26ca96e39e9ef011ff9150f77eb385864b.pdf
puguRjbs6Rg	714	IDP: Iterative Differentiable Pruning based on  Attention for Deep Neural Networks	['pruning', 'deep learning', 'attention']	We proposed a differentiable pruning method, IDP which yields the state-of-the-art pruning quality on popular computer vision and natural language models, based on attention-based soft-mask.	Deep Learning and representational learning	anonymous|idp_iterative_differentiable_pruning_based_on_attention_for_deep_neural_networks	/pdf/101dd981cd6e35a649c0a75897d9e88d49f20956.pdf
qLOaeRvteqbx	715	Disparate Impact in Differential Privacy from Gradient Misalignment	['Differential privacy', 'fairness', 'privacy']	DPSGD can have unfair outcomes on protected groups because of direction errors caused by per-sample gradient clipping, but unfairness can be dramatically reduced with a global clipping technique.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|disparate_impact_in_differential_privacy_from_gradient_misalignment	/pdf/878440e55519c32462e6168c3196cb222f8c7c94.pdf
qGuU8To1y7x	716	Networks are Slacking Off: Understanding Generalization Problem in Image Deraining	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|networks_are_slacking_off_understanding_generalization_problem_in_image_deraining	/pdf/2da75bd3ab5faa899fcf915cbb6538b3cf39470b.pdf
RrO3xNCqz7J	718	Discovering Distinctive ``Semantics'' in Super-Resolution Networks	[]		Deep Learning and representational learning	anonymous|discovering_distinctive_``semantics_in_superresolution_networks	/pdf/23d8fe64fddb561567d9937e54760cfa7f672d24.pdf
CWmvjOEhgH-	719	MPCFORMER: FAST, PERFORMANT AND PRIVATE TRANSFORMER INFERENCE WITH MPC	['Secure Multiparty Computation', 'Privacy', 'Machine Learning', 'Transformer model']	We develop a framework that allows fast, performant, and private inference with MPC for Transformer models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|mpcformer_fast_performant_and_private_transformer_inference_with_mpc	/pdf/5259aa6d4352e94659926e99f70167bcd8a62875.pdf
L2MUOUp0beo	720	CoRTX: Contrastive Framework for Real-time Explanation	['Interpretability', 'explainability', 'real-time explanation', 'feature attribution', 'feature importance ranking']	Learning real-time model explainer with limited explanation labels.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|cortx_contrastive_framework_for_realtime_explanation	/pdf/f1bb10bb20b3dc95d9dd3032154232176cfb16cc.pdf
vRq1XIHV8Go	721	Graph Neural Bandits	['Contextual Bandits', 'Graph Neural Networks']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|graph_neural_bandits	/pdf/688a01274284bc0acbd71df2d197b18c182be88b.pdf
cbpRzMy-UZH	723	Effective Self-supervised Pre-training on Low-compute networks without Distillation	['Self-supervised learning', 'Low-compute network']		Unsupervised and Self-supervised learning	anonymous|effective_selfsupervised_pretraining_on_lowcompute_networks_without_distillation	/pdf/c900582d3a8094aba1e47ad5b2b278a4f4d42901.pdf
itmei3dxTQ5	724	Configuring Mixed-Integer Linear Programming Solvers with Deep Metric Learning	['Mixed Integer Linear Programming', 'Metric Learning', 'Algorithm Configuration']	We learn similarities among MILP problem instances using deep metric learning to predict an instance-specific solver configuration	Optimization (eg, convex and non-convex optimization)	anonymous|configuring_mixedinteger_linear_programming_solvers_with_deep_metric_learning	/pdf/43d0dfb0e1c1ce21af8486b276dfbfcf6ff6b8da.pdf
9L1Ts8t66YK	725	Towards Equivariant Graph Contrastive Learning via Cross-Graph Augmentation	['equivariant', 'self-supervised learning', 'contrastive learning', 'graph neural networks']	We propose a cross-graph augmentation to achieve equivariant self-supervised learning on graphs. 	Unsupervised and Self-supervised learning	anonymous|towards_equivariant_graph_contrastive_learning_via_crossgraph_augmentation	/pdf/b68e43dddecedf32e50b9d7659cdf926fdf1dec2.pdf
dOq0Jbg9hUt	726	One Ring to Bring Them All: Model Adaptation under Domain and Category Shift	['Source-free Universal Domain Adaptation']	We propose a simple method which could address source-free universal domain adaptation and also several other different tasks.	Deep Learning and representational learning	anonymous|one_ring_to_bring_them_all_model_adaptation_under_domain_and_category_shift	/pdf/24a4d62e0396d2cbc5b70f6e81637f2e173e163c.pdf
-5EWhW_4qWP	727	NTK-SAP: Improving neural network pruning by aligning training dynamics	['empirical deep learning', 'pruning at initialization', 'neural network pruning']	We introduce a pruning-at-initialization method by aligning the eigenspectrum of NTK to that of the dense network.	Deep Learning and representational learning	anonymous|ntksap_improving_neural_network_pruning_by_aligning_training_dynamics	/pdf/33813175b25bfbdfa202bbfb4cc3afa652b87aff.pdf
HDxgaKk956l	728	Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders	['Diffusion model', 'adversarial autoencoder', 'implicit prior']	We propose truncated diffusion probabilistic models, which models an implicit prior to truncate the diffusion chain and requires significantly fewer reverse steps to generate high-quality samples.	Generative models	anonymous|truncated_diffusion_probabilistic_models_and_diffusionbased_adversarial_autoencoders	/pdf/e737e88542ac0bd9e0a5bbe70e255b18c8c3d83a.pdf
-D5TVtzt3fP	729	Sparse Tokens for Dense Prediction - The Medical Image Segmentation Case	['token pruning', 'vision transformer', 'dense prediction', 'medical image segmentation']	We show how to perform dense prediction efficiently with a sparse token ViT while maintaining performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sparse_tokens_for_dense_prediction_the_medical_image_segmentation_case	/pdf/e10cbafb5a1bf6c696f05553212a44ea59f9642e.pdf
_5jWpg7TK9b	730	On the Effectiveness of Adapting Pre-trained Transformer Models via Adversarial Noise	['Fast adaptation', 'Pre-trained Transformer Networks', 'Natural Language Understanding']	We investigate the computation efficiency vs. generalization in adapting natural language understanding tasks and propose a method to accelerates model adaptation of Transformers by up to 9.8 times.	Deep Learning and representational learning	anonymous|on_the_effectiveness_of_adapting_pretrained_transformer_models_via_adversarial_noise	/pdf/b899e584986460edaa8d4ca58d81850c4cb87dba.pdf
pjYWuX78J6p	731	A prototype-oriented clustering for domain shift with source privacy	['deep learning', 'clustering', 'privacy', 'computer vision']	We propose a method to solve the problem of unsupervised clustering under domain shift and privacy concerns.	Deep Learning and representational learning	anonymous|a_prototypeoriented_clustering_for_domain_shift_with_source_privacy	/pdf/b811bad08bbf80396bf3294fa82b48622765dd99.pdf
KfptQCEKVW4	732	Automating Nearest Neighbor Search Configuration with Constrained Optimization	['AutoML', 'Convex Optimization', 'Vector Retrieval', 'Hyperparameter Search', 'ANN']		Applications (eg, speech processing, computer vision, NLP)	anonymous|automating_nearest_neighbor_search_configuration_with_constrained_optimization	/pdf/251c78f3e7ddf199b990d662171d9de7b7c96a87.pdf
ALMbHbLb3PK	733	Multiple Instance Learning via Iterative Self-Paced Supervised Contrastive Learning	['multiple instance learning', 'whole slide image', 'contrastive learning', 'medical imaging']	We propose a framework for multiple instance learning, which iteratively improves instance-level features by jointly estimating latent instance-level pseudo labels, and show that it outperforms existing methods on three real-world medical datasets.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|multiple_instance_learning_via_iterative_selfpaced_supervised_contrastive_learning	/pdf/6be15b71e590bd66712d52796251c008e759c0b5.pdf
KwmPfARgOTD	734	Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs	['equivariant neural networks', 'graph neural networks', 'computational physics', 'transformer networks']	We propose an equivariant graph neural network based on Transformer networks and propose a novel attention mechanism, which improves upon self-attention in typical Transformers.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|equiformer_equivariant_graph_attention_transformer_for_3d_atomistic_graphs	/pdf/e2fe51927aa46602a1e1bd8af3aca502b091a05d.pdf
UIpwFLrJiDi	735	Towards Discovering Neural Architectures from Scratch	['Neural Architecture Search', 'Search Space Design', 'Bayesian Optimization']	We introduce an algebraic view on Neural Architecture Search that allows us to construct highly expressive search spaces with context-free grammars, and show that we can efficiently find well-performing architectures.	Deep Learning and representational learning	anonymous|towards_discovering_neural_architectures_from_scratch	/pdf/5673a386de669a132269e0f7ed8e11e91b492a39.pdf
8VCiVV97Pji	736	Outlier Robust Adversarial Training	[]		General Machine Learning (ie none of the above)	anonymous|outlier_robust_adversarial_training	/pdf/588b9c0173018caa829969d6837ad7b112d992b6.pdf
YsdscENWse9	737	Recommender Transformers with Behavior Pathways	['Recommendation', 'Transformers', 'Behavior Pathway']	We build the Recommender Transformer (RETR) with a novel Pathway Attention mechanism that can dynamically plan the behavior pathway. It achieves SOTA in both intra-domain and cross-domain benchmarks for sequential recommendation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|recommender_transformers_with_behavior_pathways	/pdf/0d16622428c85da217d5cc66e30ab0a638ce5eb3.pdf
u6ay5ONhWJV	738	An Empirical Study on Anomaly detection Using Density Based and Representative Based Clustering algorithms	['Anomaly', 'Outliers', 'Noise points', 'ANN', 'DBSCAN', 'DBSCAN++', 'k-means - - (minus minus)']	In this paper, we focus on existing anomaly detection approaches, by empirically studying the performance of unsupervised anomaly detection techniques.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|an_empirical_study_on_anomaly_detection_using_density_based_and_representative_based_clustering_algorithms	/pdf/61d37167cf1a1a061de62252aa868547a3b063af.pdf
z29R0uMiF3v	739	GOAT: A Global Transformer on Large-scale Graphs	['Graph Neural Network', 'Transformer', 'Node Classification']	A global graph transformer working well on both homophilious and heterophilious graphs.	Deep Learning and representational learning	anonymous|goat_a_global_transformer_on_largescale_graphs	/pdf/dbd06894aec4280da94eb4e6e56d0f4159d9867f.pdf
QEfpL9Iy2KD	740	Distribution Aware Metrics for Conditional Natural Language Generation	['Natural Language Generation', 'Video Description', 'Image Description', 'Metrics']	his work introduces alternative methods for the evaluation of conditional natural language generation based on language distributional divergences.	Applications (eg, speech processing, computer vision, NLP)	anonymous|distribution_aware_metrics_for_conditional_natural_language_generation	/pdf/05a64d682fc86f29df8842547eaef6fbdc6766b4.pdf
FvevdI0aA_h	741	Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization	['detoxify', 'debias', 'language generation']	We propose an inference-time unified detoxifying and debiasing framework, which achieves better balance among effectiveness, computation cost and generation quality.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|unified_detoxifying_and_debiasing_in_language_generation_via_inferencetime_adaptive_optimization	/pdf/df59fff70efff66826bbf5f62ab3bb3bbb4fafd5.pdf
Rsrd5wK4kEh	742	How Powerful is Implicit Denoising in Graph Neural Networks	['GNN denoising', 'GNN theory']	We theoretically analyze the denoising effect in graph neural networks.	Deep Learning and representational learning	anonymous|how_powerful_is_implicit_denoising_in_graph_neural_networks	/pdf/78a44d934b52f076e01dddf9926053b6a920e9ca.pdf
B_pCIsX8KL_	743	GRACE-C: Generalized Rate Agnostic Causal Estimation via Constraints	['Causal structure learning', 'causal learning', 'graph theory', 'brain imaging', 'fMRI']	A novel method for causal structure discovery in undersampled time-series with three orders of magnitude speedup under the same theoretical guarantees.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|gracec_generalized_rate_agnostic_causal_estimation_via_constraints	/pdf/18a39b3bace5f753ca3904fb2c8f0f86d05cd164.pdf
Bo7eeXm6An8	744	Multi-lingual Evaluation of Code Generation Models	['code generation', 'execution-based evaluation', 'test-based evaluation', 'language models', 'multi-lingual code generation benchmark', 'code insertion', 'code summarization', 'robustness for code', 'code translation', 'zero-shot code translation', 'multi-lingual', 'mono-lingual', 'language models.']		Deep Learning and representational learning	anonymous|multilingual_evaluation_of_code_generation_models	/pdf/7b598202dbc845977fc79c501ef18bff949b2df7.pdf
MXoeggsH7yP	745	Improving the Latent Space of Image Style Transfer	['style transfer', 'contrastive learning']	We find a widespread problem in style transfer caused by the inappropriate pre-trained encoders to provide supervision signals and design a training scheme to alleviate this problem. 	Deep Learning and representational learning	anonymous|improving_the_latent_space_of_image_style_transfer	/pdf/de3f0aaca759c22c5397183538366190d9d87439.pdf
P17yA67o3VL	746	CAST: Concurrent Recognition and Segmentation with Adaptive Segment Tokens	[]	A new ViT integrated with data-driven perceptual organization to simultaneously learn image segmentation for free while training the model for unsupervised recognition.	Deep Learning and representational learning	anonymous|cast_concurrent_recognition_and_segmentation_with_adaptive_segment_tokens	/pdf/6c6bbfc2182bda49c7c22e20a3af24090286d372.pdf
gO8vNRKzzjp	747	MixPath: A Unified Approach for One-shot Neural Architecture Search 	['neural architecture search', 'multi-path', 'one-shot']	A multi-path one-shot neural architecture search approach	Deep Learning and representational learning	anonymous|mixpath_a_unified_approach_for_oneshot_neural_architecture_search	/pdf/5c4446c401278c0b078878fd0848fadd60a25576.pdf
G2Q2Mh3avow	748	Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language	['prompt engineering', 'multimodal applications', 'visual language models', 'large language models', 'commonsense reasoning']	We present a modular class of systems in which multiple pretrained models may be composed zero-shot via multimodal-informed prompt engineering to capture new multimodal capabilities, without additional finetuning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|socratic_models_composing_zeroshot_multimodal_reasoning_with_language	/pdf/74cc1b0d7894320c3879cea2c009a245b850dbba.pdf
Iewi8zwGsZr	749	Promoting Semantic Connectivity: Dual Nearest Neighbors Contrastive Learning for Unsupervised Domain Generalization	[]		Deep Learning and representational learning	anonymous|promoting_semantic_connectivity_dual_nearest_neighbors_contrastive_learning_for_unsupervised_domain_generalization	/pdf/b29c6acf4b0f36536d1a9c8ffe3f9cc4d6d2de59.pdf
nYqCVDAXAPE	750	Knowledge-driven Scene Priors for Semantic Audio-Visual Embodied Navigation	['Audio-Visual Navigation', 'Scene Priors', 'Object Relations', 'Embodied AI']	We introduce knowledge-driven scene priors in audio-visual navigation, combining semantics from a knowledge graph, spatial knowledge from dual Graph Encoder Networks, and background knowledge from pre-training tasks—all within an RL framework.	Applications (eg, speech processing, computer vision, NLP)	anonymous|knowledgedriven_scene_priors_for_semantic_audiovisual_embodied_navigation	/pdf/443d7653be4a211d96b9ed311955191564029941.pdf
rdjeCNUS6TG	751	Multivariate Time-series Imputation with Disentangled Temporal Representations	['multivariate time-series imputation', 'disentangled representation']	We propose a multivariate time-series imputation model based on matrix factorization, which composes meaningful disentangled temporal representations that account for multiple explanatory factors (trend, seasonality, local bias).	Deep Learning and representational learning	anonymous|multivariate_timeseries_imputation_with_disentangled_temporal_representations	/pdf/6d828782204f135df2155cbe9c0342ca57c20168.pdf
0vqjc50HfcC	752	DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models	['Unsupervised MRI Denoising', 'Diffusion Models']		Applications (eg, speech processing, computer vision, NLP)	anonymous|ddm^2_selfsupervised_diffusion_mri_denoising_with_generative_diffusion_models	/pdf/ad40f6b28f1f563fbf8ec9032fea3179db262c5f.pdf
cxvEGLCHpgl	753	Semi-supervised Community Detection via Structural Similarity Metrics	['Semi-supervised', 'Community Detection', 'Network', 'DCBM', 'Degree Heterogeneity', 'Non-Assortative']	We propose a fast semi-supervised community detection algorithm AngleMin+ based on the structural similarity metric of DCBM, which is able to address degree heterogeneity and non-assortative network and possesses nice theoretical guarantees.	General Machine Learning (ie none of the above)	anonymous|semisupervised_community_detection_via_structural_similarity_metrics	/pdf/35db3d6934a22350247ea481d5239e3e99bb4474.pdf
p0zTRXkTtB8	754	Pareto Automatic Multi-Task Graph Representation Learning	['Graph Representation Learning', 'Multi-Objective Optimization', 'Multi-Task Learning', 'Neural Architecture Search']	From a multi-objective perspective, this paper first tries to automatically search for a general-purpose multi-task graph neural network architecture that matches various user-desired task preferences.	Optimization (eg, convex and non-convex optimization)	anonymous|pareto_automatic_multitask_graph_representation_learning	/pdf/472550e92bae44ac75f2d73ca83e2a664ee568e8.pdf
sLPhtvZ9A7f	755	FeatER: An Efficient Network for Human Reconstruction Feature map-based TransformER	['human pose estimation', 'human mesh recovery', 'transformer architecture']		Applications (eg, speech processing, computer vision, NLP)	anonymous|feater_an_efficient_network_for_human_reconstruction_feature_mapbased_transformer	/pdf/5e4f4208ad397ceb2e3b89ecac9b38acce61671e.pdf
0qmwFNJyxCL	756	Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning	['adversarial training', 'contrastive learning', 'adversarial contrastive learning']	We revisit adversarial contrastive training through the lens of data augmentation, and propose an effective adversarial contrastive framework that outperforms vanilla supervised adversarial robustness.	Unsupervised and Self-supervised learning	anonymous|rethinking_the_effect_of_data_augmentation_in_adversarial_contrastive_learning	/pdf/d9ae2dfba72a984cc034b492f9c0278fd4e67c38.pdf
9IUxnGC8e9u	757	Exploring The Capacity Mismatch Problem in Knowledge Distillation from the View of Soft Labels	['knowledge distillation', 'parameter-efficiency', 'transfer learning']	The main contributions of our work are the discovery, analysis, and validation of the effect of the smoothed soft label and a less time-consuming and adaptive transfer of the teacher's knowledge method.	Deep Learning and representational learning	anonymous|exploring_the_capacity_mismatch_problem_in_knowledge_distillation_from_the_view_of_soft_labels	/pdf/5e257b56b125b9652d78fcee458afb5095478c81.pdf
VWm4o4l3V9e	759	Block and Subword-Scaling Floating-Point (BSFP) : An Efficient Non-Uniform Quantization For Low Precision Inference	[]		General Machine Learning (ie none of the above)	anonymous|block_and_subwordscaling_floatingpoint_bsfp_an_efficient_nonuniform_quantization_for_low_precision_inference	/pdf/410320668ae6dbfdab981c179a0f97a56bd02925.pdf
h21yJhdzbwz	760	Relaxed Combinatorial Optimization Networks with Self-Supervision: Theoretical and Empirical Notes on the Cardinality-Constrained Case	['deep learning', 'combinatorial optimization', 'facility location problem', 'max coverage problem', 'portfolio optimization']	We present a Gumbel-Sinkhorn network for cardinality-constrained combinatorial optimization with theoretical and empirical notes. We surpass Erdos Goes Neural on optimization problems, and present an application on predictive portfolio optimization.	Deep Learning and representational learning	anonymous|relaxed_combinatorial_optimization_networks_with_selfsupervision_theoretical_and_empirical_notes_on_the_cardinalityconstrained_case	/pdf/28a5c1947438215f824b4260b70edc988bb5af59.pdf
FUORz1tG8Og	761	CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural Representations	['PDE', 'implicit neural representation', 'neural field', 'latent space traversal', 'reduced-order modeling', 'numerical methods']	We accelerate PDE solvers via rapid latent space traversal of continuous vector fields leveraging implicit neural representations.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|crom_continuous_reducedorder_modeling_of_pdes_using_implicit_neural_representations	/pdf/b8f0e92f2365c205cddb7bd49bf784300fca5721.pdf
-jTaz3CMk72	762	Breaking Correlation Shift via Conditional Invariant Regularizer	['OOD Generalization', 'Spurious Correlation', 'Optimization']	This paper proposes an algorithm to make the model to generalize on data with spurious correlation, the method can be implemented without information on spurious feature. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|breaking_correlation_shift_via_conditional_invariant_regularizer	/pdf/fd26390f5e7e0411543c38e2348ff05ac532c06e.pdf
rzrqh85f4Sc	764	Towards Addressing Label Skews in One-shot Federated Learning	['federated learning']	We propose FedOV to significantly improve the test accuracy under diverse label skews in one-shot federated learning.	Deep Learning and representational learning	anonymous|towards_addressing_label_skews_in_oneshot_federated_learning	/pdf/8f228ec402cbc9d28e370f293d9854e71cedfcc4.pdf
WoByU5W5te0	765	Neural Radiance Fields with Geometric Consistency for Few-Shot Novel View Synthesis	['NeRF', '3D Computer Vision']		Applications (eg, speech processing, computer vision, NLP)	anonymous|neural_radiance_fields_with_geometric_consistency_for_fewshot_novel_view_synthesis	/pdf/f6bc671f451a20523c7b7c453e674ac040758867.pdf
8FL8vRvlk59	766	Reinforced Sample Reweighting Policy for Semi-supervised Learning	['Semi-supervised Learning']		Deep Learning and representational learning	anonymous|reinforced_sample_reweighting_policy_for_semisupervised_learning	/pdf/946f6631a84d0bd1e015ab00961df4860203e08a.pdf
UGOpvh4vXS2	767	Decouple Graph Neural Networks: Train Multiple Simple GNNs Simultaneously Instead of One	['Graph neural network', 'efficient training', 'backward training']	An efficient model to decouple multi-layer graph neural networks and training them by forward and backward training	Deep Learning and representational learning	anonymous|decouple_graph_neural_networks_train_multiple_simple_gnns_simultaneously_instead_of_one	/pdf/ed2be2abdaf74029dd12f2a712263da113cbcb8a.pdf
EWjYk3R2jhr	768	Elastic Aggregation for Federated Optimization	['Federated Learning', 'AI Safety', 'Autonomous Driving', 'Drug Discovery', 'Clinical Diagnosis', 'Recommender Systems']	Elastic aggregation works well with other federated optimizers and achieves significant improvements across the board.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|elastic_aggregation_for_federated_optimization	/pdf/b9b744ecb0975b6021bd71a2b6e28cdfc96095ad.pdf
F91SROvVJ_6	769	Causal Balancing for Domain Generalization	['domain generalization', 'causality', 'latent variable model']	We propose a balanced mini-batch sampling strategy to reduce spurious correlations for domain generalization.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|causal_balancing_for_domain_generalization	/pdf/0e9a90ea20872d92a7d7957168d2480bbb4773b9.pdf
iPhccmh9FyK	770	Leveraging Hierarchical Structure for Multi-Domain Active Learning with Theoretical Guarantees	['Active Learning', 'Multi-Domain Learning']	We formalize the general definition of multi-domain active learning and propose Composite Active Learning (CAL) as the first general deep AL method for addressing this problem with theoretical guarantees by leveraging hierarchical structure. 	General Machine Learning (ie none of the above)	anonymous|leveraging_hierarchical_structure_for_multidomain_active_learning_with_theoretical_guarantees	/pdf/42cef3948c11df692603c83dc8d3b660f260781e.pdf
kh3JurmKlux	771	Node Classification Beyond Homophily: Towards a General Solution	['node classification', 'structure learning', 'homophily', 'heterophily']		Deep Learning and representational learning	anonymous|node_classification_beyond_homophily_towards_a_general_solution	/pdf/683d2ad3d2a057eb5d162780681e2058a26271b6.pdf
DswOSXvLfuy	772	MLM with Global Co-occurrence	['MLM pre-training', 'Multilingual model', 'Machine Learning for NLP', 'Language Modeling']	We present MLM-GC (Masked Language Modeling with Global Co-occurrence) for multilingual tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|mlm_with_global_cooccurrence	/pdf/9d1f6fcf2b59aa6cdafcd4d7fb79a84e49898ed8.pdf
0MqQ88Z2Kta	773	Evaluating and Inducing Personality in Pre-trained Language Models	['machine personality', 'pre-trained language model', 'personality trait theory', 'psychometric inventory', 'prompt']	We propose the Machine Personality Inventory (MPI) dataset for evaluating the machine personality and devise a Chain Prompting method to induce the language model with a specific personality, capable of producing diversified behaviors.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|evaluating_and_inducing_personality_in_pretrained_language_models	/pdf/90f116b1f0163241892f149070fe25100ee315a7.pdf
01KmhBsEPFO	774	Exploring Low-Rank Property in Multiple Instance Learning for Whole Slide Image Classification	['computational pathology', 'multiple instance learning', 'low-rank constraint', 'self-attention']	draft	Applications (eg, speech processing, computer vision, NLP)	anonymous|exploring_lowrank_property_in_multiple_instance_learning_for_whole_slide_image_classification	/pdf/6b8a109ff007fb659cd12f95c8655451f18fa096.pdf
ZccFLU-Yk65	775	DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection	[]		Deep Learning and representational learning	anonymous|dbqssd_dynamic_ball_query_for_efficient_3d_object_detection	/pdf/2ea6a6f778e4433fd2763a7aa7498870fedad70f.pdf
C0oEBO4ZpOj	776	MGMA: Mesh Graph Masked Autoencoders for Self-supervised Learning on 3D Shape	['mesh graph', 'self-supvervised learning', 'masked autoencoder', 'attention']	We introduce a self-supervised learning model to extract face nodes and global graph embeddings on meshes.	Unsupervised and Self-supervised learning	anonymous|mgma_mesh_graph_masked_autoencoders_for_selfsupervised_learning_on_3d_shape	/pdf/997929c5044fcec59adad13f2cffe0f6f1fb4b44.pdf
Qnxcl6zWobO	777	Quality Matters: Embracing Quality Clues for Robust 3D Multi-Object Tracking	[]		Deep Learning and representational learning	anonymous|quality_matters_embracing_quality_clues_for_robust_3d_multiobject_tracking	/pdf/bff40c1563f1a0c31cb2ff2f2cd0ca782b5107b7.pdf
4JRX93ADS2r	778	Extreme Masking for Learning Instance and Distributed Visual Representations	['visual representation learning', 'self-supervised learning', 'masked modeling']	A method that uses extremely large masking as a novel augmentation for learning siamese networks.	Unsupervised and Self-supervised learning	anonymous|extreme_masking_for_learning_instance_and_distributed_visual_representations	/pdf/6d3629e78b764c2fca5d4688a3fdca54c2aca7d8.pdf
OXP9Ns0gnIq	779	Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models	['Deep generative models', 'inverse problems', 'Gaussianization']		Generative models	anonymous|differentiable_gaussianization_layers_for_inverse_problems_regularized_by_deep_generative_models	/pdf/a1ef44b921aed3ed077a370eac23bc1cd2171b40.pdf
u4k-Zgqr9SN	780	Global Hardest Example Mining with Prototype-based Triplet Loss	[]		General Machine Learning (ie none of the above)	anonymous|global_hardest_example_mining_with_prototypebased_triplet_loss	/pdf/97df3bae8beb73965abab25d327eb2bee8626419.pdf
yAYHho4fATa	782	CFlowNets: Continuous control with Generative Flow Networks	['Continuous control tasks', 'Generative flow networks']	Continuous GFlowNets	Generative models	anonymous|cflownets_continuous_control_with_generative_flow_networks	/pdf/79d265b79bf2effb4a9f47cb2d23df629e21392b.pdf
wC98X1qpDBA	783	 Cycle-consistent Masked AutoEncoder for Unsupervised Domain Generalization	[]		Unsupervised and Self-supervised learning	anonymous|cycleconsistent_masked_autoencoder_for_unsupervised_domain_generalization	/pdf/269b4f6774a1b9ed6963450dc3c5af0447406ced.pdf
TnzdAU7c8WM	784	Learning Visual Representation with Synthetic Images and Topologically-defined Labels	['topology', 'persistent homology', 'self-supervised learning', 'synthetic image']	We propose a new type of pretext task for self-supervised learning with synthetic images and mathematically-defined labels to incentivise learning global topological features of images	Unsupervised and Self-supervised learning	anonymous|learning_visual_representation_with_synthetic_images_and_topologicallydefined_labels	/pdf/e0c89002548d58088db395d8ab5210ff33489f33.pdf
66kLbXgU_ae	785	EXACT: Compositional Augmentation for Image-level Weakly-Supervised Instance Segmentation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|exact_compositional_augmentation_for_imagelevel_weaklysupervised_instance_segmentation	/pdf/6bc99ef62c1cbdc22c935f7f39d5e239f89737f4.pdf
OdZcJYT5Z4k	786	Generalized structure-aware missing view completion network for incomplete multi-view clustering	['Incomplete multi-view clustering', 'Missing view imputation', 'Representation learning', 'Deep neural network']	A general incomplete multi-view clustering framework via missing view completion and recurrent graph constraint.	Deep Learning and representational learning	anonymous|generalized_structureaware_missing_view_completion_network_for_incomplete_multiview_clustering	/pdf/332ba77691d649a7eefcee6f9bbb07c6bffb9814.pdf
gx2yJS-ENqI	787	S-NeRF: Neural Radiance Fields for Street Views	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|snerf_neural_radiance_fields_for_street_views	/pdf/d4d5ebb7a4cadf12fae351a0add84348a34be127.pdf
rvsbw2YthH_	788	The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning	['Contrastive Learning', 'Self-Supervised Learning', 'Foundation Model', 'Complexity']	We focus on contrastive learning and systematically study a trade-off between label efficiency and universality both empirically and theoretically.	Unsupervised and Self-supervised learning	anonymous|the_tradeoff_between_universality_and_label_efficiency_of_representations_from_contrastive_learning	/pdf/bf2b61d894d4bd8b4534ebf7fe712442fcd443ba.pdf
reEMFxIRMAl	790	DCE: Offline Reinforcement Learning With Double Conservative Estimates	['Offline RL', 'Conservative estimation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|dce_offline_reinforcement_learning_with_double_conservative_estimates	/pdf/2b8468ea19d0a60a8ac78908f7a9ffaa9b0eb82d.pdf
nsT1vO6i3Ri	791	Efficient Surrogate Gradients for Training Spiking Neural Networks	['surragate gradient', 'spiking neural network', 'low extra overhead']	We propose a method to change the shape of surrogate gradients, which can improve the performance of spiking neural networks with low extra overhead.	Deep Learning and representational learning	anonymous|efficient_surrogate_gradients_for_training_spiking_neural_networks	/pdf/0aeff578c31498a342bbec2646d3ea8c786468fa.pdf
h-tOz83WrC	793	Interpreting Neural Networks Through the Lens of Heat Flow	['interpretable', 'explanation', 'heat', 'Laplacian', 'attribution', 'geometry', 'flow', 'PDE']	Solve the heat equation to interpret neural networks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|interpreting_neural_networks_through_the_lens_of_heat_flow	/pdf/e9ab4ad9db0cc0ddad5c3b389916dfe6f16aac2a.pdf
8Z6OZ3qKHDD	794	Robust Transfer Learning Based on Minimax Principle	['Transfer Learning', 'Minimax Principle', 'Robustness']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|robust_transfer_learning_based_on_minimax_principle	/pdf/089211580e17bc5be0a369fb31fd6c9ece786b5e.pdf
C49AIKljGaa	795	ConBaT: Control Barrier Transformer for Safety-Critical Policy Learning	['Learning from demonstration', 'Control barrier functions', 'Transformer models']		Deep Learning and representational learning	anonymous|conbat_control_barrier_transformer_for_safetycritical_policy_learning	/pdf/0106838378c23cdf7da25c375d86356cf88f531d.pdf
8T4qmZbTkW7	796	Progressive Compressed Auto-Encoder for Self-supervised Representation Learning	['MIM', 'Transformer', 'self-supervised learning']		Unsupervised and Self-supervised learning	anonymous|progressive_compressed_autoencoder_for_selfsupervised_representation_learning	/pdf/56b8cf9270cdc4695d7481283e7796af32052049.pdf
wamiG4pzNN1	797	SinGRAV: Learning a Generative Radiance Volume from a Single Natural Scene	['Generative model', '3D Single Scene']		Generative models	anonymous|singrav_learning_a_generative_radiance_volume_from_a_single_natural_scene	/pdf/1afdb116ce3dcfb97ff6763f27502bfe1cea2257.pdf
P8YIphWNEGO	799	MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization	['Graph Neural Network', 'Large-scale Graph', 'Accleration']	we propose an embarrassingly simple, yet hugely effective initialization for GNN training acceleration by initializing GNN with full trained MLP.	Deep Learning and representational learning	anonymous|mlpinit_embarrassingly_simple_gnn_training_acceleration_with_mlp_initialization	/pdf/7c6f9396e63ac5fd2fcb613c19ed0e46d254d0dc.pdf
SJO188Y53lk	800	Do We Really Achieve Fairness with Explicit Sensitive Attributes? 	['fairness', 'debias', 'demographic parity']	We found that different sample leak different amount of sensitive information and has different-level violation of demographic parity, thus we propose a new metric and method to address this problem.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|do_we_really_achieve_fairness_with_explicit_sensitive_attributes	/pdf/1b205f95c8abaa98404ab7357bdf9bb604a92e16.pdf
WZ2L6D8IHoc	801	Contextual Symbolic Policy For Meta-Reinforcement Learning	['meta learning', 'reinforcement learning', 'context variables', 'symbolic policy']	This paper propose a gradient-based framework to generate contextual symbolic policy for Meta-Reinforcement Learning to improve the generalization ability, efficiency and interpretability.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|contextual_symbolic_policy_for_metareinforcement_learning	/pdf/81ba95dd9cc21f8ffe9cc24f343775dc3b4f5bbd.pdf
uHrJ1AY1xR1	802	Distributional Reinforcement Learning via Sinkhorn Iterations	['distributional reinforcement learning', 'sinkhorn divergence']	We designed a new class of distributional RL algorithm based on Sinkhorn divergence.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|distributional_reinforcement_learning_via_sinkhorn_iterations	/pdf/b2903cd0de0b84e7b39f2e32e4d25134756f4718.pdf
nZYU28EJ3OS	803	Neural Topic Modeling with Embedding Clustering Regularization	[]	We propose a neural topic model that addresses the topic collapsing issue with a novel clustering regularization on word and topic embeddings.	Applications (eg, speech processing, computer vision, NLP)	anonymous|neural_topic_modeling_with_embedding_clustering_regularization	/pdf/594318750d35610f103b2c3d3976db8f57fccd4b.pdf
bPiHuNUNv_R	804	The Power of Regularization in Solving Extensive-Form Games	['Game Theory', 'Optimization']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|the_power_of_regularization_in_solving_extensiveform_games	/pdf/0841aa16b73c0e26ea631a91be41f62a5de1044a.pdf
zAbFj7FpD-C	805	Interpreting Distributional Reinforcement Learning: A Regularization Perspective	['distributional reinforcement learning', 'regularization', 'entropy']	We interpret distributional reinforcement learning from the perspectives of regularization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|interpreting_distributional_reinforcement_learning_a_regularization_perspective	/pdf/6ad3950a16a8a08387b17df3c0d25d24b0f2efcd.pdf
mDHjdjQl0Ae	806	Coordinate and Generalize: A Unified Framework for Audio-Visual Zero-Shot Learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|coordinate_and_generalize_a_unified_framework_for_audiovisual_zeroshot_learning	/pdf/e34704e36357496607262ef23d608953423e789e.pdf
My57qBufZWs	807	Bort: Towards Explainable Neural Networks with Bounded Orthogonal Constraint	['Neural network', 'explainable AI', 'optimizer.']	We propose an optimizer, Bort, for training explainable neural networks with boundedness and orthogonality constraints.	Optimization (eg, convex and non-convex optimization)	anonymous|bort_towards_explainable_neural_networks_with_bounded_orthogonal_constraint	/pdf/d1cdb15a5400963d2dc4b8195a89852fd6705c22.pdf
pT4ref-FMAX	808	How Does Value Distribution in Distributional Reinforcement Learning Help Optimization?	['distributional reinforcement learning', 'optimization']	We study the optimization advantages of distritbutional reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|how_does_value_distribution_in_distributional_reinforcement_learning_help_optimization	/pdf/eba77c4ba420b377e1dd057bd68c3996763ddd26.pdf
EeEU0b9CPD3	810	Inferring Fluid Dynamics via Inverse Rendering	[]		Deep Learning and representational learning	anonymous|inferring_fluid_dynamics_via_inverse_rendering	/pdf/4370bc10f9a037357c092780368d851fdcb96f8a.pdf
urF_CBK5XC0	811	Generative Augmented Flow Networks	['Generative Flow Networks (GFlowNets)', 'Exploration']	We propose a novel GFlowNet learning framework to incorporate intermediate rewards represented by intrinsic motivation to improve exploration.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|generative_augmented_flow_networks	/pdf/d35191c46f45f86677425438b6dec2f45fd33bff.pdf
CIFOsnhZvON	812	TempCLR: Temporal Alignment Representation with Contrastive Learning	['Representation learning', 'Global Sequence Alignment', 'Zero/Few-shot Transfer']	Global sequence matching under temporal order consistency matters in contrastive-based video-paragraph/text learning.	Deep Learning and representational learning	anonymous|tempclr_temporal_alignment_representation_with_contrastive_learning	/pdf/b6fcf72a71fcee6d7bf246e4937adc000f65d352.pdf
Fw516fpXI-c	813	Zipper: Decoupling the tradeoff Between Robustness and Accuracy	['Adversarial Training']	We propose a bi-expert framework where we simultaneously train base-learners with distribution-aware strategies so that it can obtain both satisfying clean accuracy and robustenss	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|zipper_decoupling_the_tradeoff_between_robustness_and_accuracy	/pdf/3fe15be9301582c0dce4cbbe471004f1b516435f.pdf
U1T5FpFZ6zZ	814	Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels	['Contrastive Learning', 'Self-supervised Learning', 'Semi-supervised Learning', 'Medical Image Segmentation']	This paper proposes a semi-supervised contrastive learning framework that seamlessly assembles three effective principles: tailness, consistency, and diversity, which outperforms existing semi-supervised and fully-supervised competitors.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|mine_your_own_anatomy_revisiting_medical_image_segmentation_with_extremely_limited_labels	/pdf/d053544a3ca1dc18b2a11a73ef48b7850cf7de88.pdf
b4t9_XASt6G	816	On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme	"['Emergent Communication', 'Emergent Language', 'Unsupervised Word Segmentation', ""Harris's Articulation Scheme"", 'Compositionality']"	This paper investigates whether Harris's articulation scheme (HAS) also holds in emergent languages.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|on_the_word_boundaries_of_emergent_languages_based_on_harriss_articulation_scheme	/pdf/7d29ab410707a07bf77e4050653385a1d70f2aa8.pdf
iN3Lh-Vy2TH	817	Phase transition for detecting a small community in a large network	['community detection', 'degree-correct block model', 'global testing', 'planted clique', 'statistical-computational gap']	Signed-quadrilateral is optimal among computationally efficient tests for detecting a small community in the degree-corrected stochastic block model.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|phase_transition_for_detecting_a_small_community_in_a_large_network	/pdf/6c96f91128e0297af8d84186383ecd1bc4f82af4.pdf
mjHlitXvReu	818	Learning Object-Language Alignments for Open-Vocabulary Object Detection	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_objectlanguage_alignments_for_openvocabulary_object_detection	/pdf/ed390479da197612b9a177c090bfb57fc1347671.pdf
fuxn3HyIZjU	820	ZERO: A Large-scale Chinese Cross-modal Benchmark with a New Vision-Language Framework	[]		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|zero_a_largescale_chinese_crossmodal_benchmark_with_a_new_visionlanguage_framework	/pdf/c54ec348e0bd832757abc240d2b50cc99e57b6b4.pdf
iOc57X9KM54	822	Neuro-Symbolic Procedural Planning with Commonsense Prompting	['Procedural Planning', 'Commonsense Knowledge', 'Prompting', 'Neuro-Symbolic']	We propose a neuro-symbolic procedural planner that elicits procedural planning knowledge from the large language models with commonsense-infused prompting. We achieve state-of-the-art performance on WikiHow and RobotHow.	Applications (eg, speech processing, computer vision, NLP)	anonymous|neurosymbolic_procedural_planning_with_commonsense_prompting	/pdf/2629a961da499b65430ac4fca70fc499ec47b0cc.pdf
4Tx2-AH-jG_	823	MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning	['self-supervised learning', 'masked image modeling']		Unsupervised and Self-supervised learning	anonymous|mixmim_mixed_and_masked_image_modeling_for_efficient_visual_representation_learning	/pdf/814b8bc2718de26d04b71eb27d42dd613dde9a67.pdf
Xj1orI5p6Sv	824	Corruption Depth: Analysis of DNN depth for Misclassification	['Classification Depth', 'Deep Representation', 'Robust Recognition']	Identify the layers lead to robust image classification 	Deep Learning and representational learning	anonymous|corruption_depth_analysis_of_dnn_depth_for_misclassification	/pdf/ee02c6dd6ec61dc50d0d437e68f5871fa6d2f28d.pdf
lqgkka9jzzK	825	Self-Organizing Pathway Expansion for Non-Exemplar Incremental Learning	['Incremental Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|selforganizing_pathway_expansion_for_nonexemplar_incremental_learning	/pdf/c366c09010ba1d41394e27350219266a6d06234a.pdf
qhplAU1BOZW	826	Lottery Aware Sparsity Hunting: Enabling Federated Learning on Resource-Limited Edge	['Sparse federated learning (FL)', 'communication efficient FL', 'computation efficient FL']	We present methodologies for sparse federated learning for resource constrained edge (both homogeneous and heterogeneous compute budget).	General Machine Learning (ie none of the above)	anonymous|lottery_aware_sparsity_hunting_enabling_federated_learning_on_resourcelimited_edge	/pdf/03a8f50ec2c5551867a18db2351d26115c6db384.pdf
DHyHRBwJUTN	828	Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning	['Mathematical Reasoning', 'Tabular Math Word Problems', 'Prompt Learning', 'Policy Gradient']	We present a new tabular math word problem dataset, TabMWP, and we propose a novel approach to it that learns to select in-context examples in few-shot GPT-3 via policy gradient. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|dynamic_prompt_learning_via_policy_gradient_for_semistructured_mathematical_reasoning	/pdf/1e76764b029b42e33c0c7b5e1a6e788d48d6a552.pdf
9-umxtNPx5E	829	Masked Frequency Modeling for Self-Supervised Visual Pre-Training	['unsupervised learning', 'self-supervised learning', 'representation learning', 'masked frequency modeling']		Unsupervised and Self-supervised learning	anonymous|masked_frequency_modeling_for_selfsupervised_visual_pretraining	/pdf/159ea684ef8002a3e384661d7fd620e8fec55d10.pdf
dBbdV4CTEQf	830	A Unified Pretraining Framework for Human Motion Analysis	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|a_unified_pretraining_framework_for_human_motion_analysis	/pdf/c93235b97dd2115a62bd6dacf1a1e6b7c6fbc6bf.pdf
2RwXVje1rAh	831	Exploring Active 3D Object Detection from a Generalization Perspective	['Active Learning', '3D Object Detection', 'Lidar Point Clouds']		General Machine Learning (ie none of the above)	anonymous|exploring_active_3d_object_detection_from_a_generalization_perspective	/pdf/e48b51097669be4f6e2670e2c4d1f125efe77cc9.pdf
rrjOLTU1jkw	832	Scratching Visual Transformer's Back with Uniform Attention	['Vision Transformer', 'Self-attention', 'Attention', 'Dense Interactions', 'Image Classification']	Vision Transformers may need yet more dense interactions. We tried to supply them with a simple trick. We get improvements.	Deep Learning and representational learning	anonymous|scratching_visual_transformers_back_with_uniform_attention	/pdf/ba3e2fa46b9cea23f94329cabd0ea58967609d84.pdf
eyyS-zovT9m	833	StyleGenes: Discrete and Efficient Latent Distributions for GANs	['generative adversarial networks', 'discrete sampling', 'unconditional training', 'conditional generation']		Generative models	anonymous|stylegenes_discrete_and_efficient_latent_distributions_for_gans	/pdf/37d0b9f4f9929d55c9629ccf6173b15b16a9120f.pdf
NeH20Y8mDvp	834	Edge Wasserstein Distance Loss for Oriented Object Detection	['oriented object detection', 'regression loss design']	This paper proposes a novel orinted object regression loss	Deep Learning and representational learning	anonymous|edge_wasserstein_distance_loss_for_oriented_object_detection	/pdf/52b5f149b05415f07ee731616dbf172f0dbcfbf1.pdf
G7_LoXdE2Oe	836	Video-based 3D Object Detection with Learnable Object-Centric Global Optimization	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|videobased_3d_object_detection_with_learnable_objectcentric_global_optimization	/pdf/6f7ef3f836748451ee19b9a59589a360d151f9e5.pdf
87n67AtiHo	837	Improved Fully Quantized Training via Rectifying Batch Normalization	['Model Compression', 'Gradient Quantization', 'Convolution Neural Networks', 'Batch Normalization']		Deep Learning and representational learning	anonymous|improved_fully_quantized_training_via_rectifying_batch_normalization	/pdf/91c5c927f5498808b82ba023f9dbc0be1ab1bb0a.pdf
TDf-XFAwc79	838	Meta Knowledge Condensation for Federated Learning	[]		General Machine Learning (ie none of the above)	anonymous|meta_knowledge_condensation_for_federated_learning	/pdf/3095d3a8e31c87b923166275a6b9bbd6802417d3.pdf
PHcLZ8Yh6h4	839	Progressive Purification for Instance-Dependent Partial Label Learning	['Partial label learning']		Deep Learning and representational learning	anonymous|progressive_purification_for_instancedependent_partial_label_learning	/pdf/0365aaf40898c9a5da0a41af7dbb4de34a533987.pdf
zOLLCOgUGIH	840	Low-Rank Winograd Transformation for 3D Convolutional Neural Networks	['3D CNN', 'Network Pruning', 'Winograd Algorithm']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|lowrank_winograd_transformation_for_3d_convolutional_neural_networks	/pdf/2ceefc4b83dea25a98503be21f2ac942700768e6.pdf
rLwC0_MG-4w	841	Denoising Diffusion Error Correction Codes	['ECC', 'Deep Learning', 'Diffusion Models']	We propose a novel SOTA Neural error correction decoder based on a new diffusion model.	Deep Learning and representational learning	anonymous|denoising_diffusion_error_correction_codes	/pdf/e5dc0b776695db7367440c2d1d4f171b71201b3a.pdf
470wZ5Qk4ur	842	Results for Perfect Classification for Graph Attention on the Contextual Stochastic Block Model	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|results_for_perfect_classification_for_graph_attention_on_the_contextual_stochastic_block_model	/pdf/738e7f0dd29a62fc15fb8aafffd9ceedfe27b956.pdf
PXibCVxXdT	843	Wasserstein Fair Autoencoders	['conditional generation', 'fair representation', 'disentanglement', 'wasserstein autoencoder']	We present a framework based on Wasserstein autoencoders that can reinforce some theoretical weak links in the variational approaches on fair or disentangled represenation.	Deep Learning and representational learning	anonymous|wasserstein_fair_autoencoders	/pdf/4e562815d04d317b333187042cba4848f529de4d.pdf
78IUEPOGjG6	844	Mitigating Forgetting in Online Continual Learning via Contrasting Semantically Distinct Augmentations	['continual learning', 'representation learning', 'memory replay']	Leverage the strong data augmentation to mitigate catastrophic forgetting	Deep Learning and representational learning	anonymous|mitigating_forgetting_in_online_continual_learning_via_contrasting_semantically_distinct_augmentations	/pdf/0eb4bc159eaca276d0bbf765270846b6e95a2492.pdf
BGF9IeDfmlH	845	Learning to Linearize Deep Neural Networks  for Secure and Efficient Private Inference	['Efficient private inference', 'cryptographic inference', 'machine learning as a service', 'efficient cryptographic inference', 'automated ReLU reduction']	We present an automated linearization method to train a DNN with limited ReLU budget for inference in yielding models able to perform significantly better than exiting private inference SOTA both in terms of potentially improved latency and accuracy.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_to_linearize_deep_neural_networks_for_secure_and_efficient_private_inference	/pdf/900e7f0ab99dcac693ce3c12220eff784ed1a7f9.pdf
Gb2Rndy5595	846	Context Autoencoder for Self-Supervised Representation Learning	['Self-Supervised Representation Learning', 'Masked Image Modeling', 'Context Autoencoder']		Unsupervised and Self-supervised learning	anonymous|context_autoencoder_for_selfsupervised_representation_learning	/pdf/9cef72d67a70eeebbb46584c1c3aed70e791b2d9.pdf
rjYUBo_uWEs	850	Manifold Characteristics That Predict Downstream Task Performance	['self-supervised learning', 'deep learning', 'representation learning']	We introduce the Representation manifold quality metric (RMQM), which measures the structure of the learned representation manifold, where we then show that RMQM correlates positively to the generalisation of neural networks to downstream tasks. 	Deep Learning and representational learning	anonymous|manifold_characteristics_that_predict_downstream_task_performance	/pdf/82bcf0c397be1c3af9632eb731b60448f8cf1223.pdf
SEh5SfEQtqB	851	Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets	['Neural Architecture Search', 'Meta Learning']	We propose a one-shot meta accuracy prediction model which can predict a given architecture's final performances on a dataset when performing KD with a given teacher, without having to actually train it on the target task. 	Deep Learning and representational learning	anonymous|metaprediction_model_for_distillationaware_nas_on_unseen_datasets	/pdf/94924d10dae6eb7ddadba59d0c722be321688497.pdf
s_2Rye-RctO	852	How do Variational Autoencoders Learn? Insights from Representational Similarity	['variational autoencoders', 'VAEs', 'CKA', 'Procrustes', 'representation learning', 'representational similarity', 'learning dynamics']	How VAEs' representations converge during learning	Generative models	anonymous|how_do_variational_autoencoders_learn_insights_from_representational_similarity	/pdf/a9ead82ce11dea800e5accf26a21cb11d6cd8b46.pdf
w4eFMKkF_a_	854	An Encryption Framework for Pre-Trained Neural Networks	[]		Deep Learning and representational learning	anonymous|an_encryption_framework_for_pretrained_neural_networks	/pdf/d439f53ac9c781141dd3d3a7c8de2ea11011dc9a.pdf
DCgjv41MD2M	855	Distortion-Aware Network Pruning and Feature Reuse for Real-time Video Segmentation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|distortionaware_network_pruning_and_feature_reuse_for_realtime_video_segmentation	/pdf/c89cc1d60b260782a912665baed2a901c799d95b.pdf
x9S5kdaQkkY	856	FONDUE: an Algorithm to Find the Optimal Dimensionality of the Latent Representations of Variational Autoencoders	['variational autoencoders', 'VAEs', 'representation learning', 'intrinsic dimension estimation', 'IDE', 'polarised regime']	A principled method using intrinsic dimension estimation to find the optimal number of latent dimensions for variational autoencoders.	Generative models	anonymous|fondue_an_algorithm_to_find_the_optimal_dimensionality_of_the_latent_representations_of_variational_autoencoders	/pdf/37e07740a19149352e6522aaf774b50ae98d201f.pdf
JJuP86nBl4q	857	LAVA: Data Valuation without Pre-Specified Learning Algorithms	['data valuation', 'optimal transport', 'model agnostic', 'data-driven']	We propose LAVA: a novel model-agnostic approach to data valuation using a non-conventional, class-wise Wasserstein discrepancy.	General Machine Learning (ie none of the above)	anonymous|lava_data_valuation_without_prespecified_learning_algorithms	/pdf/3018f630b3fcdf5f1f56b4b601efe15e5356a175.pdf
rDArMCIvldMR	858	What's Wrong with the Robustness of Object Detectors?	['Object Detection', 'Adversarial Robustness']		Deep Learning and representational learning	anonymous|whats_wrong_with_the_robustness_of_object_detectors	/pdf/4353bbb59833f8b161f66cf60dd0c8223dc7ed1a.pdf
ddcqRzq6g2n	859	On-Device Domain Generalization	['Domain Generalization', 'Mobile Applications']	A systematic study on how to improve domain generalization for tiny neural networks	Deep Learning and representational learning	anonymous|ondevice_domain_generalization	/pdf/6cd373c3fd50a95a1043fd1e909c919784d2ec44.pdf
3aBuJEza5sq	860	Test-Time Robust Personalization for Federated Learning	['Federated Learning', 'Personalized Federated Learning', 'Test-time Robustness']	We identify the pitfalls of existing personalized federated learning methods during deployment and propose a novel test-time personalization solution.	Deep Learning and representational learning	anonymous|testtime_robust_personalization_for_federated_learning	/pdf/7d309bec261e79421598ec6605ebf9e509f592ed.pdf
miyZxvBxdoP	861	Temporal Label Smoothing for Early Prediction of Adverse Events	['Healthcare', 'Time-Series', 'Label Smoothing', 'Deep Learning', 'Application']	Modulating label smoothing strength over time to reflect signal noise patterns and clinical priorities significantly improves deep learning model performance in the prediction of adverse medical events.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|temporal_label_smoothing_for_early_prediction_of_adverse_events	/pdf/be15e143301d150c8557ba075da9af5bd41f6923.pdf
N8N2VMkWdVf	862	Triplet Similarity Learning on Concordance Constraint	['Metric Learning', 'Triplet Loss', 'Concordance', 'Hard samples']	A simple and elegant loss function is proposed to exploit the concordance constraint of triplet similarity for deep metric learning.	Optimization (eg, convex and non-convex optimization)	anonymous|triplet_similarity_learning_on_concordance_constraint	/pdf/30fc9dfe52bb0294d42ccc876c971a55eff05bb0.pdf
pm7O7gJObtk	863	NIERT: Accurate Numerical Interpolation through Unifying Scattered Data Representations using Transformer Encoder	['numerical interpolation', 'transformer encoder', 'mask mechanism', 'pre-training model']	We present an accurate data-driven approach to numerical interpolation for scattered data using transformer encoder with enhancement using pre-training technique.	Deep Learning and representational learning	anonymous|niert_accurate_numerical_interpolation_through_unifying_scattered_data_representations_using_transformer_encoder	/pdf/630d2286f93e4fad16ac16b2fccdacc2b2195f54.pdf
M1BrqvlID5J	865	Accurate and Efficient Soma Reconstruction in a Full Adult Fly Brain	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|accurate_and_efficient_soma_reconstruction_in_a_full_adult_fly_brain	/pdf/2b2363adeca8902bce1f0f721ee263d20a14be85.pdf
wwRjJScpsOO	866	Targeted Adversarial Self-Supervised Learning	['adversarial self-supervised learning', 'self-supervised learning', 'targeted attack', 'robustness']	We propose a novel targeted adversarial training method for the self-supervised learning frameworks.	Unsupervised and Self-supervised learning	anonymous|targeted_adversarial_selfsupervised_learning	/pdf/3ac50c8ddcebdff11217d711ec74e7aadae88561.pdf
LLy2vm_p35C	868	Few-Shot Transferable Robust Representation Learning via Bilevel Attacks	['robust meta-learning', 'unseen domain', 'self-supervised learning', 'robustness']		Deep Learning and representational learning	anonymous|fewshot_transferable_robust_representation_learning_via_bilevel_attacks	/pdf/f838514681cdad44055e51ecac91bc35b0a16091.pdf
j2SvoOSjxH8	869	FedREP: A Byzantine-Robust, Communication-Efficient and Privacy-Preserving Framework for Federated Learning	['federated learning', 'Byzantine robustness', 'communication efficiency', 'privacy preservation']		Optimization (eg, convex and non-convex optimization)	anonymous|fedrep_a_byzantinerobust_communicationefficient_and_privacypreserving_framework_for_federated_learning	/pdf/9e60e84912cb6ae0da0910fb56d6cc8df541a3cc.pdf
Yn0xg-kHNW-	872	Provably Efficient Risk-Sensitive Reinforcement Learning: Iterated CVaR and Worst Path	['Risk-sensitive Reinforcement Learning (RL)', 'Iterated CVaR RL', 'Worst Path RL', 'RL theory']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|provably_efficient_risksensitive_reinforcement_learning_iterated_cvar_and_worst_path	/pdf/fdd05dc4c03b2cdf7ef275bc37be4a2977370e26.pdf
hLbeJ6jObDD	873	Collaborative Pure Exploration in Kernel Bandit	['Collaborative Pure Exploration (CoPE)', 'kernel bandit', 'multi-agent bandit', 'multi-task learning', 'communication round']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|collaborative_pure_exploration_in_kernel_bandit	/pdf/df19aeb3579e568059046bc4a39d01710d2a803c.pdf
xf7_gvYW1Mx	874	In-the-wild Pretrained Models Are Good Feature Extractors for Video Quality Assessment	['video quality assessment', 'pretrained models', 'metric learning']	In-the-wild pretrained models can be used as feature extractors to represent the perceptual quality of videos directly.	Applications (eg, speech processing, computer vision, NLP)	anonymous|inthewild_pretrained_models_are_good_feature_extractors_for_video_quality_assessment	/pdf/c622b7f982aadb66d1c248adf84e623f7ca5ffa6.pdf
1maXoEyeqx	876	Assessing Model Out-of-distribution Generalization with Softmax Prediction Probability Baselines and A Correlation Method	[]		Deep Learning and representational learning	anonymous|assessing_model_outofdistribution_generalization_with_softmax_prediction_probability_baselines_and_a_correlation_method	/pdf/6770eaa3b70d225c1a2376f34c5ebe20e317ac26.pdf
NIzeVwedJzB	877	Shuffle Gaussian Mechanism for Differential Privacy	['differential privacy', 'shuffle model', 'dp-sgd', 'federated learning']	We give a first non-trivial study of Gaussian mechanism in the shuffle model using R{\'e}nyi differential privacy (RDP).	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|shuffle_gaussian_mechanism_for_differential_privacy	/pdf/6a177e06ea96d826fdc4e3225b1f5421dc808586.pdf
HaHCoGcpV9	879	Sound Randomized Smoothing in Floating-Point Arithmetic	['Randomized smoothing', 'floating-point arithmetic', 'adversarial robustness', 'formal methods']	We construct classifiers producing wrong randomized smoothing certificates on images and propose a method to overcome this at a negligible cost.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|sound_randomized_smoothing_in_floatingpoint_arithmetic	/pdf/04480bd305f5ca3f641a7a1bb4ffcb85c27df7cc.pdf
H9LxwdiXlh	881	Additive Poisson Process: Learning Intensity of Higher-Order Interaction in Poisson Processes	['Poisson Process', 'Log-Linear Model', 'Energy-Based Model', 'Generalized Additive Models', 'Information Geometry']	An efficient technique that uses a log-linear model on a partial order structure to approximate a high-dimensional intensity functions in a Poisson Process.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|additive_poisson_process_learning_intensity_of_higherorder_interaction_in_poisson_processes	/pdf/c053045ee07e0ab96c46d5962f198dcadb2b12a7.pdf
dod5argWzR1	882	Improving Differentially-Private Deep Learning with Gradients Index Pruning	['Differential Privacy', 'Stochastic Gradient Descent']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|improving_differentiallyprivate_deep_learning_with_gradients_index_pruning	/pdf/8c4ecad7c3bf81ca36f20af48177fb88552dc07b.pdf
ILQVw4cA5F9	884	LDMIC: Learning-based Distributed Multi-view Image Coding	['Deep multi-view image compression', 'distributed source coding', 'cross-attention mechanism']	We design a multi-view image compression framework based on symmetric distributed source coding paradigm, which achieves higher compression performance than previous multi-view image compression methods.	Generative models	anonymous|ldmic_learningbased_distributed_multiview_image_coding	/pdf/c018d0593dfe07cefd37679d56fe7e51fddd291f.pdf
VA1YpcNr7ul	886	DASHA: Distributed Nonconvex Optimization with Communication Compression and Optimal Oracle Complexity	['Nonconvex Optimization', 'Variance Reduction', 'Compressed Communication', 'Distributed Optimization']	We provide a new method that improves the state-of-the-art theoretical complexity of distributed optimization methods with compressed communication in the nonconvex regime.	Optimization (eg, convex and non-convex optimization)	anonymous|dasha_distributed_nonconvex_optimization_with_communication_compression_and_optimal_oracle_complexity	/pdf/5c2bb5aa9baef79c553cb79e9830bbfd51b37855.pdf
0CbYJNJtM-X	887	It Takes Two: Masked Appearance-Motion Modeling for Self-Supervised Video Transformer Pre-Training	['Video Understanding', 'Masked Visual Modeling', 'Self-supervised Learning']		Deep Learning and representational learning	anonymous|it_takes_two_masked_appearancemotion_modeling_for_selfsupervised_video_transformer_pretraining	/pdf/78f73dce950cd545cdb4f4a5f471d65de94a164b.pdf
58QUPAU0RJs	888	Neural Prompt Search	['transfer learning', 'computer vision', 'parameter-efficient tuning', 'prompt learning', 'neural architecture search']	We propose to search, instead of hand-engineering, prompt modules for parameter-efficient transfer learning.	Deep Learning and representational learning	anonymous|neural_prompt_search	/pdf/5a60d6785331001199a2c3bf821265f8011b5b67.pdf
f77FhfGzQWN	890	Elastic Mean-Teacher Distillation Mitigates the Continual Learning Stability Gap	['continual learning', 'continual evaluation']		Deep Learning and representational learning	anonymous|elastic_meanteacher_distillation_mitigates_the_continual_learning_stability_gap	/pdf/244b43e24b3d701fd9da751c29fbd4e00d6667a1.pdf
eJtlrcnRtAs	892	Improving Generalization with Domain Convex Game	['transfer learning', 'domain generalization', 'convex game']		Deep Learning and representational learning	anonymous|improving_generalization_with_domain_convex_game	/pdf/ee8c626440fc298c08def4a16ba6959edad7a9f1.pdf
aibmXGQJPs0	893	Towards Semi-Supervised Learning with Non-Random Missing Labels	['semi-supervised learning', 'label missing not at random', 'pseudo-rectifying guidance']	A simple but effective approach yielding tangible improvement in the performance of semi-supervised learning with non-random missing labels.	General Machine Learning (ie none of the above)	anonymous|towards_semisupervised_learning_with_nonrandom_missing_labels	/pdf/ce6dde942cc3b07d0c03abf81d5260f9f533e65f.pdf
aIpq2eA4vDR	895	Offline Model-Based Reinforcement Learning with Causal Structure	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_modelbased_reinforcement_learning_with_causal_structure	/pdf/1681c9811b464c02c862de65ac87bd39092ad0b9.pdf
WhWlYzUTJfP	896	Knowledge-Consistent Dialogue Generation with Language Models and Knowledge Graphs	['knowledge-grounded dialogue generation', 'knowledge graph']	Knowledge-Consistent Dialogue Generation with Context-Relevant Subgraph Retrieval, Invariant Graph Encoding, and Graph-Text Contrastive Learning	Applications (eg, speech processing, computer vision, NLP)	anonymous|knowledgeconsistent_dialogue_generation_with_language_models_and_knowledge_graphs	/pdf/96592995141cf40661b0132c0ea2208face8678b.pdf
5OygDd-4Eeh	897	An Additive Instance-Wise Approach to Multi-class Model Interpretation	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|an_additive_instancewise_approach_to_multiclass_model_interpretation	/pdf/0480a06c196e4b51866681805a2c29dbb469e4c3.pdf
zqwryBoXYnh	898	Prompt Learning with Optimal Transport for Vision-Language Models	[]		Deep Learning and representational learning	anonymous|prompt_learning_with_optimal_transport_for_visionlanguage_models	/pdf/6656e606a5999777a4992b402bc269c3f00b1840.pdf
CLmXXljIf__	899	Uncertainty-Aware Self-Supervised Learning with Independent Sub-networks	['uncertainty-awareness', 'calibration', 'self-supervised pretraining', 'independent sub-networks', 'efficient ensemble']	We introduce an uncertainty-aware training regime for self-supervised models with an ensemble of independent sub-networks and a novel loss function for encouraging diversity.	Unsupervised and Self-supervised learning	anonymous|uncertaintyaware_selfsupervised_learning_with_independent_subnetworks	/pdf/72c52eb0906b0dacc37ae60751f4a131ea86d5dd.pdf
SoAnNZ7Z3xw	900	Locally Invariant Explanations: Towards Stable and Unidirectional Explanations through Local Invariant Learning	['explainable AI']	A local explanation method that is stable and unidirectional	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|locally_invariant_explanations_towards_stable_and_unidirectional_explanations_through_local_invariant_learning	/pdf/cfcef66fec7455afb1847b00ac1f55445f119c38.pdf
s-c96mSU0u5	901	SCoMoE: Efficient Mixtures of Experts with Structured Communication	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|scomoe_efficient_mixtures_of_experts_with_structured_communication	/pdf/e71d43888de1b2e73f18dcd045ffd212d4448536.pdf
zWwrB9wenY1U	902	Soundness and Completeness: An Algorithmic Perspective on Evaluation of Feature Attribution	['explainable AI', 'explainability', 'feature attribution']	We propose a novel method to evaluate \emph{soundness} and \emph{completeness} of feature attribution methods.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|soundness_and_completeness_an_algorithmic_perspective_on_evaluation_of_feature_attribution	/pdf/9ef5e212bfa7f984fedef6c7474ee8422efbf59b.pdf
a2-aoqmeYM4	903	Approximate Bayesian Inference with Stein Functional Variational Gradient Descent	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|approximate_bayesian_inference_with_stein_functional_variational_gradient_descent	/pdf/c6886d446c9090e69542460d0afec52e98c5cc03.pdf
ULsuEVQbV-9	904	Estimating individual treatment effects under unobserved confounding using binary instruments	['Causal machine learning', 'treatment effect estimation', 'instrumental variables']	We propose a multiple robust machine learning framework for individual treatment effect estimation using binary instrumental variables.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|estimating_individual_treatment_effects_under_unobserved_confounding_using_binary_instruments	/pdf/9b8e9604c472aff166375fc3048b1b4db5410247.pdf
zDjtZZBZtqK	905	Denoising Masked Autoencoders are Certifiable Robust Vision Learners	['self-supervised', 'certified robustness', 'randomized smoothing']	In this paper, we propose a new self-supervised method for learning certified robust classifiers of images.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|denoising_masked_autoencoders_are_certifiable_robust_vision_learners	/pdf/506fd6642503d93c2e391a178979bab046c17774.pdf
8aeSJNbmbQq	907	Deep Variational Implicit Processes	['Gaussian process', 'implicit process', 'variational implicit process', 'Bayesian inference', 'function-space inference', 'implicit process concatenation']	 We propose here a multi-layer generalization of IPs called the Deep Variational Implicit process, similar to that of deep GPs over GPs.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|deep_variational_implicit_processes	/pdf/506d45b489139b169ab1f31a581bc0104e1affd6.pdf
tVHCysldFe0	910	A Generalized EigenGame With Extensions to Deep Multiview Representation Learning	['Optimisation', 'Generalized Eigenvalue Problem', 'Deep CCA', 'CCA', 'PLS']	A new approach to solving Generalized Eigenvalue Problems in the stochastic setting extended to Deep Canonical Correlation Analysis with state-of-the-art results for stochastic minibatches	Optimization (eg, convex and non-convex optimization)	anonymous|a_generalized_eigengame_with_extensions_to_deep_multiview_representation_learning	/pdf/e7445b4f589801c1a5d37b1d8e58f43e38bf3c47.pdf
6orC5MvgPBK	911	Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations	['brain-inspired learning', 'neuroscience', 'recurrent neural networks', 'context inference', 'bayesian brain']	A brain-inspired algorithm that alternates optimizing in weight space with optimizing the latent embedding space in the same neural network leading to open-ended discovery of tasks and disentangled learning.		anonymous|thalamus_a_braininspired_algorithm_for_biologicallyplausible_continual_learning_and_disentangled_representations	/pdf/89aef8c4c16af0aa9048592c4764017cfb5a1d4d.pdf
hVrXUps3LFA	912	Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors	['model adaptation', 'black-box predictors', 'transfer learning']	A black-box model adaptation approach that purifies the pseudo labels for knowledge distillation.	Deep Learning and representational learning	anonymous|divide_to_adapt_mitigating_confirmation_bias_for_domain_adaptation_of_blackbox_predictors	/pdf/2ce73132f97ab910c3ce571801625c5adcbd0b73.pdf
kyJ5Mrh5Cz9	913	Learn the Time to Learn: Replay Scheduling in Continual Learning	['Continual Learning', 'Replay Methods', 'Reinforcement Learning']	We demonstrate that scheduling which tasks to replay at different times is important in continual learning scenarios. 	General Machine Learning (ie none of the above)	anonymous|learn_the_time_to_learn_replay_scheduling_in_continual_learning	/pdf/dbdb7db728279089bcc0fb8efa5f869968c6c2fc.pdf
FWl6TFsE7Cp	914	Universal Mini-Batch Consistency for Set Encoding Functions	['set']	We propose a method to make arbitrary set functions produce consistent outputs given mini-batches of a set.	Deep Learning and representational learning	anonymous|universal_minibatch_consistency_for_set_encoding_functions	/pdf/971898147605a4ce5374254aeb64e616ca12b1da.pdf
20GtJ6hIaPA	915	Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance	[]		Unsupervised and Self-supervised learning	anonymous|selfsupervised_categorylevel_articulated_object_pose_estimation_with_partlevel_se3_equivariance	/pdf/323e66b4977adb3b59a0061b6a728f60865b036f.pdf
xWutyHiLtwP	917	Practical Approaches for Fair Learning with Multitype and Multivariate Sensitive Attributes	['Fairness', 'Metrics', 'Regularization']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|practical_approaches_for_fair_learning_with_multitype_and_multivariate_sensitive_attributes	/pdf/de519dcd87aa63db98b0621cfd16b7f18e173342.pdf
YHxp8eRry6F	918	Learning Control Lyapunov Functions For High-dimensional Unknown Systems using Guided Iterative State Space Exploration	['Neural Certificates', 'Lyapunov Functions', 'Robotics']	We develop a novel algorithm that learns a stable controller for high-dimensional unknown systems. We provide theoretical guarantees for the convergence, and empirical results that it outperforms other baselines in a suite of environments.	General Machine Learning (ie none of the above)	anonymous|learning_control_lyapunov_functions_for_highdimensional_unknown_systems_using_guided_iterative_state_space_exploration	/pdf/952e65f3d93e2365b08c2f38b79ca7e037127f5a.pdf
H6LVUiHzYDE	919	MEGAN: Multi Explanation Graph Attention Network	['explainable artificial intelligence', 'interpretable machine learning', 'graph neural networks', 'attention network', 'graph regression', 'graph classification']	Novel, self-explaining graph attention network features multiple explanation channels independent of task specifications to improve interpretability of graph regression and classification problems	Deep Learning and representational learning	anonymous|megan_multi_explanation_graph_attention_network	/pdf/72e8d9ebaa7fb294df9885b1a54d1441ee0f87a2.pdf
sF2Ut0fflgx	920	On Trace of PGD-Like Adversarial Attacks	['adversarial attack characterization', 'local linearity', 'adversarial response characteristics', 'sequel attack effect']	We present ARC features where SAE is a unique trace left by PGD-like attacks.	Deep Learning and representational learning	anonymous|on_trace_of_pgdlike_adversarial_attacks	/pdf/fe08c345377e7f7570a4bdefdff33a32ba4ccb30.pdf
uzbd9jGCnN4	921	Similarity and Generalization: from Noise to Corruption	['double descent', 'online/offline training', 'generalization', 'similarity learning', 'noise']	We investigate for the first time double descent and online/offline training in the context of similarity learning and find that the resulting learning model is heavily affected both by the topology of the dataset and noise.		anonymous|similarity_and_generalization_from_noise_to_corruption	/pdf/2db4a7b656551fcdf86c10fa1c330c075c6e7a4b.pdf
PaEUQiY40Dk	922	Towards Understanding Why Mask Reconstruction Pretraining Helps in Downstream Tasks	[]		Unsupervised and Self-supervised learning	anonymous|towards_understanding_why_mask_reconstruction_pretraining_helps_in_downstream_tasks	/pdf/97580d517bb8781f367274f79e4d6a202dc9a99d.pdf
plKu2GByCNW	924	ViT-Adapter: Exploring Plain Vision Transformer for Accurate Dense Predictions	['Plain Vision Transformer', 'Adapter', 'Dense Prediction']	This work investigates a simple yet powerful dense prediction task adapter for Vision Transformer (ViT).	Applications (eg, speech processing, computer vision, NLP)	anonymous|vitadapter_exploring_plain_vision_transformer_for_accurate_dense_predictions	/pdf/438c891eb1fc720e3b5d242608db9995b85a9659.pdf
Pi5LI8sJYYz	925	Lossless Filter Pruning via Adaptive Clustering for Convolutional Neural Networks	[]	We propose a clustering-based filter pruning method which uses equivalence to remove redundancy. Our solution can omit fine-tuning and achieve the best trade-off between performance and complexity compared with other algorithms.. 	Deep Learning and representational learning	anonymous|lossless_filter_pruning_via_adaptive_clustering_for_convolutional_neural_networks	/pdf/d60a77aafb195f4dc70fa87bdc720c8c948d8b65.pdf
RWtGreRpovS	926	Simplicial Embeddings in Self-Supervised Learning and Downstream Classification	['Self-Supervised learning', 'Representation learning', 'Pre-training']	We use softmax to embed representations in a collection of simplices in SSL models, which offers improved generalization properties for downstream classification.	Unsupervised and Self-supervised learning	anonymous|simplicial_embeddings_in_selfsupervised_learning_and_downstream_classification	/pdf/e46b5ebbb073787e23782eda1ab89d402e3cd002.pdf
hZftxQGJ4Re	927	Deep Ensembles for Graphs with Higher-order Dependencies	['graph neural networks', 'higher order networks', 'deep ensembles', 'representation learning', 'semisupervised learning']	We propose an ensemble of GNNs that exploits variance in the neighborhood subspaces of nodes in graphs with higher-order dependencies and consistently outperforms baselines on semisupervised and supervised learning tasks.	Deep Learning and representational learning	anonymous|deep_ensembles_for_graphs_with_higherorder_dependencies	/pdf/4b3468c8d69dca119e3f71755bce7b8d72f8fca3.pdf
shuT5_7eeQ_	928	STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition 	['mesh-based action recognition', 'motion capture', 'transformer']	We propose the first mesh-based action recognition method which achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|stmt_a_spatialtemporal_mesh_transformer_for_mocapbased_action_recognition	/pdf/126c2acd5862e613cdcbe0ec7a428e761194d537.pdf
WZH7099tgfM	929	Least-to-Most Prompting Enables Complex Reasoning in Large Language Models	['large language models', 'natural language processing', 'prompting', 'reasoning', 'compositional generalization']	We propose a novel prompting strategy, least-to-most prompting, that enables large language models to achieve easy-to-hard generalization	Applications (eg, speech processing, computer vision, NLP)	anonymous|leasttomost_prompting_enables_complex_reasoning_in_large_language_models	/pdf/33604ce20f5ddaa24dccb3b48472ba76a36751fd.pdf
h-oMvNaV_Nr	930	$\mathrm{R}^2$-VOS: Robust Referring Video Object Segmentation via Relational Cycle Consistency	['Referring Video Object Segmentation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|\mathrmr^2vos_robust_referring_video_object_segmentation_via_relational_cycle_consistency	/pdf/45790bb08ed09f1aef02fee152e3f129221294c1.pdf
FYZCHEtt6H0	931	ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation 	['Reinforcement Learning', 'Evolutionary Algorithm', 'Representation']	A novel and effective framework to fuse Reinforcement Learning and Evolutionary Algorithm for policy optimization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|erlre^2_efficient_evolutionary_reinforcement_learning_with_shared_state_representation_and_individual_policy_representation	/pdf/5b4d4bfdcf55ff58ccf21b015c3ab50e02175b7e.pdf
KXRSh0sdVTP	932	Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction	['meta-learning', 'few-shot learning', 'Gaussian processes', 'deep kernel learning', 'bilevel optimization', 'chemistry', 'molecules', 'drug discovery']	This paper proposes a meta-learning approach for fitting deep kernel GPs via implicit differentiation, which outperforms previous SOTA methods on a variety of real-world chemical tasks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|metalearning_adaptive_deep_kernel_gaussian_processes_for_molecular_property_prediction	/pdf/169068e687254a170fd856543621675b78589a09.pdf
resApVNcqSB	933	Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning	['HOI Detection', 'Weakly-supervised Learning', 'CLIP-guided Representation Learning']		Deep Learning and representational learning	anonymous|weaklysupervised_hoi_detection_via_priorguided_bilevel_representation_learning	/pdf/86bf17965a700223d63b6d9557d4a2ca32eca30e.pdf
WoaNX-8VDrK	934	Spatially constrained Adversarial Attack Detection and Localization in the Representation Space of Optical Flow Networks	['optical flow', 'adversarial attack detection', 'adversarial attack localization']		Applications (eg, speech processing, computer vision, NLP)	anonymous|spatially_constrained_adversarial_attack_detection_and_localization_in_the_representation_space_of_optical_flow_networks	/pdf/403e633ddce905c4c5f30b5490b73983eb5ff187.pdf
3RhuF8foyPW	935	Single-shot General Hyper-parameter Optimization for Federated Learning	['Federated Learning', 'Hyperparameter Optimization', 'Optimality Gap Analysis']	We propose a single-shot hyperparameter optimization scheme for Federated Learning systems with theoretical performance guarantees and strong empirical performance against baselines.	Optimization (eg, convex and non-convex optimization)	anonymous|singleshot_general_hyperparameter_optimization_for_federated_learning	/pdf/1a68c78a44082d0895434071a634ad489db1d8ad.pdf
z0uB4Zfb-Ex	937	What Knowledge gets Distilled in Knowledge Distillation? 	['knowledge distillation']	This work studies different ways in which knowledge can get transferred from a teacher to a student.	Deep Learning and representational learning	anonymous|what_knowledge_gets_distilled_in_knowledge_distillation	/pdf/668b8a7e6c379b6114a8236f6f30185caa4efa67.pdf
W98qRtArTy3	938	Accelerating Federated Learning Convergence via Opportunistic Mobile Relaying	['Asynchronous Federated Learning', 'Convergence Analysis']		Deep Learning and representational learning	anonymous|accelerating_federated_learning_convergence_via_opportunistic_mobile_relaying	/pdf/df0bf80a295975809181dfcc127a9b1fcd0ca02a.pdf
kUI41mY8bHl	939	Robustness to corruption in pre-trained Bayesian neural networks	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|robustness_to_corruption_in_pretrained_bayesian_neural_networks	/pdf/adb77c8b74d42ef7e7a13f0004d2beae1502b03f.pdf
Z3IClM_bzvP	940	Multi-skill Mobile Manipulation for Object Rearrangement	['mobile manipulation', 'reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multiskill_mobile_manipulation_for_object_rearrangement	/pdf/7ce828646b98242c13a8c9639e15a07b845a5a40.pdf
_ruvo2KCL2x	942	Deep Ranking Ensembles for Hyperparameter Optimization	['Hyperparameter Optimization', 'Meta-learning', 'Deep Ensembles', 'Ranking Losses']	Meta-learn Deep Ensembles using Ranking Losses to improve the performance on Hyperparameter Optimization	Deep Learning and representational learning	anonymous|deep_ranking_ensembles_for_hyperparameter_optimization	/pdf/b25ec95568ef3499782789032d523996fc336fd4.pdf
4Vwx-VwS5b3	943	Implicit Neural Spatial Representations for Time-dependent PDEs	['PDE', 'implicit neural representation', 'neural field', 'numerical methods']	We replace traditional PDE solvers' spatial representations (e.g., grid, mesh, and point cloud) with a neural spatial representation.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|implicit_neural_spatial_representations_for_timedependent_pdes	/pdf/bd294e51e53ca042c922330bd253bdd7b168de01.pdf
zU8O5w0Wnh1	945	Comfort Zone: A Vicinal Distribution for Regression Problems	['Deep Learning Regularization', 'Data Augmentation', 'Regression Learning']		Deep Learning and representational learning	anonymous|comfort_zone_a_vicinal_distribution_for_regression_problems	/pdf/3d03d6eadb5f578b7d952adaeabba51fc5562270.pdf
9vcXCMp9VEp	946	Fair Attribute Completion on Graph with Missing Attributes	[]		Deep Learning and representational learning	anonymous|fair_attribute_completion_on_graph_with_missing_attributes	/pdf/97470f2dcf3663bfd2fa0688bf0dab273e6e638b.pdf
DEhSlPNviW	947	Gradient Properties of Hard Thresholding Operator	['Sparse optimization', 'Hard thresholding', 'Iterative hard thresholding', 'HT-stationary point', 'HT-stable point', 'HT-unstable point']		Optimization (eg, convex and non-convex optimization)	anonymous|gradient_properties_of_hard_thresholding_operator	/pdf/c13caf7832c9ad2ce5f4e888a62598331e34442d.pdf
8HRvyxc606	948	Reliability of CKA as a Similarity Measure in Deep Learning	['Representation Learning', 'Similarity Measures', 'Centered Kernel Alignment (CKA)']	We extensively study a broad class of cases where the very popular CKA analysis method for deep representations can give unreliable results.	Deep Learning and representational learning	anonymous|reliability_of_cka_as_a_similarity_measure_in_deep_learning	/pdf/8c1d83ebdc6a49e6532a6b74eebc19c1d823edaf.pdf
gYs7WuxALZ	949	Computational-Unidentifiability in Representation for Fair Downstream Tasks	['fairness', 'representation learning']	Propose a notion and metric for fair representations; Also, we validate the importance of fair representation learning on various downstream tasks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|computationalunidentifiability_in_representation_for_fair_downstream_tasks	/pdf/13acebfd59605e34953a242c67cfc222a91c2425.pdf
DBDpZIdVIY	950	CLR-GAM: Contrastive Point Cloud Learning with Guided Augmentation and Feature Mapping	['contrastive learning', 'point cloud representation learning', 'few shot learning', 'self supervised learning']	efficient augmentation selection strategy, and effective feature association in contrastive learning	Deep Learning and representational learning	anonymous|clrgam_contrastive_point_cloud_learning_with_guided_augmentation_and_feature_mapping	/pdf/942fc3b28608ceef057833b60c8d1cd5a9e08f5e.pdf
v3y68gz-WEz	951	Riemannian Metric Learning via Optimal Transport	['optimal transport', 'riemannian geometry', 'manifold learning', 'time series']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|riemannian_metric_learning_via_optimal_transport	/pdf/2292ddf09776be2fdf7e4e89a97164c61a981f14.pdf
k60XE_b0Ix6	952	Learning Label Encodings for Deep Regression	['Regression', 'Label Encoding']	We propose an end-to-end automated approach to learn label encodings for deep regression.	Deep Learning and representational learning	anonymous|learning_label_encodings_for_deep_regression	/pdf/a0938c386a6479bd2fa3b74aaafa774e7406fc60.pdf
vTb1JI0Gps_	953	Automated Data Augmentations for Graph Classification	['Data Augmentation', 'Graph Classification', 'Label-invariance']	We propose GraphAug, a novel automated data augmentation method aiming at computing label-invariant augmentations for graph classification.	Deep Learning and representational learning	anonymous|automated_data_augmentations_for_graph_classification	/pdf/d4e1e11f766ee295c1ce6fbe62f2d2453ef6aaad.pdf
gmwDKo-4cY	954	Composing Ensembles of Pre-trained Models via Iterative Consensus	['composing pre-trained models', 'zero-shot', 'multimodal', 'wisdom of the crowds']	We propose a unified framework for composing pre-trained models for a variety of zero-shot multimodal tasks through iterative consensus.	Deep Learning and representational learning	anonymous|composing_ensembles_of_pretrained_models_via_iterative_consensus	/pdf/f6058fe07feaec68eb2c481b7bdd6ffaa0ea9c0b.pdf
njAes-sX0m	955	PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR Error Correction	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|patcorrect_nonautoregressive_phonemeaugmented_transformer_for_asr_error_correction	/pdf/993aa54ca43f52b61a187ac5d7ec41d50ffd6fb0.pdf
DT7btGps59z	956	Your Neighbors Are Communicating: Towards Powerful and Scalable Graph Neural Networks	['Graph neural networks', 'expressiveness', 'graph isomorphism test']	We propose a general GNN framework with provably expressive power, while maintaining the scalability of the message passing scheme.	Deep Learning and representational learning	anonymous|your_neighbors_are_communicating_towards_powerful_and_scalable_graph_neural_networks	/pdf/5d5d754f6aca7b7a4b449af97fa8e3ef67ecf709.pdf
9DZKk85Z4zA	957	Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models	[]		General Machine Learning (ie none of the above)	anonymous|gradientguided_importance_sampling_for_learning_binary_energybased_models	/pdf/faddf7441ba1a0a8b318863bc0ed719c6e410d42.pdf
j_1CMt_GqSk	959	MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection	['Monocular 3D object detection', 'detection transformer', 'multi-view 3D object detection']		Applications (eg, speech processing, computer vision, NLP)	anonymous|monodetr_depthguided_transformer_for_monocular_3d_object_detection	/pdf/f8efaec4dbc0e660c5d3b203efaf0831711d4769.pdf
KZzvKrfKt7K	960	CEREAL: Few-Sample Clustering Evaluation	['evaluation metrics', 'clustering', 'surrogate functions', 'active learning', 'semi-supervised learning']	We introduce CEREAL, a comprehensive framework for few-sample clustering evaluation based on active pseudo-labeling.	General Machine Learning (ie none of the above)	anonymous|cereal_fewsample_clustering_evaluation	/pdf/69721331083e07e7053c86f85fb33802db2ed071.pdf
hY6M0JHl3uL	961	Linear Connectivity Reveals Generalization Strategies	['loss landscapes', 'OOD generalization', 'NLI', 'text classification', 'loss surfaces', 'transfer learning', 'challenge sets', 'NLP']	Basins on the in-domain test loss surface predict generalization strategies for NLI, paraphrase, and CoLA tasks.	Deep Learning and representational learning	anonymous|linear_connectivity_reveals_generalization_strategies	/pdf/98e446a9dd97ac5e6bdbde5ee86722998cfbce55.pdf
6BZJ_zn7ez7	962	PatchBlender: A Motion Prior for Video Transformers	['transformer', 'vit', 'vision', 'video', 'prior', 'temporal', 'pattern', 'dimension', 'latent', 'time', 'motion', 'attention', 'smoothing', 'blending', 'smooth', 'blend', 'patch', 'patchblender', 'inductive bias', 'kinetics', 'kinetics400', 'ssv2', 'something-something', 'something something', 'kubric', 'movia', 'movi-a']	We introduce PatchBlender, a learnable blending function that operates over patch embeddings across the temporal dimension of the latent space.	Deep Learning and representational learning	anonymous|patchblender_a_motion_prior_for_video_transformers	/pdf/5e0227363473649332a400818e89831312e7fa08.pdf
LV_MeMS38Q9	963	Betty: An Automatic Differentiation Library for Multilevel Optimization	['Multilevel Optimization', 'Automatic Differentiation', 'Bilevel Optimization', 'Meta Learning', 'Software Library']	We develop a scalable, user-friendly, and modular automatic differentiation library for multilevel optimization based on a novel interpretation of multilevel optimization as a dataflow graph.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|betty_an_automatic_differentiation_library_for_multilevel_optimization	/pdf/af5c8e069a5e2325fad7447df6f2f9bc143fa38e.pdf
ashPce_W8F-	964	Understanding Why Generalized Reweighting Does Not Improve Over ERM	['Distribution shift', 'Subpopulation shift', 'Implicit bias', 'Generalization', 'Overparameterization']	We theoretically prove that the broad family of GRW algorithms which covers many popular methods has an implicit bias almost equivalent to ERM, and thus cannot improve over ERM.	General Machine Learning (ie none of the above)	anonymous|understanding_why_generalized_reweighting_does_not_improve_over_erm	/pdf/79acfd50e93ea9a4a577417a93f5d7bae55f00d3.pdf
vk-j5pQY3Gv	965	Discovering Informative and Robust Positives for Video Domain Adaptation	['Domain Adaptation', 'Video Recognition']	We introduce the bottlenecks of in existing contrastive-based video DA methods and propose a unified solution to address them without relying on negatives by mining informative and robust intra-domain positives and cross-domain positives.	Deep Learning and representational learning	anonymous|discovering_informative_and_robust_positives_for_video_domain_adaptation	/pdf/84b9e8a8971965a064b5e3ac482cbc2a6462cc4f.pdf
23jfQBSUh4x	966	Online Continual Learning for Progressive Distribution Shift (OCL-PDS): A Practitioner's Perspective	['Distribution shift', 'Continual learning', 'Domain Adaptation', 'Semi-supervised learning', 'Model drift', 'Online learning', 'Benchmark']	We introduce the novel OCL-PDS problem for studying gradual distribution shift with time, and release 4 new benchmarks and 12 algorithms/baselines implementation for this new problem.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|online_continual_learning_for_progressive_distribution_shift_oclpds_a_practitioners_perspective	/pdf/5430764a8ada51a7eb2dc450e69132ee15db7c72.pdf
fB0hRu9GZUS	967	Generate rather than Retrieve: Large Language Models are Strong Context Generators	['prompt learning', 'large language model', 'open-domain question answering']	We propose a novel generate-then-read pipeline for solving knowledge-intensive tasks by prompting a large language model to generate relevant contextual documents.	Applications (eg, speech processing, computer vision, NLP)	anonymous|generate_rather_than_retrieve_large_language_models_are_strong_context_generators	/pdf/6b2b0d716430e55f2392c3b4ce3acf9e5eba74f4.pdf
48EwqCCosOO	968	Grafting Vision Transformers	['Vision Transformers', 'Multi-scale', 'Multi-branch', 'Grafting', 'Classification', 'Semantic segmentation', 'Object detection']	We present a simple and efficient add-on component (termed GrafT) that considers global dependencies and multi-scale information. GrafT can be easily adopted in both homogeneous (ViT) and pyramid (Swin) Transformers.	Deep Learning and representational learning	anonymous|grafting_vision_transformers	/pdf/2c0bf21a92765f58e783d1fa696297b77e4494be.pdf
CrfhZAsJDsZ	969	Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities	[]	Operator learning based on non-linear reconstruction (FNOs, shift-DeepONets) outperform methods based on linear reconstruction (DeepONets, PCA-Net) for PDEs with discontinuities.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|nonlinear_reconstruction_for_operator_learning_of_pdes_with_discontinuities	/pdf/f5d1686e913fd1289539ee62ac68107bc7528579.pdf
LI4mXhTg23M	970	Learning Disentanglement in Autoencoders through Euler Encoding	['disentanglement', 'disentangling', 'linear disentangled representations', 'autoencoder', 'latent space', 'factorizing', 'latent-space factorization', 'latent-space regularization']	We propose  the first deterministic model that is aiming to achieve disentanglement based on autoencoders without a pair of images or labels by explicitly introducing inductive biases into a model architecture through Euler encoding.	Deep Learning and representational learning	anonymous|learning_disentanglement_in_autoencoders_through_euler_encoding	/pdf/29f0844741ed966ca6efd34ac7806f86fb90c026.pdf
XWkWK2UagFR	971	General Neural Gauge Fields	['NeRF', 'Neural Scene Representation']	This paper explores how to learn the gauge transformations along with radiance fields.	Deep Learning and representational learning	anonymous|general_neural_gauge_fields	/pdf/0f80d4f0a9c35d647e0a7639e4989e32e8bdd215.pdf
t5hWOkHREBM	973	Multi-Dataset Multi-Task Framework for Learning Molecules and  Protein-target Interactions Properties	['Graph Neural Network', 'Molecules', 'Protein-ligand binding', 'Multidataset', 'Multitask']	Graph Neural Network; Multidataset Multitask; Molecular Property Prediction; Protein-ligand Binding Affinity	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|multidataset_multitask_framework_for_learning_molecules_and_proteintarget_interactions_properties	/pdf/c5f36051ac3a90efa6f44f006c9976c52f76e362.pdf
olhhqrp1sCA	974	Fast Test-Time Adaptation Using Hints	['test-time', 'adaptation', 'robustness', 'distribution shifts']	We propose a method for fast test-time adaptation to distribution shifts.	Applications (eg, speech processing, computer vision, NLP)	anonymous|fast_testtime_adaptation_using_hints	/pdf/e516ee2164230452cf6a2b811531f61567e6f149.pdf
ZrJPdY5k6sg	975	On the Universality of Langevin Diffusion for Private Euclidean (Convex) Optimization	['differential privacy', 'empirical risk minimization', 'stochastic convex optimization', 'Langevin diffusion']	We show that Langevin diffusions are universal algorithms for private optimization: they provide optimal results for DP-ERM and DP-SCO, under pure and approximate DP, for both convex and strongly convex losses.	Optimization (eg, convex and non-convex optimization)	anonymous|on_the_universality_of_langevin_diffusion_for_private_euclidean_convex_optimization	/pdf/892d62bcbfac013206f5423dace2f01ed1933f3f.pdf
XhZfFE8OmTF	976	Semi-supervised Node Classification with Imbalanced Receptive Field	['Graph Neural Network', 'Imbalanced Node Classification', 'Influence Maximization', 'Influence Balance']	The first attempt to consider the influence imbalance issue in semi-supervised node classification task of GNNs.	Deep Learning and representational learning	anonymous|semisupervised_node_classification_with_imbalanced_receptive_field	/pdf/c22be4c5141e1a4e25cb8a4bfb9fc867d1811316.pdf
hsSYDdZTIsl	979	Semi-connected Joint Entity Recognition and Relation Extraction of Contextual Entities in Family History Records	['Information Extraction', 'NER', 'Relation Detection']	A new semi-connected joint entity-relation extraction model provides better entity extraction on relationship dependent entity types.	Applications (eg, speech processing, computer vision, NLP)	anonymous|semiconnected_joint_entity_recognition_and_relation_extraction_of_contextual_entities_in_family_history_records	/pdf/8e547cd2bd9ab166258cb886fe11a410e97c5bc7.pdf
I7triE0okW3	981	Critical Learning Periods Augmented Model Poisoning Attacks to Byzantine-Robust Federated Learning	['Critical Learning Periods', 'Byzantine-Robust Federated Learning', 'Model Poisoning Attacks']		General Machine Learning (ie none of the above)	anonymous|critical_learning_periods_augmented_model_poisoning_attacks_to_byzantinerobust_federated_learning	/pdf/74fe4c7e7fc5807b33bd21c7481cb11972c90c76.pdf
5jBBG-zgrwl	982	Individual Fairness of Data Provider Regarding Privacy Risk and Gain	['differential privacy', 'privacy-preserving machine learning', 'lower bound']	We propose a new definition of individual fairness (IF) from the perspective of privacy protection and experimentally evaluate privacy-preserving machine learning based on the proposed IF. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|individual_fairness_of_data_provider_regarding_privacy_risk_and_gain	/pdf/35cbc0cbe4381db7b48825ad4f6330e009f4d416.pdf
p7Bfc_wsDtH	984	Logic-aware Pre-training of Language Models	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|logicaware_pretraining_of_language_models	/pdf/10177aa7b8afc3bd19c39ccf6903ddd5ea6495c7.pdf
xmcYx_reUn6	985	BrainBERT: Self-supervised representation learning for Intracranial Electrodes	['neuroscience', 'language models', 'self-supervision', 'transformer', 'decoding']	Modeling neural data with Transformers to create self-supervised contextual embeddings that increase decoding performance	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|brainbert_selfsupervised_representation_learning_for_intracranial_electrodes	/pdf/4b8a4852d2b9f949d9771f703644d7ab41de30ed.pdf
p49GcKDM_XH	986	Is Stochastic Gradient Descent Near Optimal?	['sample complexity', 'neural networks', 'stochastic gradient descent']	We empirically demonstrate that SGD computationally efficiently achieves theoretical sample complexity bounds on single-hidden-layer teacher networks.	Deep Learning and representational learning	anonymous|is_stochastic_gradient_descent_near_optimal	/pdf/5c8f1f695a44ba927bfd6be8b0218e11cf9177ba.pdf
ALcz2n3Wsdf	987	Mugs: A Multi-Granular Self-Supervised  Learning Framework	['multi-granular learning', 'contrastive learning', 'self-supervised learning']	we propose an effective MUlti-Granular Self-supervised  learning (Mugs) framework to explicitly learn  multi-granular visual features.	Unsupervised and Self-supervised learning	anonymous|mugs_a_multigranular_selfsupervised_learning_framework	/pdf/33474dcec00960cad6d10c38f5dd3f462337e9ea.pdf
P1MaSJlwdT4	989	Go-Explore with a guide: Speeding up search in sparse reward settings with goal-directed intrinsic rewards	['reinforcement learning', 'intrinsic motivation', 'goal-directed rewards', 'hippocampal replay', 'hard-exploration', 'sparse rewards']	Speeding up search in sparse reward settings with goal-directed intrinsic rewards	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|goexplore_with_a_guide_speeding_up_search_in_sparse_reward_settings_with_goaldirected_intrinsic_rewards	/pdf/792d0f553c3b9eb4af6aa81dea97790a1288f830.pdf
FH3Mwjb_H8B	990	Focusing on what to decode and what to train: Efficient Training with HOI Split Decoders and Split Target Guided DeNoising	['human-object interaction detection', 'transformer']	A novel one-stage framework with HOI specific denoising training strategy for human-object interaction detection.	Applications (eg, speech processing, computer vision, NLP)	anonymous|focusing_on_what_to_decode_and_what_to_train_efficient_training_with_hoi_split_decoders_and_split_target_guided_denoising	/pdf/4ea4cae2e6ddc6fdb05ea1ff5cde41cffbcc8c87.pdf
vSVLM2j9eie	992	Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting	['Transformer', 'multivariate time series forecasting', 'deep learning']	We propose Crossformer, a Transformer-based model that explicitly utilizes cross-dimension dependency for multivariate time series forecasting.	Applications (eg, speech processing, computer vision, NLP)	anonymous|crossformer_transformer_utilizing_crossdimension_dependency_for_multivariate_time_series_forecasting	/pdf/184db92d7c1d152d2b3d1884095b87f31dc34fb4.pdf
qUKsCztWlKq	993	The KFIoU Loss for Rotated Object Detection	['Rotation Detection', 'SkewIoU loss', 'Kalman Filter']		Applications (eg, speech processing, computer vision, NLP)	anonymous|the_kfiou_loss_for_rotated_object_detection	/pdf/ca0c37bf7b9959df7dd4faebf809c7c459730917.pdf
PfHk0P9lgMy	996	Expected Gradients of Maxout Networks and Consequences to Parameter Initialization	['maxout unit', 'input-output Jacobian', 'parameter initialization', 'expressivity', 'linear regions', 'curve distortion', 'NTK']	We bound the gradients of a maxout network, formulate a parameter initialization strategy, and obtain results on expressivity and NTK.	Deep Learning and representational learning	anonymous|expected_gradients_of_maxout_networks_and_consequences_to_parameter_initialization	/pdf/ba6d2115f59eab6f201e2aabea4e3da41768e122.pdf
z289SIQOQna	1001	"Plateau in Monotonic Linear Interpolation --- A ""Biased"" View of Loss Landscape for Deep Networks"	['monotonic linear interpolation', 'loss landscape', 'deep learning theory']	We explain the long plateau in the loss and error curves along the linear interpolation from the initialization to the minimum. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|plateau_in_monotonic_linear_interpolation_a_biased_view_of_loss_landscape_for_deep_networks	/pdf/125f949a003d84a8e1a6bd7b1edf9911d42f839e.pdf
SeZ5ONageGl	1004	Deep Duplex Learning for Weak Supervision	['Weakly supervised learning', 'learning with noisy labels', 'partial label learning', 'semi-supervised learning.']	We propose a deep duplex learning method for general weakly-supervised learning.	Deep Learning and representational learning	anonymous|deep_duplex_learning_for_weak_supervision	/pdf/0b3cfeddaafee41f18b16b109badbd5996c2bc71.pdf
z_mh23dtm4S	1005	Parallel Federated Learning over Heterogeneous Devices	['Federated Learning']	We achieve parallel computing between the central server and the edge nodes in Federated Learning.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|parallel_federated_learning_over_heterogeneous_devices	/pdf/34a5a222db76e37cab632c3b68ceaaecb7b7909b.pdf
HyIY8u5LVDr	1006	Discovering the Representation Bottleneck of Graph Neural Networks from Multi-order Interactions	['GNN bottleneck', 'graph rewiring', 'representation bottleneck', 'multi-order interactions']		Deep Learning and representational learning	anonymous|discovering_the_representation_bottleneck_of_graph_neural_networks_from_multiorder_interactions	/pdf/36de54f274046cbfd432feed6ac680b957836eac.pdf
tjvEnPYc3Yq	1007	Learning Symbolic Rules for Reasoning in Quasi-Natural Language	[]		General Machine Learning (ie none of the above)	anonymous|learning_symbolic_rules_for_reasoning_in_quasinatural_language	/pdf/0a3ea4d8a24b84060fd9719500f7dffa95dd46ed.pdf
hag85Gdq_RA	1008	Effective Cross-instance Positive Relations for Generalized Category Discovery	['generalized category discovery', 'semi-supervised learning', 'clustering', 'deep learning']	We propose cross-instance positive relations to bootstrap representation learning for generalized category discovery with a new semi-supervised hierarchical clustering algorithm.	Deep Learning and representational learning	anonymous|effective_crossinstance_positive_relations_for_generalized_category_discovery	/pdf/32808f5417d5a4fe9ac7e1232ef263a8fab326bd.pdf
mPxsHDgsimT	1009	Subclass-balancing Contrastive Learning for Long-tailed Recognition	['Long-tailed Recognition', 'Supervised Contrastive Learning', 'Representation Learning']	We introduce a novel subclass-balancing contrastive learning (SBCL) for long-tailed recognition.	Deep Learning and representational learning	anonymous|subclassbalancing_contrastive_learning_for_longtailed_recognition	/pdf/70f07488303694bfd1fd274621ceba39527d353e.pdf
lTDt-lsZbVe	1010	SAE: Estimation for Transition Matrix in Annotation Algorithms	[]		Unsupervised and Self-supervised learning	anonymous|sae_estimation_for_transition_matrix_in_annotation_algorithms	/pdf/ad38b5e7d56e1bfd252b79f7f4d5fd4ef44ef47a.pdf
7RBvBi3p3Et	1013	AdaStride: Using Adaptive Strides in Sequential Data for Effective Downsampling	['Downsampling', 'Pooling', 'Strides', 'Learning algorithm']	In this paper, we propose a novel downsampling methods called AdaStride, which learns to use adaptive strides in a sequential data for effective downsampling.	Deep Learning and representational learning	anonymous|adastride_using_adaptive_strides_in_sequential_data_for_effective_downsampling	/pdf/b59ec9eca363a0a02abf0ee6761c17aadeec16ac.pdf
6dtI3qPVwVp	1014	Link Prediction without Graph Neural Networks	['Link Prediction', 'Graph Neural Networks', 'Graph Learning', 'Topological Heuristics']	We address key limitations of GNN-based link prediction methods in handling class imbalance and, moreover, present a simpler, more accurate, and more efficient alternative. 	Deep Learning and representational learning	anonymous|link_prediction_without_graph_neural_networks	/pdf/7db560c24222a73c1b2ee09b6df91de65199f65a.pdf
6l46OaYQvu3	1015	Learning Robust Goal Space with Hypothetical Analogy-Making	['GAN', 'information regularization', 'neuroscience-inspired AI', 'generalizable policy']	Generating hypothetical observation and maximizing mutual information between the original observation using analogy-making module helps the RL agent’s learned policy generalize by revealing a robust goal context space.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_robust_goal_space_with_hypothetical_analogymaking	/pdf/7a1da183a77f939f86636d3d80f666522a4d2f73.pdf
ueSz5PRoPA-	1016	Physics-Regularized Stereo Matching for Depth Estimation	['stereo matching']	This paper presents a physics regularization framework to improve the stereo matching.	Applications (eg, speech processing, computer vision, NLP)	anonymous|physicsregularized_stereo_matching_for_depth_estimation	/pdf/1bd89f2ac59fe2a7d232ecb88baca18f0698a018.pdf
HE_75XY5Ljh	1017	Masked Visual-Textual Prediction for Document Image Representation Pretraining	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|masked_visualtextual_prediction_for_document_image_representation_pretraining	/pdf/316a1a81710cca92262937bf0f01058aa1d0e503.pdf
L3zKVQKyV4F	1018	Visual Timing For Sound Source Depth Estimation in the Wild	['Sparse Depth Estimation', 'Audio-Visual']	We propose a passive audiovisual depth estimation scheme based on the difference of propagation velocity between light and sound.	Applications (eg, speech processing, computer vision, NLP)	anonymous|visual_timing_for_sound_source_depth_estimation_in_the_wild	/pdf/f239bef59efbbcb2fd5b3477e48f9134bad8c691.pdf
4wZiAXD29TQ	1020	Dataset Pruning: Reducing Training Data by Examining Generalization Influence	[]		Deep Learning and representational learning	anonymous|dataset_pruning_reducing_training_data_by_examining_generalization_influence	/pdf/9008ab182bc8de9622bded542b220dc904dcc3c9.pdf
HmPOzJQhbwg	1021	ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor	['Sequential Recommendation', 'Long-term Engagement', 'Reinforcement Learning']	We propose a novel paradigm to reinforce long-term engagement in sequential recommendation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|resact_reinforcing_longterm_engagement_in_sequential_recommendation_with_residual_actor	/pdf/9b19fe43e8b11ab291c42707424c40f89868989d.pdf
D4aZrqLDFtE	1022	Sample Importance in SGD Training	['Deep Learning', 'Sample Importance', 'Hard Example Mining']	Biasing SGD towards important samples after a short warm-up phase yields fast convergence, auto-balancing of classes, efficient use of augmentations, and shows that sample importance is model specific.	Optimization (eg, convex and non-convex optimization)	anonymous|sample_importance_in_sgd_training	/pdf/25afb93460fe1e1958a68c058e7ce80a1d2efd23.pdf
GGx4EVTZU5r	1023	Exploit Unlabeled Data on the Server! Federated Learning via Uncertainty-aware Ensemble Distillation and Self-Supervision	['Federated Learning', 'Knowledge Distillation', 'Ensemble Distillation', 'Self-supervised Learning', 'Uncertainty']	A federated learning algorithm that tackles data deficiency by exploiting unlabeled data at server.	General Machine Learning (ie none of the above)	anonymous|exploit_unlabeled_data_on_the_server_federated_learning_via_uncertaintyaware_ensemble_distillation_and_selfsupervision	/pdf/57ed5abc3d61d672665529c4064d62fced4e5e75.pdf
ICYasJBlZNs	1024	Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information	['graph neural network', 'causal inference', 'variational bayes', 'asymptotic statistics', 'single-cell perturbation']	We predict single-cell perturbation responses using a graph variational Bayesian causal inference framework with distilled gene regulatory networks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|predicting_cellular_responses_with_variational_causal_inference_and_refined_relational_information	/pdf/d93838d3cf05c4455ee91685fb8f75f5418aa3b8.pdf
laO3A47q08q	1025	Rethinking Learning Dynamics in RL using Adversarial Networks	['deep learning', 'reinforcement learning', 'meta learning', 'robustness']	We propose an adversarial training regime for the meta-RL domain outperforming the straightforward training regime in many environments.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|rethinking_learning_dynamics_in_rl_using_adversarial_networks	/pdf/dd262110f3486231eea8eb715eaa6acac401d3f9.pdf
mRieQgMtNTQ	1026	Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model	['Zero-Shot', 'Inverse Problems', 'Super-Resolution', 'Diffusion Models', 'Range-Null Space', 'Image Restoration', 'Colorization', 'Compressed Sensing', 'Inpainting', 'Deblur', 'Old Photo Restoration', 'Blind Restoration']	We present a novel zero-shot image restoration framework, achieving state-of-the-art performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|zeroshot_image_restoration_using_denoising_diffusion_nullspace_model	/pdf/3f231db6776eef14218a7a86eb8950cae84b4222.pdf
XUxad2Gj40n	1027	Towards Real-Time Neural Image Compression With Mask Decay	['neural image compression', 'image codec', 'model acceleration', 'model compression', 'knowledge distillation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|towards_realtime_neural_image_compression_with_mask_decay	/pdf/41b5a61439522ebd870793758ae0b50e0d4251fd.pdf
ygYXtbb3og3	1028	Mutual Information Regularized Offline Reinforcement Learning	['Offline Reinforcement Learning', 'Mutual Information']	We propose MISA, a general framework for offline reinforcemen learning with mutual information regularization	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|mutual_information_regularized_offline_reinforcement_learning	/pdf/1637a8ab24670c271dd76ac1caed34b510f612dd.pdf
UFbxfSnxan3	1030	Improving group robustness under noisy labels using predictive uncertainty	['Spurious-cue', 'group robustness', 'noisy label robustness', 'uncertainty']		Deep Learning and representational learning	anonymous|improving_group_robustness_under_noisy_labels_using_predictive_uncertainty	/pdf/e8438fa238955cdddc9f6f70bc41580cddfeb595.pdf
pd1P2eUBVfq	1031	Diffusion Models Already Have A Semantic Latent Space	['diffusion models', 'semantic image editing']	We discover the semantic latent space of pretrained diffusion models by introducing asymmetric reverse process.	Generative models	anonymous|diffusion_models_already_have_a_semantic_latent_space	/pdf/529e6e44ea13503c0d198068160d46d1f6144edd.pdf
hXTorkeOSsg	1032	Imitation Learning via Differentiable Physics	['imitation learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|imitation_learning_via_differentiable_physics	/pdf/6c91d184b889444d33b036f24a1e4799c07968ec.pdf
4oXTQ6m_ws8	1033	The Role of ImageNet Classes in Fréchet Inception Distance	['generative models', 'evaluation', 'Fréchet Inception Distance']	We elucidate why using ImageNet pre-trained Inception features in FID can cause discrepancies with human judgement.	Generative models	anonymous|the_role_of_imagenet_classes_in_fréchet_inception_distance	/pdf/c9b4554909521c7146237c31869643bf3a1cda45.pdf
G4ywctru8UX	1034	TPC-NAS: Sub-Five-Minute Neural Architecture Search for Image Classification, Object-Detection, and Super-Resolution	['NAS', 'Neural Architecture Search', 'Image Classification', 'Object Detection', 'Super Resolution']		General Machine Learning (ie none of the above)	anonymous|tpcnas_subfiveminute_neural_architecture_search_for_image_classification_objectdetection_and_superresolution	/pdf/cd87d185e233dd98d52e0f464ffcd3902c4f2b7e.pdf
0a5r6iNmacV	1035	On Storage Neural Network Augmented Approximate Nearest Neighbor Search	['approximate nearest neighbor search', 'neural network']		General Machine Learning (ie none of the above)	anonymous|on_storage_neural_network_augmented_approximate_nearest_neighbor_search	/pdf/36757290e569ef09629144799b1aac5cf2e87f47.pdf
JHW30A4DXtO	1036	Learning to Generate Columns with Application to Vertex Coloring	['Machine learning', 'combinatorial optimization', 'column generation']		General Machine Learning (ie none of the above)	anonymous|learning_to_generate_columns_with_application_to_vertex_coloring	/pdf/5a6a4f6ad475dba65c895665d526cb671fcf00ae.pdf
9eT2pA9P-vI	1037	Adam Accumulation to Reduce Memory Footprints of both Activations and Gradients for Large-scale DNN Training	['Large model training', 'Memory reduction']	This is an algorithm-system co-designed work to ensure memory-efficient training for large-scale DNN models	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|adam_accumulation_to_reduce_memory_footprints_of_both_activations_and_gradients_for_largescale_dnn_training	/pdf/15401e4ed02053ef87ca2c294cb30d325b34daf8.pdf
ZR-C_YlIf0q	1038	BIL: Bandit Inference Learning for Online Representational Similarity Test	['two-armed bandit process', 'online learning']	Based on two-armed bandit process, this article proposes a strategic aggregation procedure for online representational similarity testing.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|bil_bandit_inference_learning_for_online_representational_similarity_test	/pdf/01a917eae947de6fe0ef2540d8116f23680b12db.pdf
_8ZuxGYmGe_	1039	CAMVR: Context-Adaptive Multi-View Representation Learning for Dense Retrieval	[]		Deep Learning and representational learning	anonymous|camvr_contextadaptive_multiview_representation_learning_for_dense_retrieval	/pdf/a43f96a57876c90f406fabf45c3790c6f924ea33.pdf
77aKxP46geN	1040	Dateformer: Transformer Extends Look-back Horizon to Predict Longer-term Time Series	['Time-series forecasting', 'Long-term forecasting', 'Transformer', 'Time-modeling method']	We propose (1) splitting time series into patches thereby enabling vanilla Transformer to predict long-term series; (2)tapping whole training set time series to break information bottlenecks. Our work surpasses SOTA by 33.6% on 7 real-world datasets.	Deep Learning and representational learning	anonymous|dateformer_transformer_extends_lookback_horizon_to_predict_longerterm_time_series	/pdf/190cabe779204d4672767f588b0f25bdf87f9a11.pdf
MpGP-z07TmM	1042	Learning Specialized Activation Functions for Physics-informed Neural Networks	['Physics-informed neural network', 'adaptive activation functions']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_specialized_activation_functions_for_physicsinformed_neural_networks	/pdf/00273374dc1d68b6be959f046b840bc4f91d50f4.pdf
ktrw68Cmu9c	1043	CodeT:  Code Generation with Generated Tests	['code generation', 'test case generation', 'pre-trained language models']		Applications (eg, speech processing, computer vision, NLP)	anonymous|codet_code_generation_with_generated_tests	/pdf/d9279577af21323ab464850f6a952b0e47fed381.pdf
W-VfwHzA2yg	1045	AdaDQH Optimizer: Evolving from Stochastic to Adaptive by Auto Switch of Precondition Matrix	['adaptive optimizer', 'Hessian approximation', 'auto switch', 'precondition matrix', 'AdaDQH']	We propose the AdaDQH optimizer, which can evolve from stochastic to adaptive by auto switch of the precondition matrix and has better performance compared to the state-of-the-art optimizers.	Optimization (eg, convex and non-convex optimization)	anonymous|adadqh_optimizer_evolving_from_stochastic_to_adaptive_by_auto_switch_of_precondition_matrix	/pdf/4a46d50504aa5b6007c5cb6ca2db5d8c2b5ceadc.pdf
-gTqRt6RpqV	1047	Gated Class-Attention with Cascaded Feature Drift Compensation for Exemplar-free Continual Learning of Vision Transformers	['Exemplar-Free Continual Learning', 'Vision Transformer', 'Class-incremental learning']	We propose a gated-class attention mechanism with feature drift compensation that achieves improved plasticity and stability for exemplar-free continual learning of visual transformers	Deep Learning and representational learning	anonymous|gated_classattention_with_cascaded_feature_drift_compensation_for_exemplarfree_continual_learning_of_vision_transformers	/pdf/3cefc5c811e1c3602fa807953e0eff8624d6e013.pdf
MbWntPvE5Tg	1051	Planning Immediate Landmarks of Targets for Model-Free Skill Transfer across Agents	['reinforcement learning', 'transfer learning']	We propose PILoT, a learning framework for transferring multi-task skills across agents.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|planning_immediate_landmarks_of_targets_for_modelfree_skill_transfer_across_agents	/pdf/1268f4a67e362911d65e2a20d7838b6c7a80f1fd.pdf
OnM3R47KIiU	1052	Visual Imitation Learning with Patch Rewards	['imitation learning', 'reinforcement learning']	We leverage to learn patch reward and present PatchAIL, an intuitive and principled learning framework for efficient visual imitation learning. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|visual_imitation_learning_with_patch_rewards	/pdf/739274b6c06efd0330943d32ef80c16c29d52f3d.pdf
itZ6ggvMnzS	1053	Causal Representation Learning for Instantaneous and Temporal Effects	['Representation Learning', 'Causality', 'Causal Representation Learning', 'Causal Discovery', 'Disentanglement']	A causal representation learning method that can identify causal variables with instantaneous effects and their graph from temporal sequences with interventions.	Deep Learning and representational learning	anonymous|causal_representation_learning_for_instantaneous_and_temporal_effects	/pdf/36ee10546b325439cdc6c13985adc43c0ea32c2e.pdf
n7lFF_zE8nm	1054	Critical Sampling for Robust Evolution Behavior Learning of Unknown Dynamical Systems	['Critical Sampling', 'Evolution Behavior Learning', 'Dynamical Systems']	We perform dynamic selection of critical samples and develop an adaptive sampling-learning method for dynamical systems based on the spatial-temporal evolution network.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|critical_sampling_for_robust_evolution_behavior_learning_of_unknown_dynamical_systems	/pdf/92e69d97d50714cc1497a93aee714ff89e48d994.pdf
A09CypdRq8D	1055	Partial Advantage Estimator for Proximal Policy Optimization	['Reinforcement learning', 'value estimator']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|partial_advantage_estimator_for_proximal_policy_optimization	/pdf/4a82dd4360de1a2c619963b623721e58c19e3298.pdf
7BfWbjOqgMf	1056	Universal Speech Enhancement with Score-based Diffusion	['Speech enhancement', 'audio', 'score matching', 'diffusion', 'mixture density networks']	We propose to consider the task of speech enhancement as a universal endeavor, and provide a diffusion-based approach to deal with 55 different distortions at the same time.	Applications (eg, speech processing, computer vision, NLP)	anonymous|universal_speech_enhancement_with_scorebased_diffusion	/pdf/f21584a556757790631724bdf8719c22a17b6e8e.pdf
oxGheSaaplr	1057	Multigraph Topology Design for Cross-Silo Federated Learning	['Federated Learning', 'Topology Design', 'Multigraph']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|multigraph_topology_design_for_crosssilo_federated_learning	/pdf/f4708208ac1ad8596e3bd1a4cbf0b3a6ccc11c5f.pdf
LvwOdSbB9Ic	1058	Minibatch Stochastic Three Points Method for Unconstrained Smooth Minimization	['Zero-order optimization', 'Machine Learning.']		Optimization (eg, convex and non-convex optimization)	anonymous|minibatch_stochastic_three_points_method_for_unconstrained_smooth_minimization	/pdf/79bd8f71e25c7e7f6581c855dc136ebf1898fca2.pdf
C2fsSj3ZGiU	1059	Neural Episodic Control with State Abstraction	['Deep reinforcement learning', 'episodic control', 'sample efficiency', 'state abstraction']	We propose NECSA, a simple and effective state abstraction-based episodic control containing a more comprehensive episodic memory, a novel state measurement, and a multi-step state analysis.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|neural_episodic_control_with_state_abstraction	/pdf/bdd3295f0176bd3bc92a3aaadd8e8bd714583fea.pdf
kIAx30hYi_p	1061	Self-Supervised Set Representation Learning for Unsupervised Meta-Learning	['Unsupervised Meta-Learning', 'Set Representation Learning', 'Self-Supervised Learning']	We propose self-supervised set representation learning for unsupervised meta-learning.	Unsupervised and Self-supervised learning	anonymous|selfsupervised_set_representation_learning_for_unsupervised_metalearning	/pdf/70b2baaa719a046ed5b76ff49e717b6ea34bc9ad.pdf
0v4VkCSkHNm	1062	Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning	['Skills', 'Transfer Learning', 'Reinforcement Learning']	We introduce 'Attentive Priors for Expressive and Transferable Skills' (APES), a hierarchical KL-regularized skill transfer method that automates the choice of information asymmetry thereby maximising transfer benefits.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|priors_hierarchy_and_information_asymmetry_for_skill_transfer_in_reinforcement_learning	/pdf/b4a131cb1a512fe6a46881a8d1e17b367b8142b2.pdf
ogsUO9JHZu0	1063	Efficient Trojan Injection: 90% Attack Success Rate Using 0.04% Poisoned Samples	['Deep Neural Networks', 'Backdoor Attacks', 'Poisoning Efficiency.']	We try to poison as few samples as possible to complete the backdoor attack.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|efficient_trojan_injection_90_attack_success_rate_using_004_poisoned_samples	/pdf/726743f8785c5399a399a363268581293e5b5636.pdf
lh3GH0BmEF	1064	Imitate Your Own Refinement: Knowledge Distillation Sheds Light on Efficient Image-to-Image Translation	['Knowledge Distillation', 'Image-to-Image Translation', 'Self-Distillation', 'Model Compression']	We propose a novel knowledge distillation method for efficient image-to-image translation by replacing the teacher network with a refining network.	Deep Learning and representational learning	anonymous|imitate_your_own_refinement_knowledge_distillation_sheds_light_on_efficient_imagetoimage_translation	/pdf/79c3f9baa52a1b6cfa426250c9d28e5290eb3fd0.pdf
mPzpPv0geS2	1065	Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models	['DNN optimizer', 'Deep Learning Optimization', 'AdamW', 'Large Batch Training', 'ViT', 'ResNet', 'Network Optimization']	An universal optimizer across vision, language, and RL tasks.	Deep Learning and representational learning	anonymous|adan_adaptive_nesterov_momentum_algorithm_for_faster_optimizing_deep_models	/pdf/becf919922129ceb4f4418d312e02e28caaf6b2b.pdf
IloMJ5rqfnt	1067	Accurate Image Restoration with Attention Retractable Transformer	['Image restoration', 'Dense and sparse attention']	A new SOTA image restoration method attention retractable Transformer.	Applications (eg, speech processing, computer vision, NLP)	anonymous|accurate_image_restoration_with_attention_retractable_transformer	/pdf/176a3f5ce510d7b6029db6d7248c002acf8a403e.pdf
4WM4cy42B81	1068	Dirichlet-based Uncertainty Calibration for Active Domain Adaptation	['domain adaptation', 'active learning', 'uncertainty', 'Dirichlet']		General Machine Learning (ie none of the above)	anonymous|dirichletbased_uncertainty_calibration_for_active_domain_adaptation	/pdf/7678675e84f88f7a3227c6be037ccc35dae14d4a.pdf
K2OixmPDou3	1069	Unleashing Mask: Explore the Intrinsic Out-of-distribution Detection Capability	[]		Deep Learning and representational learning	anonymous|unleashing_mask_explore_the_intrinsic_outofdistribution_detection_capability	/pdf/302b14bc7ab4b6c02a58cebcac7b07c6bc56821b.pdf
df84K_d5WPZ	1070	Leveraging variational autoencoders for multiple data imputation	['Variational autoencoders', 'missing data', 'multiple imputation', 'deep learning', 'power likelihood']	Multiple data imputation using variational autoencoders allows accurate imputation of missing data, while retaining good coverage.	Generative models	anonymous|leveraging_variational_autoencoders_for_multiple_data_imputation	/pdf/9163ee2c2a2140df535bc2f2a2b930c78e37d578.pdf
f2wN4v_2__W	1071	Learning Symbolic Models for Graph-structured Physical Mechanism	['Symbolic Regression', 'Graph Neural Networks', 'Physical Mechanism', 'Message-Passing Flow']	We generalize symbolic regression to graph data and propose a novel method with the key insight of learning formula skeleton by searching message-passing flows of graph neural networks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_symbolic_models_for_graphstructured_physical_mechanism	/pdf/f7b839c3ce52674ed84bcd2932fc27d385402358.pdf
oWRcXhIeWw2	1072	Edge-Varying Fourier Graph Network for Multivariate Time Series Forecasting	['fourier graph convolution', 'fourier graph shift operator', 'supra-graph', 'multivariate time series forecasting']	We make the first attempt to design a complex-valued feed-forward network in the Fourier space for efficiently computing multi-layer graph convolutions with defined Fourier graph shift operators.	Applications (eg, speech processing, computer vision, NLP)	anonymous|edgevarying_fourier_graph_network_for_multivariate_time_series_forecasting	/pdf/1115f0cfef365a3dfa24cc4151c7f9f62a1db7f7.pdf
PfJrZvtoWUd	1073	Dimensionality-Varying Diffusion Process	['Diffusion models', 'generative models']		Generative models	anonymous|dimensionalityvarying_diffusion_process	/pdf/b8d8d62ae4c5a9a4bb4dbfb98963559928fb87d7.pdf
ci7LeVhmQSn	1074	Towards Online Real-Time Memory-based Video Inpainting Transformers	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|towards_online_realtime_memorybased_video_inpainting_transformers	/pdf/dfb67a3133a5a3472f5d247fb660e7370c9627dd.pdf
OK6LV2q50l	1075	FedPSE: Personalized Sparsification with Element-wise Aggregation for Federated Learning	['Federated Learning', 'Non-IID', 'Communication Efficiency']	We propose a federated learning framework to resolve the bidirectional communication challenge on Non-IID datasets.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fedpse_personalized_sparsification_with_elementwise_aggregation_for_federated_learning	/pdf/13e200eb5bc92a9c1ed1470c707bb11e56535af8.pdf
PolHquob8M7	1076	Continual Transformers: Redundancy-Free Attention for Online Inference	['Transformer', 'Continual Inference Networks', 'Online inference', 'Stream processing', 'Acceleration', 'Online Action Detection', 'Audio classification']	A Transformer Decorder acceleration for online stream processing validated with experiments in Online Action Detection and Audio Classification.	Deep Learning and representational learning	anonymous|continual_transformers_redundancyfree_attention_for_online_inference	/pdf/50ba041cde0e02a04cc837afdf8052f02bfdd5e6.pdf
TJY-0L3WyAM	1077	Causal Information Bottleneck Boosts Adversarial Robustness of Deep Neural Network	['deep learning', 'adversarial examples', 'information bottleneck']	The information bottleneck based on the causal method could boost the adversarial robustness	Deep Learning and representational learning	anonymous|causal_information_bottleneck_boosts_adversarial_robustness_of_deep_neural_network	/pdf/9a4bf81f4783a8bc0cc0dcd206cacbe5adc0e492.pdf
TuHkVOjSAR	1079	Strategic Classification on Graphs	['Strategic classification', 'Graph Neural Networks', 'Robust classification']	We study the problem of learning graph neural networks under strategic user behavior, and propose an efficient method for learning strategy-robust graph-based classifiers.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|strategic_classification_on_graphs	/pdf/3564eff0ef118a4a11809695d7d04c22728d7aa4.pdf
s7gnrEtWSm	1083	Iterative $\alpha$-(de)Blending: Learning a Deterministic Mapping Between Arbitrary Densities	['Deterministic Denoising Diffusion']	Deriving a deterministic denoising diffusion with very basic concepts (no langevin equation, no score, etc.)	Generative models	anonymous|iterative_\alphadeblending_learning_a_deterministic_mapping_between_arbitrary_densities	/pdf/f3155acd0c919d5d773dace1b58d60e7e1a00c45.pdf
WVRb98rwbv9	1084	Truthful Self-Play	['Comm-POSG', 'Imaginary Rewards']	TSP is a general framework for evolutionary learning to emergent unbiased state representation without any supervision. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|truthful_selfplay	/pdf/b86514d2a93f869a9a860254fa2026996b5b4685.pdf
SKxzoEbLZpy	1085	PREF: Phasorial Embedding Fields for Compact Neural Representations	[]	An efficient frequency-based neural representation is proposed. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|pref_phasorial_embedding_fields_for_compact_neural_representations	/pdf/5dc180bb3172f8e2b8d5a0eeca264c7a9afd807f.pdf
-CefY2EOupj	1087	Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam	[]		Optimization (eg, convex and non-convex optimization)	anonymous|maximizing_communication_efficiency_for_largescale_training_via_01_adam	/pdf/872bf36e54aca2550fa7b6e3bc60847db5154b9c.pdf
fn0BQK5T8p	1088	CONTINUAL MODEL EVOLVEMENT WITH INNER-PRODUCT RESTRICTION	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|continual_model_evolvement_with_innerproduct_restriction	/pdf/f9b7d3fea8cc5391f6b017af6077a1da492bf55c.pdf
Lq2rsxfNt8	1089	Fusion of Deep Transfer Learning with Mixed convolution network	['Deep Transfer Learning', 'Fusion model', 'Mixed Convolution Network', 'Feature Enhancement Network']	Fusion of Deep Transfer Learning	Deep Learning and representational learning	anonymous|fusion_of_deep_transfer_learning_with_mixed_convolution_network	/pdf/275c0b03e422bb19eed2635f29350038029909c8.pdf
kn7w8UX05a	1091	Leveraging Double Descent for Scientific Data Analysis: Face-Based Social Behavior as a Case Study	['over-parameterized linear regression', 'double descent', 'generalization error', 'cross-task generalization', 'face perception', 'facial features', 'social decision making', 'attractiveness halo', 'beauty premium', 'beauty penalty', 'trustworthiness']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|leveraging_double_descent_for_scientific_data_analysis_facebased_social_behavior_as_a_case_study	/pdf/47bb6f52e1ab69fba3e94f7a927731535962ccf0.pdf
_gM8wSWA5l	1092	Mixed-Precision Inference Quantization: Radically Towards Faster inference speed,  Lower Storage requirement, and Lower Loss	['Mixed-Precision Quantization', 'Inference', 'Neural networks', 'Noise Robustness', 'Residual Network']	An appropriate quantisation method may reduce the neural network's loss, and we show our way in this paper. 	General Machine Learning (ie none of the above)	anonymous|mixedprecision_inference_quantization_radically_towards_faster_inference_speed_lower_storage_requirement_and_lower_loss	/pdf/d5edc1ee56436b2f0ab3c6a85d1fde09f6515db8.pdf
aOKs_OFS9g	1093	Latent Offline Distributional Actor-Critic	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|latent_offline_distributional_actorcritic	/pdf/fa73b9dbc8fa8a789f98a1e1005eb93694878c0e.pdf
XVisF4OaBj6	1094	Mixed-Precision Inference Quantization: Problem Resetting, Mapping math concept and Branch\&bound methods	['Mixed-Precision Quantization', 'Inference', 'Neural networks', 'Noise Robustness', 'NP hard']	change mixed precision inference quantization problem into the problem which solved by branch and  bound method	General Machine Learning (ie none of the above)	anonymous|mixedprecision_inference_quantization_problem_resetting_mapping_math_concept_and_branch\bound_methods	/pdf/ccfbe387caaff839f28d8ccb79cb4866256272dd.pdf
m6ahb1mpwwX	1095	InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning	['imbalanced semi-supervised learning', 'energy-based model']	"A novel pseudo-labeling approach that views pseudo-labeling as an evolving ""in-distribution vs out-of-distribution"" classification problem for imbalanced semi-supervised learning"	Deep Learning and representational learning	anonymous|inpl_pseudolabeling_the_inliers_first_for_imbalanced_semisupervised_learning	/pdf/48065fa2784042dd716e61e969a1478f7141fdf4.pdf
iJthfvecen2	1096	Triangle Inequality for Inverse Optimal Control	['Inverse optimal control', 'Inverse reinforcement learning', 'Imitation learning', 'Cost learning', 'Value function learning', 'Optimal control']	We propose a new inequality useful for improving inverse optimal control methods.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|triangle_inequality_for_inverse_optimal_control	/pdf/128e4595e03e672980b15d4239444c8f2a7a6590.pdf
DxmF48B_49z	1097	Random Weight Factorization improves the training of Continuous Neural Representations	[]	A simple drop-in replacement of conventional dense layers for accelerating and improving the training of coordinate-based multi-layer perceptrons (MLPs).	Deep Learning and representational learning	anonymous|random_weight_factorization_improves_the_training_of_continuous_neural_representations	/pdf/837370202132e46de512fb1732b34df53ca59d4d.pdf
rPNjqUf9eC4	1098	Does Dataset Lottery Ticket Hypothesis Exist?	['Dataset Lottery Ticket Hypothesis', 'Self-supervised Learning']		Unsupervised and Self-supervised learning	anonymous|does_dataset_lottery_ticket_hypothesis_exist	/pdf/b14ccb8ddbf931c103334a326bceaa63a8d77cbf.pdf
EwoBTLCY-Y	1099	Neural Optimal Transport with General Cost Functionals	['Optimal Transport', 'Neural Networks', 'Generative Modelling', 'Unpaired Learning']		Generative models	anonymous|neural_optimal_transport_with_general_cost_functionals	/pdf/8eaaf75cd1d9adf1d30ba89ab1bef0258c42e163.pdf
kwF1ZfHf0W	1100	Intepreting & Improving Pretrained Language Models: A Probabilistic Conceptual Approach	['Pretrained Lauguage Models', 'Generative Models', 'Probabilistic Graphical Models']	We propose a hierarchical Bayesian deep learning model to provide concept-level interpretations of pretrained language models. 	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|intepreting_improving_pretrained_language_models_a_probabilistic_conceptual_approach	/pdf/f57fb495c21c919908ca2de2f514cb28ff3b5ad6.pdf
jXQ0ipgMdU	1101	Spherical Sliced-Wasserstein	['Optimal Transport', 'Sliced-Wasserstein', 'Sphere', 'Radon Transform']	We propose a SW discrepancy on the sphere using only tools intrinsic to the manifold.	General Machine Learning (ie none of the above)	anonymous|spherical_slicedwasserstein	/pdf/531ba4789f30bef19cc1dd5ec494907d878bcf05.pdf
boVagyqWwKa	1102	Proximal Curriculum for Reinforcement Learning Agents	['curriculum design', 'reinforcement learning', 'zone of proximal development']	We propose a novel curriculum strategy for deep reinforcement learning agents based on the concept of Zone of Proximal Development.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|proximal_curriculum_for_reinforcement_learning_agents	/pdf/2643f1e080e5f435ff84a84c62ca68f07b5f0711.pdf
o2Udz4LZsL5	1103	Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance	['diffusion models', 'generative models', 'image-to-image translation', 'controllable generation', 'zero-shot learning', 'text-to-image synthesis']	By defining diffusion models' Gaussian latent spaces, they can be used like CycleGANs and GANs and beyond (e.g., zero-shot image-to-image translation with text-to-image diffusion models)	Applications (eg, speech processing, computer vision, NLP)	anonymous|unifying_diffusion_models_latent_space_with_applications_to_cyclediffusion_and_guidance	/pdf/ab2918f483cfd55e56bd334b266241d2ff9267b1.pdf
TXPN6MtdSE4	1104	Learning Sparse and Low-Rank Priors for Image Recovery via Iterative Reweighted Least Squares Minimization	['sparsity', 'low-rank', 'IRLS', 'inverse problems', 'optimization', 'recurrent networks']		Optimization (eg, convex and non-convex optimization)	anonymous|learning_sparse_and_lowrank_priors_for_image_recovery_via_iterative_reweighted_least_squares_minimization	/pdf/a5f914b1ddf81a43b7c62689b4975979433162ce.pdf
gQsRPozZYIQ	1105	Receding Neuron Importances for Structured Pruning	['structured pruning', 'regularization', 'sparsity', 'batchnorm', 'neuron importance']		Deep Learning and representational learning	anonymous|receding_neuron_importances_for_structured_pruning	/pdf/31bc3c09f2c55129e83ebc8531eedd7428bd3bf3.pdf
0YXmOFLb1wQ	1107	MotifExplainer: a Motif-based Graph Neural Network Explainer	['Graph Neural Networks', 'Explainer', 'Motif']	We propose a motif-based explainer that can provide better human-understandable explanations than methods based on nodes, edges, and regular subgraphs.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|motifexplainer_a_motifbased_graph_neural_network_explainer	/pdf/d5191eb93a96285f4cc0eabff22edf1d0a9b85a5.pdf
EONdIvi64h-	1108	Harnessing spectral representations for subgraph alignment	['Graph alignment', 'Spectral theory']		General Machine Learning (ie none of the above)	anonymous|harnessing_spectral_representations_for_subgraph_alignment	/pdf/1d5794f5e6090785c2dd75aa5b48c239fa8dd52c.pdf
4UldFtZ_CVF	1109	Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural Networks	['Learning theory', 'Graph neural networks', 'Generalization analysis', 'Graph sparisification']	Encouraged by the empirical success of sparse learners in accelerating GNN training, this paper characterizes the impact of graph sampling and neuron pruning on the sample complexity and convergence rate for a desirable test accuracy quantitatively.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|joint_edgemodel_sparse_learning_is_provably_efficient_for_graph_neural_networks	/pdf/3863edbe796ff47991e0abb7410cae8e5c6bb0aa.pdf
-qg8MQNrxZw	1110	SeaFormer: Squeeze-enhanced Axial Transformer for Mobile Semantic Segmentation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|seaformer_squeezeenhanced_axial_transformer_for_mobile_semantic_segmentation	/pdf/c69e26fc7710b7cd1fb0a82f8ad1e8657286124b.pdf
d8CBRlWNkqH	1111	Neural Optimal Transport	['weak optimal transport', 'neural networks']	We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs.	Generative models	anonymous|neural_optimal_transport	/pdf/b3c6b4f29b1cc32b6f5f9419d50ac9e1893d20fc.pdf
Zuc_MHtUma4	1112	Kernel Neural Optimal Transport	['optimal transport', 'neural networks', 'kernels']		Generative models	anonymous|kernel_neural_optimal_transport	/pdf/0790c194ecae320534de620129d5051bea175ada.pdf
b_cUyW2CJO1	1113	Accelerating Inverse Reinforcement Learning with Expert Bootstrapping	['inverse reinforcement learning', 'imitation learning', 'reinforcement learning']	This paper presents two simple, general-purpose recipes for accelerating inverse reinforcement learning through better utilization of expert information.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|accelerating_inverse_reinforcement_learning_with_expert_bootstrapping	/pdf/dd4c2dc42b8789cdbb65b15ff97498a87ebb74c2.pdf
V0Vo9eW2nzL	1114	Tiny Adapters for Vision Transformers	['Vision Transformers', 'Parameter Efficient Training', 'Adapters']	Tiny Adapters for Vision Transformers	Deep Learning and representational learning	anonymous|tiny_adapters_for_vision_transformers	/pdf/4a7a89fdba1bc58a283f0a5bb35cc0a0bbbab477.pdf
Rl4ihTreFnV	1115	Robust Multi-Agent Reinforcement Learning with State Uncertainties	['multi-agent reinforcement learning', 'robust reinforcement learning']	fundamental research about robust multi-agent reinforcement learning with state uncertainty 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|robust_multiagent_reinforcement_learning_with_state_uncertainties	/pdf/c66bcbe0217ec0a695ce709fefca0ce73d43c5eb.pdf
1CHhsUY32a	1116	Controllable Image Generation via Collage Representations	['image generation', 'controllable image generation', 'conditional image generation', 'instance-conditioned generation', 'image collage', 'out-of-distribution generation', 'unseen layout generation', 'scene generation']	We present Mixing and Match scenes (M&Ms), a novel approach to controllable image generation by conditioning on representations of image collages containing objects and backgrounds from several reference images, resulting in high quality generations.	Generative models	anonymous|controllable_image_generation_via_collage_representations	/pdf/c671c416a388e9f523279680af8acdf33f93e479.pdf
ALDM5SN2r7M	1117	Robust Active Distillation	['knowledge distillation', 'active learning', 'semi-supervised learning', 'model compression']	A new way of actively soft-labeling points in semi-supervised knowledge distillation to teach the student model in an efficient and robust way	Deep Learning and representational learning	anonymous|robust_active_distillation	/pdf/cd8ebbe1f89c842b498afbd707f8ba3ddd155723.pdf
HkQ7Ompkpqe	1118	Smart Multi-tenant Federated Learning	['federated learning', 'multi-tenant federated learning']	We propose a smart multi-tenant federated learning system, MuFL, to efficiently coordinate and execute simultaneous training activities under resource constraints by considering both synergies and differences among training activities.	Deep Learning and representational learning	anonymous|smart_multitenant_federated_learning	/pdf/445d3c7ba628691ed02ed73c960fe3d81b580dc3.pdf
L5yBcwO1yKH	1120	MixMask: Revisiting Masked Siamese Self-supervised Learning in Asymmetric Distance	['MixMask', 'Masked Siamese Networks', 'Self-supervised Learning']	A New Masking Strategy for Masked Siamese Self-supervised Learning	Unsupervised and Self-supervised learning	anonymous|mixmask_revisiting_masked_siamese_selfsupervised_learning_in_asymmetric_distance	/pdf/1c583f91a1074f47a70601f48b15baf6043a13d2.pdf
ldRb12nMfLQ	1121	A Deep Conjugate Direction Method for Iteratively Solving Linear Systems	['Computational Linear Algebra', 'Convolutional Neural Network', 'Conjugate Gradients', 'Partial Differential Equations', 'Fluid Simulation']	We present a CNN-based algorithm for solving linear systems with millions of degrees of freedom in a way that rapidly achieves convergence to a specified tolerance, a significant improvement over learning methods that converge slowly or not at all.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_deep_conjugate_direction_method_for_iteratively_solving_linear_systems	/pdf/c1e285763ae2a6a78ab20fa843b5b1c5b0275704.pdf
VV0hSE8AxCw	1122	Sparse Token Transformer with Attention Back Tracking	['Token Pruning', 'Sparse Token', 'Attention Back-tracking', 'BERT', 'Vision Transformer', 'DynamicViT']	We propose an attention back-tracking method that tracks the importance of each attention in a Transformer architecture from the outputs to the inputs, to preserve the tokens that have large impact on the final predictions.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sparse_token_transformer_with_attention_back_tracking	/pdf/50f0a626dc8d842bc0d17ad95c942c6b299a411b.pdf
0Q9H_Pgx132	1123	Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?	['Neural network', 'nonparametric regression', 'minimax optimal']	Parallel NN with only weight decay achieves an estimation error close to the minimax rates for both the Besov and BV classes.	Deep Learning and representational learning	anonymous|deep_learning_meets_nonparametric_regression_are_weightdecayed_dnns_locally_adaptive	/pdf/959a4fd50bfe7cb42ef161f55f4c5c3f9c6d425a.pdf
yhLVkvwUGtH	1124	Generative Model Based Noise Robust Training for Unsupervised Domain Adaptation	['Unsupervised Domain Adaptation', 'Generative Models', 'Feature Augmentation', 'Generative and Discriminative Consistency']		Deep Learning and representational learning	anonymous|generative_model_based_noise_robust_training_for_unsupervised_domain_adaptation	/pdf/6242335d7b93ab0bf5eb71d46f109c30ef6feb5e.pdf
wYYCBNLEmBv	1125	HyperQuery: A Framework for Higher Order Link Prediction	['link prediction', 'Hyperedge prediction', 'Hypergraph learning', 'message passing', 'hypergraphs']	A new state-of-the-art hyperedge prediction framework for knowledge hypergraphs as well as regular hypergraphs	Deep Learning and representational learning	anonymous|hyperquery_a_framework_for_higher_order_link_prediction	/pdf/38c807148ef0e57a7e1d48d6192f20282fbc7bea.pdf
SDHSQuBpf2	1127	Laziness, Barren Plateau, and Noises in Machine Learning	['theoretical issues in deep learning', 'learning representations of outputs or states']	Variational quantum algorithms are lazy and noise-resilient in the overparametrization regime.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|laziness_barren_plateau_and_noises_in_machine_learning	/pdf/7f28333723f340f28fbb6687377228ea8de9fd26.pdf
fwP9Bc4E71	1128	Learning to Take a Break: Sustainable Optimization of Long-Term User Engagement	['Lotka-Volterra dynamics', 'breaking policies', 'digital well-being', 'feed-based recommendation']	We use Lotka-Volterra dynamics to learn optimal `take-a-break' schedules that promote sustainable media habits.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_to_take_a_break_sustainable_optimization_of_longterm_user_engagement	/pdf/4a3cc7bd8f2765e0ab84bfd52e29057223a7acbb.pdf
bl5pGwUQsZq	1129	High Dimensional Bayesian Optimization with Reinforced Transformer Deep Kernels	['Bayesian Optimization', 'Reinforcement Learning', 'Deep Kernel Learning']	Transformer Deep Kernels combined with general combination gaussian process kernels help optimize high dimensional functions when using reinforcement learning acquisitions for exploration.	Optimization (eg, convex and non-convex optimization)	anonymous|high_dimensional_bayesian_optimization_with_reinforced_transformer_deep_kernels	/pdf/b7e5aeade498895e1c8ea53154c9fbf8c49c761a.pdf
l2cryUoxvaX	1130	Explainability of deep reinforcement learning algorithms in robotic domains by using Layer-wise Relevance Propagation	['Explainability', 'Deep Reinforcement Learning', 'Graph Network', 'Layer-wise Relevance Propagation', 'Robotic']	Explaining the policy learned by a deep reinforcement learning algorithm with graph networks as function approximators in robotic environments by using layer-wise relevance propagation technique.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|explainability_of_deep_reinforcement_learning_algorithms_in_robotic_domains_by_using_layerwise_relevance_propagation	/pdf/b24c72edc92ac531288e565c7ce1341bce4040b2.pdf
8Oun8ZUVe8N	1131	Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image Transformers Help 3D Representation Learning?	['Representation Learning', 'Cross-Modal Learning', '3D Point Clouds']	This paper shows that pretrained 2D image Transformers can help self-supervised 3D representation learning by training autoencoders as cross-modal teachers.	Deep Learning and representational learning	anonymous|autoencoders_as_crossmodal_teachers_can_pretrained_2d_image_transformers_help_3d_representation_learning	/pdf/e3628c71fb402eac5d86594bd33173851dc7bdec.pdf
SNZxVIFZBIq	1132	Radial Spike and Slab Bayesian Neural Networks for Sparse Data in Ransomware Attacks	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|radial_spike_and_slab_bayesian_neural_networks_for_sparse_data_in_ransomware_attacks	/pdf/4fc0ad9527fb2e0a369b956dc568f67747e6f155.pdf
ObtGcyKmwna	1133	Critic Sequential Monte Carlo	['sequential monte carlo', 'reinforcement learning as inference', 'soft Q-learning', 'heuristic factors', 'driving behavior models']	We present a novel method called CriticSMC capable of being deployed in model-predictive planning and model-free online control cases within environments with hard constraints taking advantage of informative prior policies.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|critic_sequential_monte_carlo	/pdf/8b49d4391f2e50b23115535e92542b539e292db9.pdf
ZXu1S-wdy6d	1134	EMO: Episodic Memory Optimization for  Few-Shot Meta-Learning	['Episodic memory', 'Meta-learning', 'Few-shot learning', 'Optimization']	We propose an episodic memory optimization for meta-learning, which we call EMO, that retains the gradient history of past experienced tasks in external memory. 	General Machine Learning (ie none of the above)	anonymous|emo_episodic_memory_optimization_for_fewshot_metalearning	/pdf/da8add2ea9da2eb018c51faf1603115e0a2c98df.pdf
-ltZ1uw8ZE7	1135	Variational Imbalanced Regression	['probabilistic methods', 'variational inference', 'imbalanced regression', 'uncertainty estimation']	We propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|variational_imbalanced_regression	/pdf/4c402a658a9eb0bc616e3968a6cdbf41c5d4ca2b.pdf
IowKt5rYWsK	1136	GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation	['Visual Recognition', 'Vision transformer architecture']	A high-resolution vision transformer architecture based on a new efficient global information exchange mechanism for general visual recognition.	Applications (eg, speech processing, computer vision, NLP)	anonymous|gpvit_a_high_resolution_nonhierarchical_vision_transformer_with_group_propagation	/pdf/61582a9b97352e334126c6db75e0a447425287d3.pdf
adT0c0pxbfZ	1137	PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework	['Latency-aware perception', 'aerial tracking', 'visual tracking benchmark']	This work proposes a simple framework for end-to-end latency aware visual tracking.	Applications (eg, speech processing, computer vision, NLP)	anonymous|pvt_a_simple_endtoend_latencyaware_visual_tracking_framework	/pdf/3a0075bb17cbc5d299acfce50525954cd4055461.pdf
jgsGOtbktux	1138	How Erdös and Rényi Win the Lottery	['deep learning', 'lottery tickets', 'pruning at initialization', 'random masks', 'theory']	We prove that random networks contain lottery tickets with high probability.	Deep Learning and representational learning	anonymous|how_erdös_and_rényi_win_the_lottery	/pdf/b0776799a93cab799936715fc7a5ed2dbedd6311.pdf
n-5qp16As_C	1139	Dynamical Isometry for Residual Networks	['deep learning', 'parameter initialization', 'dynamical isometry', 'ResNets']	We derive an initialization scheme for ResNets that induces perfect dynamical isometry at initialization.	Deep Learning and representational learning	anonymous|dynamical_isometry_for_residual_networks	/pdf/fd45364399c247da2cfdfcd05125d1413c020a61.pdf
f3dqV4KLZV1	1140	Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback	['Federated Learning', 'Client Sampling', 'Optimization']	An adaptive client sampling approach in federated learning	Optimization (eg, convex and non-convex optimization)	anonymous|adaptive_client_sampling_in_federated_learning_via_online_learning_with_bandit_feedback	/pdf/92ac4a75332ce740845f7e3ce1289ac66177844a.pdf
9WdB5yVICCA	1141	CausalAgents: A Robustness Benchmark for Motion Forecasting Using Causal Relationships	['robustness', 'motion forecasting', 'self-driving cars']	We construct a benchmark to measure the robustness of motion forecasting models for autonomous driving; we find models are sensitive to deleting irrelevant agents from the scene.	Applications (eg, speech processing, computer vision, NLP)	anonymous|causalagents_a_robustness_benchmark_for_motion_forecasting_using_causal_relationships	/pdf/ba136ba447143a49693179425a21e2332d7f5e22.pdf
V8xIHUK3c5Sr	1142	CroMA: Cross-Modality Adaptation for Monocular BEV Perception	['Multi-Modality', 'Cross-Modality', 'Domain Adaptation', 'Autonomous Driving']	We propose a Cross-Modality Adaptation (CroMA) framework to learn a robust monocular BEV perception model under sensor shift and domain gaps.	Applications (eg, speech processing, computer vision, NLP)	anonymous|croma_crossmodality_adaptation_for_monocular_bev_perception	/pdf/d7fed3193c267df0d4b1d6bb1076f100e0890982.pdf
dMSxTUlQgrZ	1143	A deep top-down approach to hierarchically coherent probabilistic forecasting 	['Hierarchical Forecasting', 'Time-Series']	Deep top-down proportions model for coherent probabilistic hierarchical forecasting	Deep Learning and representational learning	anonymous|a_deep_topdown_approach_to_hierarchically_coherent_probabilistic_forecasting	/pdf/883185e467ae74947b40aa03e0b45fe93148c0fa.pdf
DQou0RiwkR0	1144	Exploiting Spatial Separability for Deep Learning Multichannel Speech Enhancement with an Align-and-Filter Network	['Multichannel speech enhancement', 'microphone array beamforming', 'spatial filtering', 'signal alignment', 'relative transfer functions']	This paper presents an Align-and-Filter network to study spatial separability of sound sources for deep learning multichannel speech enhancement by incorporating relative transfer functions for signal alignment with sequential masking network design.	Applications (eg, speech processing, computer vision, NLP)	anonymous|exploiting_spatial_separability_for_deep_learning_multichannel_speech_enhancement_with_an_alignandfilter_network	/pdf/f236b80f8b18edcdb104314b4a2206e411ec9df7.pdf
WgG3bpUiSqE	1145	S^2-Transformer for Mask-Aware Hyperspectral Image Reconstruction	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|s^2transformer_for_maskaware_hyperspectral_image_reconstruction	/pdf/6678a7ad76fa9d4cce9d9e3cd4885566f2e4e6df.pdf
e9rdb24Yzqx	1146	Empirical analysis of representation learning and exploration in neural kernel bandits	['neural bandits', 'contextual bandits', 'gaussian process', 'neural tangent kernel', 'neural kernel']	Neural kernel bandits achieve better performance than neural-linear on complex UCI datasets. Impact of NK distributions on exploration varies with task complexity and need to explore.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|empirical_analysis_of_representation_learning_and_exploration_in_neural_kernel_bandits	/pdf/9fc2c719bd692cabc976c059c371b5de2e03fb30.pdf
eZ5KJo5GwSI	1147	NOAH: A New Head Structure To Improve Deep Neural Networks For Image Classification	['Deep neural network', 'convolutional neural network', 'vision transformer', 'multi-layer perceptron', 'image classification']	This paper presents a simple and universal head structure to improve the representation learning of deep neural networks for image classification.	Deep Learning and representational learning	anonymous|noah_a_new_head_structure_to_improve_deep_neural_networks_for_image_classification	/pdf/847179efda5c9733de7d911fed4d9ce416fd5bb9.pdf
xYA5j3IH19I	1148	Revisiting Embeddings for Graph Neural Networks	['Graph Neural Networks', 'Embeddings', 'Graph Attention', 'Large Pretrained Models', 'Transfer Learning']	We question current graph neural network embedding quality and present new GNN techniques to use large models (pre-trained or trained from scratch) to work directly on graph-connected data	Deep Learning and representational learning	anonymous|revisiting_embeddings_for_graph_neural_networks	/pdf/b8b422cc2a1d295115ee4050801731a8a29caad2.pdf
gMOhS9EvJDX	1149	Downstream Datasets Make Surprisingly Good Pretraining Corpora	[]		Unsupervised and Self-supervised learning	anonymous|downstream_datasets_make_surprisingly_good_pretraining_corpora	/pdf/fb3a31317e252683ad3d6cf248f793c082d23c97.pdf
CRNwGauQpb6	1150	NORM: Knowledge Distillation via N-to-One Representation Matching	['Knowledge distillation', 'model compression', 'image classification']	This paper presents a new knowledge distillation method via n-to-one representation matching	Deep Learning and representational learning	anonymous|norm_knowledge_distillation_via_ntoone_representation_matching	/pdf/d854bdb8424fdc09ceedaf15eb1a62da59ccc4ea.pdf
8YnDrbx8bnh	1151	Bias Mitigation Framework for Intersectional Subgroups in Neural Networks	['Fairness', 'Feature Interactions', 'Bias Mitigation']	This papers proposes a bias mitigation approach for intersectional subgroups.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|bias_mitigation_framework_for_intersectional_subgroups_in_neural_networks	/pdf/1375e7f9e765100001eb72306f052fbff6a44dff.pdf
i9ogGQHYbkY	1152	Near-Optimal Adversarial Reinforcement Learning with Switching Costs	['adversarial reinforcement learning', 'switching costs', 'regret analysis', 'lower bound']	This paper provides the first algorithms with near-optimal regrets for adversarial reinforcement learning with switching costs, and a matching lower bound on the regret.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|nearoptimal_adversarial_reinforcement_learning_with_switching_costs	/pdf/7f8e34e0ff21f9e26b5e6d313d76ea28fe9ed9c6.pdf
ZTMuZ68B1g	1153	Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle	['bayesian neural network', 'bayesian active learning', 'balanced entropy learning', 'uncertainty quantification']	We propose a new bayesian active learning principle.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|active_learning_in_bayesian_neural_networks_with_balanced_entropy_learning_principle	/pdf/6cea90e49318e64e706aca9b138ebb9eee687d8e.pdf
aFzaXRImWE	1154	A Holistic View of Noise Transition Matrix in Deep Learning and Beyond	[]		General Machine Learning (ie none of the above)	anonymous|a_holistic_view_of_noise_transition_matrix_in_deep_learning_and_beyond	/pdf/5f5faa6b4fb83553f35f3eb7e4fe417402367c35.pdf
uATOkwOZaI	1155	Efficient, Stable, and Analytic Differentiation of the Sinkhorn Loss	['Optimal transport', 'Wasserstein distance', 'Sinkhorn loss', 'differentiable optimization', 'deep generative model']	We have derived an analytic solution coupled with a stable and efficient algorithm for the differentiation of the Sinkhorn loss, as an approximation to the Wasserstein distance for optimal transport problems.	Generative models	anonymous|efficient_stable_and_analytic_differentiation_of_the_sinkhorn_loss	/pdf/d9c463fb641659c2862c9e9f4ad35aad8abfd247.pdf
PQ2zoIZqvm	1157	Switch-NeRF: Learning Scene Decomposition with Mixture of Experts for Large-scale Neural Radiance Fields	['Neural Radiance Fields', 'Mixture of Experts', 'Large-scale scene', 'Novel view synthesis', 'Sparse network']	 We propose an applicable end-to-end sparse NeRF network with learning-based decomposition for large-scale scenes.	Applications (eg, speech processing, computer vision, NLP)	anonymous|switchnerf_learning_scene_decomposition_with_mixture_of_experts_for_largescale_neural_radiance_fields	/pdf/3afb342ce820895d835bc5efbf3d24ce5807514e.pdf
qY1hlv7gwg	1159	Selective Annotation Makes Language Models Better Few-Shot Learners	['few-shot learning', 'language models', 'in-context learning', 'active learning']	We propose a select-then-annotate framework to make large language models better few-shot learners. Our method, vote-k, greatly improves the task performance over classification, commonsense reasoning, dialogue, and text/code generation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|selective_annotation_makes_language_models_better_fewshot_learners	/pdf/c9a2a025b9bfbd51793f48e8098d75f5cc519792.pdf
5Jq1ASp33L	1160	Understanding Incremental Learning of Gradient Descent: A Fine-grained analysis of Matrix Sensing	['deep learning theory', 'incremental learning', 'non-convex optimization']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|understanding_incremental_learning_of_gradient_descent_a_finegrained_analysis_of_matrix_sensing	/pdf/d3c7f33d8855c358ebaccfa732a9a600ce5e0917.pdf
1Imd7_uamo	1161	How you start matters for generalization	['spectral bias', 'generalization']	We promote a shift of focus towards initialization rather than neural architecture or (stochastic) gradient descent to explain this implicit regularization	Deep Learning and representational learning	anonymous|how_you_start_matters_for_generalization	/pdf/3714dd7618fe4c74f8fb8bd2647ab0f8051ff1d3.pdf
3ZPESALKXO	1162	Approximate Vanishing Ideal Computations at Scale	['approximate vanishing ideal', 'convex optimization', 'conditional gradients algorithms', 'Hessian matrix']	We study approximate vanishing ideal algorithms at scale.	General Machine Learning (ie none of the above)	anonymous|approximate_vanishing_ideal_computations_at_scale	/pdf/5101328cec36b18f9cbf934e2d3aab71f25dc19f.pdf
T7mOB22uL_	1164	Controllable Adaptive Learning	['Controllable Adaptive Learning']		Deep Learning and representational learning	anonymous|controllable_adaptive_learning	/pdf/d4516ac7cf5a16ca56933e23d071e85b5f9a8e68.pdf
tLScKVhcCR	1165	FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities	['neural ordinary differential equations', 'first integral', 'conservetaion law']	Real-world dynamical systems have invariant quantities such as energy, momenta, and mass. Even without prior knowledge, the proposed neural network finds and preserves such quantities from data by leveraging projection and discrete gradient methods.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|finde_neural_differential_equations_for_finding_and_preserving_invariant_quantities	/pdf/7bce6a9feb6dde2c0102d0a04a74cc465d941978.pdf
gfPUokHsW-	1166	Learning without Prejudices: Continual Unbiased Learning via Benign and Malignant Forgetting	['representation learning', 'continual learning', 'unbiased learning']	We propose a novel method, coined Learning without Prejudices, that encourages benign forgetting and regularizes malignant forgetting for continual unbiased learning. 	Deep Learning and representational learning	anonymous|learning_without_prejudices_continual_unbiased_learning_via_benign_and_malignant_forgetting	/pdf/9ea439ee2ff9cb5116b8ad1a568422c2ae542b84.pdf
ju_Uqw384Oq	1168	TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis	['Time Series Analysis', 'Deep Learning']	Based on the multi-periodicity, we analyze the intraperiod- and interperiod-variations in 2D space and propose the TimesNet as a task-general model, which achieves consistent state-of-the-art in five mainstream time series analysis tasks.	Deep Learning and representational learning	anonymous|timesnet_temporal_2dvariation_modeling_for_general_time_series_analysis	/pdf/47ecd3ff096aa9ae5ca2c610481e7f08c03ccb3c.pdf
rMbrVNxYuqZ	1169	EurNet: Efficient Multi-Range Relational Modeling of Spatial Multi-Relational Data	['Multi-Relational Modeling', 'Image Modeling', 'Protein Structure Modeling']	This paper proposes the EurNet for efficiently modeling spatial multi-relational data like images and protein structures.	Deep Learning and representational learning	anonymous|eurnet_efficient_multirange_relational_modeling_of_spatial_multirelational_data	/pdf/3a149aa447ec22f6162b7e17420a652e2de55de0.pdf
aCGIa6GfbmN	1171	Towards Expressive Graph Representations for Graph Neural Networks	[]	graph representation, graph neural network, set representation, expressive power	Deep Learning and representational learning	anonymous|towards_expressive_graph_representations_for_graph_neural_networks	/pdf/6b6396606bea4c71cedad0f373f49fe21da01fbd.pdf
X5SUR7g2vVw	1172	Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling	['Policy Pre-training', 'End-to-end Autonomous Driving', 'Self-supervised Learning']	We introduce a visuomotor driving policy pre-training paradigm, which leverages self-supervised geometric modeling to learn driving policy representation and achieves superior performance on various downstream driving tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|policy_pretraining_for_autonomous_driving_via_selfsupervised_geometric_modeling	/pdf/f119cc8704b3be3840113586494a0269126557a7.pdf
gYs_cRuK7V	1174	Bidirectional Propagation for Cross-Modal 3D Object Detection	['Cross-modal', '3D Object Detection', '3D Point Cloud', 'Deep Learning']	We innovatively propose bidirectional feature propagation to address cross-modal 3D object detection.  Such a new perspective will inspire the research on multi-modal learning for scene understanding and analysis.	Applications (eg, speech processing, computer vision, NLP)	anonymous|bidirectional_propagation_for_crossmodal_3d_object_detection	/pdf/eff5d7656b6d6d6d4755324bea2af54e85f7c008.pdf
T1Qx6EC08o	1175	On the Importance of Pretrained Knowledge Distillation for 3D Object Detection	['knowledge distillation', 'object detection']	We propose PreDistill, a pretrained distillation paradigm for knowledge transfer and demonstrate that PreDistill serves as a plug-and-play module to various state-of-the-art detectors.	Applications (eg, speech processing, computer vision, NLP)	anonymous|on_the_importance_of_pretrained_knowledge_distillation_for_3d_object_detection	/pdf/c8f208ae108168f40d428c17c1bfda6a3ce970b9.pdf
FAHVsSfhWs	1176	Revisiting Global Pooling through the Lens of Optimal Transport	['Global pooling', 'regularized optimal transport', 'Bregman ADMM', 'multi-instance learning', 'graph embedding']	We develop a novel and solid global pooling framework through the lens of optimal transport, which covers many existing pooling methods and performs well on various learning problems.	Deep Learning and representational learning	anonymous|revisiting_global_pooling_through_the_lens_of_optimal_transport	/pdf/e8e314f711e669265c976b9d9bb3eed3c741e953.pdf
jny79Mfgkno	1177	Dealing with missing data using attention and latent space regularization	['missing data', 'missingness', 'latent space regularization', 'measure theory']	A novel framework for dealing with missing data without imputation by regularizing latent space representations.	Deep Learning and representational learning	anonymous|dealing_with_missing_data_using_attention_and_latent_space_regularization	/pdf/e7ab604c4a951e5e1412f357c07d4f1e98851318.pdf
eMuXAIEYXh9	1178	Structural Generalization of Visual Imitation Learning with Position-Invariant Regularization	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|structural_generalization_of_visual_imitation_learning_with_positioninvariant_regularization	/pdf/d8abdd837c15b77f56747b61b6aef4a79a56af87.pdf
MLStcoDEhqi	1179	DREAM: Domain-free Reverse Engineering Attributes of Black-box Model	['Model Attribute inference', 'domain-free method']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|dream_domainfree_reverse_engineering_attributes_of_blackbox_model	/pdf/0f64922ee423e3712775919f1131d426dd57ef74.pdf
NrJ-x9KbdZ	1180	Your Denoising Implicit Model is a Sub-optimal Ensemble of Denoising Predictions	[]		Generative models	anonymous|your_denoising_implicit_model_is_a_suboptimal_ensemble_of_denoising_predictions	/pdf/f1c2cf306895f73f3636ca5735f85ffedb6ab4dd.pdf
pIPvjnW1B9A	1182	Margin-based Neural Network Watermarking	['neural network watermarking', 'machine learning', 'deep learning', 'ownership verification']	We propose margin-based watermarking for deep neural networks.	Deep Learning and representational learning	anonymous|marginbased_neural_network_watermarking	/pdf/6017d1a82628d0a07ef7407b20608af8197494d7.pdf
yYEb8v65X8	1183	Light Sampling Field and BRDF Representation for Physically-based Neural Rendering	['Neural Rendering']		Applications (eg, speech processing, computer vision, NLP)	anonymous|light_sampling_field_and_brdf_representation_for_physicallybased_neural_rendering	/pdf/78fc8dedac0aa79aa51370b014ad60db813eb7bf.pdf
vqSyt8D3ny	1186	Towards Robust Object Detection Invariant to Real-World Domain Shifts	['robust object detection', 'autonomous driving']	We perturb feature channel statistics to generalize object detectors under real-world domain shifts.	Deep Learning and representational learning	anonymous|towards_robust_object_detection_invariant_to_realworld_domain_shifts	/pdf/46033b0b0ab2b93ce3aabbf91db4ac957fdd6cae.pdf
9GOjmbRQ2o	1187	Sensitivity-aware Visual Parameter-efficient Tuning	['Visual Parameter-efficient Tuning', 'Fine-tuning', 'Visual Task Adaptation']	We propose a visual parameter-efficient tuning approach to identify and tune the parameters at task-specific important positions while being inference-efficient.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sensitivityaware_visual_parameterefficient_tuning	/pdf/44101e7c6a51a3b043f0629c45c675fd8cd2dd1a.pdf
1usJZBGNrZ	1188	Offline Reinforcement Learning with Closed-Form Policy Improvement Operators	['Offline Reinforcement Learning algorithms', 'Deep Reinforcement Learning']	We proposed a closed-form policy improvement operator and modeled the behavior policies as a Gaussian Mixture.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_reinforcement_learning_with_closedform_policy_improvement_operators	/pdf/cd7d0bc65f282f248d170a7b60aa7e948db6c98c.pdf
KjzZrBsORz	1190	Towards Generalized Combinatorial Solvers via Reward Adjustment Policy Optimization	['combinatorial optimization', 'reinforcement learning', 'traveling salesman problem', 'vehicle routing problem']	Towards Generalized Combinatorial Solvers via Reward Adjustment Policy Optimization	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_generalized_combinatorial_solvers_via_reward_adjustment_policy_optimization	/pdf/d6fbb32d94377f59613b95c5fa9a746e09e8585c.pdf
y7CNId2RnV	1191	Language Model Pre-training with Linguistically Motivated Curriculum Learning	['language model pre-training', 'curriculum learning', 'data-centric method']	We propose a language model pre-training method based on linguistically motivated curriculum learning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|language_model_pretraining_with_linguistically_motivated_curriculum_learning	/pdf/2affdb871b07c0ba788197721d22a170e17c7756.pdf
R498E9vaqZ	1193	Adaptive Update Direction Rectification for Unsupervised Continual Learning	['Continual learning', 'unsupervised learning', 'representation learning']	We propose an Actor-Critic framework with adaptive update direction rectification for unsupervised continual learning.	Deep Learning and representational learning	anonymous|adaptive_update_direction_rectification_for_unsupervised_continual_learning	/pdf/c35f4ff86fb2e2abca35663b065d5738ed60665e.pdf
WcTLZrpzfe	1194	Orientation-Aware Graph Neural Networks for Protein Structure Representation Learning	['geometric learning', 'representation learning', 'structural biology']	We design a new type of geometric neural networks for  learning protein representations.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|orientationaware_graph_neural_networks_for_protein_structure_representation_learning	/pdf/1f98eb1c435cfceb9c3a09a9d2f8cafd1935fd01.pdf
YlMvAomKXO	1195	Pruning with Output Error Minimization for Producing Efficient Neural Networks	['pruning', 'weighted least squares method', 'convolutional neural networks', 'compression']	"We present a pruning method that conducts pruning and then performs ""reconstruction"" to minimize the output error of the activation function, while previous methods minimize the error of the value before passing through the activation function."	Deep Learning and representational learning	anonymous|pruning_with_output_error_minimization_for_producing_efficient_neural_networks	/pdf/08a293ed03b76a52f0905023726de439461ad20b.pdf
3owqfawaLv	1197	Shot Retrieval and Assembly with Text Script for Video Montage Generation	['Video montage generation', 'text-to-shot retrieval', 'transformer', 'dataset construction']	We propose a novel transformer-based model for video montage generation by retrieving and assembling shots with arbitrary text scripts.	Applications (eg, speech processing, computer vision, NLP)	anonymous|shot_retrieval_and_assembly_with_text_script_for_video_montage_generation	/pdf/f2b61f50dd8efbd79b9f7216464280fa65ce91be.pdf
eKllxpLOOm	1198	Combating Exacerbated Heterogeneity for Robust Decentralized Models	[]		Deep Learning and representational learning	anonymous|combating_exacerbated_heterogeneity_for_robust_decentralized_models	/pdf/d09add60031c6a74f3c971bee328dcf26ea373c0.pdf
lhJtB_F1Ga1	1199	Accumulative Poisoning Defense with Memorization Discrepancy	[]		Deep Learning and representational learning	anonymous|accumulative_poisoning_defense_with_memorization_discrepancy	/pdf/794eeeb5e30cfde320e10534ea5e480bb01f90c1.pdf
XHgHn5gYIVP	1200	Cross Modal Domain Generalization for Query-based Video Segmentation	['domain generalization', 'multi-modal', 'video segmentation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|cross_modal_domain_generalization_for_querybased_video_segmentation	/pdf/5346e09c434e95f32bf5804f265d04b55ea2887d.pdf
WSIHedvwmru	1202	GSCA: Global Spatial Correlation Attention	['self attention', 'attention mechanism', 'cross-correlation']	A novel parameter-free self-attention with linear complexity is proposed to enhance convolution.	Deep Learning and representational learning	anonymous|gsca_global_spatial_correlation_attention	/pdf/0dd12968c9d899a8de59b67b928c8e34dfbd5fb3.pdf
8OFAtZzIf7T	1203	Logit Margin Matters: Improving Transferable Targeted Adversarial Attack by Logit Calibration	[]		Deep Learning and representational learning	anonymous|logit_margin_matters_improving_transferable_targeted_adversarial_attack_by_logit_calibration	/pdf/0ae985e798fff8394246a00b51ca5b9ffc72a4b6.pdf
uAmdu-GTG-_	1204	i-MAE: Are Latent Representations in Masked Autoencoders Linearly Separable?	['Interpretability', 'Masked Autoencoders', 'Self-supervised Learning']		Unsupervised and Self-supervised learning	anonymous|imae_are_latent_representations_in_masked_autoencoders_linearly_separable	/pdf/3864b39c3f717d8360b0ddd2ae9e7861f10d175f.pdf
BckALoxD8ow	1205	OPERA: Omni-Supervised Representation Learning with Hierarchical Supervisions	['Representation learning', 'omni-supervised learning.']	We propose an omni-supervised representation learning with hierarchical supervisions method for better transferability.	Deep Learning and representational learning	anonymous|opera_omnisupervised_representation_learning_with_hierarchical_supervisions	/pdf/6eb070bdbcfdde59674cd23c10f8c2f5954a691c.pdf
hlCBgdwvBx	1209	Rememory-Based SimSiam for Unsupervised Continual Learning	['Continual learning', 'unsupervised representation learning', 'contrastive learning', 'rememory process']	We propose a novel rememory-based SimSiam method for unsupervised continual learning.	Unsupervised and Self-supervised learning	anonymous|rememorybased_simsiam_for_unsupervised_continual_learning	/pdf/e953025bfbf23082db05b17b704c1dc9f2234b82.pdf
GcM7qfl5zY	1210	AutoGT: Automated Graph Transformer Architecture Search	[]		Deep Learning and representational learning	anonymous|autogt_automated_graph_transformer_architecture_search	/pdf/65b79e1d7ee4c03ea97c20b2b5548c98baa05d8d.pdf
ouUnWeADZKq	1211	Dynamic Historical Adaptation for Continual Image-Text Modeling	['Image-text modeling', 'continual learning', 'contrastive learning', 'cross-modal retrieval']	We propose a novel direct parameter transfer method for continual image-text modeling.	Deep Learning and representational learning	anonymous|dynamic_historical_adaptation_for_continual_imagetext_modeling	/pdf/53004c6a8a9879a17bb6409b94b9ba64a6a25e63.pdf
dPs6BGO2QT0	1212	Learning Locality and Isotropy in Dialogue Modeling	['dialogue system', 'representation learning', 'feature space calibration']	We present a simple dialogue representation calibration method to learn isotropic and conversational features during the dialogue modeling stage.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_locality_and_isotropy_in_dialogue_modeling	/pdf/c907ef01b48aa25788c5c4545370d7ea525a48f0.pdf
NFcRC4aYSWf	1213	Highway Reinforcement Learning	['reinforcement learning', 'off-policy learning', 'credit assignment', 'Bellman Equation']	a novel adaptive multi-step Bellman Optimality Equation for efficient credit assignment that converges to the optimal value function with better contraction rate under mild assumptions	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|highway_reinforcement_learning	/pdf/8a50de2d1cd74a61826166dd0a08356956317b81.pdf
_fouOVXUV7O	1215	A spatiotemporal graph neural network with multi granularity for air quality prediction	['Air quality prediction', 'graph neural network', 'long short term memory']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_spatiotemporal_graph_neural_network_with_multi_granularity_for_air_quality_prediction	/pdf/d9c8d6bd667f415ca8d5471113e4c73441a6f04a.pdf
vCbnQZ6lXw3	1216	A theory of representation learning in neural networks gives a deep generalisation of kernel methods	['Gaussian process', 'infinite-width neural networks']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|a_theory_of_representation_learning_in_neural_networks_gives_a_deep_generalisation_of_kernel_methods	/pdf/48556fbc371b34faf65b809a21f68033311ce870.pdf
7UrHaeZ5Ie7	1217	An Efficient Mean-field Approach to High-Order Markov Logic	['Logic Rules', 'Mean-field Algorithm', 'Markov Logic Network', 'Symbolic Reasoning']	This paper proposes a method to perform mean-field iteration of MLN efficiently via a novel neural network.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|an_efficient_meanfield_approach_to_highorder_markov_logic	/pdf/c22a773e4da4fcd5041b10d90e0a743c6c022f81.pdf
6OphWWAE3cS	1218	Particle-based Variational Inference with Preconditioned Functional Gradient Flow	['Posterior Sampling', 'Particle-based VI']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|particlebased_variational_inference_with_preconditioned_functional_gradient_flow	/pdf/81b3645af65bb8f3171b6e985a5d1101aa7edad4.pdf
jU_Q6UWBa2	1219	Continual Learning In Low-coherence Subspace: A Strategy To Mitigate Learning Capacity Degradation	['oblique manifold', 'continual learning', 'learning capacity degradation', 'catastrophic forgetting', 'low-coherence', 'orthogonal projection']	This paper contributes a novel method in continual learning, called Low-coherence Subspaces Projection (LcSP), which solves both the catastrophic forgetting problem and the learning capacity degradation problem.	Deep Learning and representational learning	anonymous|continual_learning_in_lowcoherence_subspace_a_strategy_to_mitigate_learning_capacity_degradation	/pdf/f1ec4437706f7571ad2953d655ebb2a9173abbbe.pdf
pOnhudsvzR	1220	Everybody Needs Good Neighbours: An Unsupervised Locality-based Method for Bias Mitigation	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|everybody_needs_good_neighbours_an_unsupervised_localitybased_method_for_bias_mitigation	/pdf/6353b0595fe987a2b93e398dfadf4597d44c0659.pdf
WWD_2DKUqdJ	1221	HierBatching: Locality-Aware Out-of-Core Training of Graph Neural Networks	['Graph Neural Network', 'Out-of-Core Training', 'Spatial Locality', 'Temporal Locality', 'Hierarchical Batching']	A locality-aware out-of-core training approach for Graph Neural Networks that is an order of magnitude faster without compromising accuracy	Deep Learning and representational learning	anonymous|hierbatching_localityaware_outofcore_training_of_graph_neural_networks	/pdf/dea927830763413db62ca2661f37da1e92cb6c3b.pdf
ap9iq9kaU8j	1222	ETAD: A Sampling-Based Approach for Efficient Temporal Action Detection	['Temporal Action Detection', 'Untrimmed Video Understanding', 'Efficient Detection']	We novelly propose to alleviate the efficiency issue in TAD by the sampling mechanism. We detailed study two questions: where to sample and how to sample in TAD.	Applications (eg, speech processing, computer vision, NLP)	anonymous|etad_a_samplingbased_approach_for_efficient_temporal_action_detection	/pdf/7645606d98782694e57d42f9a1a12700c3d548de.pdf
chDrutUTs0K	1223	POPGym: Benchmarking Partially Observable Reinforcement Learning	['partially observable', 'POMDP', 'reinforcement learning', 'memory']	We propose POPGym, an RL library containing 14 partially observable gym environments and 13 different memory architectures	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|popgym_benchmarking_partially_observable_reinforcement_learning	/pdf/2983cd6b6537b5ae86c33a2df43661a65a5aa7a6.pdf
AvSIqjCWVId	1224	Abstract Visual Reasoning by Self-supervised Contrastive Learning	[]	Demonstration of an unsupervised model to solve analogy reasoning in Raven’s Progressive Matrices task and its variant.  	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|abstract_visual_reasoning_by_selfsupervised_contrastive_learning	/pdf/e19835a143dd3b27a9938bb2b09bd1aba970cbf3.pdf
D6hDzJMbRt4	1225	Dynamics-inspired Neuromorphic Representation Learning	"['dynamics-based', 'neuromorphic representation', 'neural network', ""Hamilton's principle""]"	We build a dynamics-inspired neural mechanism that outperform the weight-based one on classification tasks.	Deep Learning and representational learning	anonymous|dynamicsinspired_neuromorphic_representation_learning	/pdf/af23c68aef0ad7fd49b95ffef15adef61b7e9ee1.pdf
5DkfiQPy9A	1226	ACAT: Adversarial Counterfactual Attention for Classification and Detection in Medical Imaging	['Medical imaging', 'counterfactual examples', 'adversarial attacks', 'attention', 'saliency maps']	We propose a method to generate counterfactual images, which are adversarially obtained, and we derive saliency maps from them. These are employed in a framework that refines a classifier pipeline and helps learning better local features.	Applications (eg, speech processing, computer vision, NLP)	anonymous|acat_adversarial_counterfactual_attention_for_classification_and_detection_in_medical_imaging	/pdf/dcca7a26e918040a8ce5e29edcd2420385099d1e.pdf
g8wBdhnstYz	1227	Closing the gap: Exact maximum likelihood training of generative autoencoders using invertible layers	[]		Generative models	anonymous|closing_the_gap_exact_maximum_likelihood_training_of_generative_autoencoders_using_invertible_layers	/pdf/945661e697bf96cbc0d359390e0f97825d5f0386.pdf
0WVNuEnqVu	1230	Pareto-Optimal Diagnostic Policy Learning in Clinical Applications via Semi-Model-Based Deep Reinforcement Learning	['medical diagnostics', 'Pareto front', 'reinforcement learning', 'non-Markovian reward', 'semi-model-based policy optimization']	Our proposed RL-based approach is able to reduce up to 85% testing cost while having the state-of-art diagnosis accuracy in three real-world medical diagnostics tasks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|paretooptimal_diagnostic_policy_learning_in_clinical_applications_via_semimodelbased_deep_reinforcement_learning	/pdf/5254adc3ca2fb698ca17881bde85225ffd92486d.pdf
v-3dUexkNn	1231	Towards predicting dynamic stability of power grids with Graph Neural Networks	['Power grids', 'dynamic stability', 'Graph Neural Networks']	Predicting the dynamic stability of future power grids with large shares of renewable energies to mitigate climate change by using Graph Neural Networks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|towards_predicting_dynamic_stability_of_power_grids_with_graph_neural_networks	/pdf/0006c432c04be1803946a1631761635b6b65aaa1.pdf
8duT3mi_5n	1232	GReTo: Remedying dynamic graph topology-task discordance via target homophily	['Dynamic graph', 'graph homophily theory', 'Graph Neural Network', 'topology-task discordance']	This paper revisits how node-wise relation modeling to facilitate regressions on dynamic graphs, from a new perspective of target-homophily. 	Deep Learning and representational learning	anonymous|greto_remedying_dynamic_graph_topologytask_discordance_via_target_homophily	/pdf/28cc9f6a1ddbe6de0acacd3de1683f4deed13817.pdf
UfMrMbSTmy	1233	Language Models Can See: Plugging Visual Controls in Text Generation	['CLIP', 'GPT-2', 'Plug-and-Play', 'Zero-Shot', 'Image Captioning', 'Visually Grounded Story Generation']	We present a novel plug-and-play decoding scheme, MAGIC Search, that enables a pre-trained language model to tackle multimodal generation tasks in a zero-shot manner.	Applications (eg, speech processing, computer vision, NLP)	anonymous|language_models_can_see_plugging_visual_controls_in_text_generation	/pdf/ed09d40e9bfb0c2f18c7efe82c8bf5d51f8084dd.pdf
gVSJ83n47IT	1234	Imposing conservation properties in deep dynamics modeling via contrastive learning	['dynamical system modeling', 'contrastive learning', 'learning conservation property']	We learn dynamical system conservation property through contrastive learning and impose it during simulation to improve prediction robustness.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|imposing_conservation_properties_in_deep_dynamics_modeling_via_contrastive_learning	/pdf/177f603a958f1a731751c66d42fe0bac7839c8e3.pdf
MR8pqi9R7xP	1235	Watch What You Pretrain For: Targeted, Transferable Adversarial Examples on Self-Supervised Speech Recognition models	['Speech recognition', 'adversarial attacks', 'self-supervised learning']	We show that recent Self-supervised ASR model are uniquely vulnerable to adversarial attacks requiring no model access	Applications (eg, speech processing, computer vision, NLP)	anonymous|watch_what_you_pretrain_for_targeted_transferable_adversarial_examples_on_selfsupervised_speech_recognition_models	/pdf/0f797d8702211acf1cf8ced4b6fa807d7bb23769.pdf
-z911HH4RFv	1236	Adversarial Learned Fair Representations using Dampening and Stacking	['Machine Learning', 'Deep Learning', 'Fairness', 'Adversarial Learning', 'Fair Representation Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|adversarial_learned_fair_representations_using_dampening_and_stacking	/pdf/1b3f6376e0005d2dce08c7be0035ef9d1970551a.pdf
HZJje06x6IO	1237	Global Context Vision Transformers	['Vision Transformers', 'Classification', 'Detection', 'Instance Segmentation', 'Semantic Segmentation']	We introduce general computer vision backbone to effectively learn both short and long-range spatial information.	Applications (eg, speech processing, computer vision, NLP)	anonymous|global_context_vision_transformers	/pdf/690f98ac5ef70b14df0154a8ce9f0aed9b3424b5.pdf
09I1M8YRJBR	1238	Neural Diffusion Processes	['diffusion models', 'gaussian processes', 'neural processes', 'stochastic processes']	Diffusion models for stochastic processes	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|neural_diffusion_processes	/pdf/a0ee573119c30477e4b2d9b1a26e6dff5f6e63e9.pdf
4IaQ99pSbg5	1239	ProtoVAE: Using Prototypical Networks for Unsupervised Disentanglement	['Unsupervised Learning', 'Disentangled Representations']	Unsupervised Disentangled representation learning using Isometric inductive biases	Unsupervised and Self-supervised learning	anonymous|protovae_using_prototypical_networks_for_unsupervised_disentanglement	/pdf/066b59024f55c693435ae6c07e1fb3baace526c5.pdf
kx8x43_1ftI	1240	C3PO: Learning to Achieve Arbitrary Goals via Massively Entropic Pretraining	['Reinforcement Learning', 'Exploration', 'Goal-conditioned Policy', 'Continuous Control']	Exploration approximating a uniform sampling over possible states to train a policy that can achieve any pose and position.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|c3po_learning_to_achieve_arbitrary_goals_via_massively_entropic_pretraining	/pdf/01f184000eaa8bacff1ccf10048b29b2e871c405.pdf
o5mLawmN232	1241	Tackling the Retrieval Trilemma with Cross-Modal Indexing	['cross-modal retrieval', 'retrieval trilemma', 'cross-modal indexing']	We propose a novel paradigm Cross-Modal Indexing that directly maps the query into identifiers of relevant candidates to achieve high accuracy, fast speed, and low storage simultaneously.	Applications (eg, speech processing, computer vision, NLP)	anonymous|tackling_the_retrieval_trilemma_with_crossmodal_indexing	/pdf/c21eb4be347b538e333c3604bac1c2da5906c732.pdf
MEdZ-7BOsKM	1242	Human Pose Estimation in the Dark	['Low-light image understanding', 'Robustness', 'Learning using privileged information', 'Human pose estimation']	We for the first time tackle human pose estimation under extremely low-light conditions, and introduce a new training strategy and new datasets for the challenging task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|human_pose_estimation_in_the_dark	/pdf/6b92a82c488d6d3f4648e4e7bd50ea78162cf0dd.pdf
oXM5kdnAUNq	1245	Initial Value Problem Enhanced Sampling for Closed-Loop Optimal Control Design with Deep Neural Networks	['Optimal Control', 'Deep Learning', 'Adaptive Sampling', 'Distribution Mismatch']	A new adaptive sampling method to improve the performance of the closed-loop controller learned by neural networks	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|initial_value_problem_enhanced_sampling_for_closedloop_optimal_control_design_with_deep_neural_networks	/pdf/df867c137b20fc22573a74847422317337e55521.pdf
4XE614GBuGR	1246	Domain-Adjusted Regression or: ERM May Already Learn Features Sufficient for Out-of-Distribution Generalization	['domain generalization', 'domain generalization theory', 'out-of-distribution generalization', 'representation learning']	"We show that features learned via ERM may be ""good enough"" for generalization, and that the main difficulty is robust classification. We give a new model of dist shift and an alg which is minimax-optimal and meets/exceeds SOTA on several benchmarks."	Deep Learning and representational learning	anonymous|domainadjusted_regression_or_erm_may_already_learn_features_sufficient_for_outofdistribution_generalization	/pdf/100159f47a69f3fc0d9753c48158e30772eb05ac.pdf
ToYi8C6fetv	1247	Personalized Subgraph Federated Learning	['Graph Representation Learning', 'Graph Neural Networks', 'Federated Learning', 'Subgraph Federated Learning']	A novel personalized subgraph federated learning framework aiming at the joint improvement of interrelated local models trained on interconnected local subgraphs, for instance, subgraphs belonging to the same community.	Deep Learning and representational learning	anonymous|personalized_subgraph_federated_learning	/pdf/b70ae2fe43c6fad78d4c30e3e746237d163e7306.pdf
_hb4vM3jspB	1248	Data-Free One-Shot Federated Learning Under Very High Statistical Heterogeneity	['One-Shot Federated Learning', 'Statistical Heterogeneity', 'Model Heterogeneity', 'Variational Autoencoder']	We vastly improve on one-shot federated learning performance under very high statistical heterogeneity by reframing the local learning task with a conditional variational autoencoder.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|datafree_oneshot_federated_learning_under_very_high_statistical_heterogeneity	/pdf/fcb0b821e57b794a20469042c2bdc437ab6a0598.pdf
5aT4ganOd98	1249	CLARE: Conservative Model-Based Reward Learning for Offline Inverse Reinforcement Learning	['offline inverse reinforcement learning', 'inverse reinforcement learning', 'offline reinforcement learning']	This paper introduces a principled algorithm to approach the reward extrapolation error in offline inverse reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|clare_conservative_modelbased_reward_learning_for_offline_inverse_reinforcement_learning	/pdf/78125e4073a38f87d954a4cf5c8e1047721654c0.pdf
TgcG85ZvBuu	1251	Effective dimension of machine learning models	['Generalization', 'capacity', 'effective dimension']	We introduce a capacity measure called the local effective dimension, which we show has desirable properties and the ability to bound generalization error.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|effective_dimension_of_machine_learning_models	/pdf/f191c0d11e79600d4e3e8fb776b22f1f10f63761.pdf
OysfLgrk8mk	1252	Graph Domain Adaptation via Theory-Grounded Spectral Regularization	[]		Deep Learning and representational learning	anonymous|graph_domain_adaptation_via_theorygrounded_spectral_regularization	/pdf/88c217b0e824e0c6699031876f4d3289cd1e6bc0.pdf
lrzX-rNuRvw	1253	Understanding Rare Spurious Correlations in Neural Networks	['spurious correlation', 'trustworthy machine learning']	Neural networks can learn spurious correlations caused by a small number of training examples. We empirically and theoretically study this phenomena.	General Machine Learning (ie none of the above)	anonymous|understanding_rare_spurious_correlations_in_neural_networks	/pdf/49e74635805c5667e19c63ecaab734e6a4c18e0c.pdf
dfPuLye6RvY	1254	Light-weight probing of unsupervised representations for Reinforcement Learning	['machine learning', 'unsupervised learning', 'reinforcement learning', 'computer vision']	Our paper proposes linear reward probing as an efficient method to evaluate the quality of pretrained representations in the RL setting, and demonstrates its positive correlation with downstream RL performance.	Deep Learning and representational learning	anonymous|lightweight_probing_of_unsupervised_representations_for_reinforcement_learning	/pdf/66cdab6f7c934373e3077255d7ab33e794644d47.pdf
bMXueK316u	1255	Training Recipe for N:M Structured Sparsity with Decaying Pruning Mask	['sparsity', 'structured sparsity', 'pruning', 'dnn', 'transformer']		General Machine Learning (ie none of the above)	anonymous|training_recipe_for_nm_structured_sparsity_with_decaying_pruning_mask	/pdf/71a444b44bc8763a323ff06eb2e325d558991367.pdf
3DIpIf3wQMC	1256	Spatial Attention Kinetic Networks with E(n)-Equivariance	[]	Equivariant functional form termed spatial attention uses neurally parametrized linear combinations of edge vectors to equivariantly yet describe node environments 	Deep Learning and representational learning	anonymous|spatial_attention_kinetic_networks_with_enequivariance	/pdf/f98c2e653c15c4a2cc2ee6537218c47db08c5d36.pdf
OhdF1l90VoC	1257	Coupling Semi-supervised Learning with Reinforcement Learning for Better Decision Making -- An application to Cryo-EM Data Collection	['Reinforcement Learning', 'Semi-supervised Learning', 'Cryo-EM']	We proposed an iterative semi-supervised learning framework for dual-learning of RL and the perception model with applications to Cryo-EM.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|coupling_semisupervised_learning_with_reinforcement_learning_for_better_decision_making_an_application_to_cryoem_data_collection	/pdf/e7dae881316f731c12427a39f0a87a912aa73f14.pdf
UMERaIHMwB3	1258	Learning to Jointly Share and Prune Weights for Grounding Based Vision and Language Models	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_to_jointly_share_and_prune_weights_for_grounding_based_vision_and_language_models	/pdf/e91d998ed3baeb11a54f485ea0caa77a2f0a6db6.pdf
4LMIZY7gt7h	1259	Robust Fair Clustering: A Novel Fairness Attack and Defense Framework	['Data Clustering', 'Fairness Attack', 'Fairness Defense', 'Consensus Clustering']	We propose a highly effective & novel fairness attack against state-of-the-art fair clustering models, & for self-completeness, we propose a defense framework based on consensus clustering & graph representation learning that is robust to our attack.	Unsupervised and Self-supervised learning	anonymous|robust_fair_clustering_a_novel_fairness_attack_and_defense_framework	/pdf/3f6717ed2d27b78f4370623e13a01eefe84b44a0.pdf
6tPGEjCN4iI	1260	TimelyFL: Heterogeneity-aware Asynchronous Federated Learning with Adaptive Partial Training 	['Submodel Training', 'Federated Learning']	An inclusiveness asynchronous federated learning with adaptive partial training.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|timelyfl_heterogeneityaware_asynchronous_federated_learning_with_adaptive_partial_training	/pdf/bb763d587757bdbbaf3b96c0824a3ecfaa825d71.pdf
vVJZtlZB9D	1261	A General Framework For Proving The Equivariant Strong Lottery Ticket Hypothesis	['Equivariant Networks', 'Strong Lottery Ticket', 'Weight Pruning']	We extend the strong lottery ticket hypothesis to Equivariant Networks and show optimal pruning strategies in theory and practice for Steerable CNNs, Higher Order GNNs, and Message Passing GNNs.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_general_framework_for_proving_the_equivariant_strong_lottery_ticket_hypothesis	/pdf/ff1cf5a2e3aeacb308b45969d99042e242f27dcb.pdf
VJeUPUge4DL	1262	Variation-based Cause Effect Identification	['Causality', 'Causal Inference', 'Causal Discovery', 'Cause Effect Identification', 'Convex Optimization', 'Semi-definite Relaxation']	A framework for causal discovery in bivariate systems based on realization of the independence of causal mechanisms postulate using convex-optimization	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|variationbased_cause_effect_identification	/pdf/4e866b7d2bc62848a0b2546b076ce9a370dc81c1.pdf
H8XpqEkbua_	1264	Differentially Private Dataset Condensation	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|differentially_private_dataset_condensation	/pdf/6a6b332f89bed12ff2cb6edac67d77559fe89cb3.pdf
slqzKkFFlp3	1266	Diverse, Difficult, and Odd Instances (D2O): A New Test Set for Object Classification	['object recognition', 'deep learning', 'model evaluation', 'tagging', 'generalization', 'out of distribution generalization']	We propose a new test set for object recognition and test a variety of object recognition and tagging models on it. We should that models fails drastically on our test set.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|diverse_difficult_and_odd_instances_d2o_a_new_test_set_for_object_classification	/pdf/caa5d3f9376999891d96fdb911a0c5c8d7c29a51.pdf
4g7nCbpjNwd	1267	NormSoftmax: Normalize the Input of Softmax to Accelerate and Stabilize Training	[]		Deep Learning and representational learning	anonymous|normsoftmax_normalize_the_input_of_softmax_to_accelerate_and_stabilize_training	/pdf/92f615ad23e19fbed4d81f4f6dcfce4d21bce416.pdf
i2JgYVPce1i	1268	BinaryVQA: A Versatile Dataset to Push the Limits of VQA Models	['Visual question answering', 'dataset benchmarks', 'datasets']	We introduce a new test set for free-form visual question answering (VQA) called BinaryVQA to push the limits of VQA models. 	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|binaryvqa_a_versatile_dataset_to_push_the_limits_of_vqa_models	/pdf/a9cf5216c53269651a9c3353c05c251847456e30.pdf
hj7uBF92qvm	1270	Breaking Beyond COCO Object Detection	['object detection', 'deep learning', 'performance analysis']	An analysis of the state of the art in object detection, the empirical upper bound, and errors in models and datasets	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|breaking_beyond_coco_object_detection	/pdf/b64642f9ced9d99f97529b07fb5608d3f7f4aedb.pdf
WoV6DA5P9OL	1271	Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning	['Evolution', 'Meta-learning', 'Neuromodulation', 'Plasticity']	We evolve plastic networks that can automatically acquire novel, cognitive (memory-dependent) tasks (never seen during evolution) from stimuli and rewards alone, much like animals do.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|learning_to_acquire_novel_cognitive_tasks_with_evolution_plasticity_and_metametalearning	/pdf/bc106b414a91bd92724d23766f1bf63c85e0f979.pdf
BGId14emsBj	1272	On the Impact of Adversarially Robust Models on Algorithmic Recourse	['Algorithmic Recourse', 'Adversarial Robustness', 'Machine Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_impact_of_adversarially_robust_models_on_algorithmic_recourse	/pdf/b52e94bb21295b4dba547a4db6fd4d58296febd0.pdf
y_icnxeeUcl	1273	WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis	['image classification', 'segmentation', 'resource-efficient', 'token-mixer', 'wavelet', 'sota']	WaveMix-Lite uses 2D discrete Wavelet transform for resource-efficient token-mixing and performs better than CNNs and transformers in image classification and segmentation tasks while requiring fewer GPU RAM and parameters.	Applications (eg, speech processing, computer vision, NLP)	anonymous|wavemixlite_a_resourceefficient_neural_network_for_image_analysis	/pdf/9af5a5dd727b4fef997ac53cd01baccf8cede1db.pdf
k1FHgri5y3-	1274	Sparse Random Networks for Communication-Efficient Federated Learning	['communication-efficient federated learning', 'sparse networks with random weights', 'compression', 'sparsity.']	We propose an FL framework, where clients find a sparse random network using a stochastic strategy; and provide (1) lower communication cost, (2) higher accuracy, (3) faster convergence, and (4) at the end of the training, a compressed final model.	Deep Learning and representational learning	anonymous|sparse_random_networks_for_communicationefficient_federated_learning	/pdf/cf84db8451a34ab3fa51d9113209ae827f5d441d.pdf
CniFDGvqbUZ	1275	Make Memory Buffer Stronger in Continual Learning: A Continuous Neural Transformation Approach	['Continual Learning']		Deep Learning and representational learning	anonymous|make_memory_buffer_stronger_in_continual_learning_a_continuous_neural_transformation_approach	/pdf/53a9d1ccea4e6e59c238cb6072aa555fbdefa27d.pdf
zWnq5AFNhFH	1276	An Improved Baseline for Masked Contrastive Learning	['contrastive learning', 'self-supervised learning', 'vision transformer']	We develop an improved contrastive baseline for vision transformer, which rivals the fine-tuning performance of masked image prediction.	Unsupervised and Self-supervised learning	anonymous|an_improved_baseline_for_masked_contrastive_learning	/pdf/10d1f7660548d3627142f1c14081a6dc4107f0fb.pdf
p7G8t5FVn2h	1277	One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks	['unlearnable examples', 'shortcut learning', 'one-pixel feature', 'deep neural network']	We propose a model-free method to craft unlearnable example by perturbing only one pixel, and construct a benchmark containing images that are unlearnable by various existing methods to avoid shortcut learning.	Deep Learning and representational learning	anonymous|onepixel_shortcut_on_the_learning_preference_of_deep_neural_networks	/pdf/a7b5ff6015e9223524417db3332fd947c30cf02b.pdf
0N66Gl63vq	1278	FS-DETR: Few-Shot DEtection TRansformer with prompting and without re-training	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|fsdetr_fewshot_detection_transformer_with_prompting_and_without_retraining	/pdf/2912ac70fce5696e6a22c0236b0d7041259e06eb.pdf
5O2uzDusEN5	1279	DFlow: Learning to Synthesize Better Optical Flow Datasets via a Differentiable Pipeline	['Synthetic data', 'Optical flow']	Differentiable and efficient optical flow data generation pipeline	Applications (eg, speech processing, computer vision, NLP)	anonymous|dflow_learning_to_synthesize_better_optical_flow_datasets_via_a_differentiable_pipeline	/pdf/afc6a1d027797b6aecc8c203f653ad06c22cf20c.pdf
eaEjWtX3xkY	1281	Continual Pre-trainer is an Incremental Model Generalizer	['Masked Image Modeling', 'Representation Learning', 'Continual Learning', 'Unsupervised Learning', 'Pretraining']	In this paper, we tackle a novel problem of Continual Pre-training, which aims to increment the generalization of model representations, encouraging positive transfer for future problems.	Deep Learning and representational learning	anonymous|continual_pretrainer_is_an_incremental_model_generalizer	/pdf/f8312dc62751186ffec77703a7bd289c3607a0f7.pdf
PQOlkgsBsik	1282	Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval	['Multi-Modal Retrieval', 'Dense Retrieval', 'Universal Embedding Space', 'Modality-Balanced Hard Negative Training', 'Image Verbalization']	This paper presents Vision-Language Universal Search (VL-UnivSearch), which builds a unified model for multi-modal retrieval, leans universal representations for images and texts, and achieves the state-of-the-art. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|universal_visionlanguage_dense_retrieval_learning_a_unified_representation_space_for_multimodal_retrieval	/pdf/da9b079300d13abcdde3458583c64585531ba5f6.pdf
0ypGZvm0er0	1283	View Synthesis with Sculpted Neural Points	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|view_synthesis_with_sculpted_neural_points	/pdf/95127ab5d9a71223ad50d91b7d1a07ef7b559ca3.pdf
-i73LPWa3bD	1284	Semi-supervised learning of partial differential operators and dynamical flows	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|semisupervised_learning_of_partial_differential_operators_and_dynamical_flows	/pdf/f1a44f732202e871feb7f5d6514cbb2224da9984.pdf
tDNGHd0QmzO	1285	TaylorNet: A Taylor-Driven Generic Neural Architecture	['Taylor Neural Networks', 'Image Classification', 'Physics Guided Machine Learning', 'Dynamical Systems']	We propose a generic neural architecture, called TaylorNet, that can introduce inductive bias to DNNs with Taylor series expansion	Deep Learning and representational learning	anonymous|taylornet_a_taylordriven_generic_neural_architecture	/pdf/1cc98779f3a0eb69be84a2561771f134ced5ec61.pdf
LV8OmADmoOe	1286	Improving the Transferability of Adversarial Attacks through Experienced Precise Nesterov Momentum	['adversarial attacks', 'transferability', 'black-box', 'momentum']	Our proposed EPN is more effective than traditional momentum in improving transferability, and extensive experiments show that EPN-based attacks are more transferable than SOTA.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|improving_the_transferability_of_adversarial_attacks_through_experienced_precise_nesterov_momentum	/pdf/4ea3ad87a56cd6ae4ee25fc6bbbdd372ea7f6f93.pdf
pxStyaf2oJ5	1287	Domain-Indexing Variational Bayes for Domain Adaptation	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|domainindexing_variational_bayes_for_domain_adaptation	/pdf/bbbc39304d1b91dd51d1587dcdcf99c719a7bfd0.pdf
FCnohuR6AnM	1288	Dataless Knowledge Fusion by Merging Weights of Language Models	['model merging', 'weight merging']	We study the problem of merging individual models built on different training data sets and propose a novel merging algorithm.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dataless_knowledge_fusion_by_merging_weights_of_language_models	/pdf/759c066e42a284c155f950653225305b5b8165ad.pdf
RusKt9aoTON	1289	FedGSNR: Accelerating Federated Learning on Non-IID Data via Maximum Gradient Signal to Noise Ratio	['Federated learning', 'Gradient Signal to Noise Ratio', 'Optimal Local Updates', 'Non-IID Data']	This paper interprets federated learning algorithms with Gradient Signal to Noise Ratio and proposes the corresponding method to accelerate model convergence with optimal local updates in non-iid scenarios.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fedgsnr_accelerating_federated_learning_on_noniid_data_via_maximum_gradient_signal_to_noise_ratio	/pdf/e7e0a1a857b036b694c7bacffc2b424ea17e57e5.pdf
YV8tP7bW6Kt	1290	Can We Faithfully Represent Absence States to Compute Shapley Values on a DNN?	['explainable AI', 'attribution methods', 'deep neural networks']	We propose a method to examine and learn baseline values for Shapley values, which ensures that the absent variables do not introduce information to the model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|can_we_faithfully_represent_absence_states_to_compute_shapley_values_on_a_dnn	/pdf/e7bc4c9d3532a5351292bbfc9786b6835c07b912.pdf
1tXzHPdOJGZ	1291	On the Universal Approximation Property of Deep Fully Convolutional Neural Networks	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_universal_approximation_property_of_deep_fully_convolutional_neural_networks	/pdf/e226e9b6c04a9c27b1a1ee2d00f25b5ba53545e4.pdf
Zy350cRstc6	1293	Continual evaluation for lifelong learning: Identifying the stability gap	['Continual learning', 'lifelong learning', 'incremental learning', 'evaluation metrics']	"Proposing an iteration-based continual evaluation framework for CL, we discover, quantify, and analyse the ""stability gap"", a phenomenon where upon learning new tasks, past tasks exhibit substantial but transient performance loss for SOTA CL methods."	Deep Learning and representational learning	anonymous|continual_evaluation_for_lifelong_learning_identifying_the_stability_gap	/pdf/2e539603615f61c56207e5e24c78bc68f4ba855c.pdf
_yoBvxHPT_Y	1294	Rademacher Complexity Over $\mathcal{H} \Delta \mathcal{H}$ Class for Adversarially Robust Domain Adaptation	['domain adaptation', 'learning theory', 'adversarial learning']	This paper studies a variant of Rademacher complexity to analyze adversarially robust domain adaptation.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|rademacher_complexity_over_\mathcalh_\delta_\mathcalh_class_for_adversarially_robust_domain_adaptation	/pdf/fdce47f9b2ebd40bd5fc3c91d2a3513905f7e0e5.pdf
Vsh8gspKmuu	1295	Why Adversarial Training of ReLU Networks Is Difficult?	['Adversarial attack', 'adversarial training']	This paper theoretically analyzes the dynamics of adversarial perturbations, and further theoretically explains the difficulty of adversarial training.	Deep Learning and representational learning	anonymous|why_adversarial_training_of_relu_networks_is_difficult	/pdf/8f986cce57d84d325ae1f0411dd7eb627ec700e1.pdf
I_HxBH2SeW	1296	Controllable Evaluation and Generation of Physical Adversarial Patch on Face Recognition	['Physical adversarial attacks', 'face recogntion', 'robustness evaluation']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|controllable_evaluation_and_generation_of_physical_adversarial_patch_on_face_recognition	/pdf/3be000e9d6504f873a34ddfb998fae59285d122d.pdf
0L8tuglXJaW	1297	HOYER REGULARIZER IS ALL YOU NEED FOR EXTREMELY SPARSE SPIKING NEURAL NETWORKS	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|hoyer_regularizer_is_all_you_need_for_extremely_sparse_spiking_neural_networks	/pdf/19f510b259d44ca82489db1a35272374a2c2cd95.pdf
P4bXCawRi5J	1298	Understanding Zero-shot Adversarial Robustness for Large-Scale Models	['Adversarial Robustness', 'Zero-Shot Recognition']		Deep Learning and representational learning	anonymous|understanding_zeroshot_adversarial_robustness_for_largescale_models	/pdf/383f5bf485906eaccc044480881f7c48568c8969.pdf
_lnFErG3F1z	1299	Can GNNs Learn Heuristic Information for Link Prediction?	['link prediction', 'graph neural networks', 'heuristics']	We study existing state-of-the-art GNN-based link prediction methods and show that these methods can hardly learn heuristic information. Our experiments also support our analysis.	Deep Learning and representational learning	anonymous|can_gnns_learn_heuristic_information_for_link_prediction	/pdf/e363f59acb386215fb27f98c3079e9b6a2579cdd.pdf
NxpyLebsLAR	1300	DELVING INTO THE HIERARCHICAL STRUCTURE FOR EFFICIENT LARGE-SCALE BI-LEVEL LEARNING	['Bi-level optimization', 'Meta learning', 'Nash game']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|delving_into_the_hierarchical_structure_for_efficient_largescale_bilevel_learning	/pdf/aa71f57de0dc6fcfe7ef563e6f6dfac091dd6210.pdf
PbkBDQ5_UbV	1301	Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pessimism_in_the_face_of_confounders_provably_efficient_offline_reinforcement_learning_in_partially_observable_markov_decision_processes	/pdf/dcf2cf597c2d2ed759ed2df99482b8063e443ea7.pdf
c5tbxWXU9-y	1302	Information-Theoretic Analysis of Unsupervised Domain Adaptation	['unsupervised domain adaptation', 'generalization', 'information theory', 'regularization']	We derived new information-theoretic generalization bounds for the unsupervised domain adaptation problem.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|informationtheoretic_analysis_of_unsupervised_domain_adaptation	/pdf/77a3e41a8f733938598cf06604e700efc59428a7.pdf
KoEa6h1o6D1	1303	Interventional Rationalization	['rationalization', 'causal intervention']	We propose a  causal intervention method to remove spurious correlations in selective rationalization.	Applications (eg, speech processing, computer vision, NLP)	anonymous|interventional_rationalization	/pdf/506c51f0c1792a058f9d944d0a0d26fa63ac5ab5.pdf
U2g8OGONA_V	1305	Multi-domain image generation and translation with identifiability guarantees	['multi-domain image generation', 'image translation', 'identifiability', 'Nonlinear ICA']	We propose a way to learn the pairing information from unpaired data with theoretial guarantees, with direct applications in learning tasks such as image-to-image translation	Generative models	anonymous|multidomain_image_generation_and_translation_with_identifiability_guarantees	/pdf/cf861c29176a2085dd991889ac9a5c8094c3206a.pdf
GQVfDsoFSBg	1307	Causal RL Agents for Out-of-distribution Generalization	['Reinforcement Learning', 'Out-of-distribution Generalization', 'Disentangled Representation']	This paper proposes a novel technique GCRL to learn a OOD generalization policy by establishing the dependence of actions on a disentangled representation that captures the information about causal factors. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|causal_rl_agents_for_outofdistribution_generalization	/pdf/b81bb0b942d2cb45734fd272af75acbe624fa27e.pdf
6zrOr_Rdhjs	1308	Parallel Deep Neural Networks Have Zero Duality Gap	['Deep neural networks', 'Convex duality', 'Convex optimization']		Deep Learning and representational learning	anonymous|parallel_deep_neural_networks_have_zero_duality_gap	/pdf/ddf3f1d5f73daf68af2dce97cc07d4b2c8174d54.pdf
4NLyCJQR3ZR	1309	Optimal Neural Network Approximation of Wasserstein Gradient Direction via Convex Optimization	['Bayesian inference', 'convex optimization', 'semi-definite programming']	Wasserstein gradient descent meets neural networks and convex optimization	Optimization (eg, convex and non-convex optimization)	anonymous|optimal_neural_network_approximation_of_wasserstein_gradient_direction_via_convex_optimization	/pdf/453d4c85dcf808bc91f4c87eacf7fc9c79d2d445.pdf
ab2mCzEPwqK	1310	Dataset Condensation with Latent Space Knowledge Factorization and Sharing	['Dataset condensation', 'Generative models']	We condense datasets by learning a set of learnable codes defined in a compact latent space followed by a set of tiny decoders which maps them differently to the original input space.	General Machine Learning (ie none of the above)	anonymous|dataset_condensation_with_latent_space_knowledge_factorization_and_sharing	/pdf/d97828823d7a591b61cc0f926cbd22483324223a.pdf
OKfmDPNPwYF	1311	Evaluating Fairness Without Sensitive Attributes: A Framework Using Only Auxiliary Models	['Fairness evaluation', 'noise transition matrix', 'sensitive attributes']	To evaluate fairness without access to any sensitive attribute, we propose a general framework with only off-the-shelf auxiliary models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|evaluating_fairness_without_sensitive_attributes_a_framework_using_only_auxiliary_models	/pdf/880b38c90fe9efffd5753e98b4ceb4d2041f2f5d.pdf
4mFTFqOovux	1312	Node Number Awareness Representation for Graph Similarity Learning	['graph representation learning', 'graph similarity learning', 'graph matching']		Deep Learning and representational learning	anonymous|node_number_awareness_representation_for_graph_similarity_learning	/pdf/6f02d1468c889c2621131b2df5cdd44c6784e045.pdf
4DL3cyuVHrV	1313	Divide and conquer policy for efficient GAN training	['GANs', 'image generation']		Generative models	anonymous|divide_and_conquer_policy_for_efficient_gan_training	/pdf/b6d5efbcc401236f48a8d7d164e668c45b6cec86.pdf
45TeQUJw9tn	1314	Exploring Chemical Space with Score-based Out-of-distribution Generation	['molecule generation', 'score-based generative modeling']	We propose a score-based molecular generative framework that aims to generate out-of-distribution molecules beyond the known molecular space and find novel chemical optima of desired properties.	Applications (eg, speech processing, computer vision, NLP)	anonymous|exploring_chemical_space_with_scorebased_outofdistribution_generation	/pdf/3de208c91049b2bd531b37eb1ff328df4a276bd5.pdf
F5LPNbgpuo0	1315	Dual Ensembled Multiagent Q-Learning with Hypernet Regularizer	['multiagent system', 'deep reinforcement learning', 'overestimation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|dual_ensembled_multiagent_qlearning_with_hypernet_regularizer	/pdf/eafe9f2625fb2f61dedf10e38e8941b87a6c378c.pdf
lMPJP3nRGtJ	1317	Batch Normalization Is Blind to the First and Second Derivatives of the Loss w.r.t. Features	['Batch Normalization', 'Deep Learning Theory', 'Neural Networks']	When we do the Taylor series expansion of the loss function w.r.t. the output of the BN operation, we prove that the BN operation will block the back-propagation of the first and second derivatives of the loss function.	Deep Learning and representational learning	anonymous|batch_normalization_is_blind_to_the_first_and_second_derivatives_of_the_loss_wrt_features	/pdf/ae502ad096044ea8a8eb55ec84ac8019889c3fe5.pdf
0cm8HroIxJV	1318	Explaining Representation Bottlenecks of Convolutional Decoder Networks	['Fourier transform', 'Deep Learning Theory', 'Representation Learning']	In this paper, we prove representation bottlenecks of a cascaded convolutional decoder network, considering the capacity of representing different frequency components of an input sample.	Deep Learning and representational learning	anonymous|explaining_representation_bottlenecks_of_convolutional_decoder_networks	/pdf/fbc356473279992bfbea2f9740b2de72e77fc613.pdf
cjavWixtG9f	1319	Deep Deformation Based on Feature-Constraint  for 3D Human Mesh Correspondence	['shape correspondence', 'deep learning', 'shape deformation']		Deep Learning and representational learning	anonymous|deep_deformation_based_on_featureconstraint_for_3d_human_mesh_correspondence	/pdf/1e6ab9f5a8db3543960e41376ae23058dba776b6.pdf
6FAWzRMRk7A	1320	Correcting Three Existing Beliefs on Mutual Information in Contrastive Learning	[]		Unsupervised and Self-supervised learning	anonymous|correcting_three_existing_beliefs_on_mutual_information_in_contrastive_learning	/pdf/778807d4d085328f527cc5879ebfa00da503a112.pdf
S2N25rUM55l	1322	IEDR: A Context-aware Intrinsic and Extrinsic Disentangled Recommender System	['Recommender Systems', 'Intrinsic and Extrinsic Factors', 'Contrastive Learning', 'Disentangled Representation', 'Mutual Information']	We propose a recommender system that capture intrinsic and extrinsic factors from various contexts to enhance the recommendation quality.	Deep Learning and representational learning	anonymous|iedr_a_contextaware_intrinsic_and_extrinsic_disentangled_recommender_system	/pdf/4f9451c8558ad6b273a007239ea22fb2872b87ff.pdf
gR5yMO1pRRc	1324	Going Deeper with Spiking Neurons: Towards Binary Outputs of Deep Logic Spiking Neural Network	['Spiking Neural Network', 'Deep Network', 'Binary output', 'Brain-Like']		Deep Learning and representational learning	anonymous|going_deeper_with_spiking_neurons_towards_binary_outputs_of_deep_logic_spiking_neural_network	/pdf/63ae420e5e940868136d381b610e93986bad19c1.pdf
qNLe3iq2El	1325	Mega: Moving Average Equipped Gated Attention	['Neural Architecture', 'Attention', 'Exponential Moving Average']	Moving Average Equipped Gated Attention	Deep Learning and representational learning	anonymous|mega_moving_average_equipped_gated_attention	/pdf/d0a603fc1873b6612360af073baa5faf28fa885a.pdf
EmH1WE1fRbt	1326	Exploring Parameter-Efficient Fine-tuning for Improving Communication Efficiency in Federated Learning	['federated learning', 'computer vision', 'vision transformer', 'fine-tuning']	We explore the viability of a parameter-efficient fine-tuning framework in federated learning to leverage strong pre-trained models and significantly reduce communication costs.	Applications (eg, speech processing, computer vision, NLP)	anonymous|exploring_parameterefficient_finetuning_for_improving_communication_efficiency_in_federated_learning	/pdf/c8a312e970e803b3ce1c63fb58108c52f152013d.pdf
iF0B-U0J5fG	1327	Teach me how to Interpolate a Myriad of Embeddings	[]	We introduce MultiMix as a way to go beyond ERM and interpolate as many examples as the mini-batch over their entire convex hull in the embedding space, thereby improving representation learning	Deep Learning and representational learning	anonymous|teach_me_how_to_interpolate_a_myriad_of_embeddings	/pdf/bfaeb93f7410c4bb27a84e52f66fa239d797365c.pdf
Bvaekygzl2m	1328	Strength-Adaptive Adversarial Training	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|strengthadaptive_adversarial_training	/pdf/8798fc4c6e5edce969b9b82bf3942e0bc608fb59.pdf
7lvuPvDNhI4	1329	Unified Algorithms for RL with Decision-Estimation Coefficients: No-Regret, PAC, and Reward-Free Learning	['reinforcement learning theory', 'decision-estimation coefficient', 'function approximation']	We design new unified algorithms for no-regret, PAC, and reward-free reinforcement learning with general model classes, building on the Decision-Estimation Coefficient and a strong model estimation procedure.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|unified_algorithms_for_rl_with_decisionestimation_coefficients_noregret_pac_and_rewardfree_learning	/pdf/dd7f4830f918a949b553c23ca16c2fef3853732e.pdf
o_Qrw9f512w	1330	Learning to Count Everything: Transformer-based Trackers are Strong Baselines for Class Agnostic Counting	['class agnostic counting', 'transformer', 'tracking']		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_to_count_everything_transformerbased_trackers_are_strong_baselines_for_class_agnostic_counting	/pdf/6f4c2aeeedd41936d470a0abe5c94a355f95cf49.pdf
_d2f3hRn0hT	1331	Single-level Adversarial Data Synthesis based on Neural Tangent Kernels	['Adversarial', 'Data Synthesis', 'Neural Tangent Kernels']	This paper formulates the adversarial data synthesis as a single-level optimization problem that is much easier to train than existing GANs.	Generative models	anonymous|singlelevel_adversarial_data_synthesis_based_on_neural_tangent_kernels	/pdf/7235e74bb0d2760da13833a030139a500f791c33.pdf
7EUu177KXY	1332	D3C2-Net: Dual-Domain Deep Convolutional Coding Network for Compressive Sensing	['image reconstruction', 'compressive sensing (CS)', 'convolutional coding', 'dual-domain optimization', 'deep unfolding networks']	We propose a novel D3C2-Net for compressive sensing based on our new proposed generalized dual-domain optimization framework, achieving higher performance than other state-of-the-arts.	Applications (eg, speech processing, computer vision, NLP)	anonymous|d3c2net_dualdomain_deep_convolutional_coding_network_for_compressive_sensing	/pdf/c51a9273b8b91e4cd88102fc3dd3eeedfd418f78.pdf
pXU-5s9yUi1	1333	MINI: Mining Implicit Novel Instances for Few-Shot Object Detection	['Object Detection', 'Few-Shot Object Detection']	Mining Implicit Novel Instances for Few-Shot Object Detection	Deep Learning and representational learning	anonymous|mini_mining_implicit_novel_instances_for_fewshot_object_detection	/pdf/23cf92e79d4c187952c78bcd11b385115ba8f6d6.pdf
dYHYXZ3uGdQ	1334	Rank Preserving Framework for Asymmetric Image Retrieval 	['Asymmetric image retreival']	We propose a rank preserving framework to achieve the consistency of the ranking lists returned by asymmetric and symmetric retrieval. 	Deep Learning and representational learning	anonymous|rank_preserving_framework_for_asymmetric_image_retrieval	/pdf/30ae4f4ea534993786aa7970fa7a21d7cb69a688.pdf
9y0HFvaAYD6	1335	Hidden Markov Transformer for Simultaneous Machine Translation	['Simultaneous machine translation', 'Machine translation', 'Natural language processing', 'Transformer']		Applications (eg, speech processing, computer vision, NLP)	anonymous|hidden_markov_transformer_for_simultaneous_machine_translation	/pdf/91ff528fe50eab11dd59ea72db2634d6b27f8f80.pdf
3lH6Pc0Qeg2	1336	Reconciling Adversarial Robustness with Accuracy via Randomized Weights	['adversarial robustness', 'adversarial training', 'randomized weights']	We study the trade-off between clean accuracy and robustness through randomized weights, design a novel adversarial training method based on Tylor series of randomized weights to improve both clean accuracy and robustness.	Deep Learning and representational learning	anonymous|reconciling_adversarial_robustness_with_accuracy_via_randomized_weights	/pdf/0c01eb4d64e26887768291872b5a775dea2e8d37.pdf
YPChvOgRXRA	1337	Backstepping Temporal Difference Learning	['reinforcement learning', 'temporal difference learning', 'policy evaluation']	This paper develops a new unifying view to design off-policy temporal difference learning algorithms.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|backstepping_temporal_difference_learning	/pdf/31a2b41f44e3493300ee370ee3f94c22a5f73a7c.pdf
PZZUcxazxSw	1338	Policy Contrastive Imitation Learning	['adversarial imitation learning', 'contrastive learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|policy_contrastive_imitation_learning	/pdf/f72423177fb54a789ce8af61d554d64f9f1469ea.pdf
U8MtHLRK06q	1340	PA-LoFTR: Local Feature Matching with 3D Position-Aware Transformer	['deep learning', 'transformer', 'image matching', 'pose estimation', 'position embedding', '3d representation']	A Transformer-based method that learns 3D position information to solve image matching problem.	Applications (eg, speech processing, computer vision, NLP)	anonymous|paloftr_local_feature_matching_with_3d_positionaware_transformer	/pdf/18b232780c3c6144b73713c4a8433e9f07e689c3.pdf
_j4ZUpoNO1e	1341	NEW TRAINING FRAMEWORK FOR SPEECH ENHANCEMENT USING REAL NOISY SPEECH	['Speech enhancement', 'Quality prediction', 'Semi-supervised learning', 'Adversarially robust']	In this study, we proposed a novel SE training method that can train on real noisy speech instead of synthetic training data (such as clean speech + noise in conventional supervised training or noisy speech + noise in MixIT)	Applications (eg, speech processing, computer vision, NLP)	anonymous|new_training_framework_for_speech_enhancement_using_real_noisy_speech	/pdf/ae110c0ecbfaa6ca123e7bbd77465d98bd280e95.pdf
uJzSlJruEjk	1342	Novel Class Discovery under Unreliable Sampling	[]		Deep Learning and representational learning	anonymous|novel_class_discovery_under_unreliable_sampling	/pdf/49d6b86ab0e7e462cb8c8ce80e8aea6faad45cd7.pdf
-Ozk9LVtqbV	1343	Cali-NCE: Boosting Cross-modal Video Representation Learning with Calibrated Alignment	['visual-textual representation learning']		Deep Learning and representational learning	anonymous|calince_boosting_crossmodal_video_representation_learning_with_calibrated_alignment	/pdf/75afba43b9ffb07cb22d427b219e9d85231971d8.pdf
ooqH4D9Xys	1344	LatentAugment: Dynamically Optimized Latent Probabilities of Data Augmentation	['data augmentation', 'image classification', 'EM algorithm']		Deep Learning and representational learning	anonymous|latentaugment_dynamically_optimized_latent_probabilities_of_data_augmentation	/pdf/daaff9f5641d118cdb0e9837f77ef87a2672baff.pdf
__czv_gqDQt	1345	EfficientTTS 2: Variational End-to-End Text-to-Speech Synthesis and Voice Conversion	['Text-to-Speech', 'Voice Conversion', 'End-to-End']		Applications (eg, speech processing, computer vision, NLP)	anonymous|efficienttts_2_variational_endtoend_texttospeech_synthesis_and_voice_conversion	/pdf/19d094ab65238e208ca61565ba3d27727d1b947f.pdf
wV09GfqYC-n	1346	Hierarchies of Reward Machines	['Hierarchical Reinforcement Learning', 'Reward Machines']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|hierarchies_of_reward_machines	/pdf/a49f7de1a58800094442fa8e9ac1c0a3a90849f7.pdf
v8Xz3gNgEo4	1347	LAMDA: Latent mapping for domain adaption of image generators	['domain adaptation', 'gan', 'image synthesis', 'image generative', 'generative models']	We adapt GANs to new domains without training on new images. This is done by only learning how to translate one latent space to another.	Generative models	anonymous|lamda_latent_mapping_for_domain_adaption_of_image_generators	/pdf/2ae525082a11e12fba316d8f45a4a77f0e3ec6f9.pdf
0xHVGIiYK2n	1348	Multi-Agent Sequential Decision-Making via Communication	['multi-agent communication', 'multi-agent reinforcement learning']	A novel communication scheme for multi-agent cooperation	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multiagent_sequential_decisionmaking_via_communication	/pdf/4441b7aa06d9b7aacaece8a1341147f89d7f679c.pdf
icmTV7mhxuQ	1349	Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning	['language-based reinforcement learning', 'multi-agent reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|entity_divider_with_language_grounding_in_multiagent_reinforcement_learning	/pdf/5043363f0bcefe49902b3e7080f7cbee6a814051.pdf
lQVpasnQS62	1350	Human MotionFormer: Transferring Human Motions with Vision Transformers	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|human_motionformer_transferring_human_motions_with_vision_transformers	/pdf/98c83a9f1d2b18651d3af8dc24166c0ea0e7caa7.pdf
WevBjPK4V3j	1351	Evaluation of Attribution Explanations without Ground Truth	['Interpretable machine learning', 'Explainable AI']	This paper proposes a metric to evaluate the objectiveness of  explanation methods without a need for the ground-truth explanations.	Deep Learning and representational learning	anonymous|evaluation_of_attribution_explanations_without_ground_truth	/pdf/29f961952bc445360fabac1afac6580a457601e2.pdf
Sy-o2N0hF4f	1352	Become a Proficient Player with Limited Data through Watching Pure Videos	['Pre-training', 'Fine-tune', 'MCTS', 'Reinforcement learning', 'Vector Quantization']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|become_a_proficient_player_with_limited_data_through_watching_pure_videos	/pdf/f1641fcbb6e5b9cc9253b636d054eb542df19ce6.pdf
HeEqRvCtN2-	1353	Consistent Targets Provide Better Supervision in Semi-supervised Object Detection	['Semi-supervised Learning', 'Object Detection']		Applications (eg, speech processing, computer vision, NLP)	anonymous|consistent_targets_provide_better_supervision_in_semisupervised_object_detection	/pdf/e9442273c5fad36e8966548f465f7d458cf65e54.pdf
2aRlyrY-LsJ	1354	Revisiting Domain Randomization Via Relaxed State-Adversarial Policy Optimization	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|revisiting_domain_randomization_via_relaxed_stateadversarial_policy_optimization	/pdf/c5379d9e2ba8bbafa9533923c0054e0340240b46.pdf
C-7D-u3q62f	1355	CCMLN: Combinatorial Correction for Multi-Label Classification with Noisy Labels	[]		Deep Learning and representational learning	anonymous|ccmln_combinatorial_correction_for_multilabel_classification_with_noisy_labels	/pdf/32f92bed81ab69fcfda237e0a0fe2353ad15f5b1.pdf
Z3825mh8yk9	1357	On the Difficulties of Video Summarization: Structure and Subjectivity	['hierarchical', 'video summarization']	We tackle subjectivity of video summarization by a semantic boundary-aware hierarchical video modeling.	Applications (eg, speech processing, computer vision, NLP)	anonymous|on_the_difficulties_of_video_summarization_structure_and_subjectivity	/pdf/ba33c4e17d640c71e8955847c7b9d5c5136eccfd.pdf
424tG_RaE-	1358	Physics-empowered Molecular Representation Learning	['Physics', 'Transformer', 'Molecular representation learning', 'ML potential']	We propose a Transformer-based molecular energy prediction model equipped with physical insights and self-supervised masked atomic modeling.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|physicsempowered_molecular_representation_learning	/pdf/24c8b18c24ee687c89bdfff267f48863b114a21a.pdf
WXjBX7uz7lO	1359	FDNet: Focal Decomposed Network for Efficient, Robust and Practical time series forecasting	['Time series Forecasting', 'Deep Learning', 'Neural Networks']	A Focal Decomposed Network for efficient, robust and practical time series forecasting	Applications (eg, speech processing, computer vision, NLP)	anonymous|fdnet_focal_decomposed_network_for_efficient_robust_and_practical_time_series_forecasting	/pdf/8121797eeb2239f79d503b43f5936c9575796c7a.pdf
CnG8rd1hHeT	1360	OpenFE: Automated Feature Generation beyond Expert-level Performance	['tabular data', 'feature generation']	OpenFE: automated feature generation beyond expert-level performance	General Machine Learning (ie none of the above)	anonymous|openfe_automated_feature_generation_beyond_expertlevel_performance	/pdf/147997948b8e5f9d81756c73a0e95d3c600491f8.pdf
CPIy9TWFYBG	1361	Proactive Multi-Camera Collaboration for 3D Human Pose Estimation	['Multi-Cameras Collaboration', 'Multi-Agent Credit Assignment', 'Active Vision', 'Human Pose Estimation']	We propose a novel MARL framework to solve proactive multi-camrea collaborations for 3D HPE in human crowds	Applications (eg, speech processing, computer vision, NLP)	anonymous|proactive_multicamera_collaboration_for_3d_human_pose_estimation	/pdf/c215b23855debd2be99ce8b5813812cbe1cc25ab.pdf
XXTyv1zD9zD	1362	Packed Ensembles for efficient uncertainty estimation	['Efficient Ensembling', 'Uncertainty Quantification', 'OOD Detection']	Packed-Ensembles leverage the width of DNNs and grouped convolutions to train subnetworks in parallel and form an efficient ensemble.	General Machine Learning (ie none of the above)	anonymous|packed_ensembles_for_efficient_uncertainty_estimation	/pdf/ea86a43d34c4a971de7aa42aa296aa770a89c010.pdf
yHLvIlE9RGN	1363	Evaluating Long-Term Memory in 3D Mazes	['Reinforcement Learning', 'Memory', 'Benchmark', 'Dataset', 'Representation Learning']	We introduce a benchmark environment and dataset for evaluating the memory abilities of RL agents and their representations.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|evaluating_longterm_memory_in_3d_mazes	/pdf/711c3b50efc404a060c3420cfaddcc90793d588b.pdf
D7shOsFXMv	1364	Online Placebos for Class-incremental Learning	['incremental learning', 'continual learning', 'class-incremental learning']	We design an online learning algorithm to quickly evaluate and select unlabeled data to improve the KD loss in class-incremental learning. 	Deep Learning and representational learning	anonymous|online_placebos_for_classincremental_learning	/pdf/fe22beff7647d11867e071b6ba8ca22ede078431.pdf
HUsh1c7p0gc	1365	T2D: Spatiotemporal Feature Learning Based on Triple 2D Decomposition	['spatiotemporal feature learning', 'video recognition', 'action recognition', 'video Transformer']	A new spatiotemporal feature learning method based on triple 2D decomposition.	Deep Learning and representational learning	anonymous|t2d_spatiotemporal_feature_learning_based_on_triple_2d_decomposition	/pdf/efa4ae22669a48ddb5ea5c58dca03fc38fe9711b.pdf
BrJATVZDWEH	1366	Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks	['Language Models', 'Generalization', 'End-to-End', 'Composition']		Deep Learning and representational learning	anonymous|subtask_decomposition_enables_learning_in_sequence_to_sequence_tasks	/pdf/e6987df0f21ad757a991099d4559e263187ffdd7.pdf
6fuPIe9tbnC	1367	Multifactor Sequential Disentanglement via Structured Koopman Autoencoders	['Koopman methods', 'Sequential Disentanglement']	A new method for learning multifactor disentangled representations of sequential data	Deep Learning and representational learning	anonymous|multifactor_sequential_disentanglement_via_structured_koopman_autoencoders	/pdf/0e6884ac3f062ee84fe045e1994956f791bee40f.pdf
7sn6Vxp92xV	1368	Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders	['self-supervised learning', 'masked auto-encoder']	We conduct analysis of the dynamics of the self-distillation scheme in masked auto-encoder.	Unsupervised and Self-supervised learning	anonymous|exploring_the_role_of_mean_teachers_in_selfsupervised_masked_autoencoders	/pdf/04bcc30a0d4a66290d98c9ac55998c2a41e1138a.pdf
3e5nHhhRK93	1369	Universal embodied intelligence: learning from crowd, recognizing the world, and reinforced with experience	['reinforcement learning', 'transformer', 'morphology', 'pretrain', 'finetune', 'generalization']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|universal_embodied_intelligence_learning_from_crowd_recognizing_the_world_and_reinforced_with_experience	/pdf/15183c9ada65b4aef4ae4a6201846b884a4ce475.pdf
En7lGmzT_x	1371	Sharper Rates and Flexible Framework for Nonconvex SGD with Client and Data Sampling	['nonconvex optimization', 'empirical risk minimization', 'SGD', 'variance reduction', 'data sampling', 'client sampling', 'optimal methods', 'biased gradient estimator', 'federated learning']		Optimization (eg, convex and non-convex optimization)	anonymous|sharper_rates_and_flexible_framework_for_nonconvex_sgd_with_client_and_data_sampling	/pdf/b95e6782b7fb5d85e41e2eae52f99947c3d1acac.pdf
Dk7tsv9fkF	1372	Correcting Data Distribution Mismatch in Offline Meta-Reinforcement Learning with Few-Shot Online Adaptation	['offline meta reinforcement learning', 'offline reinforcement learning', 'meta-reinforcement learning', 'few-shot online adaptation', 'data distribution mismatch correction']	This paper formalizes the data distribution mismatch between offline meta-training and online adaptation, and proposes a novel data correction algorithm for effective online adaptation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|correcting_data_distribution_mismatch_in_offline_metareinforcement_learning_with_fewshot_online_adaptation	/pdf/c4b496d009e2b1564ffac91497b1d9f557c9642b.pdf
4CVu_buZwt	1374	Learn Appropriate Precise Distributions for Binary Neural Networks	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|learn_appropriate_precise_distributions_for_binary_neural_networks	/pdf/2635dd5fee471834a3f8179c8094b3ae4caf24e4.pdf
V_06QV-kZX	1375	Analyzing Tree Architectures in Ensembles via Neural Tangent Kernel	['Neural Tangent Kernel', 'Tree Ensemble', 'Soft Tree']	We formulate and analyze the Neural Tangent Kernel (NTK) induced by soft tree ensembles for arbitrary tree architectures	General Machine Learning (ie none of the above)	anonymous|analyzing_tree_architectures_in_ensembles_via_neural_tangent_kernel	/pdf/f95440ce5727e28e98ea00fdd5a0fabeeaebcdf7.pdf
1tHAZRqftM	1376	Multi-task Self-supervised Graph Neural Networks Enable Stronger Task Generalization	['Graph Neural Network', 'Self-supervised Learning']	We present ParetoGNN, a novel multi-task self-supervised learning framework for graph neural networks, that enhances the task generalization across various downstream tasks and datasets.	Unsupervised and Self-supervised learning	anonymous|multitask_selfsupervised_graph_neural_networks_enable_stronger_task_generalization	/pdf/ea8f9867a98ea5ec54a8acbe62b39e0219ed49a2.pdf
pgC3fd-zjw2	1377	Cooperative Adversarial Learning via Closed-Loop Transcription	['generative models', 'rate reduction', 'closed-loop transcription']	This paper proposes a generative model that implements cooperative adversarial learning, which is robust to net architectures and performs well, and disentangled visual attributes are well modeled in independent principal components.	Generative models	anonymous|cooperative_adversarial_learning_via_closedloop_transcription	/pdf/5651578cd553ba786adc3e4e22ad3c1f8e57e42e.pdf
TM9jOSaIzN	1378	Neural Decoding of Visual Imagery via Hierarchical Variational Autoencoders	['neural decoding', 'hierarchical variational autoencoders', 'neuroscience']	We propose a novel architecture for decoding visual imagery from fMRI recordings using Hierarchical VAEs.	Applications (eg, speech processing, computer vision, NLP)	anonymous|neural_decoding_of_visual_imagery_via_hierarchical_variational_autoencoders	/pdf/6c4e56f649da63d18831338e3e82b4b902b8608d.pdf
MjsDeTcDEy	1379	What Is Missing in IRM Training and Evaluation? Challenges and Solutions	['invariant risk minimization', 'bi-level optimization']		Deep Learning and representational learning	anonymous|what_is_missing_in_irm_training_and_evaluation_challenges_and_solutions	/pdf/52dab72f3b1069e6efc843abd3352e269e557bd6.pdf
TPiwkItUSu	1380	Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis Function Decomposition	['nonconvex optimization', 'trajectory analysis', 'neural network optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|behind_the_scenes_of_gradient_descent_a_trajectory_analysis_via_basis_function_decomposition	/pdf/a2bab9bdde9c2f129aa6691e9bb4e8b61b3a26ab.pdf
nlVOZyTZna	1381	Rethinking the Training Shot Number in Robust Model-Agnostic Meta-Learning	[]		Deep Learning and representational learning	anonymous|rethinking_the_training_shot_number_in_robust_modelagnostic_metalearning	/pdf/8c0c287c728c0a054c35f05e2e2b6d934458c531.pdf
gc0HvlDPyA	1382	Rethinking Saliency in Data-free Class Incremental Learning	[]		Unsupervised and Self-supervised learning	anonymous|rethinking_saliency_in_datafree_class_incremental_learning	/pdf/82956d88de934bc614f5e249a202539fc59437b7.pdf
jbIYfq4Tr-	1383	On the Robustness of Safe Reinforcement Learning under Observational Perturbations	['Safe reinforcement learning', 'deep reinforcement learning', 'state robust reinforcement learning']	We study the robustness of safe RL under observational perturbations, and propose two effective adversaries and a defense algorithm to increase the agent's safety under attacks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_robustness_of_safe_reinforcement_learning_under_observational_perturbations	/pdf/7709cb23de285da0aa40ba9042214c5df8de2072.pdf
jKgataakTy	1384	Frame Adaptive Network	['Video Recognition', 'Temporal Deviation']	We propose a framework to train video recognition methods which can be evaluated at multiple frames and exhibit better performance compared to individual ones.	Deep Learning and representational learning	anonymous|frame_adaptive_network	/pdf/9c355c1ad7338faa12d2601c268f784b1a1be0a0.pdf
KE_wJD2RK4	1385	Modeling Multimodal Aleatoric Uncertainty in Segmentation with Mixture of Stochastic Experts	['Semantic Segmentation', 'Aleatoric Uncertainty', 'Stochastic Segmentation', 'Multiple Annotations']	We propose a novel mixture of stochastic experts (MoSE) model training with a Wasserstein-like loss, which produces an efficient two-level representation for the multi-modal aleatoric uncertainty in semantic segmentation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|modeling_multimodal_aleatoric_uncertainty_in_segmentation_with_mixture_of_stochastic_experts	/pdf/65903203965d1acdc977551eb234090c3977974a.pdf
KICUSNslb7Q	1386	Union Subgraph Neural Networks	['Graph Neural Network', 'Representation Learning']	We propose a Union Subgraph Network that introduces local structural information by a shortest-path-based descriptor.	Deep Learning and representational learning	anonymous|union_subgraph_neural_networks	/pdf/f27b752f26b54863865bc4a9c474a7a3102194b5.pdf
IA96Pn7A08h	1387	Learning to Split for Automatic Bias Detection	['bias', 'robustness', 'spurious correlation']	We propose ls, an algorithm that learns to split the given dataset so that predictors trained on the training split cannot generalize to the testing split.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_to_split_for_automatic_bias_detection	/pdf/090b50038a7e483cac4e8a106b33a5e2bfba1785.pdf
nY5e2_e7WpY	1389	Fair Multi-exit Framework for Facial Attribute Classification	['Fairness', 'Multi-Exit Deep Neural Network']	Multi-exit deep neural network improves the model fairness on facial attribute classification.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fair_multiexit_framework_for_facial_attribute_classification	/pdf/2dd3b34616c8aa414916e5a068c0cd55ac8bdb20.pdf
wOVGs7LJVs3	1390	Sparse Hyperbolic Representation Learning	['hyperbolic space', 'Riemannian manifold', 'sparse learning', 'sparse regularization', 'iterative shrinkage-thresholding algorithm', 'Riemannian gradient descent']	The paper proposes sparse regularization for hyperbolic-space-based machine learning.	Deep Learning and representational learning	anonymous|sparse_hyperbolic_representation_learning	/pdf/1707ddd24ef34493aab1d4c3a969522dc3f86942.pdf
Rc0Xpxxfx5	1392	DIFFUSED INSTANCE CONDITIONED GAN	['generative adversarial networks', 'GAN', 'conditional GAN', 'image generation']	Improving image quality and mode coverage of GAN using diffusion based Gaussian mixture in feature space as partition guidance.  	Generative models	anonymous|diffused_instance_conditioned_gan	/pdf/1590f9f6ba0683777192db0b34e26b7834a5947e.pdf
7KSeWGIOYM	1393	Bootstrap Motion Forecasting With Self-Consistent Constraints	['Motion Forecasting', 'Autonomous Driving', 'Trajectory prediction']	We introduce self-consistent constraints to improve the performance of motion forecasting in autonomous driving, which can be easily incorporated into other motion forecasting approaches.	Applications (eg, speech processing, computer vision, NLP)	anonymous|bootstrap_motion_forecasting_with_selfconsistent_constraints	/pdf/b5290de794a89b0a5c22698165769e10eea56787.pdf
WgGeNLtoDR	1394	Predicting Antimicrobial MICs for Nontyphoidal Salmonella Using Multitask Representations Learning 	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|predicting_antimicrobial_mics_for_nontyphoidal_salmonella_using_multitask_representations_learning	/pdf/07d7f26567867c5c33c6a0482606ebae408a164d.pdf
iMevKmhiUZ	1395	Joint Spatiotemporal Attention for Mortality Prediction of Patients with Long COVID	['longitudinal data', 'mortality prediction', 'COVID-19', 'attention']	We proposed a joint spatiotemporal attention mechanism for deep learning-based mortality prediction of long covid.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|joint_spatiotemporal_attention_for_mortality_prediction_of_patients_with_long_covid	/pdf/30939a8b8090e54a6c8e514143705ea09bf036b2.pdf
FAXVNe1GxX	1396	PRUDEX-Compass: Towards Systematic Evaluation of Reinforcement Learning in Financial Markets	['Evaluation', 'Reinforcement Learning', 'Finance', 'Benchmarking']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|prudexcompass_towards_systematic_evaluation_of_reinforcement_learning_in_financial_markets	/pdf/8b1cacc411ef403b5c10e82fff243c3206dd3add.pdf
NqaGPQXblk	1398	Visual Transformation Telling	['visual reasoning', 'transformation', 'captioning']	Visual Transformation Telling: a new task that requires to reason and describe transformations from a series of images.	Applications (eg, speech processing, computer vision, NLP)	anonymous|visual_transformation_telling	/pdf/567925dd118387149c60a784b3664d2b392d64cf.pdf
xQQQWB3VcpE	1399	Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks	['zero-shot', 'semi-parametric language model', 'multitask training']	We introduce the first semi-parametric language model that demonstrates strong zero-shot performance on a wide range of unseen downstream tasks	Applications (eg, speech processing, computer vision, NLP)	anonymous|zemi_learning_zeroshot_semiparametric_language_models_from_multiple_tasks	/pdf/9d9b8844bcd55dac51eab5c9dfd4848a65b01443.pdf
uwmlZn6n-gV	1400	Continual Learning with Group-wise Neuron Normalization	['continual learning', 'group-wise neuron normalization', 'experience replay', 'subset of network weights competition']		Deep Learning and representational learning	anonymous|continual_learning_with_groupwise_neuron_normalization	/pdf/628ab893a1a78a6b30f07e394a35bc01a26c80bf.pdf
qkdzAuh_gy	1402	ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets	['OOD generalization', 'underspecification']	Empirical+theoretical examination of an example of inverse correlation between ID/OOD accuracy across multiple neural networks (Camelyon17 dataset).	Deep Learning and representational learning	anonymous|id_and_ood_performance_are_sometimes_inversely_correlated_on_realworld_datasets	/pdf/a1d569a79dc146a87adf3f1431d4cff590176a0a.pdf
TnIZfXSFJAh	1403	PIPS: Path Integral Stochastic Optimal Control for Path Sampling in Molecular Dynamics	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pips_path_integral_stochastic_optimal_control_for_path_sampling_in_molecular_dynamics	/pdf/1b85540a8b32309c687816179212a1c92926443c.pdf
dr56zCCLtqY	1404	A Unified Causal View of Domain Invariant Representation Learning	[]		Deep Learning and representational learning	anonymous|a_unified_causal_view_of_domain_invariant_representation_learning	/pdf/36ad93e49604f571274e6e1fd7fc7c3979fd4d0b.pdf
-P7G-8dmSh4	1405	Formal Mathematics Statement Curriculum Learning	['neural theorem proving', 'formal mathematics', 'language modeling', 'expert iteration']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|formal_mathematics_statement_curriculum_learning	/pdf/c9c476b23214356b7897ec4ed759e2e5b30a895c.pdf
LlOOSDGLD24	1406	Flexible Relation Preserving for Adversarial Training	['adversarial training', 'adversarial robustness', 'relationship knowledge distillation']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|flexible_relation_preserving_for_adversarial_training	/pdf/22ab6a2fb2cd3c7bd8da01fd572d51b8e38ad43b.pdf
vi6H4wu44nS	1407	Fusion of Global and Local Knowledge for Personalized Federated Learning	['Federated learning', 'personalized federated learning', 'model compression']	This paper presents a novel PFL solution with higher accuracy perfomance, smaller model complexity, and lower communication cost.	Deep Learning and representational learning	anonymous|fusion_of_global_and_local_knowledge_for_personalized_federated_learning	/pdf/6b79087545fc4a67420cd8065dd0e174614e6b6a.pdf
Oc2vlWU0jFY	1409	Reversible Column Networks	[]		Deep Learning and representational learning	anonymous|reversible_column_networks	/pdf/3a9f859021951835e9265ce1ee26d69e07169b50.pdf
ZbzcLy5I4rz	1411	Stochastic Gradient Methods with Preconditioned Updates	['optimization', 'non-convex optimization', 'stochastic optimization', 'scaled methods', 'variance reduction']		Optimization (eg, convex and non-convex optimization)	anonymous|stochastic_gradient_methods_with_preconditioned_updates	/pdf/6afd7d179fffc34866664fe2b72826e842ce84be.pdf
RPyemmvfqNF	1412	Motif-induced Graph Normalization	[]		Deep Learning and representational learning	anonymous|motifinduced_graph_normalization	/pdf/92d32d33c84270dabaca3a04d03881e777cfef3c.pdf
cddbeL1HWaD	1413	Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning	['Reinforcement Learning', 'Multi-Agent Reinforcement Learning']	A novel problem formulation and methodology in MARL on learning where to communicate and where best to communicate.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|cheap_talk_discovery_and_utilization_in_multiagent_reinforcement_learning	/pdf/a7b1486e0241d42300868ab9d34a02e62bc1c124.pdf
jyHAGzMu-1Q	1414	Learning to Communicate using Contrastive Learning 	['Reinforcement Learning', 'Multi-Agent Reinforcement Learning', 'Multi-Agent Communication']	A novel approach and perspective to decentralized communication learning in MARL based on contrastive learning with a suite of evaluation methods (e.g. protocol symmetry, representation probing and zero-shot communication) to analyze protocols.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_to_communicate_using_contrastive_learning	/pdf/df9fa34b00f638d5c1a0489769931de9ffd6b701.pdf
-1k-zfgHFWQ	1415	Improving Molecular Pretraining with Complementary Featurizations	['molecular pretraining', 'featurizations', 'contrastive learning']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|improving_molecular_pretraining_with_complementary_featurizations	/pdf/a72eb20a2322686c84daf66a65ffa9a9cbb27d02.pdf
zyfEWkV6it	1417	AutoSparse: Towards Automated Sparse Training	['sparsity', 'sparse training', 'deep learning']		Deep Learning and representational learning	anonymous|autosparse_towards_automated_sparse_training	/pdf/9d356193ce1f14d4d0f917396be3d255c4031a5b.pdf
02Bt_4tx6r	1418	Joint rotational invariance and adversarial training of a dual-stream Transformer yields state of the art Brain-Score for Area V4	['Vision Transformer', 'Brain-Score competition', 'adversarial training', 'rotation invariance.']	We provide evidence that a specific Vision Transformer under a joint rotationally-invariant and adversarial optimization procedure can reach state of the art Brain-Score for Area V4	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|joint_rotational_invariance_and_adversarial_training_of_a_dualstream_transformer_yields_state_of_the_art_brainscore_for_area_v4	/pdf/b10349772a897674b4c83c8de7d7adacdf2666dd.pdf
N7ts-GTfuy	1419	3D-Aware Video Generation	['video generation', '3D', 'generative model', '3D-aware image synthesis']	3D-Aware Video Generation	Generative models	anonymous|3daware_video_generation	/pdf/0ac640a14925c7bae69959363654289ec7db7cef.pdf
TVY6GoURrw	1420	Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses	['differential privacy', 'federated learning', 'distributed optimization', 'private optimization', 'stochastic convex optimization', 'cross-silo federated learning']	Optimal algorithms for differentially private convex/strongly convex federated learning with data from people who do not trust the server or other silos/clients. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|private_federated_learning_without_a_trusted_server_optimal_algorithms_for_convex_losses	/pdf/33f7fce9b9b7de9d6a0b671c0ca50c6f6b0185a6.pdf
9gfir3fSy3J	1421	NeRN: Learning Neural Representations for Neural Networks	['Convolutional Neural Networks', 'Neural Representations', 'Implicit Representations']	In this paper we present NerN: a neural representation for the weights of a pretrained neural network, which is obtained by applying smoothness over the reconstructed weights and various knowledge distillation techniques	Deep Learning and representational learning	anonymous|nern_learning_neural_representations_for_neural_networks	/pdf/aa4e5258c9de86fe83d137fbc001a6ea3a27d54d.pdf
MuWgF-FVzON	1422	The Impact of Approximation Errors on Warm-Start Reinforcement Learning: A Finite-time Analysis	['Reinforcement Learning', 'Finite-time Analysis', 'Approximation Error', 'Warm Start']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_impact_of_approximation_errors_on_warmstart_reinforcement_learning_a_finitetime_analysis	/pdf/07e80581ca83806e8cf7d979a266d90270efb6a2.pdf
fjh7UGQgOB	1424	Rethinking Graph Lottery Tickets: Graph Sparsity Matters	['GLT']		Deep Learning and representational learning	anonymous|rethinking_graph_lottery_tickets_graph_sparsity_matters	/pdf/5ea3ac63fbbcf8b8316ebeb617d471466c4970a2.pdf
vaf8KQ8bhS	1425	RbX: Region-based explanations of prediction models	[]	Region-based explanations for local prediction importance from a black-box model	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|rbx_regionbased_explanations_of_prediction_models	/pdf/e3afd3d697a2e4b1d0b1fb6ccb1cee651052ff4e.pdf
kfOtMqYJlUU	1426	NeRF-SOS: Any-View Self-supervised Object Segmentation on Complex Scenes	['neural radiance field', 'self-supervised learning', 'object segmentation']	We propose a novel collaborative contrastive loss for NeRF to segment objects in complex real-world scenes, without any annotation.	Unsupervised and Self-supervised learning	anonymous|nerfsos_anyview_selfsupervised_object_segmentation_on_complex_scenes	/pdf/d40615d2c1c0d5620c0f9703a2c6bab859d9f08f.pdf
6TxBxqNME1Y	1427	Diffusion Probabilistic Modeling of Protein Backbones in 3D for the motif-scaffolding problem	['Diffusion Models', 'Sequential Monte Carlo', 'Protein Design', 'Geometric Deep Learning']	We have created the first generative modeling approach to motif-scaffolding by developing a diffusion probabilistic model of protein backbones and a procedure for generating scaffolds conditional on a motif.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|diffusion_probabilistic_modeling_of_protein_backbones_in_3d_for_the_motifscaffolding_problem	/pdf/e29488da7c6843e2c6814fbb4cda4c7c9522d56a.pdf
1-MBdJssZ-S	1428	Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation	['Contrastive Diffusion', 'Conditioned Generations', 'Music Generation', 'Image Synthesis']	We present a conditional contrastive diffusion approach for better input-output correspondence via maximized mutual information, applicable for music and image generations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|discrete_contrastive_diffusion_for_crossmodal_music_and_image_generation	/pdf/b71bc1cbc367c7fc82514abecc9ccd699bbd4b00.pdf
vtVDI3w_BLL	1430	AANG : Automating Auxiliary Learning	['auxiliary learning', 'automl', 'natural language processing', 'meta-learning', 'algorithmic stability', 'multitask learning']	We automatically generate a suite of auxiliary objectives and give a theoretically informed, efficient algorithm for searching the space of generated objectives to find those most useful to a specified end-task.	Unsupervised and Self-supervised learning	anonymous|aang_automating_auxiliary_learning	/pdf/eda74760ff24f2c2e7b93bffa2f83f7be84ec439.pdf
0PH-P_FIqGD	1432	Compact Bilinear Pooling via General Bilinear Projection	['Bilinear Pooling', 'Bilinear Projection', 'fine-grained recognition']	We proposed a general bilinear projection based on complete matrix bases, and then we design a compact bilinear pooling algorithm by using the proposed general bilinear pooling.	Deep Learning and representational learning	anonymous|compact_bilinear_pooling_via_general_bilinear_projection	/pdf/251ec54b52ad97111e96040f40329d06db3012e0.pdf
lb8wXVGWn0E	1433	Learnable Visual Words for Interpreting Image Recognition Models	[]		Deep Learning and representational learning	anonymous|learnable_visual_words_for_interpreting_image_recognition_models	/pdf/03981513c5d8fa4fad06dab65e1b3937efd8846b.pdf
IHGnybgLo1Z	1434	A Critical Analysis of Out-of-Distribution Detection for Document Understanding	['Document Understanding', 'Pretraining', 'Out-of-Distribution', 'Document intelligence', 'Robustness']	This work investigates the OOD robustness of pretrained models and presents a benchmark for various document understanding tasks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_critical_analysis_of_outofdistribution_detection_for_document_understanding	/pdf/56e7d9e4e2161ed0282f8e76aa8d7085b2a5d981.pdf
9aokcgBVIj1	1437	FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification	['few-shot learning', 'transfer learning', 'federated learning']	We propose FiT, a parameter efficient few-shot image classification system that uses a Naive Bayes head, FiLM layers that modulate a pretrained backbone, and an episodic fine-tuning protocol that achieves SOTA on the VTAB-1k benchmark.	Deep Learning and representational learning	anonymous|fit_parameter_efficient_fewshot_transfer_learning_for_personalized_and_federated_image_classification	/pdf/ec5e689377cc768cdfd95dc3dd2ba6abfe57b47e.pdf
e25n9Z29PeC	1438	Extracting Expert's Goals by What-if Interpretable Modeling	['counterfactuals', 'explaining decision-making', 'preference learning', 'inverse reinforcement learning', 'healthcare']	We recover clinicians' goals of treatments by integrating counterfactual reasoning into batch inverse reinforcement learning and interpretable GAM modeling	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|extracting_experts_goals_by_whatif_interpretable_modeling	/pdf/ab66a994e9e6d6bd02d3249e23936b7f7df1e082.pdf
ybFkELZjuc	1440	Data-Efficient and Interpretable Tabular Anomaly Detection	['Anomaly Detection', 'Interpretability']	We developed an interpretable tabular anomaly detection method that allows incorporation of labeled data.	Unsupervised and Self-supervised learning	anonymous|dataefficient_and_interpretable_tabular_anomaly_detection	/pdf/f6e4d26b6eeac80f60f9d26920ca398f36957c30.pdf
NUBuJsAq1U	1441	Determinant regularization for Deep Metric Learning	['Deep Metric Learning', 'Generalization', 'Jacobi Matrix']		Deep Learning and representational learning	anonymous|determinant_regularization_for_deep_metric_learning	/pdf/35428fe8b905b477b2bd5a900f36b1360193e553.pdf
qBvBycTqVJ	1442	Scalable Estimation of Nonparametric Markov Networks with Mixed-Type Data	['Structure learning', 'Markov networks', 'graphical models', 'score matching', 'model selection']	We investigate scalable estimation of nonparametric Markov networks with general distributions for all data types (i.e., continuous, discrete, and mixed-type).	General Machine Learning (ie none of the above)	anonymous|scalable_estimation_of_nonparametric_markov_networks_with_mixedtype_data	/pdf/69f8d6f89a7cbc99449ecbcdef379b5ff0e1388e.pdf
mX56bKDybu5	1444	Neural Radiance Field Codebooks	['Object-Centric Representation Learning', 'Representation Learning', 'Neural Radiance Fields']	Learning geometrically-aware, object-centric representations through elastic bottlenecks and a differentiable renderer for downstream tasks.	Deep Learning and representational learning	anonymous|neural_radiance_field_codebooks	/pdf/f07c4352299439a657a159c87d5480a06338aaf2.pdf
-CIOGGhkEfy	1445	Augmentation Backdoors	['training time attacks', 'backdoors', 'augmentation']	We present three backdoor attacks that can be covertly inserted into data augmentation functions.	General Machine Learning (ie none of the above)	anonymous|augmentation_backdoors	/pdf/1c2b6cd3694835132c99d93886fb0ab5f5565204.pdf
yyTNV4CcIR9	1447	A Unimodal, Uncertainty-Aware Deep Learning Approach for Ordinal Regression	['unimodality', 'ordinal regression', 'uncertainty', 'deep learning']		Deep Learning and representational learning	anonymous|a_unimodal_uncertaintyaware_deep_learning_approach_for_ordinal_regression	/pdf/30383ce32f7ac6e88a51eeeab5b86f4b4ecf35f0.pdf
egaddkwMOd3	1448	Implicit Offline Reinforcement Learning via Supervised Learning	['Offline Reinforcement Learning', 'Energy Based Model', 'Offline Reinforcement Learning via Supervised Learning']	This work bridged an essential gap between implicit models and explicit RL via Supervised Learning methods.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|implicit_offline_reinforcement_learning_via_supervised_learning	/pdf/8ef78bc5a469e9a42907b4689f5dfa7ddde53e52.pdf
6j3bPQtQS-3	1449	Low-Entropy Features Hurt Out-of-Distribution Performance	['Generalization', 'Out-of-Distribution', 'Entropy-based Methods', 'Unsupervised Contrastive Learning', 'Latent Representations']	We hypothesize that low-entropy features tend to be more domain-specific. This paper studies how the entropy of the intermediate representation affect the model's robustness against out-of-distribution (OOD) data.	Deep Learning and representational learning	anonymous|lowentropy_features_hurt_outofdistribution_performance	/pdf/a258d4a0e672d6a1c332ac97fbe3a1c09451743c.pdf
8Vxuz_PJNus	1451	Federated Learning of Large Models at the Edge via Principal Sub-Model Training	['Federated Learning', 'Resource-Constrained Clients', 'Sub-Model Training']	We provide a sub-model training method that enabled resource-constrained clients to train large model in FL.	Deep Learning and representational learning	anonymous|federated_learning_of_large_models_at_the_edge_via_principal_submodel_training	/pdf/3bd1ad30d632aa661bf31492ffa31df942cd2cfe.pdf
KUP3ic8jdGo	1452	Limitations of the NTK for Understanding Generalization in Deep Learning	['scaling laws', 'ntk', 'time dynamics']	1. Neural networks have significantly better scaling than neural tangent kernels. 2. The empirical NTK continues to evolve throughout the training, in contrast with prior work which suggests that it stabilizes after a few epochs of training.	Deep Learning and representational learning	anonymous|limitations_of_the_ntk_for_understanding_generalization_in_deep_learning	/pdf/f75ffe09808f1c8b3d3365a156b2cede6bcee528.pdf
eqrJZ-Davr2	1453	AdaWAC: Adaptively Weighted Augmentation Consistency Regularization for Volumetric Medical Image Segmentation	['Medical image segmentation', 'Adaptive weighting', 'Consistency regularization', 'Subpopulation shift']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|adawac_adaptively_weighted_augmentation_consistency_regularization_for_volumetric_medical_image_segmentation	/pdf/22be82f5396c1b63c00ebae37b38674f959c80fd.pdf
gfWNItGOES6	1454	Guiding continuous operator learning through Physics-based boundary constraints	['partial differential equations', 'operator learning', 'physics-constraints', 'boundary conditions', 'kernel correction']	We propose novel kernel correction mechanisms for neural operators to satisfy physical boundary constraints which are effective in improving the overall performance.	Deep Learning and representational learning	anonymous|guiding_continuous_operator_learning_through_physicsbased_boundary_constraints	/pdf/1b301465a0f686bf9ff3f4a0a7d5c1387326c899.pdf
PzBGIu-llo7	1455	Learning Proximal Operators to Discover Multiple Optima	[]		Optimization (eg, convex and non-convex optimization)	anonymous|learning_proximal_operators_to_discover_multiple_optima	/pdf/1a698c83346d2a14140030bd391ba5f6111fcf95.pdf
p7EagBsMAEO	1457	Understanding Edge-of-Stability Training Dynamics with a Minimalist Example	['edge of stability', 'nonconvex optimization', 'gradient descent', 'training dynamics', 'scalar network']		Optimization (eg, convex and non-convex optimization)	anonymous|understanding_edgeofstability_training_dynamics_with_a_minimalist_example	/pdf/1d0362e198b39ad3a1e1f8208a29ced913f8ed06.pdf
JQK0BsKpE8	1459	NetBooster: Empowering Tiny Deep Learning By Standing on the Shoulders of Deep Giants	['Network Training', 'Transfer Learning']	We propose an expansion-then-contraction training strategy on both width and depth dimension to fully unleash tiny neural network's potential on large scale datasets and downstream tasks.	Deep Learning and representational learning	anonymous|netbooster_empowering_tiny_deep_learning_by_standing_on_the_shoulders_of_deep_giants	/pdf/a6b24bec6fb977ec489941328840813c4500baa1.pdf
3itjR9QxFw	1460	Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning	['Diffusion Models', 'Discrete Data']	Generating discrete/categorical data with (continuous) diffusion models; also presents a technique that improves diffusion models in general.	Generative models	anonymous|analog_bits_generating_discrete_data_using_diffusion_models_with_selfconditioning	/pdf/2b58ef9063b36a74a39753bde17c2163d9f3d7f3.pdf
zdfUK8wPJl	1461	MODULAR FEDERATED CONTRASTIVE LEARNING WITH PEER NORMALIZATION	['federated learning', 'contrastive learning', 'normalization']		Unsupervised and Self-supervised learning	anonymous|modular_federated_contrastive_learning_with_peer_normalization	/pdf/2439d9ff9d23db88c32624dab83e86cea8acc895.pdf
DmYnLaFGMoc	1462	Deep Active Anomaly Detection With Diverse Queries	['deep anomaly detection', 'active learning', 'diversified sampling']	A new active learning approach for deep anomaly detection that leads to leads to systematic improvements over current approaches.	Unsupervised and Self-supervised learning	anonymous|deep_active_anomaly_detection_with_diverse_queries	/pdf/5f56a22f2e1f9ca336768d28daf91222654c6312.pdf
3KHzMQUOH4x	1463	DEEAPR: Controllable Depth Enhancement via Adaptive Parametric Feature Rotation	[]		Deep Learning and representational learning	anonymous|deeapr_controllable_depth_enhancement_via_adaptive_parametric_feature_rotation	/pdf/d920d787ac58fe263abc1870c528175f45e70b14.pdf
UClBPxIZqnY	1464	Deep Declarative Dynamic Time Warping for End-to-End Learning of Alignment Paths	['implicit differentiation', 'sequence matching', 'time series', 'visual localization', 'music']	We introduce a novel differentiable dynamic time warping layer based on continuous time warps and implicit differentiation.	Deep Learning and representational learning	anonymous|deep_declarative_dynamic_time_warping_for_endtoend_learning_of_alignment_paths	/pdf/9f5eea27b4a64d29cbbd0cc1efd9ead7c74dcc15.pdf
UhEJz3wgLnG	1465	Revealing Single Frame Bias for Video-and-Language Learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|revealing_single_frame_bias_for_videoandlanguage_learning	/pdf/aaf9c698c1deb714a8757faf1a8fe3b8500ee7ba.pdf
8wbnpOJY-f	1466	Trainable Weight Averaging: Efficient Training by Optimizing Historical Solutions	['efficient training', 'weight averaging', 'optimization']	We propose trainable weight averaging (TWA) to optimize historical solutions in DNNs' training to achieve efficiency and better performance.	Optimization (eg, convex and non-convex optimization)	anonymous|trainable_weight_averaging_efficient_training_by_optimizing_historical_solutions	/pdf/dc676e59985ed9a475a4f4f8b3ff145950e3a821.pdf
x-wqE_-uhAL	1467	Robust Self-Supervised Image Denoising with Cyclic Shift and Noise-Intensity-Aware Uncertainty	[]		Unsupervised and Self-supervised learning	anonymous|robust_selfsupervised_image_denoising_with_cyclic_shift_and_noiseintensityaware_uncertainty	/pdf/7f7ca19c07d51bb5332c82bcf5eb0854e4a5dca9.pdf
Mmgcp3MRp7q	1468	Identifying Latent Causal Content for Multi-Source Domain Adaptation	[]		Deep Learning and representational learning	anonymous|identifying_latent_causal_content_for_multisource_domain_adaptation	/pdf/59676647fbb0c0dac2f8bada0e8859887a3d8a0c.pdf
bA6h-N17X1E	1470	Quantum-Inspired Tensorized Embedding with Application to Node Representation Learning	['network embedding', 'node representation learning', 'quantum mechanics', 'tensorized embedding']		Deep Learning and representational learning	anonymous|quantuminspired_tensorized_embedding_with_application_to_node_representation_learning	/pdf/32a0e041e18b4d70a848206cc3c4f2d4603b2b33.pdf
B-dM7df9Axo	1471	Learning PDE Solution Operator for Continuous Modeling of Time-Series	['Neural ODEs', 'Partial differential equations', 'Neural operators', 'Time-series']	 PDE-based approach for modeling time-series.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_pde_solution_operator_for_continuous_modeling_of_timeseries	/pdf/e05fa1da9178a791683d74da21a46b73aa7b82fb.pdf
xOFD5BMwsB	1472	Conditional Invariances for Conformer Invariant Protein Representations	['Invariances', 'Conditional Invariances', 'input dependent invariances', 'proteins', 'protein representation learning', 'conformer invariant representations', 'graph neural networks', 'group invariant neural networks']	We propose the conditional invariance (CI) framework, which captures input-dependent transformation invariances as an add-on to existing neural network methods. We augment existing protein GNNs with CI to learn conformer invariant representations.	Deep Learning and representational learning	anonymous|conditional_invariances_for_conformer_invariant_protein_representations	/pdf/04cd23ea9b5fcd090f04985b41d1dabd44769ed4.pdf
to3qCB3tOh9	1473	Protein Representation Learning by Geometric Structure Pretraining	['Protein representation learning', 'self-supervised learning']	In this work, we propose a versatile protein structure encoder GearNet, a superior protein structure pre-trainining algorithm Multiview Contrast and a suite of protein structure pre-training baselines.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|protein_representation_learning_by_geometric_structure_pretraining	/pdf/434173f298f1a35b327a724df4d72b7fa28ef425.pdf
bMUZXhuFEf	1474	PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting	[]		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|promptcast_a_new_promptbased_learning_paradigm_for_time_series_forecasting	/pdf/ff2622b841cad013d8364fad8c269942b62665f7.pdf
WOfOf53mVyo	1475	Topic Aware Transformer: Domain Shift for Unconditional Text Generation Model	['Text generation', 'Domain  adaptation', 'Domain  shift', 'Transformers']	Domain  adaptation framework  of PLMs to unconditional text generation tasks.	Generative models	anonymous|topic_aware_transformer_domain_shift_for_unconditional_text_generation_model	/pdf/00253414666f6a6ecab726938317724c20dae978.pdf
LUOSN8opID1	1477	Constrained Hierarchical Deep Reinforcement Learning with Differentiable Formal Specifications	['Deep Reinforcement Learning', 'Differentiable Formal Specification Language', 'Robot Navigation', 'Robot Planning and Control']	This paper uses differentiable formal specifications to constrain the policy updates in hierarchical deep reinforcement learning. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|constrained_hierarchical_deep_reinforcement_learning_with_differentiable_formal_specifications	/pdf/da31c595cb2c0112684176c56915f2a9a60f2d04.pdf
gOZ_pKANaPW	1478	Unsupervised Model Selection for Time Series Anomaly Detection	['Time Series', 'Anomaly Detection', 'Model Selection', 'Unsupervised Learning', 'Rank Aggregation']	This paper answers the question-- Given an unlabeled dataset and a set of candidate time series anomaly detectors, how can we select the most accurate model?	General Machine Learning (ie none of the above)	anonymous|unsupervised_model_selection_for_time_series_anomaly_detection	/pdf/484f608f2aeccc55b4d7725876912d26adf264ee.pdf
YxjfKeWjuQ9	1479	Adversarial perturbation based latent reconstruction for domain-agnostic self-supervised learning	['self-supervised learning', 'representation learning', 'domain-agnostic']		Unsupervised and Self-supervised learning	anonymous|adversarial_perturbation_based_latent_reconstruction_for_domainagnostic_selfsupervised_learning	/pdf/a409e06171238b45d3179c77a5ca534b4d0de2b1.pdf
tFvr-kYWs_Y	1480	On the Saturation Effect of Kernel Ridge Regression	['Kernel ridge regression', 'Saturation effect', 'Reproducing kernel Hilbert space', 'Learning theory']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_saturation_effect_of_kernel_ridge_regression	/pdf/f90cc2db35cc19e78cd57a1ee1c069c754474dbc.pdf
7t3ggLCjl7G	1481	When Do Models Generalize? A Perspective From Data-Algorithm Compatibility	['generalization', 'data-algorithm compatibility', 'early stopping', 'overparameterized linear regression']	We propose data-algorithm-compatibility to characterize generalization, and study it in the overparameterized linear regression regime.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|when_do_models_generalize_a_perspective_from_dataalgorithm_compatibility	/pdf/63b1f7841c9d5209fc1a5ad47309b1ce95cf1cfe.pdf
5udLUhg1E5	1483	Only For You: Deep Neural Anti-Forwarding Watermark Preserves Image Privacy	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|only_for_you_deep_neural_antiforwarding_watermark_preserves_image_privacy	/pdf/62f2fb227fc667749800d4a4ecbac864a7bec69d.pdf
qoSNQprgGDs	1484	The Geometry of Self-supervised Learning Models and its Impact on Transfer Learning	['Self-supervised learning', 'Transfer Learning', 'Graphs', 'Geometry', 'Embedding', 'Computer Vision']		Unsupervised and Self-supervised learning	anonymous|the_geometry_of_selfsupervised_learning_models_and_its_impact_on_transfer_learning	/pdf/3e1079bd22bc02a4bf0d5b2df17f3d0e7a54a6bd.pdf
p-N-CoSyszH	1485	Reach the Remote Neighbors: Dual-Encoding Transformer for Graphs	['konwledge graph prediction', 'node classification', 'graph property prediction', 'MSA Transformer']	A Transformer model for diverse graph representation learning tasks	Deep Learning and representational learning	anonymous|reach_the_remote_neighbors_dualencoding_transformer_for_graphs	/pdf/993d1a161b0c2c3f9819350f32d29a34a7de127a.pdf
o3du8VqB4wL	1487	Rethink Depth Separation with Intra-layer Links	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|rethink_depth_separation_with_intralayer_links	/pdf/2c348a444139efb2bd76a7af1e1630464efa9434.pdf
4Ff0zhHYxwl	1488	Model-Agnostic Meta-Attack: Towards Reliable  Evaluation of Adversarial Robustness	['Adversarial attacks', 'robust evaluation']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|modelagnostic_metaattack_towards_reliable_evaluation_of_adversarial_robustness	/pdf/2b8923f79332152185dc672d1722638b7e99a605.pdf
xQCk26Pp00	1489	Hazard Gradient Penalty for Survival Analysis	['survival analysis', 'gradient penalty', 'KL divergence']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|hazard_gradient_penalty_for_survival_analysis	/pdf/b31f37411e3ca5e4b184204c9a354d0c4b0581d1.pdf
020JErJMvVZ	1492	Learning Continuous Grasping Function with a Dexterous Hand from Human Demonstrations	['Dexterous Grasping', 'Implicit Function', 'Generative Model', 'Sim2Real']	We propose Continuous Grasping Function (CGF) to generate grasping motion for manipulation with a dexterous hand.	Generative models	anonymous|learning_continuous_grasping_function_with_a_dexterous_hand_from_human_demonstrations	/pdf/fe8b905f6e06714a0cf8a556d38ee543661d5b31.pdf
kkpL4zUXtiw	1493	Bi-level Physics-Informed Neural Networks for PDE Constrained Optimization using Broyden's Hypergradients	['PINN', 'machine learning', 'bi-level optimization']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|bilevel_physicsinformed_neural_networks_for_pde_constrained_optimization_using_broydens_hypergradients	/pdf/e5f66625d85e25d60548b31890c7dd53cea58598.pdf
kIPyTuEZuAK	1496	A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics	['Systematic Generalization', 'Concept Learning']	We take inspiration from arithmetic and present a new benchmark for studying systematic generalization of perception, syntax, and semantics.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|a_minimalist_dataset_for_systematic_generalization_of_perception_syntax_and_semantics	/pdf/4424f1e724fe2e7ba6cc6ba04869849428d04f72.pdf
-RwZOVybbj	1497	Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation	['Risk-Aware Reinforcement Learning', 'Coherent Risk Measures', 'Non-linear Function Approximation']	We propose a unified framework to analyze the regret of risk-aware RL policy that uses a coherent risk measure in conjunction with non-linear function approximation.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|riskaware_reinforcement_learning_with_coherent_risk_measures_and_nonlinear_function_approximation	/pdf/a67aa3b02e61b6739e78709b435e03f3f84691e9.pdf
rbHfqQ9T61E	1498	KITE: A Kernel-based Improved Transferability Estimation Method	['Transfer Learning', 'Transferability Estimation']	we propose a novel transferability estimation method, called KITE, for selecting the most effective pre-trained model for fine-tuning on a target dataset	Deep Learning and representational learning	anonymous|kite_a_kernelbased_improved_transferability_estimation_method	/pdf/657f7f14f445bc5630b636edac35ad2caa141004.pdf
Qx0vjIvlkev	1499	A Deep Dive into the Stability-Plasticity Dilemma in Class-Incremental Learning	['continual learning', 'class-incremental learning', 'analysis']		Deep Learning and representational learning	anonymous|a_deep_dive_into_the_stabilityplasticity_dilemma_in_classincremental_learning	/pdf/e8f48b5481e8fe7687d3dcea3d948b6407b511ef.pdf
go0P5gsBE2	1500	Rethinking Data Augmentation for Improving Transferable Targeted Attacks	['Data augmentation', 'Transferable targeted attacks']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|rethinking_data_augmentation_for_improving_transferable_targeted_attacks	/pdf/a2da16b43557173f048b3b36732e60fbeb127601.pdf
_g-D1zNps_	1501	FAIRER: Fairness as Decision Rationale Alignment	['Fairness', 'deep neural network', 'decision rationale alignment', 'neuron parity score']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fairer_fairness_as_decision_rationale_alignment	/pdf/346bceb31a46fc8ac1cc9eef6a202000e4016e02.pdf
uCNUPuhyuU	1502	Decoupled Mixup for Data-efficient Learning	['Data Augmentation', 'Mixup', 'Data-efficient Learning', 'Semi-supervised Learning']	This paper proposes a decoupled mixup (DM) loss that can adaptively mine discriminative features without losing smoothness and improve various mixup methods in a plug-and-play manner.	Deep Learning and representational learning	anonymous|decoupled_mixup_for_dataefficient_learning	/pdf/beb70e9109fe31860b590d8521f39ba360d4ba8f.pdf
kPHOmwdHHZX	1503	motifNet: Functional motif interactions discovered in mRNA sequences with implicit neural representation learning	['RNA motif', 'implicit neural representation', 'sequence generation']	we use position coordinates for mRNA sequences representation to extract important motif patterns and evaluate the patterns in diverse datasets.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|motifnet_functional_motif_interactions_discovered_in_mrna_sequences_with_implicit_neural_representation_learning	/pdf/06c3f4bdb65a5f59c6aa86ea61c5d403af74eebc.pdf
TKIFuQHHECj	1505	Can CNNs Be More Robust Than Transformers?	['CNNs', 'Transformers', 'Out-of-Distribution Robustness']	we show CNNs can be as robust as, or even more robust than, Transformers	Deep Learning and representational learning	anonymous|can_cnns_be_more_robust_than_transformers	/pdf/caf5fa04279c8ba8731fcb9863f315d242a82fe7.pdf
5i-n9TYb-xa	1506	Decoupled and Patch-based Contrastive Learning for Long-tailed Visual Recognition	['long-tailed', 'self distillation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|decoupled_and_patchbased_contrastive_learning_for_longtailed_visual_recognition	/pdf/27ab4700266f28c180352fe782ec9fd76a6717db.pdf
vSMubaJA1j	1507	Cascaded Teaching Transformers with Data Reweighting for Long Sequence Time-series Forecasting	['Teaching', 'Reweight', 'Time-series', 'Forecast']	Cascaded Teaching Trasnformers	Deep Learning and representational learning	anonymous|cascaded_teaching_transformers_with_data_reweighting_for_long_sequence_timeseries_forecasting	/pdf/7ed0d584749d364fb2410b2c7a85dad55807a07a.pdf
LlWfawcSpf	1510	MABA-Net: Masked Additive Binary Activation Network	['Binary Neural Networks', 'Quantization', 'Binarization']		Deep Learning and representational learning	anonymous|mabanet_masked_additive_binary_activation_network	/pdf/ea7eed05c4f7c724dbf6ca5857a8789ceb906dfc.pdf
15hYIH0TUi	1511	Neural Collaborative Filtering Bandits via Meta Learning	['Neural Contextual Bandit', 'Meta Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|neural_collaborative_filtering_bandits_via_meta_learning	/pdf/f7c33ac14abded0970e1c0e16c630822655d0a5f.pdf
RjsiAoZqN6	1512	Bridging attack and prompting: An Enhanced Visual Prompting at the pixel level	['prompting', 'adversarial machine learning', 'CLIP']	We design a novel and concise visual prompting method incorporating a simple and effective training strategy inspired from adversarial attack, and ourperform traditional linear probe in many scenarios.	Deep Learning and representational learning	anonymous|bridging_attack_and_prompting_an_enhanced_visual_prompting_at_the_pixel_level	/pdf/28f57eac86a061b9ebe043e57c43ad5bca73ba37.pdf
AsSdrNJ-DZG	1513	Sweet Gradient Matters: Designing Consistent and Efficient Estimator for Zero-Shot Neural Architecture Search	['Neural Architecture Search', 'Zero-Shot', 'Estimator', 'Sweet Gradient']	We observe Sweet Gradient and propose Sweetimator, a consistent and efficient performance estimator in Zero-Shot Neural Architecture Search.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sweet_gradient_matters_designing_consistent_and_efficient_estimator_for_zeroshot_neural_architecture_search	/pdf/6110fae9a022f43ed4db5756268969885d9d749e.pdf
muHaELT29WK	1514	Beyond Single Path Integrated Gradients for Reliable Input Attribution via Randomized Path Sampling	['Explainable AI', 'Input Attribution']	We propose a new attribution method by taking the expectation of path-integrated attribution by introducing efficient path sampling method.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|beyond_single_path_integrated_gradients_for_reliable_input_attribution_via_randomized_path_sampling	/pdf/f63a33cc8f81602d7925daa51c5cdb0cd8f0c473.pdf
dCwBpTXbfIq	1515	Identifying Weight-Variant Latent Causal Models	[]		Deep Learning and representational learning	anonymous|identifying_weightvariant_latent_causal_models	/pdf/6860e79a53f3592ea553aceba63a2ab1a77ffa9e.pdf
_Mic8V96Voy	1516	Eva: Practical Second-order Optimization with Kronecker-vectorized Approximation	['Deep learning', 'Second-order optimization', 'Approximation']	We propose an efficient approximation algorithm to accelerate second-order optimization for deep learning models. 	Optimization (eg, convex and non-convex optimization)	anonymous|eva_practical_secondorder_optimization_with_kroneckervectorized_approximation	/pdf/46eea93067f0ad2e2691d0f0910d78f619f076d8.pdf
Hnk1WRMAYqg	1517	Multimodal Federated Learning via Contrastive Representation Ensemble	['Federated Learning', 'Multi-modal Learning', 'Representation-level Ensemble Knowledge Transfer']	CreamFL, a multimodal FL framework using contrastive representation-level ensemble to learn a larger server model from heterogeneous clients across multi-modalities.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|multimodal_federated_learning_via_contrastive_representation_ensemble	/pdf/7442a390ae3995ac6e7f1547eee91cf6854aba8b.pdf
KAB29urre4C	1518	Style Spectroscope: Improve Interpretability and Controllability through Fourier Analysis	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|style_spectroscope_improve_interpretability_and_controllability_through_fourier_analysis	/pdf/cf0f0b9f0b52cad60e7d6c6738ba7b94216cfa3b.pdf
3F6I-0-57SC	1520	HiViT: A Simpler and More Efficient Design of Hierarchical Vision Transformer	['Hierarchical vision transformers', 'self-supervised learning', 'masked image modeling']	A novel hierarchical vision transformer that is stronger and faster when applied to masked image modeling	Unsupervised and Self-supervised learning	anonymous|hivit_a_simpler_and_more_efficient_design_of_hierarchical_vision_transformer	/pdf/15de24feac799a5997f57b81a92b22fb940e1d44.pdf
BSZN74xLdqn	1521	FedFA: Federated Learning with Feature Alignment for Heterogeneous Data	['Federated learning', 'feature alignment', 'data heterogeneity', 'heterogeneous label distribution', 'heterogeneous feature distribution']	A federated learning framework with feature alignment is proposed to tackle the data heterogeneity problem, including label and feature distribution skews across clients, from a novel perspective of shared feature space by feature anchors.	Deep Learning and representational learning	anonymous|fedfa_federated_learning_with_feature_alignment_for_heterogeneous_data	/pdf/49ff1d293f3beab188ee4a36ab094be6e29bd542.pdf
PUwbwZJz9dO	1522	Measuring and Narrowing the Compositionality Gap in Language Models	['language modeling', 'prompting', 'question answering', 'retrieval']	Language models can solve complex problems when you let them 'talk things through', our new 'self-ask' prompt improves their ability to do that, and lets us easily plug in a search engine for even better performance.	Deep Learning and representational learning	anonymous|measuring_and_narrowing_the_compositionality_gap_in_language_models	/pdf/da0106a9ac17edc14bc0bdcbffe2ce5a119e8a95.pdf
Y-J3jGFcnr4	1523	Schrödinger's FP: Training Neural Networks with Dynamic Floating-Point Containers	['Quantization', 'Hardware Acceleration', 'Deep Learning']	Reducing the training cost and time by learning and using, on-the-fly, shorter floating-point formats	Deep Learning and representational learning	anonymous|schrödingers_fp_training_neural_networks_with_dynamic_floatingpoint_containers	/pdf/f773cd1522182f773a2787e7584e4e5164c0a45f.pdf
fhKzTDDStdZ	1524	Exploring the Generalizability of CNNs via Activated Representational Substitution	['Deep Learning', 'Convolutional Neural Network', 'Generalizability']	We propose an metric named Activation Representation Substitution (ARS)  to explore the association between representations learned by convolution kernels and generalization.	Deep Learning and representational learning	anonymous|exploring_the_generalizability_of_cnns_via_activated_representational_substitution	/pdf/eedaed5229e5213c4c296edc9a63ab90cf317f85.pdf
G-dM79m_EXd	1525	Time Series Anomaly Detection via Hypothesis Testing for Dynamical Systems	['anomaly detection', 'dynamical system', 'hypothesis testing']	We tackle the problem of anomaly detection in dynamical systems from the perspective of hypothesis testing and propose a new algorithm.	Applications (eg, speech processing, computer vision, NLP)	anonymous|time_series_anomaly_detection_via_hypothesis_testing_for_dynamical_systems	/pdf/1acada113f2df22affba236be2eaadf0766f2d04.pdf
RlCa0pFZsR9	1526	Benchmarking Encoder-Decoder Architectures for Biplanar X-ray to 3D Bone Shape Reconstruction	['2D-3D Reconstruction', 'Object Reconstruction', 'Medical Applications', 'Encoder-Decoder Architectures']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|benchmarking_encoderdecoder_architectures_for_biplanar_xray_to_3d_bone_shape_reconstruction	/pdf/b4adfca54494717053f3662eb535f6acd40cce2f.pdf
IJwkJCFQ9EJ	1528	Fast 6D Object Pose Refinement via Implicit Surface Representation Driven Optimization	['Signed Distance Field', '6D pose refinement', 'Implicit neural network', 'ICP']	In this paper, we propose a simple yet efficient self-supervised point cloud aligenment method via implicit neural network, which can serve as an alternative of ICP to achieve fast and accurate pose refinement.	Applications (eg, speech processing, computer vision, NLP)	anonymous|fast_6d_object_pose_refinement_via_implicit_surface_representation_driven_optimization	/pdf/7cfe9f9dbef6d81825a9fbe6c8f0b531412f9af4.pdf
nMwFhKoAo5v	1529	ContraGen: Effective Contrastive Learning For Causal Language Model	['Natural Language Processing', 'Contrastive Learning', 'Causal Language Model', 'Natural Language Generation and Discrimination', 'Code Generation and Discrimination']	An effective contrastive learning approach that enhances both the generation and discrimination capability of causal language models	Applications (eg, speech processing, computer vision, NLP)	anonymous|contragen_effective_contrastive_learning_for_causal_language_model	/pdf/e0c39703c90c4c6482ac9c42291a2f9526f33d77.pdf
5DKHY-Ag62E	1530	Distributionally Robust Model-Based Offline Reinforcement Learning with Near-Optimal Sample Complexity	['offline reinforcement learning', 'distributional robustness', 'model-based reinforcement learning']	This paper provides the first provably near-optimal robust offline RL algorithm that learns under model uncertainty and partial coverage.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|distributionally_robust_modelbased_offline_reinforcement_learning_with_nearoptimal_sample_complexity	/pdf/fb905ddf0df01a40df15bd31472c5cbaeaf03f6c.pdf
0KfAZAyClG1	1531	Why pseudo-label based algorithm is effective? --from the perspective of  pseudo-labeled data	['pseudo-label based algorithm', 'semi-supervised learning']	Theoretical analysis of the superiority of pseudo-label based semi-supervised learning algorithm --from the perspective of  pseudo-labeled data	Unsupervised and Self-supervised learning	anonymous|why_pseudolabel_based_algorithm_is_effective_from_the_perspective_of_pseudolabeled_data	/pdf/95e0d6fb9cf5f161a9c0286dd0ff9bdf2169604b.pdf
Mvetq8DO05O	1532	A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|a_laplaceinspired_distribution_on_so3_for_probabilistic_rotation_estimation	/pdf/bdda66ef68611e3d6b1d72c822a3dfcbec317d35.pdf
OTIhUlChVaT	1533	Generative Multi-Flow Networks: Centralized, Independent and Conservation	['GFlowNets', 'Multi-Flow']	Generative Multi-Flow Networks	Generative models	anonymous|generative_multiflow_networks_centralized_independent_and_conservation	/pdf/36e73dd04f8cde5d1e7e60fd900922f0323d4a2d.pdf
6Ysgo5RXUvn	1534	DSPNet: Towards Slimmable Pretrained Networks based on Discriminative Self-supervised Learning	['Self-supervised Learning', 'Dynamic Neural Networks', 'Knowledge Distillation']		Unsupervised and Self-supervised learning	anonymous|dspnet_towards_slimmable_pretrained_networks_based_on_discriminative_selfsupervised_learning	/pdf/a01573fdd29b95e724a14a457f496806af3d86c5.pdf
AtyO3IZYVEy	1535	HagSeg: Hardness-adaptive Guidance for Semi-supervised Semantic Segmentation	['Semi-supervised', 'Semantic Segmentation', 'Hardness-adaptive guidance']	A instance-specific and hardness-adaptive SSS framework	General Machine Learning (ie none of the above)	anonymous|hagseg_hardnessadaptive_guidance_for_semisupervised_semantic_segmentation	/pdf/9ab88ae116939903927b85b6e42661435b0e8420.pdf
gfr5yILQc7_	1536	MQSP: Micro-Query Sequence Parallelism for Linearly Scaling Long Sequence Transformer	['Sequence parallelism', 'Long Sequence Transformer', 'Distributed training']	MQSP is a novel sequence parallelism that linearly scales long sequence Transformers through all-gathering Micro-Q.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|mqsp_microquery_sequence_parallelism_for_linearly_scaling_long_sequence_transformer	/pdf/c63c3f318d3bfd8df9e0f01d60f055b12c12c3a2.pdf
djpsp_fSf2G	1537	MANDERA: Malicious Node Detection in Federated Learning via Ranking	['Federated Learning', 'Byzantine attack', 'malicious node detection', 'ranking']	We propose a statistically sound way to detect the malicious nodes in Federated Learning.	General Machine Learning (ie none of the above)	anonymous|mandera_malicious_node_detection_in_federated_learning_via_ranking	/pdf/c8e36047d7b3f2ee165f39eb2863ece181779384.pdf
NHfSJAWhKTw	1538	A Closer Look at Self-supervised Lightweight Vision Transformers	['Self-supervised Learning', 'Vision Transformers', 'Lightweight Networks']		Unsupervised and Self-supervised learning	anonymous|a_closer_look_at_selfsupervised_lightweight_vision_transformers	/pdf/0baba70e4a863ec5890da57bdb0e7cdb9c9cdda4.pdf
V_V53-WG9m6	1539	Cross-modal Graph Contrastive Learning with Cellular Images	['Celluar Image', 'Drug discovery', 'Graph neural networks', 'Self-supervised learning', 'Cross-modal learning']	We propose using high-content cell images to assist learning molecular representation in a cross-modal framwork.	Applications (eg, speech processing, computer vision, NLP)	anonymous|crossmodal_graph_contrastive_learning_with_cellular_images	/pdf/b14a8ed5db67ac788e624a1cee176d7f2185e178.pdf
3wCqIZivcJx	1540	Quark: A Gradient-Free Quantum Learning Framework for Classification Tasks	['Quantum Computing', 'Deep Learning', 'Quantum Machine Learning']	A new quantum learning framework for classification task	General Machine Learning (ie none of the above)	anonymous|quark_a_gradientfree_quantum_learning_framework_for_classification_tasks	/pdf/b7d3ba40a51fc4c0d8b270016e66775465014a58.pdf
f25VGPzATcn	1541	A Causal Approach to Detecting Multivariate Time-series Anomalies and Root Causes	['time series', 'anomaly detection', 'root cause analysis', 'causality']	A causality-based approach for anomaly detection and root cause analysis	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_causal_approach_to_detecting_multivariate_timeseries_anomalies_and_root_causes	/pdf/2ee8939ab96896f6023fdb410031514fc364e4ad.pdf
q23TzayryBG	1542	MAFormer: A Transformer Network with Multi-scale Attention Fusion for Visual Recognition	[]		Deep Learning and representational learning	anonymous|maformer_a_transformer_network_with_multiscale_attention_fusion_for_visual_recognition	/pdf/0902b71268283205474b532b06bc41a0170121db.pdf
SlzEll3EsKv	1543	Analyzing the Latent Space of GAN through Local Dimension Estimation	['generative adversarial network', 'disentanglement', 'semantic factorization', 'dimension estimation', 'grassmannian']	We analyze the latent space of GAN through local dimension estimation and propose a global disentanglement metric called Distortion.	Generative models	anonymous|analyzing_the_latent_space_of_gan_through_local_dimension_estimation	/pdf/46c431a715ed2acf03a32958b7f9bc24acb27107.pdf
3S62EPkO7k-	1544	DSP: Dynamic Semantic Prototype for Generative Zero-Shot Learning	['Zero-Shot Learning', 'Generative Model', 'Knowledge Transfer']	Dynamic Semantic Prototype should be Considered in Generative Zero-Shot Learning	Deep Learning and representational learning	anonymous|dsp_dynamic_semantic_prototype_for_generative_zeroshot_learning	/pdf/bfe141f81395515f8240825e1ec6f0e7ed8a2164.pdf
h8T5dZWTZ-Z	1546	Basic Binary Convolution Unit for Binarized Image Restoration Network	['Imgae Restoration； Low-Level Vision']	We reconsider the components in BNNs and design a strong, simple and efficient baisc binary convolution unit.	Applications (eg, speech processing, computer vision, NLP)	anonymous|basic_binary_convolution_unit_for_binarized_image_restoration_network	/pdf/fb1f0d9f503c9b3208dae44b14ed0489a6729bc1.pdf
NpZ7TIs6ws	1547	Defense against Backdoor Attacks via Identifying and Purifying Bad Neurons	['backdoor defense', 'security', 'neuron importance evaluation']	We design a backdoor defense method that identifies and purifies the backdoored neurons of victim models with a novel yet effective metric called benign salience.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|defense_against_backdoor_attacks_via_identifying_and_purifying_bad_neurons	/pdf/8a874312d1ca65be15ed3b89ef9e8fcc7630e395.pdf
t1N05TtC7CM	1548	MAT: Mixed-Strategy Game of  Adversarial Training in Fine-tuning	['natural language processing', 'adversarial training', 'mixed-strategy game', 'fine-tuning']	We generalize fine-tuning adversarial training to a mixed-strategy game.	Deep Learning and representational learning	anonymous|mat_mixedstrategy_game_of_adversarial_training_in_finetuning	/pdf/b36722dcd2788a0bfdcbeff697cf3d99b6dd5ec6.pdf
M9u_ctqFUlg	1549	Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models	[]		Generative models	anonymous|deep_generative_modeling_on_limited_data_with_regularization_by_nontransferable_pretrained_models	/pdf/14ee40f08568c4dba6f6a3b5685e9474567f9149.pdf
7GEvPKxjtt	1550	Towards Robustness Certification Against Universal Perturbations	['Universal Perturbation', 'Adversarial Attack', 'Backdoor Attack', 'Certified Robustness', 'Poisoning Attack']	A robustness certification framework against universal perturbations (including both universal adversarial noise and backdoor attacks).	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_robustness_certification_against_universal_perturbations	/pdf/005cefb500e6d1f364ad5df5d26e3c63a0d49911.pdf
BCfxM1tR8E	1551	Exploring interactions between modalities for deepfake detection	['cross-modality representation learning', 'inconsistency representation', 'interaction']		Deep Learning and representational learning	anonymous|exploring_interactions_between_modalities_for_deepfake_detection	/pdf/2f456c5f9ed54d6e57ba6dbd14f07764e94cdbbc.pdf
X2Dbqvfx-NI	1552	Bag of Tricks for FGSM Adversarial Training 	['adversarial training']	We provide the first study, which thoroughly examines a collection of tricks, to overcome the catastrophic overfitting in FGSM-AT.	Deep Learning and representational learning	anonymous|bag_of_tricks_for_fgsm_adversarial_training	/pdf/81b19201abdc78ae539a2dd8059a227ab504920c.pdf
Rq13idF0F73	1553	Molecule Generation For Target Protein Binding with Structural Motifs	['Structure-based Drug Design']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|molecule_generation_for_target_protein_binding_with_structural_motifs	/pdf/3ff151598249cbe7a324cb31d47038d64b8a0b8f.pdf
4NWwhku4AEI	1554	Robust Learning with Decoupled Meta Label Purifier	['Learning with Noisy labels', 'Decoupled Optimization', 'Meta Learning']	A method that decouples the label purification process into label-free representation learning and a simple meta label purifier.	Deep Learning and representational learning	anonymous|robust_learning_with_decoupled_meta_label_purifier	/pdf/55633e485f6c7825b0b4e4069aeb13e8036a5b90.pdf
_9k5kTgyHT	1555	Globally Optimal Training of Neural Networks with Threshold Activation Functions	['Convex optimization', 'Lasso', 'threshold activation', 'binary activation', 'quantization', 'neural networks']	We show that training problem of regularized deep neural networks with threshold activations can be equivalently formulated as a standard convex optimization problem, which parallels the LASSO method.	Optimization (eg, convex and non-convex optimization)	anonymous|globally_optimal_training_of_neural_networks_with_threshold_activation_functions	/pdf/ac68077dc248cb4c7f52c884662112870b3b4aa5.pdf
cgUFZvSEXG	1556	Path Regularization: A Convexity and Sparsity Inducing Regularization for Parallel ReLU Networks	['Convex optimization', 'deep learning theory', 'path norm', 'group sparsity', 'polynomial-time training', 'ReLU networks', 'parallel architectures', 'global optimality', 'computational complexity']	We introduce a convex analytic framework to unveil a hidden convex optimization landscape for training path regularized deep neural networks.	Optimization (eg, convex and non-convex optimization)	anonymous|path_regularization_a_convexity_and_sparsity_inducing_regularization_for_parallel_relu_networks	/pdf/6281f9e5a1bd4c23c5873d03a8bbe60e950116a5.pdf
KnqaT58PV7	1558	Federated Semi-supervised Learning with Dual Regulator	['federated learning', 'semi-supervised learning', 'dual regulator', 'class imbalance']		Unsupervised and Self-supervised learning	anonymous|federated_semisupervised_learning_with_dual_regulator	/pdf/0d7f3034ccc93766a5e910d12104301a5890ada9.pdf
VpwAo8rHDi	1559	On Fairness Measurement for Generative Models	['Fairness', 'Generative models', 'GAN']		Generative models	anonymous|on_fairness_measurement_for_generative_models	/pdf/edfee01dd0f2b3a88a2cbd17578f737fc1f5bf21.pdf
xQdweNAgel	1560	Synergistic Neuromorphic Federated Learning with ANN-SNN Conversion For Privacy Protection	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|synergistic_neuromorphic_federated_learning_with_annsnn_conversion_for_privacy_protection	/pdf/eb7d80e669d69f5e3e38a5b05561a8e156289e69.pdf
svP7EgyDcx	1561	Protective Label Enhancement for Label Privacy	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|protective_label_enhancement_for_label_privacy	/pdf/3aed2f8745d4571cf0b66947f5666e2f4125c6be.pdf
FMEXgK9-I8	1562	E$^2$: Entropy Discrimination and Energy Optimization for Source-free Universal Domain Adaptation	['Domain Adaptation', 'Confidence-guided Entropy', 'Energy-based Model']	This paper presents a novel source-free universal domain adaptation method by combining two innovative components of confidence-guided Entropy discrimination and likelihood-induced Energy optimization.	Unsupervised and Self-supervised learning	anonymous|e^2_entropy_discrimination_and_energy_optimization_for_sourcefree_universal_domain_adaptation	/pdf/9285f673d7b0d04cb1d04e45b392d4fd59cd9012.pdf
v69itrHLEu	1563	Outcome-directed Reinforcement Learning by Uncertainty \& Temporal Distance-Aware Curriculum Goal Generation	['Curriculum Learning', 'Outcome-directed RL', 'Goal-conditioned RL']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|outcomedirected_reinforcement_learning_by_uncertainty_\_temporal_distanceaware_curriculum_goal_generation	/pdf/464cd4a70c7b11fa3e7eaafe17bb511e832d0e54.pdf
xQXHkKI_7TG	1564	Local Coefficient Optimization in Federated Learning	['Federated Learning', 'Bilevel optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|local_coefficient_optimization_in_federated_learning	/pdf/36e4e6fc1c114ea69d773a170dd3f35b78328f13.pdf
S31oTB72m0G	1566	Provable Sim-to-real Transfer in Continuous Domain with Partial Observations	['sim-to-real', 'RL theory', 'partial observations']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|provable_simtoreal_transfer_in_continuous_domain_with_partial_observations	/pdf/b90698939b50ed94a2148d5b2c6aac83929dde4f.pdf
QwFw-CcUb10	1568	Self-Architectural Knowledge Distillation for Spiking Neural Networks	['Spiking Neural Networks', 'Knowledge Distillation', 'Neural Architecture Search']	We propose a Self-Architectural Knowledge Distillation framework (SAKD), which matches the knowledge (i.e., the features and logits) of ANNs to that of SNNs with the same architecture. 	Deep Learning and representational learning	anonymous|selfarchitectural_knowledge_distillation_for_spiking_neural_networks	/pdf/bc5072da06f28d57856943d1f8a3e7609eafc85b.pdf
kBR2bM0tmwe	1569	Learning large-scale Kernel Networks	['Kernel machines', 'RBF networks', 'large-scale datasets', 'data augmentation']	A new scalable algorithm for training kernel networks (generalization of RBF networks)	General Machine Learning (ie none of the above)	anonymous|learning_largescale_kernel_networks	/pdf/74c2feff73fbf11ec029ba428f376423de7d025b.pdf
5uH745DalVx	1571	CooPredict : Cooperative Differential Games For Time Series Prediction	['time series forecasting', 'time series prediction', 'neural stochastic differential equations', 'cooperative differential game']	We proposed a novel framework on time series prediction as an application of cooperative differential games. 	General Machine Learning (ie none of the above)	anonymous|coopredict_cooperative_differential_games_for_time_series_prediction	/pdf/af22e4c5f78b1d8359e23ed7fa2b5133ddd99589.pdf
hPRxEcEZJyp	1572	Gated Domain Units for Multi-source Domain Generalization	['Robust machine learning', 'domain generalization', 'out-of-distribition generalization', 'kernel theory', 'distribution shift', 'deep learning']		General Machine Learning (ie none of the above)	anonymous|gated_domain_units_for_multisource_domain_generalization	/pdf/493488cfa77458fa61ef1528c7e22f13a93276a2.pdf
dSYoPjM5J_W	1573	Revisiting Graph Adversarial Attack and Defense From a Data Distribution Perspective	['Graph Adversarial Attack', 'Robustness', 'Data Distribution']	We revisit graph adversarial attack and defense from a data distribution perspective.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revisiting_graph_adversarial_attack_and_defense_from_a_data_distribution_perspective	/pdf/c39f3723987f7a4d257a7f8d33fd77b92d0068f5.pdf
DH4v0nW7yJ	1574	Curved Representation Space of Vision Transformers	['Vision transformers', 'representation space', 'robustness', 'calibration', 'decision boundary']	We analyze how the representation space of Transformers is shaped, based on which their characteristics in terms of adversarial robustness, model calibration, and difficulty of training are explained.	Deep Learning and representational learning	anonymous|curved_representation_space_of_vision_transformers	/pdf/de4dc1ce0621126926171470e2891cf8ddbc97b3.pdf
zgYefCxXmQe	1575	TCFimt: Temporal Counterfactual Forecasting from Individual Multiple Treatment Perspective	['causal inference', 'balanced representation', 'temporal prediction']	We propose a new method to forecast future outcomes given multiple treatments in a counterfactual fashion.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|tcfimt_temporal_counterfactual_forecasting_from_individual_multiple_treatment_perspective	/pdf/e18544a7ccc7f1152794024cebeef8b49d43130c.pdf
jh9nlYWJ5kk	1576	Improving Adversarial Transferability with Worst-case Aware Attacks	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|improving_adversarial_transferability_with_worstcase_aware_attacks	/pdf/b44072ccd4b37dfcff68a04051f49a23a914ca82.pdf
GNFimGDfEiV	1577	Quadratic models for understanding neural network dynamics	['quadratic models', 'wide neural networks', 'catapult phase', 'optimization dynamics']	Quadratic models capture properties of wide neural networks in both optimization and generalization.  	Deep Learning and representational learning	anonymous|quadratic_models_for_understanding_neural_network_dynamics	/pdf/5fb6346bf737531de18e2cda81b38c2aa9e89aaa.pdf
TD7AnQjNzR6	1578	Statistical Efficiency of Score Matching: The View from Isoperimetry	['score matching', 'log-Sobolev inequality', 'isoperimetry', 'relative efficiency', 'sample complexity']	We show a tight connection between the statistical efficiency of score matching and the isoperimetric properties (e.g. log-Sobolev constant) of the distribution being estimated	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|statistical_efficiency_of_score_matching_the_view_from_isoperimetry	/pdf/46151eb0bb915f13b79049d1335bda83658ad870.pdf
Oys81jfesjQ	1579	Simultaneously Learning Stochastic and Adversarial Markov Decision Process with Linear Function Approximation	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|simultaneously_learning_stochastic_and_adversarial_markov_decision_process_with_linear_function_approximation	/pdf/1bc9d1fe5e9c375bee99b8020d08d3ace5e1403f.pdf
g77JafrHWyy	1580	Ranking-Enhanced Unsupervised Sentence Representation Learning	['Unsupervised Sentence Embedding', 'Sentence Embedding', 'Semantic Textual Similarity', 'Natural Language Processing']		Applications (eg, speech processing, computer vision, NLP)	anonymous|rankingenhanced_unsupervised_sentence_representation_learning	/pdf/6d96c126bfd8169fbd31a8db5e65c7e39af3bfce.pdf
3mRwyG5one	1581	DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection	['Object Detection', 'Detection Transformer', 'End-to-End Detector']	We present a state-of-the-art end-to-end object detector, the first DETR-like model on top of the COCO detection leader board.	Deep Learning and representational learning	anonymous|dino_detr_with_improved_denoising_anchor_boxes_for_endtoend_object_detection	/pdf/8a2fd31e70273b9b249c634427f0b29203b8597d.pdf
de-_FHXQ4--	1582	Communication-Efficient Federated Learning with Accelerated Client Gradient	['Federated learning', 'Data heterogeneity', 'Deep Neural Networks', 'Distributed Optimization']	We present, FedACG, a novel federated learning framework which reduce the gap between global and local losses by incorporating the global momentum to guide client updates.	General Machine Learning (ie none of the above)	anonymous|communicationefficient_federated_learning_with_accelerated_client_gradient	/pdf/d1277c6cbd2cdedb780a038cd209a716825798a0.pdf
5RxmkAFVs_V	1583	Progressive Image Synthesis from Semantics to Details with Denoising Diffusion GAN	['Image generation', 'GANs', 'diffusion model', 'progressive generation']	We propose a novel progressive method for image synthesis from semantics to details with diffusion denoising GAN.	Generative models	anonymous|progressive_image_synthesis_from_semantics_to_details_with_denoising_diffusion_gan	/pdf/957099cc9e1a68397e30f13698bec744060ba8ce.pdf
LnQn5-rN-LR	1584	HIVE: HIerarchical Volume Encoding for Neural Implicit Surface Reconstruction	['neural implicit surface reconstruction', 'multi-view surface reconstruction', 'hierarchical volume encoding']		Applications (eg, speech processing, computer vision, NLP)	anonymous|hive_hierarchical_volume_encoding_for_neural_implicit_surface_reconstruction	/pdf/8e1f929caee3c635162d88663bb91ef8004b069b.pdf
h-UkhDzFFj	1585	Geo-NN: An End-to-End Framework for Geodesic Mean Estimation on the Manifold of Symmetric Positive Definite Matrices	['Symmetric Postive Definite Manifolds', 'Geodesic Mean', 'Matrix Autoencoder']	We propose an end-to-end deep learning framework, the Geo-NN, to efficiently compute the geodesic mean of a collection of matrices lying on the SPD manifold	General Machine Learning (ie none of the above)	anonymous|geonn_an_endtoend_framework_for_geodesic_mean_estimation_on_the_manifold_of_symmetric_positive_definite_matrices	/pdf/3507466fb61e583e01defd350733e81f4fe5d079.pdf
VB75Pi89p7	1587	BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers	[]		Unsupervised and Self-supervised learning	anonymous|beit_v2_masked_image_modeling_with_vectorquantized_visual_tokenizers	/pdf/86fe619d36285a3a241463524abdd0ce2b49185b.pdf
CMsuT6Cmfvs	1588	Lifting the Curse of Capacity Gap in Distilling Large Language Models	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|lifting_the_curse_of_capacity_gap_in_distilling_large_language_models	/pdf/d0012f6b6a3c93f8d0955c0d57234c1d248e9ed2.pdf
YEVJI3Uqkux	1589	AutoDisc: Automatic Distillation Schedule for Large Language Model Compression	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|autodisc_automatic_distillation_schedule_for_large_language_model_compression	/pdf/8c8a8aa7fb5177ea708b96d585575e8a7a37ce63.pdf
UO8UP_xDMwD	1590	Understanding Catastrophic Overfitting in Fast Adversarial Training From a Non-robust Feature Perspective	['Fast Adversarial Training', 'Catastrophic Overfitting', 'Non-robust Feature']	We provide a new perspective on catastrophic overfitting in fast adversarial training	Deep Learning and representational learning	anonymous|understanding_catastrophic_overfitting_in_fast_adversarial_training_from_a_nonrobust_feature_perspective	/pdf/ddaf372f3256d614477dde85fe6957b9aabe9f13.pdf
YdFkY-QHkPl	1591	Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup	['mixup', 'data augmentation', 'theory', 'optimization', 'multi-view', 'feature learning', 'generalization', 'deep learning']	Mixup with appropriate hyperparameters can learn multiple predictive features for each class in a dataset, even when empirical risk minimization fails to do so.	Deep Learning and representational learning	anonymous|provably_learning_diverse_features_in_multiview_data_with_midpoint_mixup	/pdf/aa25f0a37604d6d3b1f153d01de77dad6a8d1829.pdf
vfa7--yvtYh	1592	Generative Recorrupted-to-Recorrupted: An Unsupervised Image Denoising Network for Arbitrary Noise Distribution	['Image denoising', 'Unsupervised', 'Deep learning']		Deep Learning and representational learning	anonymous|generative_recorruptedtorecorrupted_an_unsupervised_image_denoising_network_for_arbitrary_noise_distribution	/pdf/7db988f7e6c60fd046a94ef72c948a8abdfe667e.pdf
TMnxVoWdX_M	1593	A Closer Look at Dual Batch Normalization and Two-domain Hypothesis In Adversarial Training With Hybrid Samples	['Adversarial training', 'batch normalization']		Deep Learning and representational learning	anonymous|a_closer_look_at_dual_batch_normalization_and_twodomain_hypothesis_in_adversarial_training_with_hybrid_samples	/pdf/7cee244391ab18e951dc036f81715c039076a793.pdf
1mU6ADbjk-c	1594	Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions	['survival analysis', 'sieve method', 'theory']	A flexible framework of neural survival regression with provable statistical guarantees	General Machine Learning (ie none of the above)	anonymous|neural_frailty_machine_beyond_proportional_hazard_assumption_in_neural_survival_regressions	/pdf/1a99ddb0d62cbf76a2d0437bfc6735e77a8ec3f9.pdf
2VWa8qj2vd0	1595	Linear Video Transformer with Feature Fixation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|linear_video_transformer_with_feature_fixation	/pdf/10c5b95412d6ad37378de54a1ba156c7894e5c7e.pdf
jAsM_UoXUeP	1596	Grouped self-attention mechanism for a memory-efficient Transformer	['time-series data', 'Transformer', 'memory-efficient structure', 'self-attention', 'computational and space complexity', 'long-range dependency']	We proposed Grouped Self-Attention (GSA) and Compressed Cross-Attention (CCA) modules to solve the quadratic order problem on self-attention mechanism of Transformer.	Deep Learning and representational learning	anonymous|grouped_selfattention_mechanism_for_a_memoryefficient_transformer	/pdf/884de000c569b753bf4d52e09fc4627f581a08c7.pdf
pjyM7D09M5	1597	On the Necessity of Disentangled Representations for Downstream Tasks	['representation disentanglement', 'representation learning downstream task']	We show that dimension-wise disentangled representations are not necessary for downstream tasks using deep neural networks with learned representations as input. 	Deep Learning and representational learning	anonymous|on_the_necessity_of_disentangled_representations_for_downstream_tasks	/pdf/538b4222fd8ec16a8c309ddcc8b23d18c5749ece.pdf
tG6xz50IHMD	1598	Towards the gradient adjustment by loss status for Neural Network Optimization	[]		Optimization (eg, convex and non-convex optimization)	anonymous|towards_the_gradient_adjustment_by_loss_status_for_neural_network_optimization	/pdf/44f1974f6ae66b72c076d367647f41c844f1a83d.pdf
iV9Cs8s8keU	1599	Learning the Positions in CountSketch	['learning-augmented sketches', 'count-sketch', 'low-rank approximation', 'iterative Hessian sketch']	We propose the first learning-based algorithms that also optimize the locations of the non-zero entries of CountSketch matrix.	Optimization (eg, convex and non-convex optimization)	anonymous|learning_the_positions_in_countsketch	/pdf/9bab9f5bdc2c8baacabfc57f4510752192229212.pdf
z9FyE7jHXkN	1600	Environment Partitioning For Invariant Learning By Decorrelation	['OOD Generalization', 'IRM', 'Environment Partitioning', 'Decorrelation']	A method Decorr that does algorithmic environment partitioning and makes IRM more generally applicable.	Deep Learning and representational learning	anonymous|environment_partitioning_for_invariant_learning_by_decorrelation	/pdf/141155f29371ff1590ef626f62f46eac077b90a1.pdf
YfwMIDhPccD	1601	GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis	['Talking Face Generation', 'Neural Radiance Field']		Applications (eg, speech processing, computer vision, NLP)	anonymous|geneface_generalized_and_highfidelity_audiodriven_3d_talking_face_synthesis	/pdf/d8388e9ba2258f338501e757075f93ed438b1f95.pdf
PTUcygUoxuc	1602	Recursion of Thought: Divide and Conquer Reasoning with Language Models	['reasoning', 'language models', 'chain of thought']	We unleash the reasoning capability of language models, which has been constrained by the maximum size of a single context, by letting them recursively create and utilize multiple contexts.	General Machine Learning (ie none of the above)	anonymous|recursion_of_thought_divide_and_conquer_reasoning_with_language_models	/pdf/1b27738a71f966e8812da33e47318fc63a67ff27.pdf
ZAKkiVxiAM9	1603	Masked Unsupervised Self-training for Label-free Image Classification 	['zero-shot classification', 'unsupervised learning', 'self-training', 'CLIP', 'masked image modeling']	We propose a new label-free classification method which significantly improves upon CLIP by unsupervised adaptation.	Unsupervised and Self-supervised learning	anonymous|masked_unsupervised_selftraining_for_labelfree_image_classification	/pdf/328502382f2f1da597c8e5ba57ffd4fe3c2428ef.pdf
NnOZT_CR26Z	1604	GoBigger: A Scalable Platform for Cooperative-Competitive Multi-Agent Interactive Simulation	['Reinforcement Learning', 'Environment', 'Cooperation', 'Competition', 'Scalable']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|gobigger_a_scalable_platform_for_cooperativecompetitive_multiagent_interactive_simulation	/pdf/3d5acf4551d492dbe8f2d4da562716e1800a6b2f.pdf
iQYFdEL6KeS	1605	Enhancement and Numerical Assessment of Novel SARS-CoV-2 Virus Transmission Model	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|enhancement_and_numerical_assessment_of_novel_sarscov2_virus_transmission_model	/pdf/0dc89e1c527f6bf3fb6dbbaf004037a2438b9b21.pdf
MkbcAHIYgyS	1606	Mass-Editing Memory in a Transformer	['language models', 'GPT', 'transformers', 'model editing', 'factual associations', 'memory']	An algorithm that can make tens of thousands of edits to an autoregressive transformer's memory.	Applications (eg, speech processing, computer vision, NLP)	anonymous|massediting_memory_in_a_transformer	/pdf/6c4493398a88b43ea2a480f110e4d02f7ea02b07.pdf
YmVcNC2oCzq	1607	Transmission Dynamics of Hepatitis B: Analysis and Control	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|transmission_dynamics_of_hepatitis_b_analysis_and_control	/pdf/a7b599bfa251e5c214cd036972abbe9901af1b4f.pdf
gcjxr_g48GU	1608	LPMARL: Linear Programming based Implicit Task Assignment for Hierarchical Multi-agent Reinforcement Learning	['Linear programming', 'Multi-agent reinforcement learning', 'Hierarchical multi-agent reinforcement learning', 'Implicit deep learning']	Linear programming-based optimal agent-task allocation for hierarchical multi-agent reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|lpmarl_linear_programming_based_implicit_task_assignment_for_hierarchical_multiagent_reinforcement_learning	/pdf/e1bf959b50751f6deb135e9485bc7a4bd5d1aeb0.pdf
UFaOH39SZ4y	1609	Monkeypox with Cross Infection Hypothesis via Epidemiological Mode	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|monkeypox_with_cross_infection_hypothesis_via_epidemiological_mode	/pdf/1145562513cc187acaca0ec9581f45577bdb9b9d.pdf
cALu06i7JJH	1610	Holding Monotonic Improvement and Generality for Multi-Agent Proximal Policy Optimization	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|holding_monotonic_improvement_and_generality_for_multiagent_proximal_policy_optimization	/pdf/98acc1dc85cb028307cf68706eb8edc49108cd5c.pdf
1fZd4owfJP6	1611	Masked Image Modeling with Denoising Contrast	['masked image modeling', 'self-supervised learning', 'image pre-training']	We first treat masked patch prediction as denoising contrastive learning in self-supervised image pre-training, achieving state-of-the-art results.	Unsupervised and Self-supervised learning	anonymous|masked_image_modeling_with_denoising_contrast	/pdf/9d559f7da93db56c092088949d142748121ba704.pdf
pf8RIZTMU58	1612	DepthFL : Depthwise Federated Learning for Heterogeneous Clients	['Federated Learning', 'Heterogeneity']	DepthFL is a new federated learning framework based on depth scaling to tackle system heterogeneity.	Deep Learning and representational learning	anonymous|depthfl_depthwise_federated_learning_for_heterogeneous_clients	/pdf/c484f56fc56f778b641c3cc634ba535012569c05.pdf
AcyZ0Q5p6G8	1613	Learning in Compressed Domain via Knowledge Transfer	['compressed-domain vision', 'image compression', 'knowledge transfer']	We propose learning in compressed domain by transferring the knowledge learned in pixel domain.	Deep Learning and representational learning	anonymous|learning_in_compressed_domain_via_knowledge_transfer	/pdf/8d0c92502ff4a2afa6e04d4d23efb14bbb2272cb.pdf
U9FkAFUBzu2	1614	MAGA: Modeling a Group Action	['Generative Model', 'Generalization', 'Deep Learning', 'Representation Learning']	We make a new generative model that is capable of combinatorial generalization.	Deep Learning and representational learning	anonymous|maga_modeling_a_group_action	/pdf/7e2b3a3942f820f21d0492ac7a61aea2366eec8d.pdf
OSS-yWzE9Yu	1615	HRBP: Hardware-friendly Regrouping towards Block-wise Pruning for Sparse Training	['efficient training', 'sparse training', 'fine-grained structured sparsity', 'grouping algorithm']	This paper proposes a novel block-wise pruning algorithm, which accelerates the sparse training of convolutional neural networks at both forward and backward pass. 	Deep Learning and representational learning	anonymous|hrbp_hardwarefriendly_regrouping_towards_blockwise_pruning_for_sparse_training	/pdf/54e15de4f334b16e6b88c61a2607989c1392030e.pdf
XKHNu4OF6wn	1616	Node-Level Membership Inference Attacks Against Graph Neural Networks	['Graph Neural Network', 'Membership Inference Attack']	We perform the first comprehensive analysis of node-level membership inference attacks against GNNs.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|nodelevel_membership_inference_attacks_against_graph_neural_networks	/pdf/4ef4b0be5a644550b082df9bcf417a00a053e0e5.pdf
5gri-cs4RVq	1617	Do We Need Neural Collapse? Learning Diverse Features for Fine-grained and Long-tail Classification	['Neural Collapse', 'Diverse deep learning features', 'Finegrained transfer learning']	Neural collapse is not what you need: Deep features with within-class diversity improve the performance of fine-grained and long-tail learning	Deep Learning and representational learning	anonymous|do_we_need_neural_collapse_learning_diverse_features_for_finegrained_and_longtail_classification	/pdf/828bf0641834da7974e71ad9f4db23c5e5706365.pdf
ufCQZeAMZzf	1618	Low-Rank Graph Neural Networks Inspired by the Weak-balance Theory in Social Networks	['graph neural networks', 'heterophily', 'social theory', 'low rank']	Inspired by the global low-rank structures of signed networks, we propose to explicitly model the coefficient matrix as a low-rank matrix, based on which the aggregation and propagation are performed.	Deep Learning and representational learning	anonymous|lowrank_graph_neural_networks_inspired_by_the_weakbalance_theory_in_social_networks	/pdf/490f4fca9a96a837d66d84bb8b88765aec938732.pdf
OnD9zGAGT0k	1619	Diffusion Posterior Sampling for General Noisy Inverse Problems	['Diffusion model', 'Inverse problem', 'Posterior sampling']	We propose a diffusion model-based general inverse problem solver that scales to nonlinear problems and different noise statistics.	Generative models	anonymous|diffusion_posterior_sampling_for_general_noisy_inverse_problems	/pdf/654bc41d8c8be5216abaf84f535317aaab4f99dc.pdf
LHBiPX5BOwZ	1620	A Robustly and Effectively Optimized Pretraining Approach for Masked Autoencoder	[]		Deep Learning and representational learning	anonymous|a_robustly_and_effectively_optimized_pretraining_approach_for_masked_autoencoder	/pdf/07545314343124b83569b7f8f197630b86a5b2a9.pdf
km2lP70ds-0	1621	Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup	['Data Augmentation', 'Mixup', 'Image Classification', 'Self-supervised Learning', 'Representation Learning']	We propose a learnable scenario-agnostic mixup (SAMix) methods for both self-supervised and supervised vision representation learning.	Deep Learning and representational learning	anonymous|boosting_discriminative_visual_representation_learning_with_scenarioagnostic_mixup	/pdf/be9c1ab8992521759cbbccaebe5ccf2bdac5cb72.pdf
-bVsNeR56KS	1622	Modeling Sequential Sentence Relation to Improve Cross-lingual Dense Retrieval	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|modeling_sequential_sentence_relation_to_improve_crosslingual_dense_retrieval	/pdf/866444b0c951276f5c065228a6a87385b225f924.pdf
CRhzJqLhnwU	1623	Federated Learning for Inference at Anytime and Anywhere	['Federated Learning']		Deep Learning and representational learning	anonymous|federated_learning_for_inference_at_anytime_and_anywhere	/pdf/71cadbe4ce157bbcdcaf2667b454a521ddeef0e9.pdf
MTTPLcwvqTt	1624	Provable Unsupervised Data Sharing for Offline Reinforcement Learning	['offline reinforcement learning', 'unsupervised learning', 'data sharing']	We propose a principled way to leverage unlabeled offline RL dataset with guarantees in linear MDPs and it outperforms previous methods.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|provable_unsupervised_data_sharing_for_offline_reinforcement_learning	/pdf/3bb94de82c1b910ad3c8d96332b6115442c64c77.pdf
VbCMhg7MRmj	1625	Protein Representation Learning via Knowledge Enhanced Primary Structure Reasoning	['Protein Science', 'Representation Learning', 'Knowledge Graph']	We perform protein knowledge encoding by learning to exploit knowledge graphs for protein primary structure reasoning.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|protein_representation_learning_via_knowledge_enhanced_primary_structure_reasoning	/pdf/d546767f7f3a007629e88c599272734daa6c41b1.pdf
B92TMCG_7rp	1626	Re-parameterizing Your Optimizers rather than Architectures	['Deep Learning', 'Model Architecture', 'Optimizer', 'Re-parameterization']	Modify gradient flow to incorporate model-specific prior knowledge into the optimizers for training simple and efficient models.	Deep Learning and representational learning	anonymous|reparameterizing_your_optimizers_rather_than_architectures	/pdf/f0e6776a62779cd335f5c87bc7ec0260e4d33703.pdf
xq-CQz6-gfg	1627	Self Check-in: Tight Privacy Amplification for Practical Distributed Learning	['differential privacy', 'federated learning', 'privacy amplification']	A more practical/realistic protocol of differentially private federated learning, with emphasis given to the privacy analysis 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|self_checkin_tight_privacy_amplification_for_practical_distributed_learning	/pdf/601c21213b236b9b54e7f835eceb15c6baa7ee32.pdf
FIrQfNSOoTr	1628	Instance-wise Batch Label Restoration via Gradients in Federated Learning	['federated learning', 'batch label restoration', 'gradient inversion attack.']	We propose an analytic method to perform instance-wise batch label restoration and enhance the existing gradient inversion attacks.	Deep Learning and representational learning	anonymous|instancewise_batch_label_restoration_via_gradients_in_federated_learning	/pdf/dc368d363ef5c7d28cccb4b1222e7646aab55878.pdf
w-x7U26GM7j	1629	Advancing Radiograph Representation Learning with Masked Record Modeling	['Representation Learning', 'Radiograph', 'Self-supervised Learning', 'Medical Imaging']	We propose to learn radiograph representations via masked record modeling.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|advancing_radiograph_representation_learning_with_masked_record_modeling	/pdf/befc94836b9526f6a2673af53725bf9875dee25c.pdf
HHPEkUi5POw	1630	Less is More: Identifying the Cherry on the Cake for Dynamic Networks	['Dynamic Networks', 'Cherry Hypothesis', 'Efficient Architecture Designation.']	We reveal the contradiction between the human brain and dynamic networks, then propose and validate the Cherry Hypothesis to show that a partially dynamic network (PAD-Net) could advance the performance in dynamic networks.	Deep Learning and representational learning	anonymous|less_is_more_identifying_the_cherry_on_the_cake_for_dynamic_networks	/pdf/ba1c71a0001a94040bf0933cf418e9640526f4c1.pdf
EBJG0A0PUo1	1631	Enabling Probabilistic Inference on Large-Scale Spiking Neural Networks	['spiking neural networks', 'SNNs']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|enabling_probabilistic_inference_on_largescale_spiking_neural_networks	/pdf/d933b890aed2d423b741ccc1385fcb4accea0a72.pdf
Siln8xpTMrZ	1632	DADAO: Decoupled Accelerated Decentralized Asynchronous Optimization	['Decentralized Asynchronous Optimization', 'Convex Optimization', 'Time-Varying Networks']	We introduce a novel decentralized asynchronous accelerated stochastic first order algorithm to minimize a sum of smooth and strongly convex functions over a time-varying connectivity network.	Optimization (eg, convex and non-convex optimization)	anonymous|dadao_decoupled_accelerated_decentralized_asynchronous_optimization	/pdf/8447df9dd44a400124bde5ff48939e364949e7d0.pdf
2t7L0lcDqAr	1633	PathFusion: Path-consistent Lidar-Camera Deep Feature Fusion	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|pathfusion_pathconsistent_lidarcamera_deep_feature_fusion	/pdf/1acfb603d2dda923d1f48ce270591f368bd1b229.pdf
W6cTWszOQSo	1634	Neural Volumetric Mesh Generator	[]		Generative models	anonymous|neural_volumetric_mesh_generator	/pdf/a6183238f253e4f0e0832db2109484908c431cbe.pdf
pvrkJUkmto	1635	Delving into Discrete Normalizing Flows on SO(3) Manifold for Probabilistic Rotation Modeling	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|delving_into_discrete_normalizing_flows_on_so3_manifold_for_probabilistic_rotation_modeling	/pdf/d322d882ec1dd56687d684eb5cb1eeb27ad2830b.pdf
jw37FUa_Aw9	1636	Holistically Explainable Vision Transformers	['Explainable Deep Neural Networks', 'Vision Transformers', 'XAI']	We propose B-cos ViTs, which are inherently interpretable transformer models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|holistically_explainable_vision_transformers	/pdf/fa17eaac5729250b25330805aeb3a962caa427b6.pdf
bZjxxYURKT	1637	FedSpeed: Larger Local Interval, Less Communication Round, and Higher Generalization Accuracy	['federated learning']	A novel and practical federated learning method with theoretical analysis guarantees achieves higher performance in the common federated settings.	Deep Learning and representational learning	anonymous|fedspeed_larger_local_interval_less_communication_round_and_higher_generalization_accuracy	/pdf/74afba85f5f2abf102f450be71e198bd7e364fe4.pdf
SbR9mpTuBn	1638	Bag of Tricks for Unsupervised Text-to-Speech	['speech synthesis', 'unsupervised learning']	We introduce a bag of tricks to enable effective unsupervised TTS using low-quality and multi-speaker unpaired data.	Applications (eg, speech processing, computer vision, NLP)	anonymous|bag_of_tricks_for_unsupervised_texttospeech	/pdf/8ce9ed1d370eda6f6fcb41ea06c8bc087414a0ed.pdf
QUaDoIdgo0	1639	CO3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving	['Cooperative Contrastive Learning', 'Contextual Shape Prediction', 'Unsupervised Representation Learning', 'Autonomous Driving']	We propose CO3, namely {Co}operative {Co}ntrastive Learning and {Co}ntextual Shape Prediction, to learn 3D representation for outdoor-scene point clouds in an unsupervised manner.	Unsupervised and Self-supervised learning	anonymous|co3_cooperative_unsupervised_3d_representation_learning_for_autonomous_driving	/pdf/8931ddaaf88fb351621011676568608344fbb896.pdf
uqg3FhRZaq	1640	On the complexity of nonsmooth automatic differentiation	['Automatic differentiation', 'nonsmooth derivatives', 'computational complexity', 'cheap derivatives', 'conservative gradients']	Backpropagation of nonsmooth  gradients is proved to be a fast/cheap process for the vast class of locally Lipschitz semi-algebraic functions.	Optimization (eg, convex and non-convex optimization)	anonymous|on_the_complexity_of_nonsmooth_automatic_differentiation	/pdf/7615df349c48fb59221d3912a67bfb7b8dbcf187.pdf
AONW9iXn22	1641	Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes	['Deep Gaussian processes', 'Operator variational inference', 'Stein discrepancy']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|neural_operator_variational_inference_based_on_regularized_stein_discrepancy_for_deep_gaussian_processes	/pdf/250be73e323d517698d92d6fb14dd6b101adb31f.pdf
bd7tj6MoZn	1642	Uncertainty-Aware Meta-Learning for Multimodal Task Distributions	['Meta-learning', 'Bayesian inference', 'neural network linearization', 'uncertainty estimation', 'Gaussian Process', 'NTK']	We present a novel meta-learning algorithm that makes probabilistic predictions efficiently, detects out-of-distribution context data, and performs well on heterogeneous, multimodal task distributions.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|uncertaintyaware_metalearning_for_multimodal_task_distributions	/pdf/af03fdbb416f6de5cafc050cf18b4c9569543a42.pdf
jrrokKkjVsz	1643	Comparative Analysis between Vision Transformers and CNNs from the view of Neuroscience	['Vision Transformer', 'CNN', 'neuroscience', 'sparsity']	Neural sparsity of Transformers and CNNs are defined and calculated, leading to striking conclusion.	General Machine Learning (ie none of the above)	anonymous|comparative_analysis_between_vision_transformers_and_cnns_from_the_view_of_neuroscience	/pdf/a41e4d8102be18cf3ef2ee4ae51c64b5e3c8f175.pdf
rktxwkgbbPB	1644	Fed-CBS: Heterogeneity-Aware Client Sampling Mechanism for Federated Learning via Class-Imbalance Reduction	[]		Deep Learning and representational learning	anonymous|fedcbs_heterogeneityaware_client_sampling_mechanism_for_federated_learning_via_classimbalance_reduction	/pdf/e771db4c73184f98aa2aacb18d704b1d399fd1d4.pdf
VYaTFO2Myi5	1645	Towards Controllable Policy through Goal-Masked Transformers	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_controllable_policy_through_goalmasked_transformers	/pdf/85d748f00ec9b823963c44f7543aa021123e3033.pdf
XDJwuEYHhme	1647	Towards the Generalization of Contrastive Self-Supervised Learning	['deep learning theory', 'contrastive learning', 'generalization error']	This paper presents a theoretical understanding of contrastive learning and provide an upper bound of the downstream classification error.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|towards_the_generalization_of_contrastive_selfsupervised_learning	/pdf/9c54c5d3128a6e4140843f02318cff499c9c7d2d.pdf
-NAi1oQJbA3	1648	Adapting Pre-trained Language Models for Quantum Natural Language Processing	['Quantum Computing', 'Complex-valued Neural Network', 'Pre-trained Language Model']		Deep Learning and representational learning	anonymous|adapting_pretrained_language_models_for_quantum_natural_language_processing	/pdf/702f1feaa2808b9690bfc88e592d89305f91a0b6.pdf
BUewet8vCFr	1649	RetinexUTV: ROBUST RETINEX MODEL WITH UNFOLDING TOTAL VARIATION	['low light iamge enhancement', 'retinex', 'noise suppression', 'total variation']		Deep Learning and representational learning	anonymous|retinexutv_robust_retinex_model_with_unfolding_total_variation	/pdf/dcf3782ea51af8230b932e0339c89cb70a125aee.pdf
Y-PoPmNuLHZ	1650	MUTUAL EXCLUSIVE MODULATOR FOR LONG-TAILED RECOGNITION	['long-tailed recognition', 'mutual exclusive modulator', 'soft routing']		Deep Learning and representational learning	anonymous|mutual_exclusive_modulator_for_longtailed_recognition	/pdf/c7f6485bde3a1896cb5a8c30da675566f7c8369a.pdf
6ZajpxqTlQ	1651	Generalize Learned Heuristics to Solve Large-scale Vehicle Routing Problems in Real-time	['Learning', 'Vehicle Routing Problem', 'Large-scale Vehicle Routing Problem', 'Generalization', 'Combinatorial Optimization', 'Reinforcement Learning', 'Attention']	Propose a zero-shot method to generalize the data-driven heuristics trained on small-scale VRPs to solve large-scale VRPs in real-time	General Machine Learning (ie none of the above)	anonymous|generalize_learned_heuristics_to_solve_largescale_vehicle_routing_problems_in_realtime	/pdf/1bf0c51abf24e1cfbf79833bf30d5ff04dedb4ad.pdf
s0JAnAOS24	1653	DCAPS: Dual Cross-Attention Coupled with Stabilizer for Few-Shot Common Action Localization	['Few-shot action localization', 'common action localization', 'commonality']	For few-shot common action localization where no class cue of support videos is given, we mainly suggests a 3-stage cross-attention to align a long untrimmed query and trimmed support videos without losing compatibility among the support videos.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dcaps_dual_crossattention_coupled_with_stabilizer_for_fewshot_common_action_localization	/pdf/3196f5cc2fc715d70f353118707add8d4d8d7d43.pdf
9CGiwZeCAd	1654	Closing the Performance Gap between Cumbersome and Lightweight Contrastive Models	['self-supervised learning', 'contrastive learning', 'lightweight model']	We successfully improve the linear evaluation results from 36.3\% to 62.3\% of MobileNet-V3-Large and from 42.2\% to 65.8\% of EfficientNet-B0 on ImageNet, closing the accuracy gap to ResNet-50 which contains $5\times$ parameters.	Deep Learning and representational learning	anonymous|closing_the_performance_gap_between_cumbersome_and_lightweight_contrastive_models	/pdf/39b2cc4bfcb6d9eb8a9b3e2e3d511e0c74d74c0f.pdf
k-JvYGkA9o	1655	How Normalization and Weight Decay Can Affect SGD? Insights from a Simple Normalized Model	['normalization', 'stochastic gradient descent', 'optimization']	Theoretical and empirical analysis on learning dynamics of neural network with normalization and weight decay.	General Machine Learning (ie none of the above)	anonymous|how_normalization_and_weight_decay_can_affect_sgd_insights_from_a_simple_normalized_model	/pdf/7ab1a96d414b7a98c0e7f7c134209d0ceacf31a3.pdf
lOkOPfpeSl	1656	Fine-Grained Image Retrieval with Neighbor-Attention Label Correction	['noisy label', 'meta learning', 'fine-grained image retrieval']	A Neighbor-Attention Label Correction model trained by nested optimization is proposed to correct noisy label in fine-grained image retrieval	Applications (eg, speech processing, computer vision, NLP)	anonymous|finegrained_image_retrieval_with_neighborattention_label_correction	/pdf/3c9b5ce80ab45c665d26b9dba4c5cec8bda30097.pdf
q3F0UBAruO	1657	Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective	['game playing', 'multi-agent', 'human-ai communication', 'human-ai collaboration', 'deep reinforcement learning']	We propose an efficient and interpretable Meta-Command Communication-based (MCC) framework for accomplishing effective human-AI collaboration in MOBA games. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_effective_and_interpretable_humanagent_collaboration_in_moba_games_a_communication_perspective	/pdf/5fd769d0c5cf15f85c60c3fb6707047808a0e2c0.pdf
yCGgOFC0bG	1658	Specialization of Sub-paths for Adaptive Depth Networks	['convolution neural network', 'anytime network', 'adaptive network', 'accuracy-efficiency trade-offs', 'imagenet', 'coco']	We present an adaptive depth network that does not requires intermediate classifiers or decision networks. 	Deep Learning and representational learning	anonymous|specialization_of_subpaths_for_adaptive_depth_networks	/pdf/20e86f0ef58ce77cc095429b3c129be3fea71579.pdf
1VuBdlNBuR	1659	Active Learning with Partial Labels	['weakly supervised learning', 'active learning', 'partial label learning']	we propose a new problem setting named active learning with partial labels, where the oracle provides partial labels to the selected samples.	Deep Learning and representational learning	anonymous|active_learning_with_partial_labels	/pdf/d6e603d6a8244dd3b019fc7362c6b89ab8632d06.pdf
ecVbozYsBmw	1660	Towards Learning Imperceptible Adversarial Distribution for Black-Box Attacks	['adversarial attack', 'robustness', 'image classification', 'automatic recognition system']	A black-box attack method which can learn imperceptible adversarial distribution 	Deep Learning and representational learning	anonymous|towards_learning_imperceptible_adversarial_distribution_for_blackbox_attacks	/pdf/6e2326ce7e22feef23d4a052651bbb75c4734de7.pdf
bnRBltYQboI	1661	Saliency-guided Vision Transformer for Few-shot Keypoint Detection	['Saliency-guided vision transformer', 'few-shot learning', 'few-shot keypoint detection', 'masked self-attention', 'morphology learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|saliencyguided_vision_transformer_for_fewshot_keypoint_detection	/pdf/f7f2bc9b3c13c6f3340a45e4526943629aa2b742.pdf
9TpJYSI1n9t	1662	Prompt Generation Networks for Efficient Adaptation of Frozen Vision Transformers	['model adaptation', 'pretrained models', 'prompting', 'vision transformers']	A novel method for adapting frozen pretrained vision transformer models by adding prompts that vary based on each input, which can surpass even full-finetuning.	Deep Learning and representational learning	anonymous|prompt_generation_networks_for_efficient_adaptation_of_frozen_vision_transformers	/pdf/fe1c687c355d90b58f8d488704905ccd3b9f59c4.pdf
Wfvm3hYjwnC	1663	Teaching Others is Teaching Yourself Regularization For Controllable Language Models	[]		Generative models	anonymous|teaching_others_is_teaching_yourself_regularization_for_controllable_language_models	/pdf/1dc5626386da266d756df0742397a8f6628937ce.pdf
TYEY9qBqgfF	1664	Does Federated Learning Really Need Backpropagation?	['Federated Learning', 'Backpropagation-Free Training']	BAFFLE is a backpropagation-free and memory-efficient federated learning framework that only executes forward propagation during training.	General Machine Learning (ie none of the above)	anonymous|does_federated_learning_really_need_backpropagation	/pdf/661bf24fde4ac58fc3c09aab9d2455a64d7b78ad.pdf
Rumwc_raZvE	1665	On Intriguing Layer-Wise Properties of Robust Overfitting in Adversarial Training	[]		Deep Learning and representational learning	anonymous|on_intriguing_layerwise_properties_of_robust_overfitting_in_adversarial_training	/pdf/1b9dc2a64981e1aed8cd26cf42fd80d4a85952d1.pdf
lq62uWRJjiY	1666	Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning 	['Adaptive budget allocation', 'Parameter-efficient fine-tuning', 'Natural language processing']	We propsoe MARVEL to adaptively allocate the parameter budget among weight matrices in correspondence to their importance. 	Deep Learning and representational learning	anonymous|adaptive_budget_allocation_for_parameterefficient_finetuning	/pdf/9b057cb7a4243f03f83817edc3945083cc7ebb4b.pdf
7TKYqsMjNh	1669	Fully Continuous Gated Recurrent Units For processing Time Series	['Time Series forecasting', 'Continuous GRU']	Previous GRU-based models are piece-wise continuous. We proposed the first fully continuous GRU.	Deep Learning and representational learning	anonymous|fully_continuous_gated_recurrent_units_for_processing_time_series	/pdf/4e797847398164d8b28f9d970078ff51f5128cf0.pdf
5fvXH49wk2	1670	D4AM: A General Denoising Framework for Downstream Acoustic Models	['audio processing', 'speech enhancement', 'robust automatic speech recognition', 'auxiliary task learning']	We propose a general denoising framework for various downstream acoustic models (D4AM) by adopting an effective joint training scheme with the regression (denoising) objective and the classification (ASR) objective.	Applications (eg, speech processing, computer vision, NLP)	anonymous|d4am_a_general_denoising_framework_for_downstream_acoustic_models	/pdf/865b80059c91900781d5496ede668a7ed7113657.pdf
l1U_oTRQX62	1671	Disentangled Knowledge Transfer: A New Perspective for Personalized Federated Learning	['Personalized Federated Learning', 'Model Disentanglement', 'Multi-task Learning']	We present, pFedC, a novel training method for personalized Federated Learning which can avoid the irrelevant knowledge aggregation from other clients.	Deep Learning and representational learning	anonymous|disentangled_knowledge_transfer_a_new_perspective_for_personalized_federated_learning	/pdf/ead557eea0a07316c2eca5eb06d1067d8fd23750.pdf
qOV5REmPOM	1672	On the optimal precision of GANs	['Deep learning theory', 'GANs', 'Deep generative modelling']		Generative models	anonymous|on_the_optimal_precision_of_gans	/pdf/1b8d0eaa47434f447a29e8187617219d611606ac.pdf
B8a1FcY0vi	1673	From $t$-SNE to UMAP with contrastive learning	['visualization', 'dimensionality reduction', 't-SNE', 'UMAP']	We show that UMAP is effectively negative sampling applied to the t-SNE loss function.	Unsupervised and Self-supervised learning	anonymous|from_tsne_to_umap_with_contrastive_learning	/pdf/2efe633cd874e5da1514de2c5056aa04faf45107.pdf
qU6NIcpaSi-	1675	Learning Heterogeneous Interaction Strengths by Trajectory Prediction with Graph Neural Network	['relational learning', 'complex systems', 'dynamic systems', 'graph learning']	We propose a neural architecture that infers a continuous interaction graph rather than a conventional discrete one, solely from trajectories in an unsupervised manner.	Deep Learning and representational learning	anonymous|learning_heterogeneous_interaction_strengths_by_trajectory_prediction_with_graph_neural_network	/pdf/89bb7d1793bde3fab838f1a2e03210b5bb99f6e0.pdf
3QdSdm6Oqat	1676	HEAT: Hardware-Efficient Automatic Tensor Decomposition for Transformer Compression	[]		General Machine Learning (ie none of the above)	anonymous|heat_hardwareefficient_automatic_tensor_decomposition_for_transformer_compression	/pdf/c958a3b498af1b3b49f930c5ae7aef91db3e407a.pdf
-iADdfa4GKH	1677	Monocular Scene Reconstruction with 3D SDF Transformers	['3D Reconstruction', 'Monocular Scene Reconstruction', '3D Transformer', 'TSDF volume']		Applications (eg, speech processing, computer vision, NLP)	anonymous|monocular_scene_reconstruction_with_3d_sdf_transformers	/pdf/d99d2aa4433c44d79516739fd689dde9dc07867f.pdf
QUK1ExlbbA	1678	DENSE RGB SLAM WITH NEURAL IMPLICIT MAPS	['dense RGB SLAM', 'implict funciton', 'RGB VO']		Applications (eg, speech processing, computer vision, NLP)	anonymous|dense_rgb_slam_with_neural_implicit_maps	/pdf/ad5a7236b4f72d8bf4b77dcbdd43365d8c42122a.pdf
IIxe8wlXwb0	1679	Generalization bounds and algorithms for estimating the effect of multiple treatments and dosage	['Treatment effect estimation']	We propose generalization bounds for the counterfactual error in treatment effect estimation in the context of multiple treatments and dosage parameters, and regularization techniques for training prediction models inspired by these bounds.	Deep Learning and representational learning	anonymous|generalization_bounds_and_algorithms_for_estimating_the_effect_of_multiple_treatments_and_dosage	/pdf/13ffd12c10fe5d7438cbf86c90578f7e03a718c2.pdf
q8vgHfPdoQP	1680	When to Make and Break Commitments?	['optimal stopping/switching', 'sequential hypothesis testing', 'adaptive experimentation']		General Machine Learning (ie none of the above)	anonymous|when_to_make_and_break_commitments	/pdf/1e6e224637fd6ca3603ea50e29591041570dd187.pdf
-1vpxBUtP0B	1681	TransformMix: Learning Transformation and Mixing Strategies for Sample-mixing Data Augmentation	['Data Augmentation', 'Automated Data Augmentation', 'Sample-mixing', 'Computer Vision']	We propose an automated approach, TransformMix, to learn better transformation and mixing augmentation strategies from data	Deep Learning and representational learning	anonymous|transformmix_learning_transformation_and_mixing_strategies_for_samplemixing_data_augmentation	/pdf/033f0589bbbf84d8dd4585f0d0d30614c9ce6f02.pdf
luajgSjRlew	1682	Social and environmental impact of recent developments in machine learning on biology and chemistry research	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|social_and_environmental_impact_of_recent_developments_in_machine_learning_on_biology_and_chemistry_research	/pdf/a50f00815d38094aca9ca5a8e94cfb49ad73bb8d.pdf
-jP_rDkyfpI	1683	Approximate Nearest Neighbor Search through Modern Error-Correcting Codes	['Similarity Search', 'Nearest-Neighbor Search', 'Polar Codes', 'Locality-Sensitive Hashing', 'LSH']	Using modern error-correcting codes, we present an improved method of using locality-sensitive hash functions for approximate nearest-neighbor search..	General Machine Learning (ie none of the above)	anonymous|approximate_nearest_neighbor_search_through_modern_errorcorrecting_codes	/pdf/a6781d57fe115bf018808af5665203c6a15c0753.pdf
gHi_bIxFdDZ	1685	Understanding Gradient Regularization in Deep Learning: Efficient Finite-Difference Computation and Implicit Bias	['Gradient regularization', 'Implicit bias', 'Gradient ascent and descent', 'Diagonal Linear Network']	Gradient Regularzation works efficiently by a certain finite-difference computation and has a desirable implicit bias in theory	Deep Learning and representational learning	anonymous|understanding_gradient_regularization_in_deep_learning_efficient_finitedifference_computation_and_implicit_bias	/pdf/47af85a86357f78042721f2eb5bfd0912ab2841d.pdf
isiQ5KIXbjj	1686	Learning QUBO Forms in Quantum Annealing	[]		Deep Learning and representational learning	anonymous|learning_qubo_forms_in_quantum_annealing	/pdf/9015207d84ce918e2516c1a319328a9b5432f731.pdf
-0jbdOhFn4g	1687	Is the Deep Model Representation Sparse and Symbolic with Causal Patterns?	['Representation Learning', 'Deep Learning Theory', 'Explainable AI']	This paper shows that the inference logic of a deep model can usually be represented as a sparse causal graph, and the faithfulness of such a symbolic representation is theoretically guaranteed.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|is_the_deep_model_representation_sparse_and_symbolic_with_causal_patterns	/pdf/081510afc271b83939a31d4d5d71ff1b8577cc0d.pdf
IpGgfpMucHj	1689	Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding 	['multi-view', 'point cloud', '3D understanding']	We propose voint cloud, a novel 3D data structure, that combines multi-view and point clouds for robust 3D understanding tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|voint_cloud_multiview_point_cloud_representation_for_3d_understanding	/pdf/f614b31a2844e51d59d9a0f9f8308a9f857d74b0.pdf
UVgv6goRFND	1690	Pixel-Aligned Non-parametric Hand Mesh Reconstruction	['3D Hand Reconstruction', 'Mesh Reconstruction', 'Graph Convolution Network', 'Attention', 'Deep Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|pixelaligned_nonparametric_hand_mesh_reconstruction	/pdf/8261ac2ab1fb5aeb88f6bec86b30247617019b67.pdf
hPg-z_yBlcr	1691	On the Connection between Fisher's Criterion and Shannon's Capacity: Theoretical Concepts and Implementation	"['Feature selection', ""Fisher's Criterion"", ""Shannon's Capacity"", 'Neural Networks.']"	A feature selection scheme is developed by relating Fisher's criterion to Shannon's channel capacity.	General Machine Learning (ie none of the above)	anonymous|on_the_connection_between_fishers_criterion_and_shannons_capacity_theoretical_concepts_and_implementation	/pdf/733a8ff22bd5da3ac54b0283bef79757f0c40b51.pdf
iLMgk2IGNyv	1692	GAMR: A Guided Attention Model for (visual) Reasoning	['abstract visual reasoning', 'visual routines', 'out-of-distribution generalization', 'external memory', 'zero shot generalization', 'compositional learning']	A framework for a memory and attention based architecture demonstrating the capability of sample efficient learning and generalization capability on complex visual reasoning tasks aligned with the theory of visual routines. 	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|gamr_a_guided_attention_model_for_visual_reasoning	/pdf/c9deb8e3b494a7fa75a7025bc3b1db8180f7ba45.pdf
5zaWBdMxcF1	1693	Physically Plausible and Conservative Solutions to Navier-Stokes Equations Using Physics-Informed CNNs	['Finite volume method', 'Navier-Stokes equation', 'Partial differential equation', 'Physics-informed convolutional neural network']	Solving Navier-Stokes Equations Using PICNN	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|physically_plausible_and_conservative_solutions_to_navierstokes_equations_using_physicsinformed_cnns	/pdf/4d67b2d9d094399f520520fff44683724bc5f945.pdf
q5ZwEiLzDft	1695	Property Inference Attacks Against t-SNE Plots	['Property Inference Attacks', 't-SNE']	We present for the first time that t-SNE plots can be a new valid side channel for property inference attacks	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|property_inference_attacks_against_tsne_plots	/pdf/f0129ed168d83c05c693a2b90de8173c71d553ae.pdf
2ppuWD3dkie	1696	SimST: A GNN-Free Spatio-Temporal Learning Framework for Traffic Forecasting	['Traffic Forecasting', 'Spatio-Temporal Graph Neural Networks']		Applications (eg, speech processing, computer vision, NLP)	anonymous|simst_a_gnnfree_spatiotemporal_learning_framework_for_traffic_forecasting	/pdf/13aad458637d6ecc86fadc6616740943fab51c59.pdf
wLFTV-Nv2ZR	1697	Efficient and Stealthy Backdoor Attack Triggers are Close at Hand	['Backdoor Attack；Deep Neural Networks']	A new strategy for developing the trigger pattern of backdoor attacks with great efficiency and stealthiness using benign training data.	Deep Learning and representational learning	anonymous|efficient_and_stealthy_backdoor_attack_triggers_are_close_at_hand	/pdf/a6cdb765015599e271c2953bc7a6051c4dfa15a4.pdf
Pia70sP2Oi1	1698	Planckian Jitter: countering the color-crippling effects of color jitter on self-supervised training	['Contrastive Learning', 'Self-Supervised Learning', 'Color Features', 'Illuminant Invariance']		Deep Learning and representational learning	anonymous|planckian_jitter_countering_the_colorcrippling_effects_of_color_jitter_on_selfsupervised_training	/pdf/fae94f7678fc850349555f9cf98e29616c523dfd.pdf
s6QuERBSrRc	1699	"Unsupervised Threshold Learning with ""$L$""-trend Prior For Visual Anomaly Detection"	['Unsupervised', 'visual anomaly detection', 'threshold learning']	Propose a new perspective for unsupervised visual anomaly detection	Unsupervised and Self-supervised learning	anonymous|unsupervised_threshold_learning_with_ltrend_prior_for_visual_anomaly_detection	/pdf/79bd76af13a390585ad5b1e22e1e3c39c3e94096.pdf
w4ojb-FIq72	1700	MAXENT LOSS: CONSTRAINED MAXIMUM ENTROPY FOR CALIBRATING DEEP NEURAL NETWORKS	['Calibration', 'Out-of-distribution', 'Loss function', 'Machine learning safety', 'Overconfidence', 'Robustness', 'Distribution shifts']	A novel loss function involving constraints, used to improve model calibration on OOD data.	Deep Learning and representational learning	anonymous|maxent_loss_constrained_maximum_entropy_for_calibrating_deep_neural_networks	/pdf/8a2a04eb9f5e00b67a7158b58f88bcebe8d2d2ea.pdf
8IBtyLQ8GKw	1701	Ahead-of-Time P-Tuning	['Efficient Fine-Tuning', 'P-Tuning', 'Multi-Task Inference', 'Transformers', 'GLUE', 'SuperGLUE']	A novel method for parameter efficient fine-tuning. Can perform multi-task inference like P-Tuning, but up to 1.3x times faster than it.	Deep Learning and representational learning	anonymous|aheadoftime_ptuning	/pdf/c602a2a6762c34e110b8e6f65403d95b2d074734.pdf
2hTj3upOnNf	1702	Target-specific Peptide Design by Multi-fragments Autoregressive Generative Model	['Protein design', 'Machine learning', 'Deep learning', 'Graph neural network', 'Autoregressive generative model']	We present the first pure data-driven approach for designing target-specific peptides. A multi-fragment autoregressive generative model is developed. Whether or not there are provided anchors, our approach performs remarkably well in peptide design. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|targetspecific_peptide_design_by_multifragments_autoregressive_generative_model	/pdf/3cef04c3ebbb65de0c75ed2d50421f0a1642a70f.pdf
ZW5aK4yCRqU	1703	The Continuous CNN: from Task-Specific to Unified CNN Architecture	['convolutional neural networks', 'continuous convolutional kernels', 'CNNs', 'continuous parameterizations', 'sequential data', 'visual data', 'point-cloud data']	We formulate a CNN architecture that can be used across input resolutions, lengths and dimensionalities (1D, 2D, 3D) showing its viability across several 1D, 2D and 3D tasks.	Deep Learning and representational learning	anonymous|the_continuous_cnn_from_taskspecific_to_unified_cnn_architecture	/pdf/9f19ed371cb6c0b0197f0b66bb441074efe33f47.pdf
gyTuMfkOney	1704	A Functional Perspective on Multi-Layer Out-of-Distribution Detection	['Out-of-distribution detection', 'Deep Learning', 'Safety AI']	We propose an original approach to OOD detection based on a functional view of the network that exploits the sample's trajectories through the various layers and their statistical dependencies.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_functional_perspective_on_multilayer_outofdistribution_detection	/pdf/3d3ec2ee05dcb6253ca67099f5096dc0d079f4b0.pdf
0g1JdUJF7Fr	1706	An Optimal Transport Perspective on Unpaired Image Super-Resolution	['optimal transport', 'unpaired image super-resolution']		Generative models	anonymous|an_optimal_transport_perspective_on_unpaired_image_superresolution	/pdf/dbd46dfad7c373691d802e6349415aa5cbc93e02.pdf
XxnMFuv-y3h	1707	Efficient Policy Space Response Oracles	['reinforcement learning', 'multi-agent reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|efficient_policy_space_response_oracles	/pdf/f5f84bde2c5f67e595132f7d301d41e2d57d7026.pdf
kN4IkQvvrBD	1708	SUG: Single-dataset Unified Generalization for 3D Point Cloud Classification	['3D Point Cloud Classification', 'Domain Adaptation']		Deep Learning and representational learning	anonymous|sug_singledataset_unified_generalization_for_3d_point_cloud_classification	/pdf/f70b3b64de2b70533384024fe75aafe819532d4e.pdf
TrwE8l9aJzs	1709	Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased	['Human-AI Collaboration', 'Multi-Agent Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_zeroshot_cooperation_with_humans_assuming_humans_are_biased	/pdf/e58bce0f63c7521c0cff1d4f5574c6c27f9c6fd2.pdf
yZCpZrUqzK0	1710	Distribution Shift Detection for Deep Neural Networks	['Selective classification', 'Window based shift detection']		Deep Learning and representational learning	anonymous|distribution_shift_detection_for_deep_neural_networks	/pdf/8309e4e10e7e18aa54628e72867d066489bded06.pdf
khF4d1SRrGH	1712	COFS: COntrollable Furniture layout Synthesis	['generative modelling', 'conditional generation', 'layouts', 'transformers']	Language Models need an order. Layouts have no order. We show how to modify a Language Model to be order-equivariant.	Generative models	anonymous|cofs_controllable_furniture_layout_synthesis	/pdf/350df1214268a9e14b16dd6e17c5bf9da6e93c8f.pdf
mWJ0QKcPgzX	1713	When is Adversarial Robustness Transferable?	['transfer learning', 'adversarial robustness']	We study how adversarial robustness can be preserved during transfer from a source domain to a target domain by using randomized smoothing and adversarial attacks to analyze different training and target-retraining procedures.	General Machine Learning (ie none of the above)	anonymous|when_is_adversarial_robustness_transferable	/pdf/5e42a13794cd4cdd32af5de48d6e1654781ec1ee.pdf
EGobBwPc1J-	1714	TGP: Explainable Temporal Graph Neural Networks for Personalized Recommendation	['deep learning', 'graph neural networks', 'temporal graph', 'retrieval models', 'recommendation system']		Deep Learning and representational learning	anonymous|tgp_explainable_temporal_graph_neural_networks_for_personalized_recommendation	/pdf/199fb1f1e72c15a4229fad7545ff34f8d18e24b8.pdf
BLOkjU9iS24	1715	Constrained Reinforcement Learning for Safety-Critical Tasks via Scenario-Based Programming	['Constrained Reinforcement Learning', 'Scenario Based Programming', 'Safety', 'Robotic Navigation']	A novel technique for incorporating domain-expert knowledge to train a constrained DRL agent, based on scenario-based programming paradigm, we validated our method on the popular robotic mapless navigation problem, both physically and in simulation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|constrained_reinforcement_learning_for_safetycritical_tasks_via_scenariobased_programming	/pdf/037db8a93436a735e5b8586baefc2e78a15985e7.pdf
3VKiaagxw1S	1716	Gradient Boosting Performs Gaussian Process Inference	['gradient boosting', 'gaussian process', 'knowledge uncertainty', 'kernel gradient boosting']	We prove that gradient boosting converges to a Gaussian process' posterior mean and can be transformed into a sampler from the posterior, which leads to improved knowledge uncertainty estimates.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|gradient_boosting_performs_gaussian_process_inference	/pdf/7c0fed1c03c3c27cb276db23d1e28e2035c06566.pdf
cpiQjF6I7XA	1717	When Few-shot Meets Cross-domain Object Detection: Learning Instance-level Class Prototypes for Knowledge Transfer	['Domain Adaptive Object Detection', 'Few-shot Object Detection', 'Domain Adaptation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|when_fewshot_meets_crossdomain_object_detection_learning_instancelevel_class_prototypes_for_knowledge_transfer	/pdf/efa23f380e59ad2526f828ea61451b8031e81ff8.pdf
QiORiW-NNqr	1718	Low-complexity Deep Video Compression with A Distributed Coding Architecture	['Deep video compression', 'distributed coding', 'low encoder complexity']	We design the first end-to-end distributed deep video compression framework based on the distributed coding paradigm, which outperforms traditional distributed video codecs and achieves competitive performance with H.264. 	Generative models	anonymous|lowcomplexity_deep_video_compression_with_a_distributed_coding_architecture	/pdf/e6011d8d45416af166aed466a86912251a26bb01.pdf
Oj1ceY_qohC	1719	Contrastive Adversarial Loss for Point Cloud Reconstruction	['Point clouds', 'reconstruction loss', 'learning-based']	Learn a point cloud reconstruction loss by contrastive constraint and adversarial training	Deep Learning and representational learning	anonymous|contrastive_adversarial_loss_for_point_cloud_reconstruction	/pdf/7daf6f24d0bcf59128b5f6c1714d510b0cc7e92a.pdf
UT-_SVOyD1H	1720	Contextual bandits with concave rewards, and an application to fair ranking	['bandits', 'concave rewards', 'fairness', 'learning to rank']	We show a reduction of concave multi-reward contextual bandits to classical single-reward bandits, and apply this reduction to a fair ranking problem.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|contextual_bandits_with_concave_rewards_and_an_application_to_fair_ranking	/pdf/b254e18bf1e348f50b9fa73e9a9af12a38603fba.pdf
HYfD5CoCjDX	1721	NÜWA-LIP: Language-guided Image Inpainting with Defect-free VQGAN	['Language-guided image inpainting', 'Vector quantization', 'Visual synthesis', 'Generative model']	This paper proposes NÜWA-LIP by incorporating DF-VQGAN with MP-S2S to address receptive spreading or information loss in language-guided image inpainting.	Applications (eg, speech processing, computer vision, NLP)	anonymous|nüwalip_languageguided_image_inpainting_with_defectfree_vqgan	/pdf/271581d3ef37604266628b726abd035eba585164.pdf
oCx90Ezdox_	1722	Don't Throw Your Old Policies Away: Knowledge-based Policy Recycling Protects Against Adversarial Attacks	['Domain Knowledge', 'Knowledge Representation', 'Representation Learning', 'Policy Ensemble']	Incorporating domain-knowledge over auxiliary tasks enhances deep reinforcement policy robustness against adversarial attacks in both Atari games and a high dimensional Robot Food Court environment. 	Deep Learning and representational learning	anonymous|dont_throw_your_old_policies_away_knowledgebased_policy_recycling_protects_against_adversarial_attacks	/pdf/f77ada263b615965419c20b1e006c757bafcdee7.pdf
9MbhFHqrti9	1723	ImaginaryNet: Learning Object Detectors without Real Images and Annotations	['Object detection', 'Visual synthesis', 'Generative model']	This paper propose ImaginaryNet obtain about 70% performance in object detection trained without real images or annotations and improve the performance by incorporating real images and annotations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|imaginarynet_learning_object_detectors_without_real_images_and_annotations	/pdf/1b9acab03ebbe533eda069cefb51112e5ea2042b.pdf
2U_AM7TcRQK	1724	Deep Reinforcement Learning for Cryptocurrency Trading: Practical Approach to Address Backtest Overfitting	['Computing methodologies', 'Markov decision processes', 'Neural networks', 'Reinforcement learning']	A practical approach to address backtest overfitting for cryptocurrency trading using deep reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|deep_reinforcement_learning_for_cryptocurrency_trading_practical_approach_to_address_backtest_overfitting	/pdf/502d67e567a5b038528f1c8b2df013f9aa6197f8.pdf
ERjQnrmLKH4	1725	Learning Counterfactually Invariant Predictors	['causality', 'kernel mean embeddings', 'counterfactual fairness', 'counterfactual invariance']	We propose a new technique to train predictors that are counterfactually invariant, i.e., robust to interventions on specified covariates.	General Machine Learning (ie none of the above)	anonymous|learning_counterfactually_invariant_predictors	/pdf/c885c2357dbf7b19332ea949e382521a61b105b6.pdf
X1-0f_y88F9	1726	Continual Vision-Language Representaion Learning with Off-Diagonal Information	['representation learning', 'continual learning']	we explore the feasibility of training CLIP model continuously through streaming data and find the reason about cognitive disorder in continual CLIP training and produce a new framework Mod-x to alleviate model's cognitive disorder.	Deep Learning and representational learning	anonymous|continual_visionlanguage_representaion_learning_with_offdiagonal_information	/pdf/b06b7454b103cbbae9f07b87dfbd6cff047fce05.pdf
OoOIW-3uadi	1727	Deep Learning on Implicit Neural Representations of Shapes	[]		Deep Learning and representational learning	anonymous|deep_learning_on_implicit_neural_representations_of_shapes	/pdf/7629e757f01dc901daf99b96fce7ae7f70aef4fd.pdf
ejHUr4nfHhD	1728	Temperature Schedules for self-supervised contrastive methods on long-tail data	['contrastive learning', 'long-tail data', 'self-supervised learning', 'temperature', 'analysis']	Simple temperature schedules in self-supervised contrastive learning improve representation learning on long-tail distributions	Unsupervised and Self-supervised learning	anonymous|temperature_schedules_for_selfsupervised_contrastive_methods_on_longtail_data	/pdf/63844d10676fc0744ae461b6a4d43179f4138790.pdf
-5fSvp1ofdd	1729	Memory of Unimaginable Outcomes in Experience Replay	['Transfer Multitask and Meta-learning', 'Robotics', 'Model-Based Reinforcement Learning', 'Batch/Offline RL', 'Deep RL', 'Continuous Action RL']	This paper proposes techniques to add only the most relevant experiences in the replay buffer, using model uncertainty as selection criterion.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|memory_of_unimaginable_outcomes_in_experience_replay	/pdf/d6c12fbe2df297c72e84697ebb41ab9e58845b31.pdf
J_kUIC1DNHJ	1730	Dynamic Loss for Learning with Label Noise	['label noise', 'robust loss function', 'dynamic']	To handle the mismatch between the statics of robust loss functions and the dynamics of DNNs learning with label noise, we propose a dynamic loss function which improves robustness gradually.	Deep Learning and representational learning	anonymous|dynamic_loss_for_learning_with_label_noise	/pdf/ccf10ba84a3b77712060d9525d6a0a00fd32a838.pdf
fwt8vkm_9Hn	1731	BiTAT: Neural Network Binarization with Task-Dependent Aggregated Transformation	[]		Deep Learning and representational learning	anonymous|bitat_neural_network_binarization_with_taskdependent_aggregated_transformation	/pdf/a884fb4472a1fc8b87939a66b77c6d73819848b2.pdf
OmGZ7ymnSno	1732	On the Nonconvex Convergence of SGD	['Stochastic gradient descent', 'nonconvex optimization', 'nonsmooth optimization', 'random-reshuffling stochastic gradient descent']	This paper shows that the $\epsilon$-stationary point exists in the final iterates of SGDs in minimizing nonconvex objectives, not just anywhere in the entire range of iterates---A much stronger result than the existing one.	Optimization (eg, convex and non-convex optimization)	anonymous|on_the_nonconvex_convergence_of_sgd	/pdf/8da65121fba46dae5bb102003f44c754aeaf8e68.pdf
5P96KWeULzE	1733	$\Delta$-PINNs: physics-informed neural networks on complex geometries	['deep learning', 'Laplace-Beltrami', 'physics-informed neural networks', 'partial differential equations']	We encode the geometry using the Laplace-Beltrami eigenfunctions to solve partial differential equations with physics-informed neural networks on complex geometries.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|\deltapinns_physicsinformed_neural_networks_on_complex_geometries	/pdf/d4cd076a51672bf9d39f37d4bfb0618e7c9e06ee.pdf
HpEfFkzHUgt	1734	Auto-Encoding Adversarial Imitation Learning	['imitation learning', 'reinforcement learning', 'auto-encoders']	this paper presents a new adversarial imitation learning method based on auto-encoding	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|autoencoding_adversarial_imitation_learning	/pdf/4787f82c08502400f7716ddbe204c8ef46794009.pdf
Z6XKjKM2zBA	1736	ColoristaNet for Photorealistic Video Style Transfer	['Photorealistic Video Style Transfer', 'ColoristaNet', 'Style Removal-and-Reconstruction', 'Decoupled Instance Normalziation']	In this paper, we propose a novel photorealistic video style transfer network called ColoristaNet, which can conduct color style transfer in videos without introducing any painterly spatial distortions and inconsistent flickering artifacts.	Applications (eg, speech processing, computer vision, NLP)	anonymous|coloristanet_for_photorealistic_video_style_transfer	/pdf/55ff81865002568b6dec878351a2ebc6c907fa12.pdf
i4z90HQjBZa	1737	Revisiting Feature Acquisition Bias for Few-Shot Fine-Grained Image Classification	[]		Deep Learning and representational learning	anonymous|revisiting_feature_acquisition_bias_for_fewshot_finegrained_image_classification	/pdf/186a8b603df6ec4218e76a6f6e5e05175d72a4ef.pdf
xMWFqb5Uyk	1738	Relative Positional Encoding Family via Unitary Transformation	['Linear Transformer', 'Relative positional encoding', 'Unitary transformation']	Introducing unitary relative positional encoding, a principal design for relative position encoding,  applicable inclusively for linear and vanilla transformer.	Deep Learning and representational learning	anonymous|relative_positional_encoding_family_via_unitary_transformation	/pdf/896c3e7616ac6bd2ff21037d7277cb068367baeb.pdf
zzL_5WoI3I	1739	An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning	['Multi-Agent Reinforcement Learning', 'Entropy Regularization', 'Exploration-Exploitation Tradeoff']	This paper proposes  an adaptive entropy-regularization framework for multi-agent reinforcement learning to learn the adequate amount of exploration for each agent based on the degree of required exploration.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|an_adaptive_entropyregularization_framework_for_multiagent_reinforcement_learning	/pdf/9d5f6611c127fa6d872f057c5ea87b62d0631c75.pdf
IxmWsm4xrua	1740	Toeplitz Neural Network for Sequence Modeling	['Toeplitz Matrix', 'Sequence Modeling', 'Relative position']	An efficient method that uses Toeplitz matrices to model sequences.	Deep Learning and representational learning	anonymous|toeplitz_neural_network_for_sequence_modeling	/pdf/315c17b1a1e1105af320eecc95640a4116ee8ea1.pdf
cYZupNY8DS4	1741	Online Policy Optimization for Robust MDP	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|online_policy_optimization_for_robust_mdp	/pdf/b136afaa476dfa353e70c8c420eab124e307aa0f.pdf
n0Pb9T5kmb	1742	Towards the Out-of-Distribution Generalization of Contrastive Self-Supervised Learning	['Contrastive learning', 'out-of-distribution generalization']	This paper studies the out-of-distribution generalization of contrastive self-supervised learning, and propose an augmentation-robust contrastive learning algorithm to improve the OOD performance.	Unsupervised and Self-supervised learning	anonymous|towards_the_outofdistribution_generalization_of_contrastive_selfsupervised_learning	/pdf/be81fc831913a4b85b65e801dc536c107f1ea1c9.pdf
2vmGv5wPDBZ	1743	Learning to Estimate Single-View Volumetric Flow Motions without 3D Supervision	[]	We train a network to estimate 3D motions and densities from single view videos of smoke without using 3D ground truth.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_to_estimate_singleview_volumetric_flow_motions_without_3d_supervision	/pdf/1abacffa7752a2fb3fae3420f9b14440ed618ebe.pdf
Xp-__WzXiBy	1744	DIMENSION-REDUCED ADAPTIVE GRADIENT METHOD	['Deep learning optimizer']		Deep Learning and representational learning	anonymous|dimensionreduced_adaptive_gradient_method	/pdf/e593849525ede803feeae28498e491382c72160e.pdf
wZRgC1McxyU	1745	Neural Field Discovery Disentangles Equivariance in Interacting Dynamical Systems	['Interacting Dynamical systems', 'Graph Neural Networks', 'Neural Fields', 'Equivariance']	We disentangle global fields effects from local object interactions in interacting dynamical systems, and propose neural fields to discover underlying fields.	Deep Learning and representational learning	anonymous|neural_field_discovery_disentangles_equivariance_in_interacting_dynamical_systems	/pdf/7ac107c0c52c9ddc0d8c51f88a8b01685d878036.pdf
ZtW4gh_q5AC	1746	RegQ: Convergent Q-Learning with Linear Function Approximation using Regularization	['reinforcement learning', 'Q-learning', 'reinforcement learning theory']	This paper develops convergent Q-learning algorithm when linear function approximation is used.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|regq_convergent_qlearning_with_linear_function_approximation_using_regularization	/pdf/4c5bd0580b44bf4e4f09d2359519d894e5afe809.pdf
7IMneQViz6h	1747	Mutual Information-guided Knowledge Transfer for Open-World Semi-Supervised Learning	['Novel Class Discovery', 'Open-world Semi-supervised learning', 'Knowledge Transfer', 'Mutual Information']		Deep Learning and representational learning	anonymous|mutual_informationguided_knowledge_transfer_for_openworld_semisupervised_learning	/pdf/5f805925c915b06af2cb7a1da80c780a52f25fa9.pdf
k5e6oQP2zHx	1749	QUANTILE-LSTM: A ROBUST LSTM FOR ANOMALY DETECTION	['Anomaly', 'Quantile', 'LSTM', 'Activation Function']		Deep Learning and representational learning	anonymous|quantilelstm_a_robust_lstm_for_anomaly_detection	/pdf/506a658e4bc38de166ab74963e01b700e373237a.pdf
lEFM4OTz62c	1750	Group-level Brain Decoding with Deep Learning	['deep learning', 'transfer learning', 'decoding', 'neuroimaging', 'MEG', 'permutation feature importance']	We propose a neuroscientifically interpretable deep learning model capable of jointly decoding multiple subjects in neuroimaging data aided by subject embeddings.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|grouplevel_brain_decoding_with_deep_learning	/pdf/6a26d42cd148acdc01f07f653734c3bb6d1e3db8.pdf
YtghWaAhboM	1751	Learning Inductive Object-Centric Slot Initialization via Clustering	['Slot representation', 'Clustering', 'Unsupervised learning', 'Object discovery', 'Novel view synthesis']		Deep Learning and representational learning	anonymous|learning_inductive_objectcentric_slot_initialization_via_clustering	/pdf/1f937363cc275e7d08094a5d063b1cdb43df86e6.pdf
FRLswckPXQ5	1752	Improved Convergence of Differential Private SGD with Gradient Clipping	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|improved_convergence_of_differential_private_sgd_with_gradient_clipping	/pdf/7febba42d1fb2a8c3ede1a4f45f80f73b4ec25f3.pdf
unKdm72T5wP	1753	High probability error bounds of SGD in unbounded domain	[]		Optimization (eg, convex and non-convex optimization)	anonymous|high_probability_error_bounds_of_sgd_in_unbounded_domain	/pdf/9a8bddc51abd6e9594e5cbb7f25c384baaa00c3e.pdf
p8hMBcPtvju	1754	Scalable Subset Sampling with Neural Conditional Poisson Networks	[]		Deep Learning and representational learning	anonymous|scalable_subset_sampling_with_neural_conditional_poisson_networks	/pdf/a894b3ec730d66dce2a18167d4139fc176ae41e8.pdf
FpkVnbE_h6i	1755	SAAL: Sharpness-Aware Active Learning	['active learning', 'loss sharpness', 'SAM']	We propose Sharpness-Aware Active Learning, or SAAL, which adopts the loss sharpness for the acquisition score.	Deep Learning and representational learning	anonymous|saal_sharpnessaware_active_learning	/pdf/8947ed87889595faea704c9866594d6930060360.pdf
TtxOsdYU92d	1756	Generalized Sum Pooling for Metric Learning	['Metric learning', 'feature selection', 'global average pooling', 'zero-shot regularization']	We generalize global average pooling and propose a learnable generalized sum pooling method which effectively choose a subset of the features to be re-weighted in aggregation.	Deep Learning and representational learning	anonymous|generalized_sum_pooling_for_metric_learning	/pdf/94e06fe3dfa72b7e4446a8f9056cc6e85617cc08.pdf
aHwehiwz6YW	1758	Considering Layerwise Importance in the Lottery Ticket Hypothesis	['Lottery Ticket Hypothesis']	Using different importance measures in the LTH procedure to determine properties of the resulting LTs.	Deep Learning and representational learning	anonymous|considering_layerwise_importance_in_the_lottery_ticket_hypothesis	/pdf/ea2e79062b1cbfa81d563a7aaca825e29af61b91.pdf
vhFu1Acb0xb	1759	Transformers are Sample-Efficient World Models	['deep learning', 'reinforcement learning', 'model-based reinforcement learning', 'world models', 'learning in imagination', 'transformers', 'discrete autoencoders', 'generative modeling', 'sequence modeling']	We introduce a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|transformers_are_sampleefficient_world_models	/pdf/2961426d7811fe9f50b7b042dd5ce9fbd79eca80.pdf
1J-ZTr7aypY	1760	Differentiable Mathematical Programming for Object-Centric Representation Learning	[]		Deep Learning and representational learning	anonymous|differentiable_mathematical_programming_for_objectcentric_representation_learning	/pdf/1fd8ffcdae772c5d986aa9768cf2d3d449e44bfd.pdf
C3ukgkqJuh0	1761	Reinforcement learning for instance segmentation with high-level priors	['Instance Segmentation', 'Reinforcement Learning', 'Biomedical Imaging']	Instance segmentation can be learned from high-level rules only for objects following a regular shape prior.	Unsupervised and Self-supervised learning	anonymous|reinforcement_learning_for_instance_segmentation_with_highlevel_priors	/pdf/81cd55cfb6b445dbca1a507985ceea9d0eb9db12.pdf
S07feAlQHgM	1762	A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning	['class-incremental learning']		Deep Learning and representational learning	anonymous|a_model_or_603_exemplars_towards_memoryefficient_classincremental_learning	/pdf/60b2e9b98ddfef7a0bc2bcc1ebac22f88827ae94.pdf
Ck1UtnVukP8	1763	From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models	['Large Language Model', 'Visual Question Answer', 'Prompts', 'Zero-Shot']		Applications (eg, speech processing, computer vision, NLP)	anonymous|from_images_to_textual_prompts_zeroshot_vqa_with_frozen_large_language_models	/pdf/5ce6877e18e47a089210564b5cce52f08f4d8b63.pdf
qxcQqFUTIpQ	1764	Byzantine-robust Decentralized Learning via ClippedGossip	['Byzantine-robustness', 'distributed machine learning', 'robustness', 'optimization', 'decentralized learning']	In this paper, we study the challenging task of Byzantine-robust decentralized training on arbitrary communication graphs. 	Optimization (eg, convex and non-convex optimization)	anonymous|byzantinerobust_decentralized_learning_via_clippedgossip	/pdf/7fc3066dd1d3b609d8fbf85ea7cb6374e342a44c.pdf
_8mS2NE-HXN	1766	SYNC: SAFETY-AWARE NEURAL CONTROL FOR STABILIZING STOCHASTIC DELAY-DIFFERENTIAL EQUATIONS	['Stochastic delay-differential equations', 'safety guarantee', 'stochastic stabilization', 'neural networks']	We propose a new class of neural control polices for stabilizing stochastic delay-differential equations with safety guarantee, named as SYNC and including both deterministic and stochastic control outperforming the existing methods.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|sync_safetyaware_neural_control_for_stabilizing_stochastic_delaydifferential_equations	/pdf/410288cc9433a23bfa02ee4c1423674305b34705.pdf
p4bZLgHUB6L	1767	Learn Low-dimensional Shortest-path Representation of Large-scale and Complex Graphs	['shortest-path distance', 'graph representation learning', 'random walk']	We propose an efficient and interpretable shortest-path representation method for fast, accurate and scalable shortest-path distance queries.	Deep Learning and representational learning	anonymous|learn_lowdimensional_shortestpath_representation_of_largescale_and_complex_graphs	/pdf/dbdc4e13a0cda685764849219ef546e53283b41b.pdf
socffUzSIlx	1768	Anisotropic Message Passing: Graph Neural Networks with Directional and Long-Range Interactions	['Message Passing', 'Graph Neural Networks', 'Directional', 'Long-Range', 'Equivariant', 'Quantum Chemistry', 'QM/MM']	Modified message passing for the efficient description of long-range and directional interactions with applications to quantum-chemical systems.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|anisotropic_message_passing_graph_neural_networks_with_directional_and_longrange_interactions	/pdf/43e96b87891cf93addfc6dfefbbb1cfaf06c03c2.pdf
JSZvTDggUvz	1770	Understanding Masked Image Modeling via Learning Occlusion Invariant Feature	[]		Unsupervised and Self-supervised learning	anonymous|understanding_masked_image_modeling_via_learning_occlusion_invariant_feature	/pdf/b56b64845367f8d6f47a72afe788589b225db44f.pdf
3FdmckXo3cN	1771	BPFL: Towards Efficient Byzantine-Robust and Provably Privacy-Preserving Federated Learning	['federated learning', 'Byzantine-robust', 'privacy-preserving']	We propose to address both Byzantine (security) attacks and data reconstruction (privacy) attacks against federated learning.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|bpfl_towards_efficient_byzantinerobust_and_provably_privacypreserving_federated_learning	/pdf/e0f0bc1e27da4d1b52c924a57bdce41c409a6f00.pdf
FPeVU4Y_Lo6	1772	Newton Losses: Efficiently Including Second-Order Information into Gradient Descent	['differentiable algorithms', 'backpropagation', 'differentiable']	Applying Newton to the loss and gradient descent to the neural network.	Deep Learning and representational learning	anonymous|newton_losses_efficiently_including_secondorder_information_into_gradient_descent	/pdf/2825c258247f9950d6e0e3f09e1f4faa4df49d5d.pdf
0h4_YLDhf4K	1773	SeqSHAP: Subsequence Level Shapley Value Explanations for Sequential Predictions	['XAI', 'Explainability', 'SHAP', 'Sequential Predictions']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|seqshap_subsequence_level_shapley_value_explanations_for_sequential_predictions	/pdf/1db8c4c76892b1cf404f833704cf1b8c3b12cbed.pdf
VELL0PlWfc	1774	Tailoring Language Generation Models under Total Variation Distance	['language generation', 'maximum likelihood estimation', 'total variation distance', 'text degeneration']	We analyze total variation distance (TVD) as a robust metric to outliers and devise a new training objective based on TVD to alleviate text degeneration and improve the generation quality.	Applications (eg, speech processing, computer vision, NLP)	anonymous|tailoring_language_generation_models_under_total_variation_distance	/pdf/db9910d1b60a040caad6e3da4e8b80abed7a8910.pdf
0h-YwriPUI	1775	Memory-Augmented Variational Adaptation for Online Few-Shot Segmentation	['Online few-shot segmentation', 'Variation inference', 'Memory-augmented.']	We propose a memory-augmented variational adaptation mechanism, which learns to adapt the model to every new sample that arrives sequentially.	Applications (eg, speech processing, computer vision, NLP)	anonymous|memoryaugmented_variational_adaptation_for_online_fewshot_segmentation	/pdf/8ba7247e91933a0933f377db83e8795ea1b66d4b.pdf
aBHTGMkisy-	1777	Gradient Inversion via Over-parameterized Convolutional Network in Federated Learning	['Gradient Inversion', 'Federated Learning']		General Machine Learning (ie none of the above)	anonymous|gradient_inversion_via_overparameterized_convolutional_network_in_federated_learning	/pdf/38ab75602f93124190e9fd748f7ea89fa764b981.pdf
d_iQXvrt9KN	1778	BED: Boundary-Enhanced Decoder for Chinese Word Segmentation	['Chinese Word Segmentation', 'deep learning', 'nature language processing']	 An optimized decoder for the CWS model called Boundary-Enhanced Decoder.	Applications (eg, speech processing, computer vision, NLP)	anonymous|bed_boundaryenhanced_decoder_for_chinese_word_segmentation	/pdf/089ba8d18cdb5f85dd54960257874ee7362db227.pdf
EJka_dVXEcr	1779	TabDDPM: Modelling Tabular Data with Diffusion Models	['tabular data', 'diffusion models', 'generative modelling']	Proposed a new state-of-the-art approach for tabular data generation using diffusion models	Generative models	anonymous|tabddpm_modelling_tabular_data_with_diffusion_models	/pdf/736497735c84ff92669b8f44c588264ce736c7fb.pdf
KrGgylZ0tw_	1780	Test-time recalibration of conformal predictors under distribution shift based on unlabeled examples	['classification', 'uncertainty estimation', 'conformal prediction']	We propose a novel test-time recalibration method for conformal prediction based on unlabeled examples that provides excellent uncertainty estimates under natural distribution shifts.	General Machine Learning (ie none of the above)	anonymous|testtime_recalibration_of_conformal_predictors_under_distribution_shift_based_on_unlabeled_examples	/pdf/d4c1bba506dec84c1ca6206514a30eb1ddbf3c61.pdf
9czfKu1QqcN	1781	ErGOT: entropy-regularized graph optimal transport	['Graph comparison', 'entropy-regularized optimal transport', 'NP-hard problem', 'graph matching', 'graph alignment', 'graph sketching', 'graph retrieval']		General Machine Learning (ie none of the above)	anonymous|ergot_entropyregularized_graph_optimal_transport	/pdf/8a0ee0abdb5e36307d8c0f47b63efb7646aa51ad.pdf
xI1ZTtVOtlz	1782	Evidential Uncertainty and Diversity Guided Active Learning for Scene Graph Generation	['Active learning', 'Scene graph generation', 'Uncertainty estimation']	We proposed an Active Learning framework for the Scene Graph Generation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|evidential_uncertainty_and_diversity_guided_active_learning_for_scene_graph_generation	/pdf/3e9b720b616835d44a08cdcc14a466a43cc0b764.pdf
4eJ43EN2g6l	1783	SketchKnitter: Vectorized Sketch Generation with Diffusion Models	[]		Generative models	anonymous|sketchknitter_vectorized_sketch_generation_with_diffusion_models	/pdf/928f8cba0be9afcd3004f30622b435d86427cbf4.pdf
0UzYWLzPBjA	1784	An Intrinsic Dimension Perspective of Transformers for Sequential Modeling	['intrinsic dimension', 'transformer', 'text Classification', 'NLP']	The analysis of transformers applied to sequential modeling from an perspective of intrinsic dimension.	Deep Learning and representational learning	anonymous|an_intrinsic_dimension_perspective_of_transformers_for_sequential_modeling	/pdf/34f2dddfaebdec7277475288ed925f1a863c38aa.pdf
Qyz2cMy-ty6	1786	A New Paradigm for Federated Structure Non-IID Subgraph Learning	['graph neural network', 'federated learning', 'structure non-iid subgraphs']	The first attempt to investigate the structure non-iid problem in federated subgraph learning.	Deep Learning and representational learning	anonymous|a_new_paradigm_for_federated_structure_noniid_subgraph_learning	/pdf/0c2e08ce483d3be7619a37c91fc3b964d9e1faf4.pdf
EXnIyMVTL8s	1787	Towards Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated Learning	['federated Learning', 'representation Learning', 'data heterogeneity', 'dimensional collapse']	We show data heterogeneity in federated learning causes dimensional collapse for trained models, and propose FedDecorr to mitigate such problem.	Deep Learning and representational learning	anonymous|towards_understanding_and_mitigating_dimensional_collapse_in_heterogeneous_federated_learning	/pdf/523d69df57acec7564b0f2ce1e45e154097d3d7b.pdf
Zdpvtif5nPZ	1788	Formal Conceptual Views in Neural Networks	['Conceptual Scaling', 'Explainable AI', 'Global Explanation', 'Formal Concept Analysis', 'Lattices']	Conceptual structures allow for global insights into neural network models resulting in novel approaches for explainable AI. 	Deep Learning and representational learning	anonymous|formal_conceptual_views_in_neural_networks	/pdf/ca3279793d6aead584a3cc1d0742bfec8b2f2f89.pdf
wle-ah5tiY	1789	miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|micse_mutual_information_contrastive_learning_for_lowshot_sentence_embeddings	/pdf/d51aa0f56beaf8e1eacc1893f371acd9551a9868.pdf
S80I3NwbbpS	1790	CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling	['Long Sequence Modeling', 'Benchmark', 'Efficient Attention']	We propose Comprehensive Attention Benchmark (CAB) with seven real-world tasks from different research areas to evaluate efficient attentions under four fine-grained attention patterns.	Deep Learning and representational learning	anonymous|cab_comprehensive_attention_benchmarking_on_long_sequence_modeling	/pdf/3d9d7fefbe5aab204701d76b6e5c0c34b460de12.pdf
YPHIlC3K4J	1791	Neural Discrete Reinforcement Learning	['Deep Reinforcement Learning', 'Representation Learning', 'Action Space']	Discrete all types of action spaces in decision making and utilize arbitrary DRL algorithm to solve them.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|neural_discrete_reinforcement_learning	/pdf/0f5c01aafa1d1b37b7f7220d4a41329e35edb3e6.pdf
-CoNloheTs	1792	An Exact Poly-Time Membership-Queries Algorithm for Extracting a Three-Layer ReLU Network	['Learning With Queries', 'ReLU Networks', 'Model Extraction']	A first polynomial-time algorithm to extract the parameters and architecture of two- and three-layer neural networks using membership-queries	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|an_exact_polytime_membershipqueries_algorithm_for_extracting_a_threelayer_relu_network	/pdf/9bbf9cace92f89bd55d0c884c42b5eb41aa7cfc6.pdf
4I3vW2sInc	1794	Efficient Evaluation of Adversarial Robustness for Deep Hashing based Retrieval	['Adversarial Attack', 'Adversarial Training', 'Deep Hashing', 'Similarity Retrieval']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|efficient_evaluation_of_adversarial_robustness_for_deep_hashing_based_retrieval	/pdf/cb646e3ad7c24d265a014d7e4b677ac1294e17e4.pdf
ngg86sSNDn	1795	MULTILEVEL XAI: VISUAL AND LINGUISTIC BONDED EXPLANATIONS	['Deep neural networks', 'Black box', 'Explainable Artificial Intelligence', 'Saliency maps']	We propose a novel XAI methodology to explain DNNs predictions in a multilevel manner (i.e., visual and linguistic) without requiring per-image annotations.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|multilevel_xai_visual_and_linguistic_bonded_explanations	/pdf/07d258da2eaa9f0da69cf1f1fc78d60728a88069.pdf
YrmoVzxBLSa	1796	Momentum Diminishes the Effect of Spectral Bias in Physics-Informed Neural Networks	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|momentum_diminishes_the_effect_of_spectral_bias_in_physicsinformed_neural_networks	/pdf/901f255279c6a63ef059c30a6ece2a6bf3915ee3.pdf
lJX9okHBVMb	1797	Universal approximation and model compression for radial neural networks 	['universal approximation', 'model compression', 'radial functions', 'parameter space symmetries', 'projected gradient descent']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|universal_approximation_and_model_compression_for_radial_neural_networks	/pdf/213f3ef521f151f6ec7763f0218d9d0097f9ef26.pdf
5L1ctJ223ML	1798	Regularizing hard examples improves robustness	['deep learning', 'adversarial robustness', 'adversarial examples']	We study the negative effect of hard examples on generalization in adversarial training and propose a new method to mitigate the effect of hard examples.	Deep Learning and representational learning	anonymous|regularizing_hard_examples_improves_robustness	/pdf/93c66f79ba127fcef86074f8c365bdfb646952ba.pdf
kciCTrtbzVl	1799	Koopman neural operator for learning non-linear partial differential equations	['Neural Operator', 'Koopman Theory', 'Partial Differential Equations', 'Dynamic System']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|koopman_neural_operator_for_learning_nonlinear_partial_differential_equations	/pdf/afd8b91bfa07b4ae2ea039d125b6d64f83f8e78d.pdf
PFUIHZGE4DS	1800	MESSAGENET: MESSAGE CLASSIFICATION USING NATURAL LANGUAGE PROCESSING AND META-DATA	['Message classification · Meta data injection · Deep learning · Natural language processing']	We propose a deep neural network based on blocks for message classification using meta-data inputs	Deep Learning and representational learning	anonymous|messagenet_message_classification_using_natural_language_processing_and_metadata	/pdf/d1f52dd0c08b9beb39d4acd37176d0a039a0654b.pdf
tm8p3x5Rf8N	1801	Local Attention Layers for Vision Transformers	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|local_attention_layers_for_vision_transformers	/pdf/801707f68b1154d9ec50f12e815f6998ddab24a7.pdf
8JRQza2MaO4	1802	Revitalize Region Feature for Democratizing Video-language Pre-training of Retrieval	[]		Deep Learning and representational learning	anonymous|revitalize_region_feature_for_democratizing_videolanguage_pretraining_of_retrieval	/pdf/47dc9f0d9c34f8a2dd1b303b701bab8fb8e6a697.pdf
pO7KggcbMiP	1803	BAMBI: Vertical Federated Bilevel Optimization with Privacy-Preserving and Computation Efficiency	['Vertical federated learning', 'zeroth-order estimation']	To our best knowledge, this is the first work on the bilevel optimization under the setting of VFL.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|bambi_vertical_federated_bilevel_optimization_with_privacypreserving_and_computation_efficiency	/pdf/528003075b3e555a2ff45622a444c22433673275.pdf
Js4vqB4bWVh	1805	Decentralized Online Bandit Optimization on Directed Graphs with Regret Bounds	['Bandit optimization', 'multi-agent learning', 'decentralized learning', 'joint bandit-rewards']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|decentralized_online_bandit_optimization_on_directed_graphs_with_regret_bounds	/pdf/a87e0d5d285306b40fcc8704b85bec190e68166a.pdf
f7VHa2mwDEq	1806	Heterogeneous Continual Learning	['Continual learning', 'representational learning', 'deep learning', 'model progression']	A novel framework and a solution to tackle the continual learning problem with progressive evolution of neural networks.	Deep Learning and representational learning	anonymous|heterogeneous_continual_learning	/pdf/f14de28b4493e9d7f6635c190ad30d860d60c126.pdf
dOHZkdrtnrD	1807	Learning Transferable Spatiotemporal Representations from Natural Script Knowledge	['Spatiotemporal Representation Learning', 'Video Pre-training', 'Action Recognition']	A video pre-training method that learns transferable spatiotemporal representations from large-scale uncurated data, exhibiting strong out-of-the-box capabilities.	Deep Learning and representational learning	anonymous|learning_transferable_spatiotemporal_representations_from_natural_script_knowledge	/pdf/8695df1199a93829261e989187d008186cb1805a.pdf
gZ1UIqjW1Q	1809	CorruptEncoder: Data Poisoning Based Backdoor Attacks to Contrastive Learning	['Backdoor Attack', 'Contrastive Learning']	We propose data poisoning based backdoor attacks to contrastive learning that achieves the state-of-the-art performance.	Unsupervised and Self-supervised learning	anonymous|corruptencoder_data_poisoning_based_backdoor_attacks_to_contrastive_learning	/pdf/a71769013eb8042087131d5a81891020c7af2964.pdf
nfMQJ4pz2Y	1810	Learning Instance-Solution Operator For Optimal Control	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_instancesolution_operator_for_optimal_control	/pdf/77588674c49d7bf748fe546eae52918be60c3699.pdf
OgbtSLESnI	1811	TabCaps: A Capsule Neural Network for Tabular Data Classification with BoW Routing	['capsule neural network']	We proposed a capsule neural network for tabular data classification.	Deep Learning and representational learning	anonymous|tabcaps_a_capsule_neural_network_for_tabular_data_classification_with_bow_routing	/pdf/a1a2d632a2b8085314966b9f7fdbb16f46d884d5.pdf
QCtizuT48D	1812	FedCL: Critical Learning Periods-aware Adaptive Client Selection in Federated Learning	['Critical Learning Periods', 'Federated Learning', 'Client Selection']		General Machine Learning (ie none of the above)	anonymous|fedcl_critical_learning_periodsaware_adaptive_client_selection_in_federated_learning	/pdf/4b61fc21f31943cfed2cd6d8e12eb07cb0510f02.pdf
tc2UP4qhplB	1813	ObPose: Leveraging Pose for Object-Centric Scene Inference and Generation in 3D	['Object-centric scene inference', 'Object-centric representation learning', 'Scene generation', '3D']	We present an object-centric scene inference and generation model that learns 3D structured latent representations from RGB-D scenes.	Deep Learning and representational learning	anonymous|obpose_leveraging_pose_for_objectcentric_scene_inference_and_generation_in_3d	/pdf/ac185fbf83b46d6c6a1b64eabb4a5da72595b782.pdf
_lyO4HOLDF	1816	M$^3$Video: Masked Motion Modeling for Self-Supervised Video Representation Learning	['Self-supervised Video Representation Learning', 'Action Recognition', 'Masked Motion Modeling']	We propose a masked motion modeling task, where the model is asked to predict the motion of masked moving objects, for self-supervised video representation learning	Unsupervised and Self-supervised learning	anonymous|m^3video_masked_motion_modeling_for_selfsupervised_video_representation_learning	/pdf/6d5ceacb8f61a2e5fe5b9720220474b0159b307c.pdf
rZ-wylY5VI	1817	Programmatically Grounded, Compositionally Generalizable Robotic Manipulation	['Vision-Language-Action Grounding', 'Zero-Shot Generalization', 'Compositional Generalization', 'Neurosymbolic Learning']	We parse and execute semantically grounded neural programs for robotic manipulation, enabling better zero-shot and compositional generalizable to new manipulation behaviors.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|programmatically_grounded_compositionally_generalizable_robotic_manipulation	/pdf/3ab56974ae722a1f0f4f18a5b0eb54f145e34556.pdf
DeG07_TcZvT	1818	Emergent world representations: Exploring a sequence model trained on a synthetic task	['world representation', 'GPT']		Deep Learning and representational learning	anonymous|emergent_world_representations_exploring_a_sequence_model_trained_on_a_synthetic_task	/pdf/0efb0215eefd5ed73d637bef1b51ad140d4ea09b.pdf
w7ds3UKtQJl	1819	Learning Diverse and Effective Policies with Non-Markovian Rewards	['policy diversity', 'non-Markovian Rewards', 'reinforcement learning']	We propose a diversity matrix to quantify policy diversity and theoretically prove that if the diversity matrix is positive definite, then the diversity of policies can be achieved without sacrificing their effectiveness.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_diverse_and_effective_policies_with_nonmarkovian_rewards	/pdf/a72f1ae86ccbcb1acb1b0c417c3404c8d985c275.pdf
etPgCVMh8IB	1820	Distraction is All You Need For Fairness	['Fairness', 'Deep Learning', 'Neural Networks', 'Adversarial Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|distraction_is_all_you_need_for_fairness	/pdf/b388d48226c212d02754e3afe066f8f99dc568fd.pdf
dGzgbdQbgwm	1821	Improve learning combining crowdsourced labels by weighting Areas Under the Margin	['crowdsourcing', 'ambiguity', 'area under the margin', 'aggregation', 'noisy labels']	We introduced the weighted Areas Under the Margin to identify ambiguous tasks in crowdsourced learning scenarios	General Machine Learning (ie none of the above)	anonymous|improve_learning_combining_crowdsourced_labels_by_weighting_areas_under_the_margin	/pdf/0a3ae532a5a51e82aab9ce41318bfcb49dd0a6cf.pdf
PQXP4WZNcM	1822	Bringing Saccades and Fixations into Self-supervised Video Representation Learning	['Self-supervised learning', 'video self-supervised learning', 'bio-inspired']	In this paper, we propose a self-supervised video representation learning method by taking inspiration from cognitive science and neuroscience on human visual perceptionization. 	Unsupervised and Self-supervised learning	anonymous|bringing_saccades_and_fixations_into_selfsupervised_video_representation_learning	/pdf/478de2ebbb16fed86c57a0f5662de44132eeffef.pdf
ay4xkpMnyE	1823	Enhancing Robustness of Deep Networks Based on a Two-phase Model of Their Training with Noisy Labels	['Image classification', 'Noisy label', 'Robust training']		Deep Learning and representational learning	anonymous|enhancing_robustness_of_deep_networks_based_on_a_twophase_model_of_their_training_with_noisy_labels	/pdf/32404e4378e7ce6b8ae7a8d5b07fa5193e549387.pdf
W-nZDQyuy8D	1824	GOOD: Exploring geometric cues for detecting objects in an open world	['open world', 'object detection', 'geometric cues', 'mid-level representations']	We propose incorporating geometric cues into open-world object detector training and make significant improvements on various benchmarks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|good_exploring_geometric_cues_for_detecting_objects_in_an_open_world	/pdf/ffb6fcecc8e9a01ecf30de18e569bfd90be16a20.pdf
okwxL_c4x84	1825	Clifford Neural Layers for PDE Modeling	['Geometric Deep Learning', 'PDE modeling', 'multivector fields', 'Clifford algebra', 'Clifford convolution', 'Clifford Fourier transform']	We introduce neural network layers on composite objects of scalars, vectors, and higher order objects such as bivectors.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|clifford_neural_layers_for_pde_modeling	/pdf/6d6c78f7b8dc56d6183f8bc6221a4261523f09a9.pdf
IJV0augCyk	1826	Logit Clipping for Robust Learning against Label Noise	['noisy labels', 'robust loss functions', 'logit clipping', 'overfitting']	We propose to clamp the norm of the logit output, which can enhance the noise-robostness of existing loss functions with theoretical guarantee.	Deep Learning and representational learning	anonymous|logit_clipping_for_robust_learning_against_label_noise	/pdf/e7323ce911612ac7b182f4c2417c7361bde5b9e8.pdf
GbsvQSaJV-6	1827	Towards Skilled Population Curriculum for MARL	['multi-agent reinforcement learning', 'multi-agent cooperation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_skilled_population_curriculum_for_marl	/pdf/aca8b092720728b0728f4519823c65e222aac905.pdf
4dZeBJ83oxk	1828	3D Segmenter: 3D Transformer based Semantic Segmentation via 2D Panoramic Distillation	['3D semantic segmentation', 'knowledge distillation']	Distill knowledge from 2D strong model to enhance 3D semantic segmentation	Applications (eg, speech processing, computer vision, NLP)	anonymous|3d_segmenter_3d_transformer_based_semantic_segmentation_via_2d_panoramic_distillation	/pdf/58e9d1de074dfa11677b05bc15eccac91178fef3.pdf
m3QhpKNXU6-	1829	What can be learnt with wide convolutional neural networks?	['hierarchical models', 'kernel learning', 'neural tangent kernel', 'theory of deep learning', 'generalization', 'convolutional neural networks']	theoretical study of generalisation rates for deep CNNs in the kernel regime	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|what_can_be_learnt_with_wide_convolutional_neural_networks	/pdf/fa4cbb9568585fb2749ce360632ee273df67405d.pdf
l02pjIT6JWy	1833	Single-Stage Open-world Instance Segmentation with Cross-task Consistency Regularization	['Open world', 'instance segmentation', 'Cross-task Consistency Regularization']	This paper proposed a single-stage open-world instance segmentation framework with a cross-task consistency loss, achieving superior performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|singlestage_openworld_instance_segmentation_with_crosstask_consistency_regularization	/pdf/daec4d4921c58c4072f7b150dcf892392272f05e.pdf
9RHjy5oHmfe	1834	EIT: Enhanced Interactive Transformer for Sequence Generation	['Transformer', 'Multi-head self-attention', 'Sequence Generation', 'Machine Translation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|eit_enhanced_interactive_transformer_for_sequence_generation	/pdf/93e63700c7cadda7d7fe39a6e78ddb6f0da079cc.pdf
uhLAcrAZ9cJ	1835	Efficient Federated Domain Translation 	[]		Generative models	anonymous|efficient_federated_domain_translation	/pdf/76b6eb05729514a51f9345682b25c7a69461f25e.pdf
LSz-gQyd0zE	1837	Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive Machine Translation	['Machine translation', 'Non-autoregressive generation', 'Fuzzy alignment']	We introduce a fuzzy alignment objective in Directed Acyclic Graph for NAT, setting a new state of the art for NAT on the raw training data.	Applications (eg, speech processing, computer vision, NLP)	anonymous|fuzzy_alignments_in_directed_acyclic_graph_for_nonautoregressive_machine_translation	/pdf/4a0f4baaacf1749e82effffe6f6d953014d7f086.pdf
4Xd_aAqNe7h	1838	FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders	['FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders']	A novel method for privacy-preserving face recognition.	Applications (eg, speech processing, computer vision, NLP)	anonymous|facemae_privacypreserving_face_recognition_via_masked_autoencoders	/pdf/098a1ca6c3cfa9c9110997828276040846c2de19.pdf
iUCI3mQ8KkR	1839	Differentiable Meta-Logical Programming	['meta interpreter', 'differentiable forward chaining inference', 'first order logic']	We realize a differentiable logical meta interpreter (DLMI) using differentiable forward-chaining reasoning in first-order logic. 	General Machine Learning (ie none of the above)	anonymous|differentiable_metalogical_programming	/pdf/44574b5a6353c9312c29095219c8793417771e06.pdf
KzfhxLoh6s0	1840	 Robust Constrained Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|robust_constrained_reinforcement_learning	/pdf/3cc2de1ce592ba3869422bc1fa61393e90f4b16f.pdf
LFHFQbjxIiP	1842	Conditional Antibody Design as 3D Equivariant Graph Translation	['conditional antibody generation', 'equivariant', 'multi-channel attention']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|conditional_antibody_design_as_3d_equivariant_graph_translation	/pdf/a299367f4fafd4ab707e3085a2c0d9fb4e6e7059.pdf
uAb5lQqdeHd	1843	HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks	['deep learning', 'hypernetworks', 'maml', 'few-shot learning', 'meta-learning', 'adaptation', 'hypermaml', 'few-shot', 'meta', 'learning', 'mini-imagenet']	We use Hypernetworks for generating weight updates for novel tasks in Few-Shot learning.	Deep Learning and representational learning	anonymous|hypermaml_fewshot_adaptation_of_deep_models_with_hypernetworks	/pdf/eeb11195dd69bdedc76ebaa3947ec74e46372ec5.pdf
QCrw0u9LQ7	1844	Iterative Patch Selection for High-Resolution Image Recognition	['high-resolution images', 'memory-efficient deep learning', 'multiple instance learning', 'transformer', 'image recognition', 'computer vision']	We propose a simple, memory-efficient method that selects the most salient patches from a high-resolution image and then aggregates them into a global representation for image recognition.	Applications (eg, speech processing, computer vision, NLP)	anonymous|iterative_patch_selection_for_highresolution_image_recognition	/pdf/d9ff834bf2ad37b5969ebb0062dda0917e5b3077.pdf
j3mm8mci4u	1845	On the Fast Convergence of Unstable Reinforcement Learning Problems	['unstable reinforcement learning', 'LQR', 'optimization']	We propose new methods to effectively improve the convergence of policy gradient method for unstable reinforcement problems.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_fast_convergence_of_unstable_reinforcement_learning_problems	/pdf/b6da5c672b1cd54f628f2f783116796c5be0860c.pdf
u1Vj68CJZP	1847	Uncertainty-based Multi-Task Data Sharing for Offline Reinforcement Learning	['multi-task data sharing', 'offline reinforcement learning', 'uncertainty quantification']	We propose an uncertainty-based multi-task data sharing approach that shares the entire dataset without data selection.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|uncertaintybased_multitask_data_sharing_for_offline_reinforcement_learning	/pdf/a0ee8402cdfbdc1bd093f076a42b7ccfafd17126.pdf
9EcAsB7wgM	1851	Take 5: Interpretable Image Classification with a Handful of Features	['xAI', 'interpretability', 'fine-grained image classification', 'sparsity', 'image classification', 'interpretability by design']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|take_5_interpretable_image_classification_with_a_handful_of_features	/pdf/409f8142f9c2f8897bcda6dae1d2b2738464bc77.pdf
8JqINxA-2a	1852	Unified Discrete Diffusion for Simultaneous Vision-Language Generation	['Multi-modal', 'Image generation', 'Image Caption.']	We proposed Unified Discrete Denoising Diffusion model, which allows us to construct a joint vision-language probability distribution, leading to a capability of simultaneously generating cross-domain results. 	Generative models	anonymous|unified_discrete_diffusion_for_simultaneous_visionlanguage_generation	/pdf/11401f50d91d6c9e15e9c0b376886b3bf09a9eb9.pdf
Fp0CMUtBtw	1853	VLG: General Video Recognition with Web Textual Knowledge	['Video Recognition', 'Multi Modality', 'Video-language representation learning']	We build a comprehensive video benchmark of Kinetics-GVR including close-set, long-tail, few-shot and open-set, and present a unified video-text framework (VLG) with web textual knowledge to achieve SOTA performance under different settings.	Applications (eg, speech processing, computer vision, NLP)	anonymous|vlg_general_video_recognition_with_web_textual_knowledge	/pdf/a01275b2e9c07541d7471fe1422464a6b79861c5.pdf
2bhXOpq53RP	1854	A Robust Stacking Framework for Training Deep Graph Models with Multifaceted Node Features	[]		Deep Learning and representational learning	anonymous|a_robust_stacking_framework_for_training_deep_graph_models_with_multifaceted_node_features	/pdf/7de6f736b5a7bbf8100b9ef459b5d9ce76ffab36.pdf
1kTxYvMRR8N	1855	AdaptFSP: Adaptive Fictitious Self Play	['Deep reinforcement learning', 'game theory', 'exploitability']	Use deep rl to modify FSP for better performance in continuous control games	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adaptfsp_adaptive_fictitious_self_play	/pdf/2237edce3ca4820aff615b4ca3693ace2d7670c6.pdf
cH4MVZsScm	1856	OoD-Control: Out-of-Distribution Generalization for Adaptive UAV Flight Control	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|oodcontrol_outofdistribution_generalization_for_adaptive_uav_flight_control	/pdf/6966716b8a5da77c6298d1feb89efd01b84fd550.pdf
kjPLodRa0n	1857	Revisiting Pretraining Objectives for Tabular Deep Learning	['Deep Learning', 'Tabular Data', 'Pretraining']	We identify best practicies for pretraining tabular DL models and show significant increase in downstream perfomance, which often leads to superiority over GBDTs.	Deep Learning and representational learning	anonymous|revisiting_pretraining_objectives_for_tabular_deep_learning	/pdf/e7c2c0a11377bae13393a6915c69e65ad008eccd.pdf
raU07GpP0P	1858	Improving Deep Regression with Ordinal Entropy	['regression', 'classification', 'entropy', 'depth estimation', 'counting', 'age estimation']	We observe that many regression problems are preferably formulated as classification tasks, and we provide a theoretical analysis to explain this phenomenon then we propose an ordinal entropy loss to improve the performance of regression.	Deep Learning and representational learning	anonymous|improving_deep_regression_with_ordinal_entropy	/pdf/f8e1335f751cb919743ddd2120facd73495a3db3.pdf
yyLvxYBJV1B	1859	AnyDA: Anytime Domain Adaptation	['Efficient Domain Adaptation', 'Anytime Prediction', 'Knowledge Distillation', 'Resource-constrained Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|anyda_anytime_domain_adaptation	/pdf/825693e10dc7dc77aa1d23f435ae4b3fca83e1c9.pdf
8is5PNk68ql	1860	Inferring Causal Relations between Temporal Events	['causality', 'temporal event']	method to infer causal relations between temporal events	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|inferring_causal_relations_between_temporal_events	/pdf/6c6f9b728974747349d9fda34d50d8e3f306dd11.pdf
aEFaE0W5pAd	1861	How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|how_to_exploit_hyperspherical_embeddings_for_outofdistribution_detection	/pdf/ce99fddb813b49129c8c257f3f6f5072e11e7465.pdf
LVujM8Yxsi	1862	DoE2Vec: Representation Learning for Exploratory Landscape Analysis	['autoencoder', 'optimization', 'exploratory landscape analysis', 'representation learning']	We propose DoE2Vec, a variational autoencoder (VAE)-based methodology to learn optimization landscape characteristics for downstream meta-learning tasks.	Optimization (eg, convex and non-convex optimization)	anonymous|doe2vec_representation_learning_for_exploratory_landscape_analysis	/pdf/74b908f5449782f432b611cc707f32bbd55c9539.pdf
SxO-qoAwVM	1864	Understanding Hindsight Goal Relabeling Requires Rethinking Divergence Minimization	['reinforcement learning', 'multi-goal reinforcement learning', 'imitation learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|understanding_hindsight_goal_relabeling_requires_rethinking_divergence_minimization	/pdf/916bf81972cae1705a77d99a562a532a60fa090c.pdf
S-h1oFv-mq	1866	Long-Tailed Learning Requires Feature Learning	['deep learning theory', 'generalization', 'long-tailed data distribution']	We study the importance of learning features in order to achieve good generalization when the data distribution has a long tail. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|longtailed_learning_requires_feature_learning	/pdf/d84f2b3476458846a3b587e7fa9dba62544a87e6.pdf
r0xte-t40I	1867	Learning Human-Compatible Representations for Case-Based Decision Support	['human-compatible representation learning', 'human triplet judgments']	We combine metric learning and supervised classification to learn human-compatible decision-focused representation.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_humancompatible_representations_for_casebased_decision_support	/pdf/49448a66f0a95bee6df4166bddbac50870628572.pdf
0paCJSFW7j	1868	ISAAC Newton: Input-based Approximate Curvature for Newton's Method	[]		Deep Learning and representational learning	anonymous|isaac_newton_inputbased_approximate_curvature_for_newtons_method	/pdf/1a5590d116699248514d5de8489dfa8c2e432393.pdf
1FsLDqHivn4	1869	Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings	['Multi-modal Learning', 'Music Description', 'Text Generation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|musictotext_synaesthesia_generating_descriptive_text_from_music_recordings	/pdf/cfb1fba9611d0d0e23e87c4f0aef124bc7bb45c6.pdf
r_vnM5H9Fm	1870	DEEPER-GXX: DEEPENING ARBITRARY GNNS	['Graph Neural Networks', 'Deep Learning']		Deep Learning and representational learning	anonymous|deepergxx_deepening_arbitrary_gnns	/pdf/5afe880d0b9da07e5fbb2a511e2b18df1a990ab3.pdf
5VBBA91N6n	1871	LMC: Fast Training of GNNs via Subgraph Sampling with Provable Convergence	['Graph Nerual Networks', 'Scalable Training', 'Provable Convergence', 'Local Message Compensation']	We propose a novel and efficient subgraph-wise sampling method with a convergence guarantee by Local Message Compensation (LMC).	Optimization (eg, convex and non-convex optimization)	anonymous|lmc_fast_training_of_gnns_via_subgraph_sampling_with_provable_convergence	/pdf/e1f5306b6c6ed7de8e88e42ce528daf5efddf3e8.pdf
24quGic59-	1872	Take One Gram of Neural Features, Get Enhanced Group Robustness	['group robustness', 'distribution shift', 'spurious correlations', 'Gram matrices']	We improve group robustness without group annotations by introducing GramClust, a two-stage method which (1) partition a dataset into groups based on features Gram matrices and (2) apply a robust optimization based on these pseudo-groups. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|take_one_gram_of_neural_features_get_enhanced_group_robustness	/pdf/ea504433d91ea86cdb5e0e59425851e52ce1d719.pdf
J7CTp-jNyJ	1873	SYNG4ME: Model Evaluation using Synthetic Test Data	['Model Evaluation', 'Synthetic data']	Evaluating ML supervised models by generating synthetic test data	General Machine Learning (ie none of the above)	anonymous|syng4me_model_evaluation_using_synthetic_test_data	/pdf/dc16fc554d28d29a81cc9d95a6b1f7bda04c61d0.pdf
nsz2ZxnD9D	1874	Enhance Local Consistency for Free: A Multi-Step Inertial Momentum Approach	['federated learning', 'optimization']	 we propose a novel federated learning algorithm, named FedMIM, which adopts the multi-step inertial momentum on the edge devices and enhances the local consistency for free during the training to improve the robustness of the heterogeneity.	Deep Learning and representational learning	anonymous|enhance_local_consistency_for_free_a_multistep_inertial_momentum_approach	/pdf/d7aa822303598c920952ff439dad815c7c3992b7.pdf
K5UfKyHIBS	1875	Imitation Improvement Learning for  Large-scale Capacitated Vehicle Routing Problems	['capacitated vehicle routing', 'deep reinforcement learning', 'imitation learning', 'clockwise clustering']	We propose an imitation learning and a clockwise clustering framework to efficiently solve large-scale capacitated vehicle routing problems	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|imitation_improvement_learning_for_largescale_capacitated_vehicle_routing_problems	/pdf/23bd766aa797470bed4db5e68b1473f22ded8af6.pdf
Db8XXy9RCL	1876	Points2NeRF: Generating Neural Radiance Fields from 3D point cloud	['NeRF', 'Neural Radiance Fields', '3D point clouds']	We convert 3D point clouds into Neural Radiance Fields (NeRFs).	Generative models	anonymous|points2nerf_generating_neural_radiance_fields_from_3d_point_cloud	/pdf/e194574c7a7cf2eb86eebe0a97409fd07568f9ab.pdf
I7Mvqi0p9Xj	1877	VC Theoretical Explanation of Double Descent	['Double Descent', 'Deep Learning', 'SVM', 'Least Squares', 'VC Dimension', 'VC Generalization Bounds', 'Structural Risk Minimization']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|vc_theoretical_explanation_of_double_descent	/pdf/6830f52df399d74299021d03c024a0843cff99c0.pdf
b7jXzuQMq8W	1878	"""Why did the Model Fail?"": Attributing Model Performance Changes to Distribution Shifts"	['distribution shifts', 'Shapley attribution', 'model robustness']	We propose a method to attribute model performance changes to distribution shifts in causal mechanisms.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|why_did_the_model_fail_attributing_model_performance_changes_to_distribution_shifts	/pdf/6d0bc1d40c4c3e7b0e18ad40b8cb40a6a15239b8.pdf
eWtMdr6yCmL	1879	Trading Information between Latents in Hierarchical Variational Autoencoders	['VAE', 'hierarchical VAE', 'rate distortion theory', 'information theory']	We generalize the rate/distortion theory of VAEs and analyze both theoeretically and analytically how manipulating each individual layer's rate affects performance.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|trading_information_between_latents_in_hierarchical_variational_autoencoders	/pdf/554fe4fcaf0c1ee399f15cc93c7bc625ee7aecc0.pdf
JEY4Rgx62Vt	1880	Complex-Target-Guided Open-Domain Conversation based on offline reinforcement learning	['target-guided dialogue', 'offline RL']		Deep Learning and representational learning	anonymous|complextargetguided_opendomain_conversation_based_on_offline_reinforcement_learning	/pdf/277b57914491493056093130507aa67268f9c4f0.pdf
I89hkzP0U4y	1881	Analyzing the Effects of Classifier Lipschitzness on Explainers	['Explainers', 'Explanation', 'Robustness', 'Astuteness', 'Lipschitz', 'Blackbox', 'Classifiers']	Theoretical work in support of the intuition that robust classifiers lend themselves to robust explainers	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|analyzing_the_effects_of_classifier_lipschitzness_on_explainers	/pdf/d8b5428756e3798f1d36e0e6848878bd4d9c52b5.pdf
n8toFjHwyjq	1882	Robust Neural ODEs via Contractivity-promoting Regularization	['contraction theory', 'neural ODEs', 'robustness', 'adversarial attacks', 'convolutional neural networks']	We use contraction theory for dynamical systems to design regularizers improving the robustness of neural ODEs.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|robust_neural_odes_via_contractivitypromoting_regularization	/pdf/8b71da1224bee1951df268635cc67a383648029f.pdf
C_PRLz8bEJx	1883	DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images	['3D Scene Decomposition', 'Object Manipulation', 'Neural Rendering']	In this paper, we study the problem of 3D scene geometry decomposition and manipulation from 2D views.	Deep Learning and representational learning	anonymous|dmnerf_3d_scene_geometry_decomposition_and_manipulation_from_2d_images	/pdf/946bb9e802a8c4f4c0835befa3135e3866f7173c.pdf
HtoA0oT30jC	1884	Novel View Synthesis with Diffusion Models	['3D', 'diffusion', 'ddpm', 'novel', 'view', 'synthesis', 'generative', 'models']	Novel View Synthesis with diffusion models from as few a single image	Generative models	anonymous|novel_view_synthesis_with_diffusion_models	/pdf/f84f4d758029ef24a48d77b9a7d4b9b3020da9fc.pdf
vPXp7K_Yhre	1885	Asynchronous Gradient Play in Zero-Sum Multi-agent Games	['asynchronous gradient play', 'OMWU', 'zero-sum polymatrix games']	This work provides the first set of algorithms and analyses on understanding asynchronous gradient play in zero-sum multi-agent polymatrix games under a wide range of delay assumptions.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|asynchronous_gradient_play_in_zerosum_multiagent_games	/pdf/c1f9cffb974b81f729ecf1b6b13dc58da2e7daca.pdf
H6T7AAoTUsR	1886	Towards Realtime Distributed Virtual Flow Meter via Compressed Continual Learning	['continual learning', 'distributed sensor', 'compressed learning']		Deep Learning and representational learning	anonymous|towards_realtime_distributed_virtual_flow_meter_via_compressed_continual_learning	/pdf/cb26ea3dfb89d3662338770b0b1a2c0080406b19.pdf
J4mJjotSauh	1887	Fooling SHAP with Stealthily Biased Sampling	['Explainability', 'Robustness', 'SHAP', 'Stealthily Sampling']	We show that Shapley-based explanation techniques commonly used in ML can be manipulated to show false compliance (e.g., during an algorithmic fairness audit) and that this type of attack can be hard to detect.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fooling_shap_with_stealthily_biased_sampling	/pdf/db4b4ae040a6183b13782b38dba764c60725bd3e.pdf
fxkACnJZmy_	1888	Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes	['double descent', 'Gaussian processes', 'Bayesian statistics']	We prove marginal likelihood for optimally-tuned Gaussian processes increases monotonically with input dimension, contrasting with posterior predictive losses that can exhibit double descent.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|monotonicity_and_double_descent_in_uncertainty_estimation_with_gaussian_processes	/pdf/8903ecd2b6ce934cd789f51e2a3549c9f0db24d8.pdf
5MUJsSRuylD	1889	Causal Inference via Nonlinear Variable Decorrelation in Healthcare	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|causal_inference_via_nonlinear_variable_decorrelation_in_healthcare	/pdf/d9676142046a51873e825a8509699e806f2d668e.pdf
S0v71vsLBYhM	1890	Inducing Gaussian Process Networks	['Gaussian processes', 'Kernel Methods', 'Classification', 'Regression']	We introduce a new method to efficiently learn the kernel and inducing points for Gaussian processes.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|inducing_gaussian_process_networks	/pdf/957afa1613b07221ce9cd51689dd6f89fb8efb7d.pdf
ih0uFRFhaZZ	1891	Continual Unsupervised Disentangling of Self-Organizing Representations	['continual disentanglment', 'generative model', 'VAE', 'SOM']	We proposed a novel generative model describing a topologically-connected mixture of spike-and-slab distributions in the latent space for continual unsupervised learning and disentangling representations.	Deep Learning and representational learning	anonymous|continual_unsupervised_disentangling_of_selforganizing_representations	/pdf/3c2373e60c21ef885bbca2c00d69d07d8b170466.pdf
pjePBJjlBby	1893	Point-based Molecular Representation Learning from Conformers	['molecular representation learning']	This paper proposes a point-based deep network for molecular representation learning from three-dimensional conformers. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pointbased_molecular_representation_learning_from_conformers	/pdf/9a0a39776c178f085ca7dfbfe6d6e2eefb218df0.pdf
TjEzIsyEsQ6	1894	Multi-Objective Reinforcement Learning: Convexity, Stationarity and Pareto Optimality	[]	We propose a linear scalarization based algorithm that has the potential to find the entire Pareto front.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multiobjective_reinforcement_learning_convexity_stationarity_and_pareto_optimality	/pdf/de8fce7f423a3cee499bb67c1dd04b2d69afd635.pdf
83piwkGNzOP	1895	A unified optimization framework of ANN-SNN Conversion: towards optimal mapping from activation values to firing rates	['ANN-SNN conversion']		General Machine Learning (ie none of the above)	anonymous|a_unified_optimization_framework_of_annsnn_conversion_towards_optimal_mapping_from_activation_values_to_firing_rates	/pdf/add977a5b65678bddfa24be03e7f40b61eb1124d.pdf
8XqDnrmZQNF	1897	Robust Attention for Contextual Biased Visual Recognition	['Causal Inference', 'Object Recognition', 'Attention Mechanism', 'Confounding Context', 'Interventional Dual Attention']		Deep Learning and representational learning	anonymous|robust_attention_for_contextual_biased_visual_recognition	/pdf/167bc5c4dc031c2fb0d44a63dcfdd8fba997183c.pdf
elDEe8LYW7-	1898	NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis	['voice synthesis', 'integrated framework', 'zero-shot voice conversion', 'text-to-speech', 'singing voice synthesis', 'voice designing']	This paper introduces a unified voice synthesis framework that tackles four tasks, zero-shot voice conversion, text-to-speech, singing voice synthesis, and voice designing.	Applications (eg, speech processing, computer vision, NLP)	anonymous|nansy_unified_voice_synthesis_with_neural_analysis_and_synthesis	/pdf/a376c15d10fac815959f81d9e546da352329079c.pdf
XHc5zRPxqV9	1899	DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases	['knowledge base', 'question answering', 'information retrieval', 'semantic parsing']	We propose a novel KBQA framework that jointly generates both direct answers and logical forms, and then combines them to obtain the final answers.	Applications (eg, speech processing, computer vision, NLP)	anonymous|decaf_joint_decoding_of_answers_and_logical_forms_for_question_answering_over_knowledge_bases	/pdf/6513446722409b8f22fc687a7db6316b69259e5a.pdf
ULkdnAqaZTx	1900	Learning with MISELBO: The Mixture Cookbook	['Variational Autoencoders', 'Mixture VAEs', 'Bayesian Inference', 'GMMs', 'ELBO', 'VI', 'Adaptive Importance Sampling', 'Deep Ensembles', 'Deep Mixtures', 'Density Estimation']	We demonstrate the power and flexibility of GMMs as variational approximations in SGD-based VI in terms of density estimation and representation learning, provide a cookbook for implementing them, and point to novel connections between VI and AIS.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|learning_with_miselbo_the_mixture_cookbook	/pdf/e71db576c81e47653120cd0f81a833a629cdef90.pdf
XCTVFJwS9LJ	1902	Flow Annealed Importance Sampling Bootstrap	['Normalizing flow', 'Boltzmann distribution', 'Boltzmann generator', 'Annealed Importance Sampling', 'Approximate Inference']	We train normalizing flows to fit multi-modal target distributions by generating samples where the flow is a poor approximation of the target using an annealed importance sampling bootstrap procedure.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|flow_annealed_importance_sampling_bootstrap	/pdf/ad3f34097d4b183a2d727a31360df698e33445c5.pdf
W8UYLEvvYeR	1903	Learning with Instance-Dependent Label Noise: Balancing Accuracy and Fairness	['noisy labels', 'supervised learning']	We propose an approach for instance dependent label noise and demonstrate its ability to balance discriminative performance and fairness in a variety of settings.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_with_instancedependent_label_noise_balancing_accuracy_and_fairness	/pdf/8150180f986fcd4af9c4eaacc1c09c7db002bf92.pdf
yLv6eSBmA-	1904	Adversarial Detector for Decision Tree Ensembles Using Representation Learning	['Machine Learning', 'Representation Learning', 'Adversarial Learning', 'Evasion Attacks', 'Adversarial Detection', 'Tree Ensembles', 'Decision Trees']		Deep Learning and representational learning	anonymous|adversarial_detector_for_decision_tree_ensembles_using_representation_learning	/pdf/de2232cfe0fe6c9ad70a2b68e4de2c2aaa2511f9.pdf
lcSfirnflpW	1905	ManyDG: Many-domain Generalization for Healthcare Applications	['Patient covariate shift', 'Domain Generalization', 'Healthcare', 'EEG', 'EHR']	"New ""many-domain generalization"" setting and new approach ManyDG for the setting in healthcare applications"	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|manydg_manydomain_generalization_for_healthcare_applications	/pdf/d0b901c6474d455df07aad2501887eb0eeb675a1.pdf
zDiHoIWa0q1	1906	Omnigrok: Grokking Beyond Algorithmic Data	['grokking', 'loss landscape', 'neural dynamics', 'representation learning', 'initialization']	We aim to understand grokking through the lens of neural loss landscapes, and show grokking can occur for various datasets beyond algorithmic datasets.	Deep Learning and representational learning	anonymous|omnigrok_grokking_beyond_algorithmic_data	/pdf/ce521d5e7cea73b2a9b2f302dbd4d9d63b68574d.pdf
PTZhYSD8aUv	1907	Model-based Value Exploration in Actor-critic Deep Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|modelbased_value_exploration_in_actorcritic_deep_reinforcement_learning	/pdf/627be885d1533cb21b79159100bd87def10a7365.pdf
nd3yVgRYKVJ	1908	Deep Reinforcement learning on Adaptive Pairwise Critic and Asymptotic Actor	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|deep_reinforcement_learning_on_adaptive_pairwise_critic_and_asymptotic_actor	/pdf/aefe858060a422340f3b3f21d894efb24c28d5f3.pdf
RlPmWBiyp6w	1910	GAIN: On the Generalization of Instructional Action Understanding	['Action Analysis', 'Instructional Video', 'OOD Generalization']		Applications (eg, speech processing, computer vision, NLP)	anonymous|gain_on_the_generalization_of_instructional_action_understanding	/pdf/783dd6b0e5f80a06f3aa9bdfca5715d57e2cad46.pdf
XomEU3eNeSQ	1911	Code Translation with Compiler Representations	['Neural Machine Translation', 'Unsupervised Learning', 'Programming Languages', 'LLVM', 'Decompilation', 'Deep Learning', 'Program Translation']	We leverage compiler intermediate representations (IR) for the unsupervised neural machine translation of programming languages and get state-of-the-art results	Applications (eg, speech processing, computer vision, NLP)	anonymous|code_translation_with_compiler_representations	/pdf/135cc0227226b71aa6dd7ff39561d4d686264e41.pdf
7C9aRX2nBf2	1912	Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting	['Time series', 'generative models', 'Bayesian meta-learning']	We present the very first step toward few-shot high-dimensional sequence forecasting by a Bayesian meta-learning model that learns the process of learning latent dynamics that changes with the small number of observations that are available.	Generative models	anonymous|sequential_latent_variable_models_for_fewshot_highdimensional_timeseries_forecasting	/pdf/f9221161d10d88346fa8e074427cfd65118e386c.pdf
4QIgPD5BLnv	1913	Diffusing Graph Attention	['Graph Transformer', 'graph neural networks', 'transformers', 'long-range context']		Deep Learning and representational learning	anonymous|diffusing_graph_attention	/pdf/bc8b887898766c999c7b86dd1271179fd330ccb0.pdf
sDNuHPA7Ib4	1914	Certification of Attribution Robustness for Euclidean Distance and Cosine Similarity Measure	['interpretation', 'robustness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|certification_of_attribution_robustness_for_euclidean_distance_and_cosine_similarity_measure	/pdf/d6bc84a602f83ac21201be07b66de879ac8cab86.pdf
Q-UHqMorzil	1915	Sign and Basis Invariant Networks for Spectral Graph Representation Learning	['Invariance', 'Equivariance', 'Eigenvectors', 'Spectral', 'Neural Networks']	We develop neural networks invariant to the symmetries of eigenvectors, which are theoretically expressive and empirically improve performance in geometric learning tasks.	Deep Learning and representational learning	anonymous|sign_and_basis_invariant_networks_for_spectral_graph_representation_learning	/pdf/2c3b5573bf2e22d31d105243bc1917d654be4d2e.pdf
C6CEY8xiA7v	1916	Automaton Distillation: A Neuro-Symbolic Transfer Learning Approach for Deep RL	['reinforcement learning', 'transfer learning', 'neuro-symbolic', 'formal languages', 'automaton']	Transfer reinforcement learning using symbolic knowledge extracted from a teacher	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|automaton_distillation_a_neurosymbolic_transfer_learning_approach_for_deep_rl	/pdf/dbd2b4ac85816b6d20b4931885228dac91680d9a.pdf
N3fc0aKFB-0	1917	Reward-free Policy Learning through Active Human Involvement	['Human-in-the-loop Reinforcement Learning', 'Safety', 'Sample Efficiency', 'Reward-free']	We propose a reward-free policy learning method called Proxy Value Propagation that conveys human intents explicitly to the learning policy through active human involvement	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|rewardfree_policy_learning_through_active_human_involvement	/pdf/f853a56a192a9d466379ec636e7ea906975906d8.pdf
bBBA-8ELXcF	1918	Entropy-Regularized Model-Based Offline Reinforcement Learning	['Reinforcement learning', 'model-based', 'offline RL', 'entropy regularization']	We propose a single model that learns a pessimistic MDP for offline RL scenarios which is regularized for transitions that are outside of the data support.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|entropyregularized_modelbased_offline_reinforcement_learning	/pdf/5eb578bc6272ba45e8f8cf83d5f35a18101c249b.pdf
p0yrSRbN5Bu	1920	Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning	['prompt tuning', 'natural language processing', 'few-shot learning']	For improving few-shot prompt tuning, we propose a Sample-specific Ensemble of Source Models to transfer knowledge from soft prompts trained on source tasks to target tasks by adjusting the contribution of source models for each target sample.	Applications (eg, speech processing, computer vision, NLP)	anonymous|model_ensemble_instead_of_prompt_fusion_a_samplespecific_knowledge_transfer_method_for_fewshot_prompt_tuning	/pdf/ee267ff7f160cc1bc287a04a2c9862e02efaa7d3.pdf
yFQjggu62T	1921	Scalable and Privacy-enhanced Graph Generative Model for Graph Neural Networks	['graph generative model', 'graph neural networks', 'graph convolutional networks', 'benchmark graph generation']	We propose a novel, modern graph generation problem to enable generating privacy-controlled, synthetic substitutes of large-scale real-world graphs that can be effectively used to evaluate GNN models.	Deep Learning and representational learning	anonymous|scalable_and_privacyenhanced_graph_generative_model_for_graph_neural_networks	/pdf/e2657d0f50f5770269549df327cedeb94600fb5b.pdf
xBeGd7sAND	1922	Spotting Expressivity Bottlenecks and Fixing Them Optimally 	['neural network', 'expressivity', 'optimization', 'quadratic programming', 'layer growth', 'tangent space', 'gradient']	We quantify the concept of lack of expressivity in neural networks and propose an algorithm to fix them by appropriately adding neurons.	Optimization (eg, convex and non-convex optimization)	anonymous|spotting_expressivity_bottlenecks_and_fixing_them_optimally	/pdf/4e74eee20a8abd9e5072a63fc7b534df2f986e4b.pdf
yyBis80iUuU	1923	Hybrid RL: Using both offline and online data can make RL efficient	['reinforcement learning theory', 'hybrid reinforcement learning', 'online reinforcement learning', 'offline reinforcement learning']	We propose a new hybrid RL framework with access to both offline dataset and online interaction, and design a hybrid RL algorithm that is statistically and computationally efficient.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|hybrid_rl_using_both_offline_and_online_data_can_make_rl_efficient	/pdf/d1a71f6023dc530966b74d688375f05f70f84462.pdf
6w1k-IixnL8	1924	Beyond calibration: estimating the grouping loss of modern neural networks	['calibration', 'grouping loss', 'decision making', 'model evaluation']	We provide an estimator to evaluate confidence scores beyond calibration, revealing the subgroups heterogeneities that undermine individual predicted probabilities.	General Machine Learning (ie none of the above)	anonymous|beyond_calibration_estimating_the_grouping_loss_of_modern_neural_networks	/pdf/843747cd042cdaad93f5d6779c26e98fb176c891.pdf
HOF3CTk2WH6	1925	LEARNING THE SPECTROGRAM TEMPORAL RESOLUTION FOR AUDIO CLASSIFICATION	['audio classification', 'differentiable temporal resolution', 'feature dimension reduction']	This paper proposes DiffRes, which enables differentiable temporal resolution learning on audio spectrogram (as opposed to common fixed hop size approaches) to improve the performance of audio classification models. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_the_spectrogram_temporal_resolution_for_audio_classification	/pdf/23960b470327d7077d7e745c16d995186bbdff1d.pdf
XHiC52N24ox	1926	ON INJECTING NOISE DURING INFERENCE	['activation noise', 'energy-based modeling']		Generative models	anonymous|on_injecting_noise_during_inference	/pdf/6fe88f228d24d612148d5d4d269b8a6ea71aeabd.pdf
_s1N-DnxdyT	1927	Stochastic Multi-Person 3D Motion Forecasting	['stochastic forecasting', 'multi-person 3D motion', 'dual-level generative modeling']	We introduce a new task of stochastic multi-person 3D motion forecasting, and propose a dual-level generative modeling framework to address this task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|stochastic_multiperson_3d_motion_forecasting	/pdf/f6cf56ff28309997bd4b91151dc7cd140d47f39a.pdf
yQpZ4WnRZM	1928	Landscape Learning for Neural Network Inversion	['Neural Network Inversion', 'Loss Landscape', 'Optimization']	We learn an easy-to-optimize loss landscape for neural network inversion problems such as GAN inversion and adversarial defense.	Applications (eg, speech processing, computer vision, NLP)	anonymous|landscape_learning_for_neural_network_inversion	/pdf/c14e4dbd825228a06dce31c183452fe147d232ee.pdf
J1fysSeRdk	1929	Shape Analysis by Shadow Synthesis	['3D Reconstruction', 'Shadow', 'Differentiable Rendering', 'Neural Fields']	We propose a method to reconstruct a 3D object from just its shadow by inverting an implicit 3D generative model	Applications (eg, speech processing, computer vision, NLP)	anonymous|shape_analysis_by_shadow_synthesis	/pdf/c563bbbddebde62afe6f3575b1b3c97870e4c8e4.pdf
mAazgkPutZ	1930	Improving Information Retention in Large Scale Online Continual Learning	['online continual learning', 'moving average', 'geo-localization']		Deep Learning and representational learning	anonymous|improving_information_retention_in_large_scale_online_continual_learning	/pdf/04b25286152a0d87c0f8c1383e4254c5c42d42cb.pdf
ik91mY-2GN	1931	Diffusion Probabilistic Fields	['Generative Models', 'Field Representation', 'Diffusion Models']	A diffusion model that can learn distribution over fields	Generative models	anonymous|diffusion_probabilistic_fields	/pdf/5ab8697e8960510e361637d6910661b1641d6c31.pdf
FQvAlf6xwTy	1932	Convergence of Generative Deep Linear Networks Trained with Bures-Wasserstein Loss	['deep linear network', 'low-rank approximation', 'Bures-Wasserstein distance', 'optimal transport', 'implicit generative model', 'critical points']	We prove convergence of gradient decent optimization of generative deep linear networks trained with the Bures-Wasserstein loss. 	Optimization (eg, convex and non-convex optimization)	anonymous|convergence_of_generative_deep_linear_networks_trained_with_bureswasserstein_loss	/pdf/c545462b6a771b5396202fb56aef9d1311f246b2.pdf
M4UxoupR3az	1933	The Reward Hypothesis is False	['the reward hypothesis', 'reward functions', 'multi-objective reinforcement learning', 'MORL']	We argue that the reward hypothesis is false, by providing several counterexamples. We also provide necessary and sufficient conditions for when a MORL problem can be reduced to ordinary RL, and describe a new way to express tasks for RL agents.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_reward_hypothesis_is_false	/pdf/d0927d1c852354c445a07ba954ded595f32cc4ce.pdf
3YFDsSRSxB-	1934	Unicom: Universal and Compact Representation Learning for Image Retrieval	['Cluster Discrimination', 'Image Retrieval']		Deep Learning and representational learning	anonymous|unicom_universal_and_compact_representation_learning_for_image_retrieval	/pdf/fdafb1fe2f59a1cc01276dba7aa45f8f10021446.pdf
ZMxVNpd76mw	1935	Robust Reinforcement Learning with Distributional Risk-averse formulation	['Robust Reinforcement Learning', 'Risk-Averse Reinforcement Learning', 'Deep Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|robust_reinforcement_learning_with_distributional_riskaverse_formulation	/pdf/b2c1e9573e5ebf45bed01e2428f08df11beae2a4.pdf
heDr8wIYmw_	1936	Parameter-varying neural ordinary differential equations with partition-of-unity networks	['neural ordinary differential equations', 'partition-of-unity networks', 'parameter-varying neural networks']	Parameter-varying neural ODEs with spectrally represented model parameters using partition-of-unity networks	Deep Learning and representational learning	anonymous|parametervarying_neural_ordinary_differential_equations_with_partitionofunity_networks	/pdf/c2867b00eecafcd8d6b41ed3c9d1b7684d08b349.pdf
uYFRjvSJXbQ	1937	Cross-Quality Few-Shot Transfer for Alloy Yield Strength Prediction: A New Material Science Benchmark and An Integrated Optimization Framework	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|crossquality_fewshot_transfer_for_alloy_yield_strength_prediction_a_new_material_science_benchmark_and_an_integrated_optimization_framework	/pdf/731efb3738345d6a39c863b043dd3ef35e868322.pdf
FI5IysDR8pG	1938	Learning Dynamic Query Combinations for Transformer-based Object Detection and Segmentation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_dynamic_query_combinations_for_transformerbased_object_detection_and_segmentation	/pdf/a16cc36b540d4d4de7779a42dd9ff0354f9bdbf8.pdf
IDSXUFQeZO5	1939	NeuralPCG: Learning Preconditioner for Solving Partial Differential Equations with Graph Neural Network	['Physics Simulation', 'Graph Neural Network', 'Applied Mathematics']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neuralpcg_learning_preconditioner_for_solving_partial_differential_equations_with_graph_neural_network	/pdf/b39b6fde1cee7fe05704dd2d9c63a6f8a8ab4c72.pdf
ElI9znK_eUz	1940	Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning	['Cognitive Science', 'Deep Reinforcement Learning', 'Perceptual Grouping', 'Neuroscience']	Strategies for improving deep reinforcement learning agents can be predicted from their generalization performance.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|diagnosing_and_exploiting_the_computational_demands_of_videos_games_for_deep_reinforcement_learning	/pdf/9aa48e3fa1e8510ab221248b2c2ce6a9168d16f1.pdf
LB6KMRUqng2	1941	Transferability Between Regression Tasks	['Transferability estimation', 'Transfer learning']		Deep Learning and representational learning	anonymous|transferability_between_regression_tasks	/pdf/294b7dee79ba395aa14b642f7ac88506882d7c86.pdf
HnlCZATopvr	1942	Transformer Meets Boundary Value Inverse Problems	['inverse problems', 'attention', 'operator learning', 'Transformer', 'partial differential equations']	We argue that, from both theoretical and experimental perspective, the attention mechanism is a structure-conforming neural architecture for learning the PDE-based boundary value inverse problems.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|transformer_meets_boundary_value_inverse_problems	/pdf/08441810c3431b44453fb9c94096f465805792b5.pdf
3KUfbI9_DQE	1943	Distributionally Robust Post-hoc Classifiers under Prior Shifts	['Distributional robustness', 'post-hoc scaling', 'group robustness', 'class imbalance', 'spurious correlations']	We propose a method for scaling the model predictions at test-time for improved distribution robustness to prior shifts. 	Deep Learning and representational learning	anonymous|distributionally_robust_posthoc_classifiers_under_prior_shifts	/pdf/191f7c3b859689964b235a6e6c13cf2eb57936e6.pdf
NMoeVEwekzC	1944	On Convergence of Average-Reward Off-Policy Control Algorithms in Weakly-Communicating MDPs	['Reinforcement Learning', 'Average-Reward', 'Off-Policy', 'Convergence']	Showing average-reward off-policy control algorithms converge in weakly-communicating MDPs	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_convergence_of_averagereward_offpolicy_control_algorithms_in_weaklycommunicating_mdps	/pdf/e48a9a4f65b3e90e5eb68d7d40919f152896d463.pdf
sciA_xgYofB	1945	Impossibly Good Experts and How to Follow Them	['Imitation Learning', 'Reinforcement Learning', 'Experts', 'Distillation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|impossibly_good_experts_and_how_to_follow_them	/pdf/9b40374ffbdfec5c5c40bb500ffe02019ed88912.pdf
CIoSZ_HKHS7	1946	AIM: Adapting Image Models for Efficient Video Understanding	['Video action recognition', 'efficient finetuning']	We propose a new method to adapt frozen image pre-trained model for efficient video action recognition	Deep Learning and representational learning	anonymous|aim_adapting_image_models_for_efficient_video_understanding	/pdf/86f4305576c65a5dcc785783ea4b66e530c23a1e.pdf
2SV2dlfBuE3	1947	Predictor-corrector algorithms for stochastic optimization under gradual distribution shift	[]		Optimization (eg, convex and non-convex optimization)	anonymous|predictorcorrector_algorithms_for_stochastic_optimization_under_gradual_distribution_shift	/pdf/584f4bf518f2f54003a72df418a3c5354065a229.pdf
r7bFgAGRkpL	1949	When does Bias Transfer in Transfer Learning?	['transfer learning', 'bias']	We study a potential vulnerability of transfer learning where biases and other vulnerabilities from the source dataset remain present in downstream models.	Deep Learning and representational learning	anonymous|when_does_bias_transfer_in_transfer_learning	/pdf/b90bb1b74183004b40919dd0901f77fb5c101345.pdf
KaeYRGTaODt	1950	Multi-Agent Policy Transfer via Task Relationship Modeling	['Multi-agent reinforcement learning', 'cooperative transfer learning']	We propose to model task relationships by learning effect-based task representations for more efficient multi-agent policy transfer.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multiagent_policy_transfer_via_task_relationship_modeling	/pdf/1f54369e679466d49fa5bc215e5d118be388b6a6.pdf
l5XHUBGrBkD	1951	RNAS-CL: Robust Neural Architecture Search by Cross-Layer Knowledge Distillation	['Robust Neural Architecture Search', 'Knowledge Distillation', 'Efficient Deep Learning Model']		Deep Learning and representational learning	anonymous|rnascl_robust_neural_architecture_search_by_crosslayer_knowledge_distillation	/pdf/4a72586fb4cb50c64750a0572e620330aa1d2abb.pdf
dGRP5SfwkgY	1952	MAE are Secretly Efficient Learners	['self-supervised learning', 'masked autoencoder', 'efficient training']	we significantly accelerate MAE training by 59x or more	Deep Learning and representational learning	anonymous|mae_are_secretly_efficient_learners	/pdf/840f7a6a46888bc481640ed2b41b908a1592b207.pdf
F_P8Dtg43vF	1953	Spatio-temporal Self-Attention for Egocentric 3D Pose Estimation	['pose estimation', 'egocentric vision', 'computer vision', 'self-attention', 'spatio-temporal data analysis']	spatio-temporal egocentric pose estimation using transformers.	Applications (eg, speech processing, computer vision, NLP)	anonymous|spatiotemporal_selfattention_for_egocentric_3d_pose_estimation	/pdf/5fadca4ad1b6e3d7e97ce765bd747b53430eb112.pdf
NGMAKE75_N7	1954	Solving and Learning non-Markovian Stochastic Control problems in continuous-time with Neural RDEs	['stochastic control', 'neural RDEs', 'rough paths', 'reinforcement learning']	We propose a novel framework for solving non-Markovian stochastic control problems in continuous-time using Neural RDEs	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|solving_and_learning_nonmarkovian_stochastic_control_problems_in_continuoustime_with_neural_rdes	/pdf/66ef5b61e37363b53a19e7e6ec5851734ee4b3f9.pdf
p66AzKi6Xim	1955	What Can we Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers?	['selective prediction', 'selective classification', 'reject option', 'risk coverage trade-off', 'deep learning', 'neural networks']	What are the best DNNs and training regimes for eliciting superior uncertainty estimation? Analyzing 523 DNNs in order to provide insights that practitioners and researchers can use to maximize the potential of current methods and discover new ones	Deep Learning and representational learning	anonymous|what_can_we_learn_from_the_selective_prediction_and_uncertainty_estimation_performance_of_523_imagenet_classifiers	/pdf/ae89eac8589e04160f62febbe4bcfe5e4f7469bc.pdf
o7koEEMA1bR	1956	Deep Generative Symbolic Regression	['Symbolic Regression', 'Deep Generative Model', 'Deep Symbolic Regression']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|deep_generative_symbolic_regression	/pdf/0df5a5b970303e74b229f5c23b70ad2644cc77c3.pdf
9Q7wZ0Uq4Z6	1957	Policy-Induced Self-Supervision Improves Representation Finetuning in Visual RL	['visual reinforcement learning', 'representation learning', 'transfer learning']	We study the transfer of visual representations in RL, show that they can be partially frozen, and propose a self-supervised method to accelerate their finetuning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|policyinduced_selfsupervision_improves_representation_finetuning_in_visual_rl	/pdf/b7a52d7f2b10b30307b4f2c0d70fed07a71ac513.pdf
2_BsVZ6R-ef	1958	Analytical Composition of Differential Privacy via the Edgeworth Accountant	['Differential Privacy', 'f-Differential Privacy', 'Edgeworth Expansion', 'PLLR', 'Edgeworth Accountant']	We developed an efficient analytical tool via the Edgeworth expansion with finite-sample bounds to to keep track of DP guarantees with a large number of compositions.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|analytical_composition_of_differential_privacy_via_the_edgeworth_accountant	/pdf/e5fe0e62438635ddd495d68a337624d2b63f51c0.pdf
5b9uVL3l1T4	1960	Data Drift Correction via Time-varying Importance Weight Estimator	['distribution shift', 'data drift over time', 'propensity scoring']	Data gradually evolves over time in the real-world applications. This paper proposes a simple yet effective way to detect gradual shifts in data.	General Machine Learning (ie none of the above)	anonymous|data_drift_correction_via_timevarying_importance_weight_estimator	/pdf/9682ea097a914873360ce095765ceb526391b494.pdf
Th98b8dH4yr	1961	Tangential Wasserstein Projections	['Optimal Transport', 'Wasserstein', 'Generalized geodesics', 'Projection', 'Tangent Cone', 'Causal Inference']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|tangential_wasserstein_projections	/pdf/f32defb820132f885219d51041d63d00bbdf7df9.pdf
cwiFbXPW4G0	1962	Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees	['Robustness', 'online bipartite matching', 'reinforcement learning']	This paper proposes a novel reinforcement learning approach to solve edge-weighted online bipartite matching with robustness guarantees.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_for_edgeweighted_online_bipartite_matching_with_robustness_guarantees	/pdf/57646e3176bb10bea3755a7c553b8369b9b78f4a.pdf
8vz6hO1S4o5	1963	Fair Clustering via Equalized Confidence	['fair clustering', 'Sinkhorn divergence', 'equalized confidence']	fair clustering based on equality of predicted confidence between different demographic groups	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fair_clustering_via_equalized_confidence	/pdf/4b1c725880c36b21b92316227ee94fb166a00588.pdf
Whf5OGxibGR	1964	Causal discovery from conditionally stationary time series	['causal discovery', 'temporal data', 'graph neural network', 'time series', 'non-stationary', 'probabilistic modelling']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|causal_discovery_from_conditionally_stationary_time_series	/pdf/c3978d9dc5bb353414fc5981f19501c0ace2cc79.pdf
jwgnijhdF3V	1967	Posterior Sampling Model-based Policy Optimization under Approximate Inference	['Reinforcement learning', 'Posterior', 'Model-based reinforcement learning']	We proposed an improved posterior factorization for PSRL under approximate inference; and two sampling strategies.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|posterior_sampling_modelbased_policy_optimization_under_approximate_inference	/pdf/2464bf764b542c9c6c250b146a14619fff02539c.pdf
G7iioWGldQ7	1968	To be robust and to be fair: aligning fairness with robustness	['fairness', 'adversarial robustness']	bridging adversarial robustness of fairness and accuracy in a unified framework	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|to_be_robust_and_to_be_fair_aligning_fairness_with_robustness	/pdf/2a841c31a08553fcdbde3223344e604dc6001c06.pdf
nG08xiRT2As	1969	InfoOT: Information Maximizing Optimal Transport	['Optimal Transport', 'Unsupervised Alignment', 'Domain Adaptation', 'Mutual Information']	We present InfoOT, an information-theoretic extension of optimal transport that combines the geometry with the mutual information between domains.	General Machine Learning (ie none of the above)	anonymous|infoot_information_maximizing_optimal_transport	/pdf/1ead3688248aba0117df4a2aa6ecc43689d42dba.pdf
TC39w69m8bB	1970	ELRT: Towards Efficient Low-Rank Training for Compact Neural Networks	[]		Deep Learning and representational learning	anonymous|elrt_towards_efficient_lowrank_training_for_compact_neural_networks	/pdf/5b2929a1bcc4c242ba449bca6b6c75f43d729278.pdf
vDFA1tpuLvk	1971	Retrieval-based Controllable Molecule Generation	['controllable molecule generation', 'retrieval mechanism', 'exemplar molecules', 'drug discovery']	We propose a first-of-its-kind retrieval-based framework for controllable molecule generation which can effectively extrapolate beyond the retrieval database and achieves state-of-the-art performance on various benchmarks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|retrievalbased_controllable_molecule_generation	/pdf/f79d2f149645f2e00efa09a5a40e75c575dc93a4.pdf
_NlE9YiyXKb	1972	Tessellated Neural Networks: A Robust Defence against Adversarial Attacks	['AI safety', 'fairness', 'privacy', 'robustness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|tessellated_neural_networks_a_robust_defence_against_adversarial_attacks	/pdf/eb31d33cc822a207f57944f6109846cb39df6244.pdf
MQcmfgRxf7a	1973	Simplifying Model-based RL: Learning Representations, Latent-space Models, and Policies with One Objective	['Latent-space models', 'objective mismatch', 'model based RL']	We present a joint objective for latent space model based RL which lower bounds the RL objective. Maximising this bound jointly with the encoder, model and the policy matches the performance of SOTA methods, while being 6-10 times faster. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|simplifying_modelbased_rl_learning_representations_latentspace_models_and_policies_with_one_objective	/pdf/d1233d552fb13e44830d5478ffde552219c5fa3e.pdf
PrRWSVT2htx	1974	CEPD: Co-Exploring Pruning and Decomposition for Compact DNN Models	[]		Deep Learning and representational learning	anonymous|cepd_coexploring_pruning_and_decomposition_for_compact_dnn_models	/pdf/1a22a63e20abe425c9c0b736fa338699b5c2a993.pdf
TFbwV6I0VLg	1975	SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models	['Object-centric learning', 'dynamics modeling', 'Transformer']	We propose a general Transformer-based dynamic model to enable consistent future prediction in object-centric models	Unsupervised and Self-supervised learning	anonymous|slotformer_unsupervised_visual_dynamics_simulation_with_objectcentric_models	/pdf/148d50aa9886e1b112d463fa7c6edfbfe3c5bada.pdf
7qSpaOSbRVO	1976	Data Poisoning Attacks Against Multimodal Encoders	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|data_poisoning_attacks_against_multimodal_encoders	/pdf/937efa66743fd2c69e02e694d3f5351791f05cee.pdf
Iuubb9W6Jtk	1977	A framework for benchmarking Class-out-of-distribution detection and its application to ImageNet	['benchmarking', 'out of distribution', 'class out of distribution', 'OOD', 'OOD detection']	We present a framework for benchmarking the performance of image classifiers in detecting OOD. We apply it to benchmark 525 pretrained ImageNet classifiers, and analyze their performance resulting in interesting conclusions	Deep Learning and representational learning	anonymous|a_framework_for_benchmarking_classoutofdistribution_detection_and_its_application_to_imagenet	/pdf/b33c61db9585e3d6c992abcda35b7627c6227bba.pdf
gwTP_sA-aj-	1978	Interval Bound Interpolation for Few-shot Learning with Few Tasks	['meta-learning', 'metric learning', 'task interpolation', 'Interval Bound Propagation']	A method to densify the task distribution for few-task few-shot learning using task interpolation within interval-arithmetic-based bounds	Deep Learning and representational learning	anonymous|interval_bound_interpolation_for_fewshot_learning_with_few_tasks	/pdf/fc4da5c817c2fd18b281cbe3fa9b9b16532772f6.pdf
ZOn4HXehSJ6	1979	ProGen2: Exploring the Boundaries of Protein Language Models	[]	Exploration of billion-scale model and dataset sizes to examine the boundaries of protein language models	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|progen2_exploring_the_boundaries_of_protein_language_models	/pdf/a76d0a7d7f58b3b4ae80c45815932df188bcf495.pdf
YycrpoVQB4G	1980	Predicting Drug Repurposing Candidates and Their Mechanisms from A Biomedical Knowledge Graph	['Drug Repurposing', 'Reinforcement Learning', 'Biomedical Knowledge Graph']	We predict drug repurposing candidates and their path-based mechanisms of action based on a large biomedical knowledge graph.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|predicting_drug_repurposing_candidates_and_their_mechanisms_from_a_biomedical_knowledge_graph	/pdf/6fd522b1aed3983b4449a7ac5d3fee6ccd91a6fb.pdf
ieWqvOiKgz2	1981	No Double Descent in PCA: Training and Pre-Training in High Dimensions	['PCA', 'generalization theory', 'overparameterization', 'pre-training theory', 'encoder-decoder models', 'double descent', 'linear regression']	We analyse PCA with linear regression for its generalization with high dimensional data and extend the setting to training the two model parts on two different data sets to establish connections to pre-training theory.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|no_double_descent_in_pca_training_and_pretraining_in_high_dimensions	/pdf/fce575bbe496ea544b4d98761b0adc8c42b46e39.pdf
5ktFNz_pJLK	1982	Learning to Estimate Shapley Values with Vision Transformers	['ViTs', 'Shapley values', 'amortization', 'explainability']	A learning-based approach to efficiently calculate Shapley values for ViTs	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_to_estimate_shapley_values_with_vision_transformers	/pdf/5f98da34cf7724c9f629f5645f36f98e01c70889.pdf
Xq2J1kiZeHE	1983	KL-Entropy-Regularized RL with a Generative Model is Minimax Optimal	['Reinforcement Learning', 'Minimax-Optimality', 'Generative Model', 'KL Regularization', 'Entropy Regularization']	We show that KL-entropy-regularized value iteration is minimax-optimal under the generative model setting.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|klentropyregularized_rl_with_a_generative_model_is_minimax_optimal	/pdf/c2497a63991aee1612136d184c3a4f6d902f9fe5.pdf
6P9Y25Pljl6	1984	FedDAR: Federated Domain-Aware Representation Learning	['federated learning', 'healthcare', 'fairness', 'personalization']		Deep Learning and representational learning	anonymous|feddar_federated_domainaware_representation_learning	/pdf/6687e2aae049c23d66b38a0d78200e8e9ba74102.pdf
vdv6CmGksr0	1985	Learning differentiable solvers for systems with hard constraints	['differentiable optimization', 'PDEs', 'physics', 'neural networks', 'differentiable constraints', 'dictionary learning']	We propose a method to solve partial differential equations (PDEs) through enforcing constraints in neural networks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_differentiable_solvers_for_systems_with_hard_constraints	/pdf/afddd3ce9a124b903f69341ffa3f97da551a1db3.pdf
ukveBtI9lnk	1986	Convolutions are competitive with transformers for protein sequence pretraining	['protein', 'pretrain', 'convolution']	For proteins, large pretrained CNNs are competitive with large pretrained transformers. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|convolutions_are_competitive_with_transformers_for_protein_sequence_pretraining	/pdf/2a176fcae2213e8310a1180f6286f64282776857.pdf
2EO8eQ2vySB	1987	Masked inverse folding with sequence transfer for protein representation learning	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|masked_inverse_folding_with_sequence_transfer_for_protein_representation_learning	/pdf/da0f42506af7b3f41e6e0671ec241a77f5e7d1ae.pdf
0qSOodKmJaN	1988	Calibrating Sequence likelihood Improves Conditional Language Generation	['Natural Language Processing', 'conditional language models', 'sequence-to-sequence', 'text generation']	A proposed sequence likelihood calibration stage improves fine-tuned conditional language models, leading to new state-of-the-art results in abstractive summarization, question generation, abstractive question answering and data-to-text.	Applications (eg, speech processing, computer vision, NLP)	anonymous|calibrating_sequence_likelihood_improves_conditional_language_generation	/pdf/a8e7d215eeb4e0e50e824e26e04a42e9730e8b74.pdf
70BaDC5ceIO	1989	Neural Network Approximations of PDEs Beyond Linearity: Representational Perspective	['PDE', 'Partial Differential Equations', 'Deep Learning Theory', 'Universal Approximation']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|neural_network_approximations_of_pdes_beyond_linearity_representational_perspective	/pdf/f63de4f982fe6c7eb8e848c1b5983d9bbee6eac7.pdf
dYQnWPqCCAs	1990	A Unified Framework for Comparing Learning Algorithms	['algorithm comparison', 'model comparison', 'data-centric', 'influence', 'datamodels', 'data augmentation', 'pretraining', 'learning rate']	A unified framework for comparing models trained with two different learning algorithms based on how models use training data to make predictions	Deep Learning and representational learning	anonymous|a_unified_framework_for_comparing_learning_algorithms	/pdf/cf7e74ac632fb375e0db0028814b1decc2607fec.pdf
ltCuqJpZl7S	1991	Equilibrium-finding via exploitability descent with learned best-response functions	['equilibrium finding', 'game solving', 'best-response function', 'computational game theory']	We propose a new method for equilibrium finding based on the idea of learned best-response functions.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|equilibriumfinding_via_exploitability_descent_with_learned_bestresponse_functions	/pdf/acffcebf727f33cf9c95fbca28d4d94f3eef46ac.pdf
9qgOs_IwRS3	1992	Neighborhood Gradient Clustering: An Efficient Decentralized Learning Method for Non-IID Data Distributions	['Federated Learning', 'Distributed Machine Learning', 'Decentralized Learning', 'Communication Efficient', 'Energy Efficient', 'Non-IID Data Distribution', 'Convergence']	Proposed a novel decentralized learning algorithm to improve the performance over non-IID data distributions through manipulation of local-gradients	Deep Learning and representational learning	anonymous|neighborhood_gradient_clustering_an_efficient_decentralized_learning_method_for_noniid_data_distributions	/pdf/1fe2940c2e783ffe48987ba65131cf357e72552f.pdf
DBMttEEoLbw	1993	Understanding new tasks through the lens of training data via exponential tilting	['Out-of-distribution generalization', 'model selection', 'subpopulation shift', 'concept drift']		Deep Learning and representational learning	anonymous|understanding_new_tasks_through_the_lens_of_training_data_via_exponential_tilting	/pdf/19df199687e7aac38a6ad8e4a3a0864d6c96d4ab.pdf
RgUPdudkWlN	1994	CUDA: Curriculum of Data Augmentation for Long-tailed Recognition	['Long-tailed recognition', 'class imbalance']	We propose a class-wise data augmentation method by designing the curriculum of data augmentation, which is based on our findings that stronger augmentation on major classes improves the performance on long-tailed recognition.	Deep Learning and representational learning	anonymous|cuda_curriculum_of_data_augmentation_for_longtailed_recognition	/pdf/5bf32cc22e5672e8699553a2e735437bcb43e981.pdf
3k5CUGDLNdd	1995	Benchmarking Offline Reinforcement Learning on Real-Robot Hardware	['offline reinforcement learning', 'robotic manipulation', 'dexterous manipulation', 'TriFinger platform']	We propose new robotics datasets for dexterous manipulation and benchmark offline RL algorithms on them.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|benchmarking_offline_reinforcement_learning_on_realrobot_hardware	/pdf/5ae4a6feef8db642b69b00ddfae507f7a8a1ffc6.pdf
E01k9048soZ	1996	UNIFIED-IO: A Unified Model for Vision, Language, and Multi-modal Tasks	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|unifiedio_a_unified_model_for_vision_language_and_multimodal_tasks	/pdf/4bd024022bfa9a08253b47f264f4251f1a21ded7.pdf
z7FfWq2iaW4	1997	Towards Identification of Microaggressions in real-life and Scripted conversations, using Context-Aware Machine Learning Techniques.	['Microaggression', 'social conversations', 'Natural language Processing', 'Contextual Model', 'RoBERTa', 'Support Vector Machines.']	Classification of microaggressions from text data (extracted from real life conversation, social media platforms and classic TV shows) using SVMs and RoBERTA, considering the impact of varying amounts of context on overall models' performance. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_identification_of_microaggressions_in_reallife_and_scripted_conversations_using_contextaware_machine_learning_techniques	/pdf/15ea22ff38c4c8295c2cbfaaa35f36bbb9d3c62f.pdf
q89i5jKql38	1998	D-CIPHER: Discovery of Closed-form Partial Differential Equations	['differential equations', 'symbolic regression']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|dcipher_discovery_of_closedform_partial_differential_equations	/pdf/e8f1cc296b68d066480f2f44d198da0a950d5b31.pdf
C__2aUY0_3w	1999	Semantic Video Synthesis from Video Scene Graphs	['video synthesis', 'scene graph', 'scene understanding']	A video scene graph-to-video synthesis framework is proposed with a pre-trained video scene graph encoder, VQ-VAE and auto-regressive Transformer.	Generative models	anonymous|semantic_video_synthesis_from_video_scene_graphs	/pdf/dfeb065022236046ce3e14df7f6c451b0a5ac191.pdf
Yo06F8kfMa1	2001	How Much Space Has Been Explored? Measuring the Chemical Space Covered by Databases and Machine-Generated Molecules	['molecular generation', 'drug discovery', 'coverea measures', 'chemical space measures']	We propose a novel evaluation framework for measures of the chemical space in the context of drug discovery.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|how_much_space_has_been_explored_measuring_the_chemical_space_covered_by_databases_and_machinegenerated_molecules	/pdf/7ad65c19552bb2306b971933f746aaa519f2dfc9.pdf
eG14tR9lssZ	2003	Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|efficient_reward_poisoning_attacks_on_online_deep_reinforcement_learning	/pdf/1db96f1bebfd8b467f9e7d5ff3b20131c8b023da.pdf
hXsBCVNJu_v	2004	ADVERSARIALLY BALANCED REPRESENTATION FOR CONTINUOUS TREATMENT EFFECT ESTIMATION	[]		Deep Learning and representational learning	anonymous|adversarially_balanced_representation_for_continuous_treatment_effect_estimation	/pdf/663f6981023f37631ff9302b7a8c2b817738ad32.pdf
81VJDmOE2ol	2005	Markup-to-Image Diffusion Models with Scheduled Sampling	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|markuptoimage_diffusion_models_with_scheduled_sampling	/pdf/60e7eb195133ee9b6075dc256dd2fc4bc6d04501.pdf
b0JxQC7JLWh	2008	Certified Defences Against Adversarial Patch Attacks on Semantic Segmentation	['certified defences', 'adversarial robustness', 'adversarial patch attacks']	We propose the first approach for certified recovery and certified detection against adversarial patch attacks on semantic segmentation, which is based on novel masking schemes and image inpainting.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|certified_defences_against_adversarial_patch_attacks_on_semantic_segmentation	/pdf/5c85d0a582129c11fc545db1f3726e0b0f83ed4e.pdf
6JMXLWX68Kj	2009	On the Performance of Temporal Difference Learning With Neural Networks	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_performance_of_temporal_difference_learning_with_neural_networks	/pdf/0d564b6c47407c22a280b1beb5bd0df2ec59cb4e.pdf
UFKW7EVrJAm	2011	Generating Adversarial Examples with Task Oriented Multi-Objective Optimization	['Multi-Objective Optimization', 'Adversarial Machine Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|generating_adversarial_examples_with_task_oriented_multiobjective_optimization	/pdf/67a00a20ab7a3d3821d9830a24ff9464477f46b6.pdf
8WTAh0tj2jC	2012	Agent-based Graph Neural Networks	['Graph Neural Networks', 'GNN', 'Graph Classification', 'Expressive Graph Neural Networks', 'Sublinear algorithms']	We present a new agent-based sublinear and expressive GNN architecture for graph-level tasks.	Deep Learning and representational learning	anonymous|agentbased_graph_neural_networks	/pdf/bd9ecabb342c84837b80ae5b077cc14a8a703ce8.pdf
ySQeVdXOcx0	2013	Quantum Fourier Networks for solving Parametric PDEs	['quantum computing', 'quantum machine learning', 'quantum deep learnin', 'fourier transform', 'fourier neural operator', 'PDE', 'partial differential equation']	We provide three new quantum circuits to reproduce the Fourier Neural Operator, in order to learn PDEs solutions, and tested them on practical use cases.	Deep Learning and representational learning	anonymous|quantum_fourier_networks_for_solving_parametric_pdes	/pdf/576043962306d6704ca4a1e64611c7ad279522cb.pdf
ZhuXksSJYWn	2015	Masked Vision and Language Modeling for Multi-modal Representation Learning	['Vision and language', 'multi-modal learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|masked_vision_and_language_modeling_for_multimodal_representation_learning	/pdf/059fb9807d12309d2aadbc03b5b75a174063824a.pdf
5g4FC-SHkaV	2016	Find Your Friends: Personalized Federated Learning with the Right Collaborators	['Federated learning', 'Personalized federated learning', 'Decentralized federated learning']	We propose a novel personalized decentralized federated learning framework for heterogeneous client data by collaborating with the right clients.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|find_your_friends_personalized_federated_learning_with_the_right_collaborators	/pdf/61e0bb612f69c6aa9baaf6d14aee748b20c61834.pdf
4-aEhZnvNnk	2017	Neural Embeddings for Text	['text embedding', 'semantic embedding', 'neural embedding', 'neural text representation']	We propose a new kind of embedding for natural language text that deeply represents semantic meaning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|neural_embeddings_for_text	/pdf/0ae5eb3dcb3eb0ede8743177cb16415419f2fe0a.pdf
8gU_8IdHN9g	2018	Generated Graph Detection	['Generated Graph', 'Graph Neural Network', 'Contrastive Learning', 'Metric Learning']	We propose a general framework to detect generated graphs using GNN-based methods.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|generated_graph_detection	/pdf/252cf37edf6de71de113b9c2f4ec110034663c5a.pdf
QTbAoQ5yMCg	2019	Decentralized Robust V-learning for Solving Markov Games with Model Uncertainty	['Machine Learning', 'Reinforcement Learning', 'Markov Games']	Robust reinforcement learning algorithm for Markov games	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|decentralized_robust_vlearning_for_solving_markov_games_with_model_uncertainty	/pdf/0849b7fd1bf5e7e6baddc6909808b0b1ebcbcbcc.pdf
g4JB0ksCrKe	2020	Contrastive Prompt Tuning Improves Generalization in Vision-Language Models	['Prompt tuning', 'Vision-language models', 'Contrastive learning']	We introduce contrastive prompt tuning for improved generalization in vision-language models by optimizing for the learned prompts to be consistent with the image space.	Applications (eg, speech processing, computer vision, NLP)	anonymous|contrastive_prompt_tuning_improves_generalization_in_visionlanguage_models	/pdf/57dab48fc142332bc637b881b942a42d2602b6db.pdf
A7v2DqLjZdq	2021	Bridge the Inference Gaps of Neural Processes via Expectation Maximization	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|bridge_the_inference_gaps_of_neural_processes_via_expectation_maximization	/pdf/fa75ffe755e4b16f649bb52a9890c450a63c1868.pdf
hQwb-lbM6EL	2022	InCoder: A Generative Model for Code Infilling and Synthesis	['code generation', 'program synthesis', 'language to code']	An infilling-capable code completion model, evaluated on tasks including language-to-code, type inference, and comment generation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|incoder_a_generative_model_for_code_infilling_and_synthesis	/pdf/bbaa17aa569c6cda832dac9d688c9ebd374308c3.pdf
vm3jAx_pLCV	2023	Learning Control Policies for Region Stabilization in Stochastic Systems	['Stability', 'learning for control', 'martingale', 'verification']	We learn policies and certificates for proving region stabilization in control systems	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_control_policies_for_region_stabilization_in_stochastic_systems	/pdf/7950e98392d8acae0f8b9ad4025629b7b4836313.pdf
TntbHxxGd6j	2024	Output Distribution over the Entire Input Space: A Novel Perspective to Understand Neural Networks	['model evaluation', 'comprehensive input-output mapping relation']	We draw the connection between energy in physics and output of neural networks and propose an efficient sampler for better understanding of the input-output mapping relationship of the (binary) neural classifiers. 	Deep Learning and representational learning	anonymous|output_distribution_over_the_entire_input_space_a_novel_perspective_to_understand_neural_networks	/pdf/fbac1331be66eb21ec5a05aadf5e7143e0e7b1d5.pdf
E4-uRvmKkeB	2025	Beyond Traditional Transfer Learning: Co-finetuning for Action Localisation	['transformer', 'video', 'action recognition', 'action detection', 'multi-task learning', 'co-training', 'transfer learning']	"Instead of pretraining on ""upstream"" datasets and then finetuning on ""downstream"" tasks, we simultaneously train on all datasets, achieving significant performance improvements across all tasks, and particularly on rare classes."	Applications (eg, speech processing, computer vision, NLP)	anonymous|beyond_traditional_transfer_learning_cofinetuning_for_action_localisation	/pdf/ff663e0aac0138dd657d3c53e956711b7e2de223.pdf
83xscrmnw6Q	2026	Knowledge-Driven New Drug Recommendation	['drug recommendation', 'medication recommendation', 'healthcare', 'electronic health record', 'few-shot learning']	recommendation for new drugs with limited historical prescription data	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|knowledgedriven_new_drug_recommendation	/pdf/0c76a0c45f8f2008df8c1ed09a43a5a2f20827b0.pdf
8JCg5xJCTPR	2027	Provable Memorization Capacity of Transformers	['Transformer', 'Expressivness', 'Memorization', 'Deep learning theory', 'contextual mapping', 'permutation equivariance']	We provide the memorization capacity of Transformer architecture in sequence input.	Deep Learning and representational learning	anonymous|provable_memorization_capacity_of_transformers	/pdf/0aed13ed7d5c83f401c4c67382d20277f7f397a4.pdf
7kpmIkHVpHu	2028	Hyperbolic Contrastive Learning for Visual Representations beyond Objects	['Self Supervised learning for Scene images', 'Hyperbolic objective', 'Hierarchical scene-object structure.']	We use hyperbolic objective to learn scene-object hypernymy, and show significant improvements for multiple datasets across multiple SSL tasks.	Unsupervised and Self-supervised learning	anonymous|hyperbolic_contrastive_learning_for_visual_representations_beyond_objects	/pdf/9f2e4b363ff31f403cfa78ffc0ea293deb1e71c4.pdf
3ly9cG9Ql9h	2029	What does a platypus look like? Generating customized prompts for zero-shot image classification	['zero-shot', 'image classification', 'prompts', 'open vocabulary models']	Using GPT-3 to generate better CLIP prompts	Applications (eg, speech processing, computer vision, NLP)	anonymous|what_does_a_platypus_look_like_generating_customized_prompts_for_zeroshot_image_classification	/pdf/a4d8a409e7a737b4ae29842b2ae603e463a17609.pdf
3OaBBATwsvP	2030	Generative Modeling Helps Weak Supervision (and Vice Versa)	['generative model', 'weak supervision']		General Machine Learning (ie none of the above)	anonymous|generative_modeling_helps_weak_supervision_and_vice_versa	/pdf/4b11924d3f18c2e0e1c9d503d40841b1d83d3cef.pdf
cDYRS5iZ16f	2031	Learning to Grow Pretrained Models for Efficient Transformer Training	['Transformer', 'Efficient Training', 'Model Reuse']	Learning to grow smaller, extant models to enable faster training of newer, larger transformers.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_to_grow_pretrained_models_for_efficient_transformer_training	/pdf/c255f8ca4fddf64b95723bb366f2d811a668f6df.pdf
9jXqR128vKs	2033	In-Context Policy Iteration	['Reinforcement Learning', 'In-Context Learning', 'Foundation Models']	We present a novel algorithm for performing policy iteration through in-context adaptation	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|incontext_policy_iteration	/pdf/8688462dedad758bbe83448721bebdcd9b0a387b.pdf
IUXAo-N9AGh	2034	Progressive Transformation Learning For Leveraging Virtual Images in Training	['progressive learning', 'virtual image', 'synthetic image', 'low-shot learning', 'cross-domain detection', 'UAV-based human detection']	We introduce progressive transformation learning (PTL) that progressively expands the training set with realistically transformed virtual images while addressing the large domain gap in training a transformation generator.	Applications (eg, speech processing, computer vision, NLP)	anonymous|progressive_transformation_learning_for_leveraging_virtual_images_in_training	/pdf/03abb8250cc3d781f3a08d636833ac1c7ee45f69.pdf
WUs4tNgcBYe	2035	FAME: Fast Adaptive Moment Estimation based on Triple Exponential Moving Average	['Optimization', 'Computer Vision', 'Deep learning', 'Triple Exponential Moving Average']	We propose the first optimizer that is based on the Triple Exponential Moving Average for deep learning 	Applications (eg, speech processing, computer vision, NLP)	anonymous|fame_fast_adaptive_moment_estimation_based_on_triple_exponential_moving_average	/pdf/78eef6f345d90c44cd8a9be91d63ba9537ccce31.pdf
SmjW4kKLjuU	2036	ON COMPLEX-DOMAIN CNN REPRESENTATIONS FOR CLASSIFYING REAL/COMPLEX-VALUED DATA	['Complex-valued neural networks', 'Complex-valued representations', 'Complex-value CNN', 'Classification', 'Complex numbers']	We address the contradictory answers present in the literature for the following question: CV-CNN performs better or worse than RV-CNN for classification task?	Deep Learning and representational learning	anonymous|on_complexdomain_cnn_representations_for_classifying_realcomplexvalued_data	/pdf/60a1e3cf5c7a3d4cb98ae7f397c2bc29f84b35b7.pdf
JIl_kij_aov	2037	Early Stopping for Deep Image Prior	['early stopping', 'deep image prior', 'deep generative models', 'overparametrization', 'overfitting']		Applications (eg, speech processing, computer vision, NLP)	anonymous|early_stopping_for_deep_image_prior	/pdf/752096d5cb2aa8649dab6f486a64528b6f28c86d.pdf
3YjQfCLdrzz	2038	FoSR: First-order spectral rewiring for addressing oversquashing in GNNs	['oversquashing', 'oversmoothing', 'graph rewiring', 'graph neural networks', 'GNN', 'relational GNN', 'spectral expansion']	We propose a graph rewiring algorithm that prevents oversquashing in GNNs via spectral expansion while retaining the original graph via a relational structure that prevents oversmoothing.	Deep Learning and representational learning	anonymous|fosr_firstorder_spectral_rewiring_for_addressing_oversquashing_in_gnns	/pdf/66360d13b99d07e14e28c170dee138ccbd9b2fd6.pdf
TTSyyMBNUjd	2040	Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations	['Neural Collapse', 'Representation Learning', 'Neural Networks']	We provide compelling empirical evidence proving that there exists fine-grained structures in the last-layer representations of a well trained neural network, as a complement to existing Neural Collapse hypothesis.	Deep Learning and representational learning	anonymous|are_neurons_actually_collapsed_on_the_finegrained_structure_in_neural_representations	/pdf/44cf3a2bd50ec2bf02807c1704b0a2aa8d461279.pdf
3IFO8Jii0vI	2041	Algorithmic Determination of the Combinatorial Structure of the Linear Regions of ReLU Neural Networks	['ReLU networks', 'algebraic topology', 'linear regions', 'computational geometry']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|algorithmic_determination_of_the_combinatorial_structure_of_the_linear_regions_of_relu_neural_networks	/pdf/93d113a087ddc911c92196401986ea40a37681a5.pdf
XEQ2pdweH9q	2042	FixEval: Execution-based Evaluation of Program Fixes for Competitive Programming Problems	['automated program repair', 'language models', 'dataset', 'deep learning', 'bug fixing']	We introduce FixEval, a novel dataset consisting of competitive programming submissions that incorporates additional program contexts, such as time and space requirements, to evaluate code generated by deep learning models for automatic bug fixing.	Applications (eg, speech processing, computer vision, NLP)	anonymous|fixeval_executionbased_evaluation_of_program_fixes_for_competitive_programming_problems	/pdf/bc91239704c764b6fffa8d9d02903a28b939d3a9.pdf
3OR2tbtnYC-	2043	Near-optimal Policy Identification in Active Reinforcement Learning	['reinforcement learning', 'contextual bayesian optimization', 'kernelized least-squares value iteration']	We propose a novel kernelized LSVI algorithm for active reinforcement learning which provably identifies a near-optimal policy uniformly over the entire state space.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|nearoptimal_policy_identification_in_active_reinforcement_learning	/pdf/d4cf9afd71c83a321e51c0ba152538ce94491ddf.pdf
I_IJf5oDRo	2044	Explainable Recommender with Geometric Information Bottleneck	['Interpretability', 'Recommender System', 'Information Extraction']	To consider user-item interactions for an interpretable recommender system, we propose to incorporate the geometric regularisation derived from user-item interaction graphs to learn the latent factors of review text in a variational network.	Applications (eg, speech processing, computer vision, NLP)	anonymous|explainable_recommender_with_geometric_information_bottleneck	/pdf/dd77622bf0a9b08622e485e901c82793f0d235d2.pdf
TJ2nxciYCk-	2045	On Emergence of Activation Sparsity in Trained Transformers	['Transformers', 'Sparse', 'Calibration', 'Robustness', 'Label Noise', 'Efficiency']	Learned Transformers for NLP (e.g., T5) and Vision (e.g., ViT) tasks produce sparse representations in their MLP layers. The sparsity may be leveraged to improve robustness, calibration, and computational efficiency of Transformer models.	Deep Learning and representational learning	anonymous|on_emergence_of_activation_sparsity_in_trained_transformers	/pdf/ea119d70979cbb3d4b30b0084b054fecf629e1ad.pdf
Z4QNXXyLhGN	2046	FedDA: Faster Framework of Local Adaptive Gradient Methods via Restarted Dual Averaging	[]		Optimization (eg, convex and non-convex optimization)	anonymous|fedda_faster_framework_of_local_adaptive_gradient_methods_via_restarted_dual_averaging	/pdf/68cd01f3028da82e3ceb43988e17b50aca30e5c5.pdf
6i6ajdIinJm	2047	Local Stochastic Bilevel Optimization with Momentum-Based Variance Reduction	[]		Optimization (eg, convex and non-convex optimization)	anonymous|local_stochastic_bilevel_optimization_with_momentumbased_variance_reduction	/pdf/d8c1ec26658fe735ca3e5a0266825f1decdb12cd.pdf
Xl5Wwp495iC	2048	Towards Efficient Posterior Sampling in Deep Neural Networks via Symmetry Removal	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|towards_efficient_posterior_sampling_in_deep_neural_networks_via_symmetry_removal	/pdf/32ffc90f3d58e79f4834137c5b8afe8ea0a1b990.pdf
Refb0S-paCx	2049	An Investigation of Domain Generalization with Rademacher Complexity	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|an_investigation_of_domain_generalization_with_rademacher_complexity	/pdf/73d2f7b77e45dc31d50ad6c6b01619b25bf485c4.pdf
Pe7R48fCkM_	2050	Unravel Structured Heterogeneity of Tasks in Meta-Reinforcement Learning via Exploratory Clustering	['Meta Reinforcement Learning', 'Variational Inference']	We propose a method to automatically discover and utilize the cluster structures of tasks for meta-reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|unravel_structured_heterogeneity_of_tasks_in_metareinforcement_learning_via_exploratory_clustering	/pdf/c9a5696c7f00ac9fde781dbbf630fe3179f34051.pdf
AdPJb9cud_Y	2051	VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for Analysis-by-Synthesis	['Differentiable Rendering', 'Analysis-by-Synthesis', 'Pose Estimation']	VoGE is a differentiable renderer based on ray tracing volume densities, which gives better gradients for occlusion reasoning and yields better pose estimation results.	Applications (eg, speech processing, computer vision, NLP)	anonymous|voge_a_differentiable_volume_renderer_using_gaussian_ellipsoids_for_analysisbysynthesis	/pdf/7a96573a3f94c18c4c4d097d4d29538cc081c0f7.pdf
8sSnD78NqTN	2052	Learning Soft Constraints From Constrained Expert Demonstrations	['inverse reinforcement learning', 'constraint learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_soft_constraints_from_constrained_expert_demonstrations	/pdf/ee9673a6905c7ea11e4067d407af7ab96a9097e9.pdf
78xgBm6ckZr	2053	Sparse tree-based Initialization for Neural Networks	[]		Deep Learning and representational learning	anonymous|sparse_treebased_initialization_for_neural_networks	/pdf/17a2ecb65dd5ca9c2d93bbd32f863a884365edf1.pdf
dZaYbIIW9Cu	2054	Towards Global Optimality in Cooperative MARL with Sequential Transformation	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_global_optimality_in_cooperative_marl_with_sequential_transformation	/pdf/727d0fcc3e506caa3f9b87aa2303e2df0f348e7d.pdf
yYbhKqdi7Hz	2055	Continuized Acceleration for Quasar Convex Functions  in Non-Convex Optimization	[]		Optimization (eg, convex and non-convex optimization)	anonymous|continuized_acceleration_for_quasar_convex_functions_in_nonconvex_optimization	/pdf/90f4a1a46d8656aa73e8cf8afb996d87a5045f3d.pdf
B7HJ9KLFV9U	2056	Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor Attacks in Federated Learning	['Privacy', 'Federated Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|thinking_two_moves_ahead_anticipating_other_users_improves_backdoor_attacks_in_federated_learning	/pdf/907764e284b86d36dd816dcd5a63d650c875f849.pdf
yLzLfM-Esnu	2057	Constructive TT-representation of the tensors given as index interaction functions with applications	['Tensor approximation', 'Discrete multivariate functions', 'Tensor train decomposition', 'TT-Tucker format', 'Game theory', 'Combinatorial problems']	A method to build tensor train representation for a wide class of tensors for which an analytical dependence on the indices is given.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|constructive_ttrepresentation_of_the_tensors_given_as_index_interaction_functions_with_applications	/pdf/aefa4f0fafa19b5429a8599d4996bc2dee8a3354.pdf
iA8XoWjDeGK	2058	Structured Pruning of CNNs at Initialization	['Pruning', 'Pruning-at-Initialization', 'Structured Pruning', 'Efficient Deep Learning', 'Efficient Model']	Structured pruning-at-initialization method can be as good as unstructured ones.	Deep Learning and representational learning	anonymous|structured_pruning_of_cnns_at_initialization	/pdf/2c153521ae4e589f30381266efb5fc12e8dedbeb.pdf
vEAHushUBGc	2059	Inverse Kernel Decomposition	['Nonlinear dimensionality reduction', 'GPLVM', 'eigen-decomposition', 'kernel', 'latent estimation']	We propose a novel eigen-decomposition-based nonlinear dimensionality reduction method.	Unsupervised and Self-supervised learning	anonymous|inverse_kernel_decomposition	/pdf/b9ea22eb9571e73c4d916e22edffc4f7fa394252.pdf
lGh3JsP0j7k	2060	Target-Free Ligand Scoring via One-Shot Learning	['drug discovery', 'ligand scoring', 'one-shot learning']	A new method for scoring ligands by activity using a one-shot learning approach.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|targetfree_ligand_scoring_via_oneshot_learning	/pdf/d5d539283f878982e262d6cb07dd28273dd45d5e.pdf
am22IukDiKf	2063	Learning by Distilling Context	['language models', 'NLP', 'prompting', 'distillation']	applying context distillation as a general tool to translate language into parameter updates; used to distill instructions, explanations, examples, knowledge, and reasoning procedure.	Deep Learning and representational learning	anonymous|learning_by_distilling_context	/pdf/517809913cc4ebc4b8146412b09a4f64acc45a1e.pdf
WdN2gD6EsXm	2064	An Upper Bound for the Distribution Overlap Index and Its Applications	['Distribution Overlap', 'Finite-Sample Approximation', 'One-Class Classification', 'Domain Shift Analysis']	This paper proposes an easy-to-compute upper bound for the overlap index and applies it for domain shift analysis and one-class classification.	General Machine Learning (ie none of the above)	anonymous|an_upper_bound_for_the_distribution_overlap_index_and_its_applications	/pdf/fd0995b4bb61c75d5eb1519f4438086e309f6759.pdf
kKF8_K-mBbS	2065	DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking	['molecular docking', 'protein-ligand binding', 'diffusion models', 'score-based models', 'molecular structure', 'equivariance', 'geometric deep learning']	Molecular docking via non-Euclidean diffusion modeling and confidence estimation	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|diffdock_diffusion_steps_twists_and_turns_for_molecular_docking	/pdf/147319808a2d1191f70ce94c41ee367e2aeb1054.pdf
KkI8sjKqtnV	2066	Fair Federated Learning via Bounded Group Loss	['Federated Learning', 'Group Fairness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fair_federated_learning_via_bounded_group_loss	/pdf/979d5d7ad26ed1b1b8213293509faf76f006452d.pdf
wOzKzPf6BBv	2067	Dynamic Embeddings of Temporal High-Order Interactions via Neural Diffusion-Reaction Processes	['Embedding Trajectory', 'Tensor Decomposition']	We develop a neural diffusion-reaction process model to estimate the dynamic embeddings for the participant entities in tensor decomposition.	Deep Learning and representational learning	anonymous|dynamic_embeddings_of_temporal_highorder_interactions_via_neural_diffusionreaction_processes	/pdf/11e312efbafdf40fdeb15681fb00b67fdd6a0114.pdf
fR_0uObMTjG	2068	GLASU: A Communication-Efficient Algorithm for Federated Learning with Vertically Distributed Graph Data	['Federated Learning', 'Graph Neural Network', 'Feature Distributed Federated Learning']	This paper proposed a GNN model design approach and a communication efficient algorithm for federated learning on feature distributed graph data	Deep Learning and representational learning	anonymous|glasu_a_communicationefficient_algorithm_for_federated_learning_with_vertically_distributed_graph_data	/pdf/5cdab34b6f8f5e9b99e391366eb90e51cffc93ba.pdf
uHaWaNhCvZD	2069	Meta-Learning in Games	['meta-learning', 'algorithmic game theory', 'online learning']	We formalize and study the problem of meta-learning across a wide range of fundamental multi-agent settings.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|metalearning_in_games	/pdf/90dde424a5986a34d806bbd282b8efb23cfbc12f.pdf
gxq1n1f0c7l	2070	Min-Max Zero-Shot Multi-Label Classification	['Transfer learning', 'zero-shot learning']		Deep Learning and representational learning	anonymous|minmax_zeroshot_multilabel_classification	/pdf/a529d2f734a1677348869f3660d969bbbc8ae4a7.pdf
yPQoijKtdHO	2071	RelationCLIP: Training-free Fine-grained Visual and Language Concept Matching	['Zero-shot', 'Image-text Matching', 'CLIP']	A simple but effective method that can improve zero-shot performance for CLIP-like models on fine-grained Image-text matching datasets	Applications (eg, speech processing, computer vision, NLP)	anonymous|relationclip_trainingfree_finegrained_visual_and_language_concept_matching	/pdf/2c17b5cec6a77d613d29c30a0a1da1ad4470eb2a.pdf
8qjSA5QACb40	2072	Combinatorial-Probabilistic Trade-Off: P-Values of Community Properties Test in the Stochastic Block Models	['combinatorial inference', 'stochastic block models', 'community properties', 'minimax lower bound']	We propose an inferential framework testing the general community combinatorial properties of the stochastic block model and prove the minimax lower bound of the general community property test.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|combinatorialprobabilistic_tradeoff_pvalues_of_community_properties_test_in_the_stochastic_block_models	/pdf/259fe79dfc32a0634a5ac6ff286245252a3d599a.pdf
_tIZQEMcWyv	2073	Adaptive Gradient Methods with Local Guarantees	[]		Optimization (eg, convex and non-convex optimization)	anonymous|adaptive_gradient_methods_with_local_guarantees	/pdf/f5305a9cb2bcd3cd13cfc6e43cc7ef0ce185d9c2.pdf
7P_yIFi6zaA	2075	Are vision transformers more robust than CNNs for Backdoor attacks?	['Backdoor Attacks', 'Vision Transformers', 'Robustness']		Deep Learning and representational learning	anonymous|are_vision_transformers_more_robust_than_cnns_for_backdoor_attacks	/pdf/769d621c491a52ad7e98f7efa69949a09d56f6af.pdf
OJ8aSjCaMNK	2076	Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve	['Variational Autoencoders', 'VAEs', 'Hypernetworks', 'Response Functions', 'Hyperparameter Tuning']	MR-VAEs can construct the rate-distortion curve in a single training run.	Deep Learning and representational learning	anonymous|multirate_vae_train_once_get_the_full_ratedistortion_curve	/pdf/af2573e128454bac91e892bedb362b279828ae4e.pdf
bzpCoHn1Vc_	2077	The Convergence Rate of SGD's Final Iterate: Analysis on Dimension Dependence	[]		Optimization (eg, convex and non-convex optimization)	anonymous|the_convergence_rate_of_sgds_final_iterate_analysis_on_dimension_dependence	/pdf/196d44f40e2002f1101bfd583b223e9b85ec27eb.pdf
J9Z3MlnPU_f	2078	Compound Tokens: Channel Fusion for Vision-Language Representation Learning	['question answering tasks', 'multi-modal fusion', 'vision-language model', 'representation learning']	We provide a new multi-modal fusion method that concatenates tokens along the channel dimension. 	Deep Learning and representational learning	anonymous|compound_tokens_channel_fusion_for_visionlanguage_representation_learning	/pdf/cbfbe8167a26779e73423ed89e0a27d498379c06.pdf
Jqas82UP428	2079	Lower Bounds for Differentially Private ERM: Unconstrained and Non-Euclidean	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|lower_bounds_for_differentially_private_erm_unconstrained_and_noneuclidean	/pdf/9bd82f0f6adb30b7619be1453f6dffbd10125389.pdf
X9yCkmT5Qrl	2080	GNNDelete: A General Unlearning Strategy for Graph Neural Networks	['Graph Unlearning', 'Graph Neural Networks', 'Knowledge Graphs', 'Graph Representation Learning', 'Data Deletion']		Deep Learning and representational learning	anonymous|gnndelete_a_general_unlearning_strategy_for_graph_neural_networks	/pdf/bcb37f321ebf2c7b9f5e5c455ee2febd91f9393b.pdf
0W1TQ_hoMFN	2082	Policy Architectures for Compositional Generalization in Control	['Reinforcement Learning', 'Imitation Learning', 'Compositionality']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|policy_architectures_for_compositional_generalization_in_control	/pdf/089289def6fd56960386d327d7a750fef7e60a37.pdf
Y6Gs9DdZGj5	2083	Bridging the Gap Between Cascade and End-to-End Cross-modal Translation Models: A Zero-Shot Approach	['Zero-Shot', 'End-to-End', 'Speech Translation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|bridging_the_gap_between_cascade_and_endtoend_crossmodal_translation_models_a_zeroshot_approach	/pdf/c7c60484a3ddf39332bd51469a999cd11cbf227b.pdf
rSHfAMCc997	2084	SimA: Simple Softmax-free Attention For Vision Transformers	['Computer Vision', 'Vision Transformer', 'Efficient Vision Transformer', 'Image Recognition']	SimA is a simple softmax-free and hardware friendly attention that has on-par accuracy with SOTA vision transformers. 	Deep Learning and representational learning	anonymous|sima_simple_softmaxfree_attention_for_vision_transformers	/pdf/a4ebdd09f354eaec70abc6b0661858e71b7e0a11.pdf
4xzk3zGtz1h	2085	Hybrid Federated Learning for Feature & Sample Heterogeneity: Algorithms and Implementation	['Federated Learning', 'Model Ensemble', 'Model Design', 'Algorithm Design']	In this paper, we proposed the first hybrid federated learning model and algorithm, which deals with partially overlapped features and samples in clients' datasets	Optimization (eg, convex and non-convex optimization)	anonymous|hybrid_federated_learning_for_feature_sample_heterogeneity_algorithms_and_implementation	/pdf/a8bec8cbc82491f74fd513f2cdc63f82f5795518.pdf
m3twGT2bAug	2086	Countinuous pseudo-labeling from the start	['selt-training', 'pseudo-labeling', 'speech recognition', 'data selection and filtering']	We show how to perform continuous self-training right from the start without any supervised pre-training.	Unsupervised and Self-supervised learning	anonymous|countinuous_pseudolabeling_from_the_start	/pdf/5859af0ca41c43afddb8ae09f77c1afa6f353806.pdf
NzcUQuhEGef	2087	Graph Contrastive Learning Under Heterophily: Utilizing Graph Filters to Generate Graph Views	['GNN', 'Contrastive learning', 'Heterophily', 'Graph Representation Learning']	We proposed HLCL, a contrastive learning framework that leverages a high-pass graph filter as our augmentation method to generate meaningful representations for heterophily graphs.	Deep Learning and representational learning	anonymous|graph_contrastive_learning_under_heterophily_utilizing_graph_filters_to_generate_graph_views	/pdf/ebe3a0d22677073cf77292951b9e887a6b28bafb.pdf
WmIwYTd0YTF	2088	Stable Target Field for Reduced Variance Score Estimation	['generative model', 'score-based models', 'diffusion models', 'variance reduction']	We propose a low variance objective to improve the training of score-based models	Generative models	anonymous|stable_target_field_for_reduced_variance_score_estimation	/pdf/8ea84fc11f7c01465dfbf772a7e61d04bd0a1561.pdf
99RpBVpLiX	2092	Distilling Model Failures as Directions in Latent Space	['datasets', 'biases', 'subpopulations']	We present a scalable method for automatically distilling and captioning a model's failure modes as directions in a latent space.	Deep Learning and representational learning	anonymous|distilling_model_failures_as_directions_in_latent_space	/pdf/8d19f349d1fc6b3401aa1d375c1de2b0c0f54eb2.pdf
0DTpO6lLIN	2093	On the Complexity of Bayesian Generalization	['Bayesian Generalization', 'Rational Analysis']	Correlating the shift between rule- and similarity-based generalization with the subjective complexity of the natural visual world.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|on_the_complexity_of_bayesian_generalization	/pdf/b178fc8e6b432fe47b2c5baa2627f4621c2422c6.pdf
o8g9WfWDTF	2094	Accelerating Adaptive Federated Optimization with Local Gossip Communications	['Federated learning', 'Nonconvex optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|accelerating_adaptive_federated_optimization_with_local_gossip_communications	/pdf/199abce4c12751ee9ae4b45aa678a9c3ac9d4eb7.pdf
cFuMmbWiN6	2095	Relational Attention: Generalizing Transformers for Graph-Structured Tasks	['Graph Neural Networks', 'Transformers', 'Graph Representation Learning', 'Neural Algorithmic Reasoning']	We generalize transformer attention to include edge vectors, which are then updated along with the standard node vectors in each layer of a transformer's computation.	Deep Learning and representational learning	anonymous|relational_attention_generalizing_transformers_for_graphstructured_tasks	/pdf/0516a9582a67e1c1c26343e3d1044387a1581279.pdf
NT51Ty0-Bfu	2096	Offline Reinforcement Learning with Differential Privacy	['offline reinforcement learning', 'differential privacy']	We present the first provably efficient offline RL algorithms with differential privacy guarantees.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|offline_reinforcement_learning_with_differential_privacy	/pdf/0498e253574b26e0d80a14a11c24c88547540af1.pdf
oHBgj83w1MB	2097	Causal Proxy Models For Concept-Based Model Explanations	['Explainability', 'Causality', 'Concept-Based Explanations', 'Causal Explanations']	We introduce Causal Proxy Models (CPMs), a novel concept-based explanation method. Our method used counterfactual training data to achieve state-of-the-art explanation performance on the CEBaB benchmark.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|causal_proxy_models_for_conceptbased_model_explanations	/pdf/43e47d49e9678c6e4a9b48763ac5d505a46e29c3.pdf
cuZNcYohQCX	2098	GeONet: a neural operator for learning the Wasserstein geodesic	['Wasserstein', 'optimal transport', 'neural operator', 'GeONet']	We design a neural operator deep learning framework for learning the Wasserstein geodesic from any input pair of distributions.	Deep Learning and representational learning	anonymous|geonet_a_neural_operator_for_learning_the_wasserstein_geodesic	/pdf/34af284644ae6b867d6dcac5e1c79a3b8b81e5fe.pdf
yxj33c6NuX	2100	Minimum Curvature Manifold Learning	['Autoencoder', 'Manifold', 'Curvature', 'Riemannian geometry']	We propose a minimum extrinsic curvature principle for manifold regularization and Minimum Curvature Autoencoder (MCAE), a graph-free coordinate-invariant extrinsic curvature minimization framework for autoencoder regularization.	Generative models	anonymous|minimum_curvature_manifold_learning	/pdf/91dc3839c436b85ece9f4387c8f1b45a9decc68e.pdf
boik01yhssB	2101	Average Sensitivity of Decision Tree Learning	['decision tree', 'average sensitivity', 'trustworthy machine learning']	We design decision tree learning algorithms that are stable against perturbations in the training data.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|average_sensitivity_of_decision_tree_learning	/pdf/c6342ea0458dcf7b4f207658ae2b7c091fef5d14.pdf
4fZc_79Lrqs	2102	ACMP: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks	[]		Deep Learning and representational learning	anonymous|acmp_allencahn_message_passing_with_attractive_and_repulsive_forces_for_graph_neural_networks	/pdf/0a12c766528d6c2465cedadbda18010be07f471e.pdf
6Fq1-57gff	2103	The World is Changing: Improving Fair Training under Correlation Shifts	['trustworthy AI', 'fairness', 'correlation shifts']	We analyze fundamental limits in accuracy and fairness of in-processing fair algorithms when the data bias changes with correlation shifts and propose a novel pre-processing step that improves their performances.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|the_world_is_changing_improving_fair_training_under_correlation_shifts	/pdf/e55423ebdd06e8ce1f3b7c04f9bd6f45c024c2d6.pdf
1bLT3dGNS0	2105	Relational Curriculum Learning for Graph Neural Networks	['Graph neural networks', 'Curriculum learning']	We propose a novel curriculum learning strategy to improve the generalization performance of graph neural network models by gradually involving edges from well-expected to less-expected in training.	Deep Learning and representational learning	anonymous|relational_curriculum_learning_for_graph_neural_networks	/pdf/2cb8f7901db69993985ac0aa764ab477d540be61.pdf
wFOGJB88Y5	2106	HYPERPRUNING: EFFICIENT PRUNING THROUGH LYAPUNOV METRIC HYPERSEARCH	['Network Pruning', 'Efficient Hyperparameter Searching', 'Lyapunov Spectrum']	We proposed a novel method to search over pruning method and hyperparameters based on Lyapunov Spectrum.	Applications (eg, speech processing, computer vision, NLP)	anonymous|hyperpruning_efficient_pruning_through_lyapunov_metric_hypersearch	/pdf/d9c7cd3bac03eda48725742f10d4b99eaa247c26.pdf
5HLoTvVGDe	2107	Dual Diffusion Implicit Bridges for Image-to-Image Translation	[]		Generative models	anonymous|dual_diffusion_implicit_bridges_for_imagetoimage_translation	/pdf/4f81597102123af764ed9bb705cf565fa9d35553.pdf
YfSFF4WaTj	2108	PATCH-MIX TRANSFORMER FOR UNSUPERVISED DOMAIN ADAPTATION: A GAME PERSPECTIVE	['Unsupervised domain adaptation', 'Game theory', 'Transformer', 'Mixup']		Unsupervised and Self-supervised learning	anonymous|patchmix_transformer_for_unsupervised_domain_adaptation_a_game_perspective	/pdf/c1a0f285ac847ce4961bc983eb23155aafd7e096.pdf
0VhwJYrZew	2109	FINE: Future-Aware Inference for Streaming Speech Translation	['Streaming Speech Translation', 'Future-Aware Inference']	Future-aware inference for streaming speech translation	Applications (eg, speech processing, computer vision, NLP)	anonymous|fine_futureaware_inference_for_streaming_speech_translation	/pdf/d347f4ac4a2c462421d25e5ffb8ccbd994499f9f.pdf
COZDy0WYGg	2110	Hungry Hungry Hippos: Towards Language Modeling with State Space Models	['language modeling', 'state space models', 'efficiency']	We study the expressivity gap between state space models (SSMs) and attention on language modeling and reduce the hardware barrier between SSMs and attention.	Deep Learning and representational learning	anonymous|hungry_hungry_hippos_towards_language_modeling_with_state_space_models	/pdf/92767b01f4c01b64d031f0d7dc53f33c20a2824e.pdf
nZGu4Ltnl5	2111	AxBERT: An Explainable Chinese Spelling Correction Method Driven by Associative Knowledge Network	['Chinese spelling correction', 'explainable deep learning', 'associative knowledge network', 'explainable statistic', 'attention distribution', 'statistical alignment']	The proposed AxBERT as an explainable Chinese spelling correction method can achieve a predictable and regulatable correction process with extraordinary performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|axbert_an_explainable_chinese_spelling_correction_method_driven_by_associative_knowledge_network	/pdf/975a1f22983c2c94ae7274453660f854f982607b.pdf
vbnxKVZDr4	2112	Representational Task Bias in Zero-shot Recognition at Scale	['vision-language models', 'CLIP', 'prompting', 'task representation']	We show CLIP image representations are biased towards being used for a specific task a priori, and provide a simple method cue which task is desired without model retraining.	Applications (eg, speech processing, computer vision, NLP)	anonymous|representational_task_bias_in_zeroshot_recognition_at_scale	/pdf/273fa25c24eef3d1cdb3521dc98d0f360f3f6929.pdf
w0QXrZ3N-s	2113	The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation	['multimodal learning', 'knowledge distillation']	We provide a thorough investigation of crossmodal knowledge transfer	General Machine Learning (ie none of the above)	anonymous|the_modality_focusing_hypothesis_towards_understanding_crossmodal_knowledge_distillation	/pdf/41e9779fad0506e48defab41c2c4f24c1597eff0.pdf
3yJ-hcJBqe	2115	Adaptive Robust Evidential Optimization For Open Set Detection from Imbalanced Data	['Open Set Detection', 'Imbalanced Data']	We propose adaptive robust uncertainty mass quantification for effective open set detection from imbalanced data. 	Deep Learning and representational learning	anonymous|adaptive_robust_evidential_optimization_for_open_set_detection_from_imbalanced_data	/pdf/929890533523302bb0170644a702fda69b495782.pdf
4D4TSJE6-K	2116	Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions	['mathematical reasoning', 'multi-target learning', 'self-sampling', 'large language models']	We propose to let pretrained language models sample additional solutions for each problem and learn from the self-sampled solutions that are correct or partially-correct.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_math_reasoning_from_selfsampled_correct_and_partiallycorrect_solutions	/pdf/8ebea551a701f2698722221cd606500742f099c3.pdf
sKD1LojqWYR	2118	Cluster and Landmark Attributes Infused Graph Neural Networks for Link prediction	['Graph Neural Networks', 'Link prediction']	We propose a simple representation of positional information using a set of representative nodes called landmarks, and show that the proposed method achieves superior link prediction performances on various datasets.	Deep Learning and representational learning	anonymous|cluster_and_landmark_attributes_infused_graph_neural_networks_for_link_prediction	/pdf/91985d6f478eacf69d777ae6be9975aef48099f5.pdf
YCMKCwN4PQw	2119	Diving into Unified Data-Model Sparsity for Class-Imbalanced Graph Representation Learning	['Graph representation learning', 'Class-imbalanced data']	We propose Graph Decantation, a novel method of discovering unified dynamic sparsity from both GNN model and graph data, to learn balanced graph representations.	Deep Learning and representational learning	anonymous|diving_into_unified_datamodel_sparsity_for_classimbalanced_graph_representation_learning	/pdf/a96e2706f6574a8b6aa09ec08f460443e86ec0c8.pdf
0bLE93R9d0O	2120	Transformer Module Networks for Systematic Generalization in Visual Question Answering	['Systematic generalization', 'Neural Module Network', 'Transformer']	Investigating whether and how modularity brings benefits to Transformer-based models	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|transformer_module_networks_for_systematic_generalization_in_visual_question_answering	/pdf/5c8f8f8c982033bcd2207db64bc26d44fca9a3d5.pdf
tCPheuUFBC	2121	$$CONVOLUTION AND POOLING OPERATION MODULE WITH ADAPTIVE STRIDE PROCESSING EFFEC$$	['convolution', 'pooling', 'adaptive', 'stride']		Deep Learning and representational learning	anonymous|convolution_and_pooling_operation_module_with_adaptive_stride_processing_effec	/pdf/4486360dc6d0bce3ded8bbba1fcf83057d712f58.pdf
H-VlwsYvVi	2122	Speculative Decoding: Lossless Speedup of Autoregressive Translation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|speculative_decoding_lossless_speedup_of_autoregressive_translation	/pdf/eafdac4ce58a9dd6b0525764d74a49d6471ccfaf.pdf
j9m-mVnndbm	2124	MIMT: Masked Image Modeling Transformer for Video Compression	['video compression', 'masked image modeling', 'transformer', 'entropy model']	draft	Applications (eg, speech processing, computer vision, NLP)	anonymous|mimt_masked_image_modeling_transformer_for_video_compression	/pdf/2e27626c20626b4ff1f79a1b7a2caa9bfa8b660b.pdf
gEvzRWqFoCO	2125	Contrastive Novelty Learning: Anticipating Outliers with Large Language Models	['selective prediction', 'open-set classification', 'large language models', 'NLP']	We present Contrastive Novelty Learning, a method to improve open-set selective classification by generating probable novel examples with a large language model, then training a classifier for lower relative confidence on generated examples.	Applications (eg, speech processing, computer vision, NLP)	anonymous|contrastive_novelty_learning_anticipating_outliers_with_large_language_models	/pdf/45a70cf817cf0e2e6d7eabeb6ad8ea2f84a84b34.pdf
IrUFsuTxVfY	2126	A Data-Based Perspective on Transfer Learning	['transfer learning', 'datasets', 'subpopulations']	In this work, we present a framework for probing the impact of the source dataset on transfer learning performance.	Deep Learning and representational learning	anonymous|a_databased_perspective_on_transfer_learning	/pdf/679e7d0e7b503eb3556ca219d989b81b08af1ec5.pdf
j6sAOkvn4GI	2127	Unsupervised Visual Anomaly Detection with Score-Based Generative Model	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|unsupervised_visual_anomaly_detection_with_scorebased_generative_model	/pdf/80e7db363ba976ad8a8952edd11529f6d54a6f13.pdf
jlAjNL8z5cs	2128	Visual Classification via Description from Large Language Models	['vision-language models', 'CLIP', 'prompting', 'GPT-3', 'large language models', 'zero-shot recognition', 'multimodal']	We enhance zero-shot recognition with vision-language models by comparing to category descriptors from GPT-3, enabling better performance in an interpretable setting that also allows for incorporation of new concepts and bias mitigation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|visual_classification_via_description_from_large_language_models	/pdf/cf8670b853598bf50bf4c1b2e42e1a4f3bf24372.pdf
p8ZiYjVPk8g	2129	GENERATIVE OF ORIGIN MODEL DISTRIBUTION MASKED WITH EMOTIONS AND TOPICS DISTRIBUTION IN HYBRID METHOD	['Masked Distribution', 'Learning Approximation Representation', 'Topic Analytics', 'Sentiment Analytics', 'Meta Learning']	Embedding constructors for effective representation of natural language	Deep Learning and representational learning	anonymous|generative_of_origin_model_distribution_masked_with_emotions_and_topics_distribution_in_hybrid_method	/pdf/989edb499e18b5d7e9df5b186849fac009e4c77f.pdf
tQG-o3SeipT	2130	On the Perils of Cascading Robust Classifiers	['Certifiable Robustness', 'Ensemble', 'Adversarial Attack', 'Soundness']	Our work reveals a critical pitfall of cascading certifiably robust models by showing that the seemingly beneficial strategy of cascading can actually hurt the robustness of the resulting ensemble.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_perils_of_cascading_robust_classifiers	/pdf/1924f2069fc1c9c9bc2f913eb989c85e6a2aa222.pdf
o0LFPcoFKnr	2131	SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency	['Backdoor Detection', 'Backdoor Defense', 'Backdoor Learning', 'AI Security', 'Deep Learning']	We reveal an intriguing phenomenon that the predictions of poisoned samples are significantly more consistent when amplifying all pixel values, based on which we design a simple yet effective black-box input-level backdoor detection.	Deep Learning and representational learning	anonymous|scaleup_an_efficient_blackbox_inputlevel_backdoor_detection_via_analyzing_scaled_prediction_consistency	/pdf/d36f525325ed88023012c191245d083380d53cde.pdf
h3vfP9ASoXEK	2133	Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing	['Crowdsourcing', 'multiple choice', 'detecting confusion', 'task difficulty', 'two-stage inference algorithm', 'minimax optimal convergence rate']	We propose a computationally and statistically efficient algorithm for multi-choice crowdsourced labeling to recover not only the ground truth but also the most confusing answer with confusion probability.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|recovering_toptwo_answers_and_confusion_probability_in_multichoice_crowdsourcing	/pdf/79506ab252967f8a59b8e615e449b6c2466ed60b.pdf
uFWSIObdx5H	2134	Beyond Counting Linear Regions of Neural Networks, Simple Linear Regions Dominate!	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|beyond_counting_linear_regions_of_neural_networks_simple_linear_regions_dominate	/pdf/5ed7046617e8ca24b0ee0fb9a2d4b123a811c353.pdf
lUr4FoC1wCx	2135	Causal Knowledge Transfer from Task Affinity	['Causal Inference', 'Transfer Learning']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|causal_knowledge_transfer_from_task_affinity	/pdf/b7ade7276eee810b136d6bcaac22ad0a56d26317.pdf
c7rM7F7jQjN	2136	From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data	['behavior generation', 'robot manipulation', 'learning from play']	We train a transformer-based model on uncurated play data, which can produce targeted real-world robot policies by conditioning on future observations.	Deep Learning and representational learning	anonymous|from_play_to_policy_conditional_behavior_generation_from_uncurated_robot_data	/pdf/9185e03d0ecbf3ffb85ec158f340e5c732a90242.pdf
gnULZPMCPz	2137	On the Neural Tangent Kernel of Equilibrium Models	['Equilibrium model', 'neural tangent kernel']		General Machine Learning (ie none of the above)	anonymous|on_the_neural_tangent_kernel_of_equilibrium_models	/pdf/01a6075e8843e3493713b1820e23b0bce94bba87.pdf
WW7BJ15ivoo	2138	MaskConver: A Universal Panoptic and Semantic Segmentation Model with Pure Convolutions	['panoptic segmentation', 'semantic segmentation', 'convolutional networks', 'mobile models']	Universal panoptic segmentation model with pure convolutions tailored for mobile devices.	Applications (eg, speech processing, computer vision, NLP)	anonymous|maskconver_a_universal_panoptic_and_semantic_segmentation_model_with_pure_convolutions	/pdf/0b3032f9d2575b18f92a7ba490a4c7ad940832f0.pdf
PxwqKdOshWI	2139	Concentric Ring Loss for Face Forgery Detection	['face forgery detection', 'metric learning']		Deep Learning and representational learning	anonymous|concentric_ring_loss_for_face_forgery_detection	/pdf/e84900d692db36197644dc92f1988f17411d8986.pdf
NTTc8wZktaT	2140	Substructured Graph Convolution for Non-overlapping Graph Decomposition	['Graph convolution', 'non-overlapping graph decomposition', 'parallel computation', 'substructuring method']	A novel graph convolution for non-overlapping graph decomposition.	General Machine Learning (ie none of the above)	anonymous|substructured_graph_convolution_for_nonoverlapping_graph_decomposition	/pdf/2843de5175987693447fe69d510ed86a1d5b7e39.pdf
h5z_RaWLdG1	2142	How Does Adaptive Optimization Impact Local Neural Network Geometry?	['optimization', 'adaptive algorithms', 'neural networks']	We study the difference between the local geometry of the training objective in deep learning using Adaptive algorithms and SGD.	Optimization (eg, convex and non-convex optimization)	anonymous|how_does_adaptive_optimization_impact_local_neural_network_geometry	/pdf/ffac329411645d7a7390f85afbce27c3da46ba35.pdf
hQ4K9Bf4G2B	2144	Behavior Prior Representation learning for Offline Reinforcement Learning	['offline reinforcement learning', 'representation learning']	We propose a state representation learning method with a surprisingly simple, easy-to-integrate objective based on behavior cloning of the dataset	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|behavior_prior_representation_learning_for_offline_reinforcement_learning	/pdf/233253658cb97745061937d23fcd2efd2268cbfa.pdf
HnSceSzlfrY	2145	RPM: Generalizable Behaviors for Multi-Agent Reinforcement Learning	['multi-agent system', 'multi-agent reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|rpm_generalizable_behaviors_for_multiagent_reinforcement_learning	/pdf/d7354a28cd7d7d1048e3ceb090176963b1a1d8a8.pdf
gLl0fZQo6Vu	2146	Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information	['offline RL', 'exogenous information', 'representation learning', 'latent state recovery', 'robustness']	representation learning methods for robustness to exogenous information based new offline RL benchmarks	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|agentcontroller_representations_principled_offline_rl_with_rich_exogenous_information	/pdf/cd2a30689c0df7c8eac6403ba49c337a7463c92d.pdf
YDJRFWBMNby	2147	HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing	['Protein Thermostability', 'Protein Editing', 'Dataset', 'Structure-aware Pre-training', 'Factorized Sparse Tuning']	A new dataset and a novel learning framework for protein thermostability prediction and editing.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|hotprotein_a_novel_framework_for_protein_thermostability_prediction_and_editing	/pdf/25c4e4a8fcf9ffe7aa6652c68ca3056129f699a2.pdf
XIzO8zr-WbM	2148	Data Valuation Without Training of a Model	['Data valuation', 'generalization error bounds', 'complexity-gap score', 'data pruning', 'training dynamics']	In this paper, we define a training-free data valuation score, which can be directly computed from data and can effectively quantify the impact of individual instances in optimization and generalization of neural networks.	Deep Learning and representational learning	anonymous|data_valuation_without_training_of_a_model	/pdf/21bba07397a264f7d4ef50e944f396bbafd1fd96.pdf
zJXg_Wmob03	2149	Progressive Voronoi Diagram Subdivision Enables Accurate Data-free Class-Incremental Learning	['Voronoi Diagram', 'Computational Geometry']	We show that progressive Voronoi Diagram is a powerful model for Class-incremental Learning.	Deep Learning and representational learning	anonymous|progressive_voronoi_diagram_subdivision_enables_accurate_datafree_classincremental_learning	/pdf/061540fc7a77215d138f703a875997c1c41825ed.pdf
HgQR0mXQ1_a	2150	Write and Paint: Generative Vision-Language Models are Unified Modal Learners	['Foundation model', 'Multi-modal learning', 'Vision-language pre-training']	The paper proposes a simple, scalable, and versatile seq2seq foundation model, which is capable of vision-language understanding, image-to-text generation, and text-to-image generation with a single unified architecture	Deep Learning and representational learning	anonymous|write_and_paint_generative_visionlanguage_models_are_unified_modal_learners	/pdf/3dba885a23f0316aa813cab4fd8b651583e5a773.pdf
9dFQcu9vmX	2151	MemoNav: Working Memory Model for Visual Navigation	['Image-Goal Navigation', 'Memory mechanism', 'Embodied visual navigation', 'Embodied AI']	The MemoNav learns three types of scene representations, which contain goal-relevant information and scene-level features and are utilized to improve navigation performance in both 1-goal and multi-goal ImageNav tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|memonav_working_memory_model_for_visual_navigation	/pdf/96022ed929d69899d880d2e5598d36e8752d395a.pdf
i7hWcu3t0S	2152	Clustering-Assisted Foreground and Background Separation for Weakly-supervised Temporal Action Localization	['weakly-supervised temporal action localization', 'online clustering']		Applications (eg, speech processing, computer vision, NLP)	anonymous|clusteringassisted_foreground_and_background_separation_for_weaklysupervised_temporal_action_localization	/pdf/677e890cd22ee97dd7d5df2145c254618d3b4e8c.pdf
FKXVK9dyMM	2153	Simple Yet Effective Graph Contrastive Learning for Recommendation	['recommender systems', 'graph neural networks', 'contrastive learning']	A new lightweight graph contrastive learning approach to enhance recommender systems	Applications (eg, speech processing, computer vision, NLP)	anonymous|simple_yet_effective_graph_contrastive_learning_for_recommendation	/pdf/d0dfbf5566e8db6555bd8a3ed2fee68ada6b09fb.pdf
917v6o8fO7	2155	Generalizable Person Re-identification Without Demographics	['Generalizable Person Re-Identification', 'Distributionally robust optimization', 'Change-of-measure technique']		Applications (eg, speech processing, computer vision, NLP)	anonymous|generalizable_person_reidentification_without_demographics	/pdf/75bbf1b7062f3c0cb5c66f12d7977d80b15db040.pdf
JwUmXwqXhr	2156	Chasing Better Deep Image Priors Between Over- and Under-parameterization	[]		Deep Learning and representational learning	anonymous|chasing_better_deep_image_priors_between_over_and_underparameterization	/pdf/21592f21927b1739672c2d288552234b36eb1f28.pdf
9wx-QXt-JaN	2157	Can Language Models Make Fun? A Case Study in Chinese Comical Crosstalk	['humor generation', 'Chinese crosstalk', 'pre-trained language model', 'GPT', 'natural language generation']	Testing whether AI could make fun!	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|can_language_models_make_fun_a_case_study_in_chinese_comical_crosstalk	/pdf/bc85ccca4c8c06752fe148fa62903a148fcfaa8b.pdf
N-S6pJrlkK	2159	Improving Language Model Pretraining with Text Structure Information	['Language Model Pretraining', 'Representation Learning']	A pretraining task that distinguishes text structure relationships between sentences can improve general-purpose language model pretraining.	Deep Learning and representational learning	anonymous|improving_language_model_pretraining_with_text_structure_information	/pdf/676530778bfefcbc6f4b6ee2586df26bf72587f7.pdf
44GCcwJ5X2	2160	Representing Multi-view Time-series Graph Structures for Multivariate Long-term Time-series Forecasting	['time series forecasting', 'deep learning', 'representational learning']	An efficient, highly accurate, lightweight model for multivariate long-term time series forecasting.	Deep Learning and representational learning	anonymous|representing_multiview_timeseries_graph_structures_for_multivariate_longterm_timeseries_forecasting	/pdf/9fe59004fbf6b1e5c6842aa1773579b078150f60.pdf
9xlU4lhri9	2161	Rethinking the Structure of Stochastic Gradients: Empirical and Statistical Evidence	['Gradient Noise', 'SGD', 'Deep Learning']	We rethink the heavy-tail phenomenon and the covariance structure of stochastic gradients via novel empirical and statistical evidences.	Deep Learning and representational learning	anonymous|rethinking_the_structure_of_stochastic_gradients_empirical_and_statistical_evidence	/pdf/fd12fac7f41166feb9776eeecc0642290035f656.pdf
zgWbA-AecP	2162	Randomized Smoothing with Masked Inference for Adversarially Robust NLP Systems	['Natural language processing', 'textual adversarial example', 'adversarial attack', 'adversarial robustness']	We propose a new framework called randomized smoothing with masked inference (RSMI) for improving adversarial robustness of NLP systems.	Applications (eg, speech processing, computer vision, NLP)	anonymous|randomized_smoothing_with_masked_inference_for_adversarially_robust_nlp_systems	/pdf/be148a985c78b6907c14e4ae27c5bfe888e02261.pdf
E3ip6qBLF7	2164	Distributionally Robust Recourse Action	['Robust Optimization', 'Explainable AI', 'Algorithmic Recourse']	Distributionally Robust Recourse Action framework generates a recourse action that has high probability of being valid under a mixture of model shifts.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|distributionally_robust_recourse_action	/pdf/9b2885cdec63c880b573242e03c8a6d73ce324be.pdf
SXZr8aDKia	2165	Personalized Federated Learning with Feature Alignment and Classifier Collaboration	['Federated Learning', 'Personalization', 'Collaboration']		General Machine Learning (ie none of the above)	anonymous|personalized_federated_learning_with_feature_alignment_and_classifier_collaboration	/pdf/59597f9da833f62f9266e37e9b5ca0d1cdd078f5.pdf
qV3g530QHhg	2166	RegCLR: A Self-Supervised Framework for Tabular Representation Learning in the Wild	['self-supervised learning', 'representation learning', 'computer vision', 'table detection']	Regularized contrastive learning is effective in self-supervised tabular representation learning.	Unsupervised and Self-supervised learning	anonymous|regclr_a_selfsupervised_framework_for_tabular_representation_learning_in_the_wild	/pdf/0bfef204e699bb10efb1c9e1e1319e817a9caa98.pdf
pgU3k7QXuz0	2167	Spiking Convolutional Neural Networks for Text Classification	['Spiking neural networks', 'Text classification', 'Training method']	Spiking Convolutional Neural Networks for Text Classification	General Machine Learning (ie none of the above)	anonymous|spiking_convolutional_neural_networks_for_text_classification	/pdf/d64ef8e6f85c0c7397a69918354df1091d2a672b.pdf
SEfxlDwL7fR	2168	Temporally-Weighted Spike Encoding for Event-based Object Detection and Classification	['Event-based vision', 'spiking neural networks', 'object detection', 'classification']	Performing spiking neural network-based classification and object detection using a new spike encoding method for event-based vision sensors.	Applications (eg, speech processing, computer vision, NLP)	anonymous|temporallyweighted_spike_encoding_for_eventbased_object_detection_and_classification	/pdf/fe0b1d71c6cf92cb3d57c22247c2c2f7bc569a09.pdf
a_yFkJ4-uEK	2169	Data-efficient Supervised Learning is Powerful for Neural Combinatorial Optimization	['combinatorial optimization', 'data augmentation', 'neural combinatorial optimization', 'learning to optimize']		Applications (eg, speech processing, computer vision, NLP)	anonymous|dataefficient_supervised_learning_is_powerful_for_neural_combinatorial_optimization	/pdf/f278b899331ec246e9ffb0945c7bd07c5122b2d5.pdf
zNQ0IywxSuU	2171	REPRESENTATIVE PROTOTYPE WITH CONSTRASTIVE LEARNING FOR SEMI-SUPENVISED FEW-SHOT CLASSIFICATION	['SEMI-SUPENVISED FEW-SHOT CLASSIFICATION']		Deep Learning and representational learning	anonymous|representative_prototype_with_constrastive_learning_for_semisupenvised_fewshot_classification	/pdf/6f053619e6f2008990b7ec49f09fc1cac69c4b13.pdf
Hq16Jk2bVlp	2172	AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE	['Fully Homomorphic Encryption', 'Multi-Objective Co-Evolutionary Search', 'RNS-CKKS']	Automated adaption of CNNs to the RNS-CKKS FHE scheme by jointly evolving polynomial activations (EvoReLUs) and searching for placement of bootstrapping operations.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|autofhe_automated_adaption_of_cnns_for_efficient_evaluation_over_fhe	/pdf/efbf26a6beb733c1980bc584e3ab5c4f070c7635.pdf
oWjudQ3w2y	2173	EM-Network: Learning Better Latent Variable for Sequence-to-Sequence Models	['Connectionist temporal classification', 'Speech recognition', 'Machine translation']	We propose a new sequence model that can learn a promising latent variable by allowing the target sequence as the model's additional input. It significantly advances the current SOTA approaches in speech recognition and machine translation tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|emnetwork_learning_better_latent_variable_for_sequencetosequence_models	/pdf/531c23d050f96be1d625efa160c95fa28058a15a.pdf
ckIyo92KL6	2174	SpeedAug: A Simple Co-Augmentation Method for Unsupervised Audio-Visual Pre-training	[]		Unsupervised and Self-supervised learning	anonymous|speedaug_a_simple_coaugmentation_method_for_unsupervised_audiovisual_pretraining	/pdf/9ec0dc03e568b093839f1d02266329957ddab582.pdf
QVcDQJdFTG	2175	Ensuring DNN Solution Feasibility for Optimization Problems with Linear Constraints	['Deep learning', 'Deep neural network', 'Constrained optimization', 'Solution feasibility guarantee', 'Optimal power flow']	This paper proposes a preventive learning framework to ensure DNN solution feasibility for optimization problems with linear constraints without post-processing.	Deep Learning and representational learning	anonymous|ensuring_dnn_solution_feasibility_for_optimization_problems_with_linear_constraints	/pdf/7e7ecc6ab17f732d84f04dd996ddee9452db0093.pdf
1PL1NIMMrw	2176	Self-Consistency Improves Chain of Thought Reasoning in Language Models	['Language models', 'natural language processing', 'reasoning']	We propose a new decoding strategy, self-consistency, that greatly improves chain-of-thought prompting	Applications (eg, speech processing, computer vision, NLP)	anonymous|selfconsistency_improves_chain_of_thought_reasoning_in_language_models	/pdf/10539c5f6b1341f15073a8f9746450d5aa953368.pdf
OhUAblg27z	2177	Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting	['offline reinforcement learning', 'reinforcement learning', 'sampling', 'experience replay']	We propose a sample selection strategy that enables offline reinforcement learning algorithms to learn a better policy in mixed datasets with sparse high-return trajectories.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|harnessing_mixed_offline_reinforcement_learning_datasets_via_trajectory_weighting	/pdf/bdc370711dc42cbaff29fe0a3595c3841259b78b.pdf
AO8F51yRk67	2179	Covariance-Robust Minimax Probability Machines for Algorithmic Recourse	['Optimization and Learning under Uncertainty', 'Algorithmic Recourse', 'Trustworthy ML and Statistics']	We propose a novel pipeline to generate a model-agnostic recourse that is robust to model shifts.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|covariancerobust_minimax_probability_machines_for_algorithmic_recourse	/pdf/208c33079afaf81fdd4fcb0f7d72bf5594d5b877.pdf
XFSCKELP3bp	2180	Your Contrastive Learning Is Secretly Doing Stochastic Neighbor Embedding	['theoretical understanding', 'contrastive learning', 'stochastic neighbor embedding']	This work proposes a novel perspective that interprets SSCL methods as a type of SNE methods, which facilitates both deeper theoretical understandings of SSCL, and methodological guidelines for practical improvement.	Unsupervised and Self-supervised learning	anonymous|your_contrastive_learning_is_secretly_doing_stochastic_neighbor_embedding	/pdf/362abbcbc9aa0b62030b630d7fb0555226307d15.pdf
GUSf17i8RMZ	2181	CircuitNet: A Generic Neural Network to Realize Universal Circuit Motif Modeling	['Bio-inspired neural network', 'Deep Learning']	We proposed CircuitNet by modeling the universal circuit motifs and structures in human brains to function as a generic neural network and tested in several machine learning tasks.	Deep Learning and representational learning	anonymous|circuitnet_a_generic_neural_network_to_realize_universal_circuit_motif_modeling	/pdf/a682ee9e1a9541cce5351471dbe6ebed3b3d63de.pdf
vCVTZYFcmCm	2182	Domain-Specific Risk Minimization for Out-of-Distribution Generalization	['Out-of-Distribution Generalization', 'adaptivity gap', 'hypothesis space enhancement']	In this paper, we develop a new generalization bound that is independent of hypothesis space choice and measure the adaptivity gap directly. Two test-time adaptation methods are then proposed inspiried by the bound. 	Deep Learning and representational learning	anonymous|domainspecific_risk_minimization_for_outofdistribution_generalization	/pdf/94858ccfe6a9492571bc8cd55c0df32a461d24b7.pdf
K8oz8DyuJD	2185	Supernet Training for Federated Image Classification Under System Heterogeneity	['Federated Learning', 'Image Classification', 'Supernet Training', 'System Heterogeneity']	We propose a novel framework to tackle issues of data-heterogeneity and model-heterogeneity simultaneously by referring to supernet training.	Deep Learning and representational learning	anonymous|supernet_training_for_federated_image_classification_under_system_heterogeneity	/pdf/37cdfee32d359b8314be039b5aca6762639ae965.pdf
V9ppvImFso_	2186	SimForest:  An Efficient Plug-in to Boost Few-Shot Learning Performance	['few-shot learning', 'ensemble learning', 'deep learning', 'machine learning', 'image classification']	We develop an efficient (i.e:  computation-efficient, convenient, universally adaptable) ensemble method which can significantly boost the performance of varioius few-shot learning algorithms.	Deep Learning and representational learning	anonymous|simforest_an_efficient_plugin_to_boost_fewshot_learning_performance	/pdf/1d31d9e7c0ce5f14fa4bf592ecb26e295f76db35.pdf
VGI9dSmTgPF	2187	Schema Inference for Interpretable Image Classification	[]		Deep Learning and representational learning	anonymous|schema_inference_for_interpretable_image_classification	/pdf/bf421235296a821b60c810b99b74ace8ae5f7f6a.pdf
79xEHFvjx9p	2188	Feature-Driven Talking Face Generation with StyleGAN2	['Talking face', 'GAN', 'Feature Selection']	Audio and image features are extracted through Gan to generate talking face.	Generative models	anonymous|featuredriven_talking_face_generation_with_stylegan2	/pdf/d77b9ea719024ec5937bf18618e7247f33309615.pdf
TTMyoOdB9hZ	2189	Important Channel Tuning	[]		Deep Learning and representational learning	anonymous|important_channel_tuning	/pdf/9bf14b2e26e65c6f45cf2249ea7d066c7a3a0bae.pdf
vT2OIobt3pQ	2190	Few-Shot Learning with Representative Global Prototype	[]		Deep Learning and representational learning	anonymous|fewshot_learning_with_representative_global_prototype	/pdf/790243c03d2d6a017f853f4ce6fdf5aab515d1a1.pdf
C9sU3Tnnki8	2191	Exploring Transformer Backbones for Heterogeneous Treatment Effect Estimation	['Causal Inference', 'Continuous Treatment Effect', 'Heterogeneous Treatment Effect']	We propose a general-purpose treatment effect estimator which significantly outperforms competitive baselines on a variety of challenging TEE problems.	Deep Learning and representational learning	anonymous|exploring_transformer_backbones_for_heterogeneous_treatment_effect_estimation	/pdf/458e1428b8412ecf391d32586d9684c2cb713b46.pdf
yFuHxmSwGus	2192	AVT: Audio-Video Transformer for Multimodal Action Recognition	['Audio and video classification', 'multimodal action recognition']		Applications (eg, speech processing, computer vision, NLP)	anonymous|avt_audiovideo_transformer_for_multimodal_action_recognition	/pdf/cdf09d678b073e93d72b29c7efaacbf718010c7c.pdf
fGm87trHel_	2193	A Closer Look at the Calibration of Differentially Private Learners	['Calibration', 'Differential Privacy']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_closer_look_at_the_calibration_of_differentially_private_learners	/pdf/62f7fdd5cf967abce522fe4b041245144556b718.pdf
gUZWOE42l6Q	2194	Out-of-distribution Representation Learning for Time Series Classification	['Domain generalization', 'out-of-distribution generalization', 'time series classification']	We present a novel perspective on time series classification and present algorithms and theory to solve it, with solid experiments.	Deep Learning and representational learning	anonymous|outofdistribution_representation_learning_for_time_series_classification	/pdf/5e2f2d8be7d79d05004fd01a187cb86c0c8d8944.pdf
iP77_axu0h3	2195	3EF: Class-Incremental Learning via Efficient Energy-Based Expansion and Fusion	['EBMs', 'Compatibility', 'Continual Learning']	A unifying energy-based theory and framework called 3EF to analyze and achieve the goal of class-incremental learning. 	Deep Learning and representational learning	anonymous|3ef_classincremental_learning_via_efficient_energybased_expansion_and_fusion	/pdf/b99fd55b1597a2f4d9650184f412685a399892ae.pdf
x0BPR9iXc1	2196	Contrastive Alignment of Vision to Language Through Parameter-Efficient Transfer Learning 	['vision-language', 'CLIP', 'image-text retrieval', 'transformers']	Changing a small number (<7%) of parameters in already trained language and image models can match the performance of full model training for creating CLIP-like models. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|contrastive_alignment_of_vision_to_language_through_parameterefficient_transfer_learning	/pdf/893738ab8e7c58b556d731fd68c2f21e73fc8f36.pdf
OM7doLjQbOQ	2197	ILA-DA: Improving Transferability of Intermediate Level Attack with Data Augmentation	['adversarial examples', 'adversarial transferability', 'data augmentation']	We proposed ILA-DA, a method that employs 3 novel augmentation techniques to improve the transferability of adversarial attacks.	Deep Learning and representational learning	anonymous|ilada_improving_transferability_of_intermediate_level_attack_with_data_augmentation	/pdf/3b9cf6e6e0550a603b6b11c1ff3dd588db0bb88a.pdf
cIFtriyX6on	2198	GCINT: Dynamic Quantization Algorithm for Training Graph Convolution Neural Networks Using Only Integers	['Quantization', 'Graph Neural Networks', 'Acceleration Training', 'Integers Networks']	Robust and Adaptive Quantization Algorithm for Training Graph Convolution Neural Networks Using Only Integers	Deep Learning and representational learning	anonymous|gcint_dynamic_quantization_algorithm_for_training_graph_convolution_neural_networks_using_only_integers	/pdf/ed95c4bcd6adab13afbd8b1e4a103183ce45bb04.pdf
Iki4ufHeEGN	2199	Hybrid and Collaborative Passage Reranking	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|hybrid_and_collaborative_passage_reranking	/pdf/6842c53da57aebe72505c6d5b1cf35c58641f2eb.pdf
JX1OCjfABRj	2200	Self-Adaptive Perturbation Radii for Adversarial Training	[]		General Machine Learning (ie none of the above)	anonymous|selfadaptive_perturbation_radii_for_adversarial_training	/pdf/dcb8e10f7e89ad1aa788b86b1e7a7d0cc204589c.pdf
frwz3TheDeH	2201	AIA: learn to design greedy algorithm for NP-complete problems using neural networks	[]		Optimization (eg, convex and non-convex optimization)	anonymous|aia_learn_to_design_greedy_algorithm_for_npcomplete_problems_using_neural_networks	/pdf/f47b6b5e2c9fe50a676c3321fbc9429c91f835c1.pdf
QwKvL6wC8Yi	2202	Coverage-centric Coreset Selection for High Pruning Rates	['Coreset', 'Data coverage', 'Data pruning']	We study the importance of data coverage in coreset selection and propose a coverage-centric method for coreset selection, which we show achieves significantly better accuracy than SOTA methods with high pruning rates.	General Machine Learning (ie none of the above)	anonymous|coveragecentric_coreset_selection_for_high_pruning_rates	/pdf/7d7e0831c4c92add7300fbedfcbc1dbcc37949af.pdf
1UbNwQC89a	2203	RGI: robust GAN-inversion for mask-free image inpainting and unsupervised pixel-wise anomaly detection	['Robust GAN-inversion', 'Mask-free Semantic Inpainting', 'Unsupervised Pixel-wise Anomaly Detection']		Unsupervised and Self-supervised learning	anonymous|rgi_robust_ganinversion_for_maskfree_image_inpainting_and_unsupervised_pixelwise_anomaly_detection	/pdf/998b6eaa711371f36c752551ef57c7643acce638.pdf
BsxMeLGAmU	2204	Likelihood adjusted semidefinite programs for clustering heterogeneous data	['clustering', 'likelihood inference', 'semidefinite programming', 'alternating maximization']	We propose an iterative likelihood adjusted SDP for clustering under data heterogeneity.	Unsupervised and Self-supervised learning	anonymous|likelihood_adjusted_semidefinite_programs_for_clustering_heterogeneous_data	/pdf/7f45df3f561fdcca60c43ab0c5f675d0bf8199c6.pdf
QHiuyzE69Bx	2205	Grounding High Dimensional Representation Similarity by Comparing Decodability and Network Performance	['ablation', 'representation', 'semantic decoding', 'linear decoding', 'representation similarity', 'neural network interpretability', 'activation space']	We evaluate representation similarity measures for sensitivity to decoding and network function using ablation on convolutional neural networks.	Deep Learning and representational learning	anonymous|grounding_high_dimensional_representation_similarity_by_comparing_decodability_and_network_performance	/pdf/93f888a6b79196c0382c8aede991ce175289be65.pdf
VN6MxIRez-c	2206	Partition Matters in Learning and Learning-to-Learn Implicit Neural Representations	['implicit neural representations', 'partition', 'meta-learning']	We use partition techniques to speed up the convergence of learning INRs and learning-to-learn INRs.	Deep Learning and representational learning	anonymous|partition_matters_in_learning_and_learningtolearn_implicit_neural_representations	/pdf/96945116d8cac20100da8ec70236ceef6889292e.pdf
aqP3WFwMPbe	2207	Multiscale Multimodal Transformer for Multimodal Action Recognition	['audio and video classification', 'multimodal action recognition']		Applications (eg, speech processing, computer vision, NLP)	anonymous|multiscale_multimodal_transformer_for_multimodal_action_recognition	/pdf/3f1853753df24e17a192ca1aeca1da9832686180.pdf
bBpT6dEjeRG	2208	Adversarial Attacks on Adversarial Bandits	['adversarial attacks', 'adversarial bandits', 'target action', 'sublinear cumulative attack cost']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|adversarial_attacks_on_adversarial_bandits	/pdf/ee58970ccce36d8c984ac542387f3ca0b314d699.pdf
9X-hgLDLYkQ	2209	Hierarchical Protein Representations via Complete 3D Graph Networks	[]		Deep Learning and representational learning	anonymous|hierarchical_protein_representations_via_complete_3d_graph_networks	/pdf/0f361a34bd2a300dbc16e232982b79c4ce25f224.pdf
-59_mb1lOf4	2210	Communication-Efficient and Drift-Robust Federated Learning via Elastic Net	['Federated learning', 'Data heterogeneity', 'Optimization']		General Machine Learning (ie none of the above)	anonymous|communicationefficient_and_driftrobust_federated_learning_via_elastic_net	/pdf/9613756cf1120673911f4df570303c2be4809c3b.pdf
NO0ThzteQdI	2211	NERDS: A General Framework to Train Camera Denoisers from Single Noisy Images	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|nerds_a_general_framework_to_train_camera_denoisers_from_single_noisy_images	/pdf/631707c1703852849efffb01ce5bc6cbf73d800c.pdf
nUsP9lFADUF	2212	Prototypical Calibration for Few-shot Learning of Language Models	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|prototypical_calibration_for_fewshot_learning_of_language_models	/pdf/15379f5b0dd9b369ceb58ec14e4396b974a6526b.pdf
u89Eq-_3oE4	2213	AutoShot: A Short Video Dataset and State-of-the-Art Shot Boundary Detection	['Shot boundary detection', 'short video', 'dataset']		Applications (eg, speech processing, computer vision, NLP)	anonymous|autoshot_a_short_video_dataset_and_stateoftheart_shot_boundary_detection	/pdf/ea938b1107c8907999b376163ed3ece0a5ec283d.pdf
rUxKM6u8WER	2214	Test-time Adaptation for Better Adversarial Robustness	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|testtime_adaptation_for_better_adversarial_robustness	/pdf/0f12ae5da1f549aa058809ba236403ac98a072d9.pdf
CUOaVn6mYEj	2215	Hierarchical Sliced Wasserstein Distance	['Sliced Wasserstein', 'Radon Transform', 'Optimal Transport', 'Generative Models']	The paper proposes hierarchical sliced Wasserstein distance which is faster than the conventional sliced Wasserstein distance.	General Machine Learning (ie none of the above)	anonymous|hierarchical_sliced_wasserstein_distance	/pdf/93162a7788eb2c4b7cf905c217a98d14da5be1aa.pdf
jh1nCir1R3d	2216	SWIFT: Rapid Decentralized Federated Learning via Wait-Free Model Communication	['Federated Learning', 'Asynchronous', 'Decentralized', 'Wait-Free']	We propose a wait-free decentralized Federated Learning algorithm which achieves SOTA results while massively reducing communications costs.	Optimization (eg, convex and non-convex optimization)	anonymous|swift_rapid_decentralized_federated_learning_via_waitfree_model_communication	/pdf/1aa793ebb08b0aae86182b6e83a03fd1789043c0.pdf
LTvSyvRaJO	2217	Improving Vision Attention with Random Walk Graph Kernel	['vision transformer', 'long sequence modeling']	We approach a novel linear attention mechanism based on random walk graph kernel, can be widely used in vision transformer with long sequence inputs	Applications (eg, speech processing, computer vision, NLP)	anonymous|improving_vision_attention_with_random_walk_graph_kernel	/pdf/f9baa5114493a9566e4be2c3317a6a9e2453ab4c.pdf
ZPtEyovpo6	2218	Class Prototype-based Cleaner for Label Noise Learning	['Label Noise Learning']		Deep Learning and representational learning	anonymous|class_prototypebased_cleaner_for_label_noise_learning	/pdf/d2fdf0d10adb18449a3bf6260c7fb8f28098f383.pdf
pBaSwBkHBE	2220	EMP: Effective Multidimensional Persistence for Graph Representation Learning	['multiparameter persistence', 'topological data analysis', 'machine learning']		General Machine Learning (ie none of the above)	anonymous|emp_effective_multidimensional_persistence_for_graph_representation_learning	/pdf/bc08045c1528d32a64ea703c39ba937cb377904c.pdf
zt53IDUR1U	2222	MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting	['long-term forecasting', 'local and global context', 'multi-branch architecture', 'different potential patterns.']	New modeling perspective, new forecasting framework, linear complexity and best performance.	Deep Learning and representational learning	anonymous|micn_multiscale_local_and_global_context_modeling_for_longterm_series_forecasting	/pdf/eb33a007640f5c52b25ab27e159d37c3f84f6705.pdf
lV0fWRDJwR	2223	Adversarially Robust Neural Lyapunov Control	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adversarially_robust_neural_lyapunov_control	/pdf/1d69a358c61f60c745785ccb135c68f386cab985.pdf
51GXyzOKOp	2225	Characterizing the Influence of Graph Elements	['Interpretable Machine Learning', 'Influence functions', 'Graph Neural Networks']	Use influence functions to model the influence of elements in graphs, and understand the model behavior of graph convolution networks. 	General Machine Learning (ie none of the above)	anonymous|characterizing_the_influence_of_graph_elements	/pdf/4be390ba96c45f524bb5eab576c4afefaa17d847.pdf
lbzA07xjED	2226	Analysis of Error Feedback in Compressed Federated Non-Convex Optimization	[]		Optimization (eg, convex and non-convex optimization)	anonymous|analysis_of_error_feedback_in_compressed_federated_nonconvex_optimization	/pdf/b31675f38d5c168a7326d6d3f0185cc4be5b38ab.pdf
TkSRbrUjQf3	2227	k-Median Clustering via Metric Embedding: Towards Better Initialization with Differential Privacy	['k-Median Clustering', 'Differential Privacy']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|kmedian_clustering_via_metric_embedding_towards_better_initialization_with_differential_privacy	/pdf/420205fd85333d3db4549b8bc4d86de5ef9f370b.pdf
o3yygm3lnzS	2228	PV3D: A 3D Generative Model for Portrait Video Generation	[]		Generative models	anonymous|pv3d_a_3d_generative_model_for_portrait_video_generation	/pdf/67fb5bcbc0ef86e9caf28e853cf0b09bd715edc4.pdf
1ndyt02WPo	2229	Better handling unlabeled entity problem using PU-learning and negative sampling	['NER', 'unlabeled entity problem', 'PU-learning', 'negative sampling', 'self-supervision']		Deep Learning and representational learning	anonymous|better_handling_unlabeled_entity_problem_using_pulearning_and_negative_sampling	/pdf/83ec36b12d76349b57a4436d57fa7751a44e3187.pdf
_2bDpAtr7PI	2230	Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction	['equivariance', 'sample efficiency', 'pose detection', 'symmetry', 'SO(3)']	We propose a novel architecture which efficiently describes uncertainty in pose estimation from images by using learned SO(3)-equivariant features to generate complex distributions over SO(3) with the Fourier basis.	Deep Learning and representational learning	anonymous|image_to_sphere_learning_equivariant_features_for_efficient_pose_prediction	/pdf/733d64a62945e78f3f698caf72f63e3bbb82056b.pdf
v8Mi8KU6056	2231	Wav2Tok: Deep Sequence Tokenizer for Audio Retrieval	['sequence representation learning', 'audio search', 'music retrieval']	Represent query and target sequences as compressed token sequences for quick retrieval; similarity semantics are learned from sequence pairs	Unsupervised and Self-supervised learning	anonymous|wav2tok_deep_sequence_tokenizer_for_audio_retrieval	/pdf/6e0a4fa1c1fd7e1af6aaf62c86b76c8f784ab46d.pdf
N5fNFLO_MyD	2232	N-Student Learning: An Approach to Model Uncertainty and Combat Overfitting	['Noisy Labels', 'Pseudo-Labels', 'Overfitting', 'Supervised Learning']	A pseudo-label based multi-network training setup to help combat the problem of overfitting.	Deep Learning and representational learning	anonymous|nstudent_learning_an_approach_to_model_uncertainty_and_combat_overfitting	/pdf/dda5a2906920f9b23fa0771810338e894628d79c.pdf
tZmqS73_07	2234	3D Molecular Generation by Virtual Dynamics	['3D molecular generation', 'structure-based drug design']	We propose a novel pocket-based 3D molecular generation framework VD-Gen, which consists of a Virtual Dynamics mechanism and several carefully designed stages to generate fine-grained molecules with binding positions in the pocket cavity end-to-end.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|3d_molecular_generation_by_virtual_dynamics	/pdf/cdd95b032cdf2577c5b6064d83de3910789a27ff.pdf
uwBUzlm0GS	2237	LAU: A novel two-parameter learnable Logmoid Activation Unit	['Neural network', 'Learnable activation function', 'Function approximation', 'Dilated convolution']	A learnable Activation Unit	Deep Learning and representational learning	anonymous|lau_a_novel_twoparameter_learnable_logmoid_activation_unit	/pdf/ea156ad987309caf5a2f447def452f87a6ab5834.pdf
OxNQXyZK-K8	2238	Breaking the Curse of Dimensionality in Multiagent State Space: A Unified Agent Permutation Framework	['Multiagent Reinforcement Learning', 'Permutation Invariance', 'Permutation Equivariance']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|breaking_the_curse_of_dimensionality_in_multiagent_state_space_a_unified_agent_permutation_framework	/pdf/ab1361254d16f2a704374b1b8d24674db6fa4022.pdf
UiaUEICawgw	2240	Learned Index with Dynamic $\epsilon$	['Learned Index', 'Dynamic $\\epsilon$']	Based on the theoretically derived prediction error bounds, we propose a mathematically-grounded learned index framework with dynamic $\epsilon$, which is efficient and pluggable to several state-of-the-art learned index methods.	General Machine Learning (ie none of the above)	anonymous|learned_index_with_dynamic_\epsilon	/pdf/05e9488e36731e84ab8bdde341ce7e0a2a241c2a.pdf
FwlV6h4KxVE	2241	Test-Time Adaptation for Visual Document Understanding	['Test-time adaptation', 'source data-free domain adaptation', 'visual document understanding']	Proposing a novel test-time adaptation approach and three benchmarks for visual document understanding via masked language modeling and pseudo labeling.	Deep Learning and representational learning	anonymous|testtime_adaptation_for_visual_document_understanding	/pdf/b9d4f3449ec8ddda18957ed628e941773b70c5c5.pdf
idY99Ugd5ek	2242	Sparsity by Redundancy: Solving $L_1$ with a Simple Reparametrization	['L1', 'sparsity', 'feature selection', 'deep learning', 'landscape']	We propose a simple method for solving general L1 penalized objectives with gradient descent	Deep Learning and representational learning	anonymous|sparsity_by_redundancy_solving_l_1_with_a_simple_reparametrization	/pdf/f4a85dd50201c6c3c65a7a093bb078d2b0fbd400.pdf
8U4joMeLRF	2244	Empirical Study of Pre-training a Backbone for 3D Human Pose and Shape Estimation	['pre-training', '3D human pose and shape estimation', 'self-supervised representation learning']	Empirical Study of Pre-training a Backbone for 3D Human Pose and Shape Estimation	Applications (eg, speech processing, computer vision, NLP)	anonymous|empirical_study_of_pretraining_a_backbone_for_3d_human_pose_and_shape_estimation	/pdf/4855217726d90d9cc9098e1e32b2ae00e43bef3a.pdf
P8DHF1Y_dph	2245	Learning to Generate All Feasible Actions	['Generative neural networks', 'feasible actions', 'f-divergence']	We propose to train a generative neural network to generate all feasible actions within an interactive environment.	General Machine Learning (ie none of the above)	anonymous|learning_to_generate_all_feasible_actions	/pdf/7988bf9227075e7de4b72a6a85c2197026086ddf.pdf
XGHRFuJ_ue-	2246	Towards Boosting the Open-Domain Chatbot with Human Feedback	['Dialogue System', 'Human Feedback']	A novel and efficient approach Diamante is proposed to boost the open-domain chatbot, where two kinds of human feedback (including explicit demonstration and implicit preference) are collected and leveraged.	Applications (eg, speech processing, computer vision, NLP)	anonymous|towards_boosting_the_opendomain_chatbot_with_human_feedback	/pdf/0f1f65ccc30813dd1ba8e0a7ba8c9c37f925bca3.pdf
yvF7mAuWv3z	2247	Scalable 3D Object-centric Learning	[]		Deep Learning and representational learning	anonymous|scalable_3d_objectcentric_learning	/pdf/79ad6e054d44102ab30b42d5d9dc3f2aee8d2d17.pdf
w_Pz9Z3DOB6	2248	From Coarse to Fine-grained Concept based Discrimination for Phrase Detection	['Phrase Detection', 'Vision Language Understanding']		Applications (eg, speech processing, computer vision, NLP)	anonymous|from_coarse_to_finegrained_concept_based_discrimination_for_phrase_detection	/pdf/6b5db47244488bb1b7ebf352437f49df56d3a56f.pdf
9sPDt0z3oL4	2249	Finite-time Analysis of Single-timescale Actor-Critic on Linear Quadratic Regulator	['single-timescale actor-critic', 'linear quadratic regulator']	Finite-time convergence of single-sample single-timescale actor-critic with a global optimality guarantee	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|finitetime_analysis_of_singletimescale_actorcritic_on_linear_quadratic_regulator	/pdf/1f168bf773946b6126bb96b52479f7ba3a40d287.pdf
QzbKH8nNq_V	2250	MaskFusion: Feature Augmentation for Click-Through Rate Prediction via Input-adaptive Mask Fusion	['Input-adaptive', 'Mask Fusion', 'Feature Augmentation', 'Click-Through rate prediction']	Feature Augmentation via Adaptive Mask Fusion	Applications (eg, speech processing, computer vision, NLP)	anonymous|maskfusion_feature_augmentation_for_clickthrough_rate_prediction_via_inputadaptive_mask_fusion	/pdf/cdd2e60a9402f125eb2e67155fd511dee22870a6.pdf
aKK-Dhm3O4	2251	Bias Mimicking: A Simple Sampling Approach for Bias Mitigation	['Fairness', 'Spurious Correlations', 'Bias', 'Sampling Methods.']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|bias_mimicking_a_simple_sampling_approach_for_bias_mitigation	/pdf/780ba9875ce5f4a9c8bf81c0eaddd9c178a669df.pdf
inU2quhGdNU	2253	Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap	[]		Deep Learning and representational learning	anonymous|generalizing_and_decoupling_neural_collapse_via_hyperspherical_uniformity_gap	/pdf/eb9024f6bbe114a7f5ca79a4b595de5d1e1f6716.pdf
O0sS_cujvV0	2256	Smoothed-SGDmax: A Stability-Inspired Algorithm to Improve Adversarial Generalization	['Adversarial Training', 'Robust Overfitting', 'Generalization Bound']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|smoothedsgdmax_a_stabilityinspired_algorithm_to_improve_adversarial_generalization	/pdf/ef0ffc62cb4d511b827a5aa6c11898f6c89b3579.pdf
TtMJJWG_J1j	2257	TensorVAE: A Direct Generative Model for Molecular Conformation Generation driven by Novel Feature Engineering	['generative model', 'feature engineering', 'molecular conformation generation']		Generative models	anonymous|tensorvae_a_direct_generative_model_for_molecular_conformation_generation_driven_by_novel_feature_engineering	/pdf/aa990f9e18b8090e39496ee464b5e4c61891ea8c.pdf
b0UksKFcTOL	2259	Latent State Marginalization as a Low-cost Approach to Improving Exploration	['MaxEnt RL', 'latent variable modeling', 'world models']	We show how to efficiently marginalize latent variable policies for MaxEnt RL to enable better exploration and more robust training at very minimal additional cost.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|latent_state_marginalization_as_a_lowcost_approach_to_improving_exploration	/pdf/cfa75f14de97ef43312b28b31f2bba0aad21cb56.pdf
7d-g8KozkiE	2260	Cycle to Clique (Cy2C) Graph Neural Network: A Sight to See beyond Neighborhood Aggregation	[]		Deep Learning and representational learning	anonymous|cycle_to_clique_cy2c_graph_neural_network_a_sight_to_see_beyond_neighborhood_aggregation	/pdf/fb74f06662c35642ab99f880276635675dbb4780.pdf
lj1Eb1OPeNw	2261	Maximizing Spatio-Temporal Entropy of Deep 3D CNNs for Efficient Video Recognition	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|maximizing_spatiotemporal_entropy_of_deep_3d_cnns_for_efficient_video_recognition	/pdf/5347750305c11a4a9aeb046a1b013f020a43e5b7.pdf
DWDPhB6Hi7k	2262	A Representation Bottleneck of Bayesian Neural Networks	['interpretability', 'Bayesian neural network']	We theoretically prove and empirically verify a representation bottleneck of Bayesian neural networks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_representation_bottleneck_of_bayesian_neural_networks	/pdf/6c074e2056aa377fbeead1a26a7b2666c51d60ee.pdf
40RNVzSoCqD	2263	FedDM: Iterative Distribution Matching for Communication-Efficient Federated Learning	['data distillation', 'federated learning']		General Machine Learning (ie none of the above)	anonymous|feddm_iterative_distribution_matching_for_communicationefficient_federated_learning	/pdf/944c71fd905011f78d5fc397f750230aa14e3113.pdf
dqITIpZ5Z4b	2264	A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning	['general function approximation', 'sample-efficient RL', 'optimization-based exploration', 'Eluder dimension', 'Bellman rank', 'witness rank', 'complexity measure', 'hypothesis class']	We provide a unified framework that nearly includes all model-free and model-based RL classes while maintaining sharp sample efficiency.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_general_framework_for_sampleefficient_function_approximation_in_reinforcement_learning	/pdf/3d6c19747d1db6a25d17a23fc494362a8c635ab5.pdf
xQAjSr64PTc	2265	EUCLID: Towards Efficient Unsupervised Reinforcement Learning with Multi-choice Dynamics Model	['Reinforcement Learning', 'Unsupervised RL', 'Model-based RL']	We propose a novel model-fused paradigm for Unsupervised Reinforcement Learning to jointly pre-train the dynamics model and unsupervised exploration policy in the pre-training phase, thus improving the downstream task sampling efficiency.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|euclid_towards_efficient_unsupervised_reinforcement_learning_with_multichoice_dynamics_model	/pdf/fdb97d003c14ceb2a9d6e0df913a14f67a596b2b.pdf
ItUvrU0dQpC	2266	Theoretical generalization bounds for improving the efficiency of deep online training	['online training', 'generalization risk', 'noisy label']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|theoretical_generalization_bounds_for_improving_the_efficiency_of_deep_online_training	/pdf/d3f40af70cb2fe2e203ef56d029f205f808d9194.pdf
zH9GcZ3ZGXu	2267	Learning an Invertible Output Mapping Can Mitigate Simplicity Bias in Neural Networks	['Simplicity Bias', 'Out-of-distribution robustness', 'OOD Generalization', 'Deep Learning']	We propose a regularizer that enforces the reconstruction of features from the output logits of neural networks, in order to overcome Simplicity Bias and boost their OOD generalization.	Deep Learning and representational learning	anonymous|learning_an_invertible_output_mapping_can_mitigate_simplicity_bias_in_neural_networks	/pdf/ee7eef961d616b74507fc5ffe1421e0a1fe5c3b6.pdf
xeg2fW5E2l3	2268	Set-Level Self-Supervised Learning from Noisily-Labeled Data	['Self-supervised learning', 'Noisy label learning', 'Meta-learning', 'EM algorithm']	This paper proposes a set-level self-supervised learning techniques on each training mini-batch to tackle noisy-label learning problems.	Deep Learning and representational learning	anonymous|setlevel_selfsupervised_learning_from_noisilylabeled_data	/pdf/2dc0d07292f9ec6fc0c4cb9691632a5055bfab3d.pdf
_-FN9mJsgg	2269	Unsupervised Object-Centric Learning with Bi-level Optimized Query Slot Attention	['unsupervised object-centric learning']	With simple adjustments to slot attention, we propose a model that significantly outperforms previous baselines (~10%) on both synthetic and real images, and shows potential in concept binding and generalization.	Unsupervised and Self-supervised learning	anonymous|unsupervised_objectcentric_learning_with_bilevel_optimized_query_slot_attention	/pdf/02c9bbbf6e08edf71f39eb34581ca29b04a88ea9.pdf
1FVv8PS8LYW	2270	Dr-Fairness: Dynamic Data Ratio Adjustment for Fair Training on Real and Generated Data	['trustworthy AI', 'fairness', 'visual recognition', 'generated data']	We propose a novel sampling approach called Dr-Fairness that adaptively adjusts data ratios among groups and between real and generated data, which improves group fairness while minimizing accuracy degradation.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|drfairness_dynamic_data_ratio_adjustment_for_fair_training_on_real_and_generated_data	/pdf/382ef60a997250bef4f3e3517c1ceec0bdfaafad.pdf
hlsu-HrU7ON	2271	Intrinsic Motivation via Surprise Memory	['reinforcement learning', 'intrinsic motivation', 'exploration', 'memory']	Intrinsic motivation emerges through measuring surprise novelty as retrieval errors of a memory network	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|intrinsic_motivation_via_surprise_memory	/pdf/b133ae7e3c571e3c12322ebbefd6fc101ae8739c.pdf
NxnYzayR2CW	2272	Personalized Semantics Excitation for Federated Image Classification	[]		Deep Learning and representational learning	anonymous|personalized_semantics_excitation_for_federated_image_classification	/pdf/f7585f76d2ca3148fdbdfc7eaf2cfa064409f2d3.pdf
xxhl7l64Nsz	2273	Uncertainty Guided Depth Fusion for Spike Camera	['Spike camera', 'Uncertainty', 'Depth estimation', 'Fusion Strategies']	We propose a novel uncertainty-guided fusion framework for spike depth estimation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|uncertainty_guided_depth_fusion_for_spike_camera	/pdf/f725f9c19eac124cc849f615bdcbc0bf94b1b6ec.pdf
CtR4H2enl90	2274	SpeechLM: Enhanced Speech Pre-Training with Unpaired Textual Data	['Speech pre-training', 'Speech-text joint modeling', 'Unified tokenizer']	This is the first work to explicitly use phoneme/hidden units as the the shared space of speech and text modalities for pre-training.	Applications (eg, speech processing, computer vision, NLP)	anonymous|speechlm_enhanced_speech_pretraining_with_unpaired_textual_data	/pdf/bb249755770ddf5b0453f93a9b0d6280ddee5184.pdf
BeI1fdNH_X	2276	Improving Explanation Reliability through Group Attribution	['Explainable AI', 'Attribution methods', 'Group attribution', 'Attribution reliability']	We have proposed the group-wise attribution methods to yield more reliable explanation in understanding a model's prediction	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|improving_explanation_reliability_through_group_attribution	/pdf/8d76ba9ff81f48097a9005dfb0c8607bad3c54b6.pdf
JXkz3zm8gJ	2277	Learning to Learn with Generative Models of Neural Network Checkpoints	['diffusion', 'DDPMs', 'learning to learn', 'generative models', 'transformers']	We construct a dataset of neural network checkpoints and train a loss-conditional generative model on the parameters. The generative model can train neural networks with unseen initializations in one step.	Generative models	anonymous|learning_to_learn_with_generative_models_of_neural_network_checkpoints	/pdf/6b90210a29c13b993cb0b7e549bf6e7d2f9e8f56.pdf
9irBKvxsw9	2278	Deep Learning-based Source Code Complexity Prediction	['computational complexity', 'code classification', 'programming language', 'data augmentation', 'code understanding']	We suggest a deep-learning based approach for estimating computational (time) complexity of given programs and provide the largest code complexity dataset as the benchmark.	Applications (eg, speech processing, computer vision, NLP)	anonymous|deep_learningbased_source_code_complexity_prediction	/pdf/52ebd01d405a3c333922ba81f00a56ca93b7fdab.pdf
ltWade-cpK	2279	Optimal Activation Functions for the Random Features Regression Model	['Random Features Regression Model', 'Learning theory for neural networks', 'Functional analysis and variational calculus']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|optimal_activation_functions_for_the_random_features_regression_model	/pdf/f72b3958d877e632bfc136506487d096c9ab3894.pdf
FOeVcSmRAeQ	2280	CUSTOMIZING PRE-TRAINED DIFFUSION MODELS FOR YOUR OWN DATA	['Diffusion models', 'score-based models', 'generative models', 'personalization']	We propose a method to utilize the pre-trained text-to-image diffusion models to generate a custom dataset.	Generative models	anonymous|customizing_pretrained_diffusion_models_for_your_own_data	/pdf/f894d07c16eb1bcab589e3cd8220829d62609eea.pdf
0tiMn18oNd	2281	Group-Equivariant Transformers Without Positional Encoding	['equivariant', 'invariant', 'group-equivariant', 'self-attention', 'transformer', 'group-equivariant convolution', 'group-equivariant self-attention']	We propose an effective group-equivariant transformer without positional encoding, replacing point-wise MLPs with group-equivariant convolutions to act as both a group mixer and an implicit positional encoding.	Deep Learning and representational learning	anonymous|groupequivariant_transformers_without_positional_encoding	/pdf/6c823a45900ce97a71509e7395f1ca440c4eabaa.pdf
5s2v_0F7MG	2282	OrthoReg: Improving Graph-regularized MLPs via Orthogonality Regularization	[]		Deep Learning and representational learning	anonymous|orthoreg_improving_graphregularized_mlps_via_orthogonality_regularization	/pdf/4ef5d6b78977cb940e3f8d6722ad34113ee2c80a.pdf
dSYkYNNZkV	2283	Localized Graph Contrastive Learning	[]		Deep Learning and representational learning	anonymous|localized_graph_contrastive_learning	/pdf/a3f37f5357e14eb092bf38e7216708457b7c3ff1.pdf
sbS10BCtc7	2284	Gromov-Wasserstein Autoencoders	['representation learning', 'deep generative models', 'variational autoencoders', 'optimal transport', 'implicit distributions', 'meta-prior', 'disentanglement', 'clustering']	GWAEs, our novel generative models, learn representations based on meta-priors by directly fitting their latent space into the data space.	Deep Learning and representational learning	anonymous|gromovwasserstein_autoencoders	/pdf/73851e1dfd2d57401fcea7b26ca3abdbe87ebf5f.pdf
amyZRbMrUA	2285	Joint Gaussian Mixture Model for Versatile Deep Visual Model Explanation	['Explainable AI', 'interpretable model', 'pixel attributing', 'convolutional neural networks']	This paper proposes a GMM-based probablistic model to explain DCNN representations and inference by proxy models and explanatory examples.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|joint_gaussian_mixture_model_for_versatile_deep_visual_model_explanation	/pdf/5637c65a26d05da3c3c3067c7dcdf41fce671d3a.pdf
xWFguIF_hG	2286	In Search of Smooth Minima for Purifying Backdoor in Deep Neural Networks	['AI Security', 'Backdoor or Trojan Attacks on Deep Networks', 'Safe and Robust AI']		Deep Learning and representational learning	anonymous|in_search_of_smooth_minima_for_purifying_backdoor_in_deep_neural_networks	/pdf/6aeba990757a77d2882eb6de38118256f6415c98.pdf
lc8asG5NwF	2287	Estimating Riemannian Metric with Noise-Contaminated Intrinsic Distance	[]		Unsupervised and Self-supervised learning	anonymous|estimating_riemannian_metric_with_noisecontaminated_intrinsic_distance	/pdf/71be694e49cb7486cf57d5c714786d6a6068813d.pdf
gsU2MKneFy	2289	Efficient Method for Bi-level Optimization with Non-smooth Lower-Level Problem	['bilevel optimization', 'nonsmooth']	We propose a method solving the nonsmooth bilevel problem and give a new analysis	Optimization (eg, convex and non-convex optimization)	anonymous|efficient_method_for_bilevel_optimization_with_nonsmooth_lowerlevel_problem	/pdf/cc38ab47484344eb21efd919909e848a0b1c90f1.pdf
xZD10GhCvM	2290	Toward Adversarial Training on Contextualized Language Representation	['pre-trained language model', 'adversarial training']	Adversarial training optimized to deviate contextualized language representation with all-powerful performance gain	Applications (eg, speech processing, computer vision, NLP)	anonymous|toward_adversarial_training_on_contextualized_language_representation	/pdf/00492a819f772c3c79781326ef543123ce68280a.pdf
pYC3W83uwm	2292	Understanding Curriculum Learning in Policy Optimization for Online Combinatorial Optimization	['reinforcement learning theory', 'curriculum learning']	We initiate the study on using reinforcement learning for solving combinatorial optimization problems, focusing on the curriculum learning technique.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|understanding_curriculum_learning_in_policy_optimization_for_online_combinatorial_optimization	/pdf/060abf3cac8b7ab73f8455c65adb34755689d22e.pdf
kJWcI39kXY	2293	ODAM: Gradient-based Instance-Specific Visual Explanations for Object Detection	['instance-specific visual explanation', 'object detection']	ODAM: a gradient-based instance-specific explanation technique for object detectors; ODAM-Train: improve the explanation ability on object discrimination; ODAM-NMS: distinguish the duplicate detected objects with the help of ODAM.	Deep Learning and representational learning	anonymous|odam_gradientbased_instancespecific_visual_explanations_for_object_detection	/pdf/39f805e1fffec919f133fbb1d8488f3c1b3b0bc2.pdf
4gUIeq2lyM	2295	Visual Reinforcement Learning with Self-Supervised 3D Representations	['Reinforcement Learning', '3D Representation Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|visual_reinforcement_learning_with_selfsupervised_3d_representations	/pdf/efc5fa412cbf265075733964c0c95fded003358f.pdf
DWn1TEb2fK	2296	Treeformer: Dense Gradient Trees for Efficient Attention Computation	['Transformers', 'Attention', 'Decision Trees']	Efficient Decision Tree based attention computation to reduce FLOPs for self-attention	Deep Learning and representational learning	anonymous|treeformer_dense_gradient_trees_for_efficient_attention_computation	/pdf/0f9c5bbdf88084e7ae8cacd49db382187bfdb8fa.pdf
G1H4NSATlr	2297	RoPAWS: Robust Semi-supervised Representation Learning from Uncurated Data	['semi-supervised learning', 'representation learning', 'uncurated data']	We propose a robust semi-supervised learning method for uncurated data derived from a novel probabilistic view of learned representations	Deep Learning and representational learning	anonymous|ropaws_robust_semisupervised_representation_learning_from_uncurated_data	/pdf/c7c3a6e6fd158826e3f0f26e7d1c181a2874f542.pdf
PXRN-uxHoIE	2298	Learning Invariant Features for Online Continual Learning	['continual learning', 'online continual learning']		Deep Learning and representational learning	anonymous|learning_invariant_features_for_online_continual_learning	/pdf/4d259848cd9513c42c706da6c7d4f5d2805caa6f.pdf
g9VAye0eIKO	2299	Horizon-Free Reinforcement Learning for Latent Markov Decision Processes	['reinforcement learning theory', 'markov decision process', 'latent markov decision process']	We studied RL for Latent MDPs under the episodic, context in hindsight setting. A SOTA upperbound and the first lowerbound were presented.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|horizonfree_reinforcement_learning_for_latent_markov_decision_processes	/pdf/8d5308c72b408706270c256e07e7021429d68897.pdf
P44WPn1_aJV	2300	LMSeg: Language-guided Multi-dataset Segmentation	['Segmentation', 'Multi-dataset', 'Vision-language']		Applications (eg, speech processing, computer vision, NLP)	anonymous|lmseg_languageguided_multidataset_segmentation	/pdf/b6f1591e7cf897a269d189a5098c50bb9f4d3a84.pdf
5m_3whfo483	2301	ETSformer: Exponential Smoothing Transformers for Time-series Forecasting	['time-series', 'forecasting', 'transformer', 'decomposition', 'season-trend', 'interpretable']	We propose an interpretable Transformer architecture which decomposes forecasts into level, growth, and seasonality components.	Deep Learning and representational learning	anonymous|etsformer_exponential_smoothing_transformers_for_timeseries_forecasting	/pdf/3b640857151aa7ec82446771ad215864fa28f745.pdf
Mqul6rfHoq	2302	Multi-agent Linear Contextual Bandits with Bounded O(1) Regret	['Bounded regret', 'Linear Contextual bandit', 'Recurring arrivals', 'Counterfactual', 'Upper Confidence Bound']	A recurring linear contextual bandit problem with $O(1)$ regret policy is proposed.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|multiagent_linear_contextual_bandits_with_bounded_o1_regret	/pdf/03a9f78946cbd8b37d4ffcbe1135697f2368012f.pdf
RVgssxlEVfl	2303	Non-Parametric State-Space Models: Identifiability, Estimation and Forecasting	['state-space model', 'time series forecasting', 'causal representation learning']	Flexible state space model for time series forecasting, inspired by the general structural causal model.	Deep Learning and representational learning	anonymous|nonparametric_statespace_models_identifiability_estimation_and_forecasting	/pdf/ea0ad77cdc4f5e205327da1e88c6ba16c827bfd2.pdf
13rQhx37o3u	2304	DeepTime: Deep Time-index Meta-learning for Non-stationary Time-series Forecasting	['time-series', 'forecasting', 'deep learning', 'implicit neural representation', 'meta-learning', 'time-index', 'non-stationary']	We propose a deep time-index model which leverages a meta-learning formulation to tackle non-stationary time-series forecasting.	Deep Learning and representational learning	anonymous|deeptime_deep_timeindex_metalearning_for_nonstationary_timeseries_forecasting	/pdf/7bc9af5825308ec38d972731ea07051f857827ab.pdf
CGBCTp2M6lA	2305	Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction	['Trajectory prediction', 'Autonomous driving', 'Neural relation inference', 'Stochasticity modeling', 'Multimodal prediction']	We defined and modeled Future Relationship to better modeling interaction between vehicles.	Applications (eg, speech processing, computer vision, NLP)	anonymous|leveraging_future_relationship_reasoning_for_vehicle_trajectory_prediction	/pdf/ed1004721438418ef5b1613e184d74d80f6b623a.pdf
dfDv0WU853R	2306	In-sample Actor Critic for Offline Reinforcement Learning	['offline reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|insample_actor_critic_for_offline_reinforcement_learning	/pdf/5418b4da7bdcd2f8c1e368693dd574e0194284f2.pdf
zQWqV2tzDv	2307	CircNet: Meshing 3D Point Clouds with Circumcenter Detection	['Meshing', '3D Point Cloud', 'Point Cloud Triangulation', 'Surface Reconstruction', 'Geometry Processing']	We present a deep neural architecture that detects circumcenters of triangles in the dual space to reconstruct 3D point clouds into triangular meshes efficiently	Applications (eg, speech processing, computer vision, NLP)	anonymous|circnet_meshing_3d_point_clouds_with_circumcenter_detection	/pdf/a9ed890b3af9e7f1262b1f5863bd47b7daec0cbc.pdf
EpvL_FaLtw	2308	Multi-Treatment Effect Estimation with Proxy: Contrastive Learning and Rank Weighting	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|multitreatment_effect_estimation_with_proxy_contrastive_learning_and_rank_weighting	/pdf/2407bbda886499fbfc7788ca329d0c2ec027531b.pdf
tkwP32nsEq	2309	Variance-Aware Sparse Linear Bandits	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|varianceaware_sparse_linear_bandits	/pdf/1d3735fb61a00a6b49baa1f72a56ced49a93653d.pdf
BMsqS_XALQU	2310	SuperMarioDomains: Generalizing to Domains with Evolving Graphics	['Domain Generalization', 'Domain', 'Shift', 'Domain Adaptation']	SuperMarioDomains is a new challenging Domain Generalization benchmark featuring domains derived from evolving video game graphics.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|supermariodomains_generalizing_to_domains_with_evolving_graphics	/pdf/363577cbb80f805da9fc1fbc8fda9f383e32764e.pdf
a30kyHbuXfI	2311	Exact manifold Gaussian Variational Bayes	['variational inference', 'Bayes', 'Riemann', 'black box', 'deep learning']	New algorithm for bayesian optimization	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|exact_manifold_gaussian_variational_bayes	/pdf/250b7b32564c4e860b7680e533b7f5f55e6468d0.pdf
DL8dTTvCpU	2312	Deformable Graph Transformer	['Graph Transformer', 'Graph Neural Networks']		Deep Learning and representational learning	anonymous|deformable_graph_transformer	/pdf/ee292559083c37bd0307dde41cc862e4c5e4b8df.pdf
sP0p5S-gZ2	2313	Optformer: Beyond Transformer for Black-box Optimization	['Transformer', 'Black-box optimization']		Deep Learning and representational learning	anonymous|optformer_beyond_transformer_for_blackbox_optimization	/pdf/e14c862cb429a1cf05a9e3319767275444f880ca.pdf
_G7dzxxSKM	2314	On the Power-Law Hessian Spectra in Deep Learning	['Deep Learning', 'Loss Landscape', 'Hessian']	We are the first to demonstrate that the Hessian spectra of well-trained deep neural networks exhibit simple power-law structures and critically relate to multiple behaviors of deep learning. .	Deep Learning and representational learning	anonymous|on_the_powerlaw_hessian_spectra_in_deep_learning	/pdf/fd044be9a692c2b178c66acf2fa5434050bd9ab2.pdf
AwWaBXLIJE	2315	Q-Pensieve: Boosting Sample Efficiency of Multi-Objective RL Through Memory Sharing of Q-Snapshots	['Multi-objective reinforcement learning', 'sample efficiency']	We boost the sample efficiency of multi-objective RL by using Q snapshots 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|qpensieve_boosting_sample_efficiency_of_multiobjective_rl_through_memory_sharing_of_qsnapshots	/pdf/306e3a4da3406eef5a846f5bd3cdfe60c7c4f352.pdf
Ur_qORZ6-9R	2316	DECN: Evolution Inspired Deep Convolution Network for Black-box Optimization	['Learning to Optimize', 'Black-box Optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|decn_evolution_inspired_deep_convolution_network_for_blackbox_optimization	/pdf/c605b3fc472e4150b1c4fc5c00840f8544781144.pdf
5-3YJbVPp6m	2317	Transfer Learning with Pre-trained Conditional Generative Models	['Deep Learning', 'Transfer Learning', 'Deep Generative Models', 'Semi-supervised Learning']	We propose a novel transfer learning method using conditional generative models pre-trained on source dataset for an inductive transfer learning setting where NN architectures are not consistent.	Deep Learning and representational learning	anonymous|transfer_learning_with_pretrained_conditional_generative_models	/pdf/28301b8bb4affdc0759858c4e3fa21c9fbc1f8b6.pdf
ykql_wKavL	2318	$z$-SignFedAvg: A Unified  Stochastic Sign-based Compression for Federated Learning	['federated averaging', 'compression', 'communication efficiency', 'signSGD']	This work proposes the first federated averaging algorithm with sign-based compression.	Optimization (eg, convex and non-convex optimization)	anonymous|zsignfedavg_a_unified_stochastic_signbased_compression_for_federated_learning	/pdf/da62811b2bd1ad9a5dbe21a39043a4ade39b6c55.pdf
4vfv4GDG6G	2319	Agent Prioritization with Interpretable Relation for Trajectory Prediction	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|agent_prioritization_with_interpretable_relation_for_trajectory_prediction	/pdf/9dacf964d32bd595371dff89a5ed88edab6f9251.pdf
Y3McfgrhX5	2320	Towards Information-Theoretic Pattern Mining in Time Series	['Deep learning', 'Unspervised learning', 'Variational Autoencoders']	The paper offers a novel method for discovering patterns from time series data.	Unsupervised and Self-supervised learning	anonymous|towards_informationtheoretic_pattern_mining_in_time_series	/pdf/96b1843eb8a7e73b4b14a3adaf466dd98079e47d.pdf
6KYPBGeYxv	2321	CacheGNN: Enhancing Graph Neural Networks with Global Information Caching	[]		Deep Learning and representational learning	anonymous|cachegnn_enhancing_graph_neural_networks_with_global_information_caching	/pdf/33dab9eb9ecaceef1a167598a4fece2caa41e4b0.pdf
fxjzKOdw9wb	2322	Exploring Temporally Dynamic Data Augmentation for Video Recognition	['Video Recognition', 'Data Augmentation']	We propose a novel data augmentation framework for video recognition that extends the static nature of image augmentations into temporally dynamic.	Applications (eg, speech processing, computer vision, NLP)	anonymous|exploring_temporally_dynamic_data_augmentation_for_video_recognition	/pdf/e0cbe0113a4ea7e8f18d01ef64a786f7844f7299.pdf
qPI2SzRjA3	2324	Group-oriented Cooperation in Multi-Agent Reinforcement Learning	['MARL', 'Multi-Agent Reinforcement Learning', 'Group-wise Learning']	We propose an automatic grouping mechanism in cooperative MARL, which dynamically adjusts the grouping of agents as training proceeds and achieves efficient team cooperation by facilitating intra- and inter-group coordination.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|grouporiented_cooperation_in_multiagent_reinforcement_learning	/pdf/5aaad54ed8a161d63ec736a2cf7a92aacd3a9b45.pdf
7ks5PS09q1	2325	Quasi-Taylor Samplers for Diffusion Generative Models based on Ideal Derivatives	['diffusion models', 'score based models', 'neural generative models']	Taylor-expansion approach for diffusion generative models is discussed.	Generative models	anonymous|quasitaylor_samplers_for_diffusion_generative_models_based_on_ideal_derivatives	/pdf/e94b42d49247375a597d4e391ace0a3afc18581d.pdf
Z7d-t6wbNy	2326	Scaled Neural Multiplicative Model for Tractable Optimization	['Input Convex Neural Networks', 'Shape Constrained Models', 'Shelf Space Optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|scaled_neural_multiplicative_model_for_tractable_optimization	/pdf/2ae886fde3dd0499f9cb7a8c38bc62cd2ce4b740.pdf
1T853KDY3t	2327	Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection	['Vision Transformer', 'Object Detection', 'Instance Segmentation', 'Representation Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|unleashing_vanilla_vision_transformer_with_masked_image_modeling_for_object_detection	/pdf/c58b03de5a167f0596d8995122051ccd9d87112b.pdf
IVE5g1af87	2328	Switching One-Versus-the-Rest Loss to Increase Logit Margins for Adversarial Robustness	['Adversarial examples', 'Deep learning', 'Loss function', 'Adversarial training']	We prove that one-versus-rest loss (OVR) increases logit margins two times greater than cross-entropy and propose switching between cross-entropy and OVR by the criterion of logit margins to improve adversarial robustness.	Deep Learning and representational learning	anonymous|switching_oneversustherest_loss_to_increase_logit_margins_for_adversarial_robustness	/pdf/a6649aeced56b19c8a2658dff96c3b1ce85a340a.pdf
Iwq3HPz96O	2329	Multi-Level Contrastive Learning for Dense Prediction Task	['Self-supervised learning', 'Detection', 'Segmentation']	Multi-Level Contrastive Learning is an efficient self-supervised method to learn region-level feature representation for dense prediction tasks.	Unsupervised and Self-supervised learning	anonymous|multilevel_contrastive_learning_for_dense_prediction_task	/pdf/c2a0ba561a1e6eaf1b22dab360e6861c35377c9b.pdf
-vKlt84fHs	2330	Towards Lightweight, Model-Agnostic and Diversity-Aware Active Anomaly Detection	['Active Anomaly Discovery', 'Diversity Sampling', 'Deep Learning']		General Machine Learning (ie none of the above)	anonymous|towards_lightweight_modelagnostic_and_diversityaware_active_anomaly_detection	/pdf/8410298c8b788db22fcdc5255cd7a444cc2ccc9b.pdf
42Xu5gudPL	2332	Impact of the Last Fully Connected Layer on Out-of-distribution Detection	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|impact_of_the_last_fully_connected_layer_on_outofdistribution_detection	/pdf/3eda963e38cb51dd182ff54491e6fc840c71c599.pdf
UvlCVoLV1i	2333	Probable Dataset Searching Method with Uncertain Dataset Information in Adjusting Architecture Hyper Parameter	[]		Deep Learning and representational learning	anonymous|probable_dataset_searching_method_with_uncertain_dataset_information_in_adjusting_architecture_hyper_parameter	/pdf/edfe9a9790acaf48cfdf2cef54e56e5415de1ce9.pdf
h2L7xRNh7n_	2334	Adversarial IV Regression for Demystifying Causal Features on Adversarial Examples	['Adversarial Examples', 'Causal Feature', 'Adversarial Robustness']	We propose a way of understanding the adversarial vulnerability through a causal perspective.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|adversarial_iv_regression_for_demystifying_causal_features_on_adversarial_examples	/pdf/adcbd9c990eb92af52fb2f8839f3a3b9f7f99372.pdf
o8xdgmwCP8l	2335	Time to augment visual self-supervised learning	['object representations', 'self-supervised learning', 'time-based augmentations', 'data augmentations']	We show that time-based augmentations resulting from ego-motion and object manipulations improve over standard data-augmentations methods on the ability to visually recognize object categories.	Unsupervised and Self-supervised learning	anonymous|time_to_augment_visual_selfsupervised_learning	/pdf/d40a542908e818d6a2310b1c30ad9f5ceb74cd5d.pdf
r6a21wSch9p	2336	Non-equispaced Fourier Neural Solvers for PDEs	['Neural Operators', 'PDE Solvers']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|nonequispaced_fourier_neural_solvers_for_pdes	/pdf/83b35762199bac2a2bea237825c954f6eb16f6d8.pdf
hT4qiZK0Iv	2340	On the robustness of self-supervised models for generative spoken language modeling	['robustness', 'speech', 'language modeling', 'spoken language modeling']	Method to learn robust self-supervised speech representation for generative spoken language modeling	General Machine Learning (ie none of the above)	anonymous|on_the_robustness_of_selfsupervised_models_for_generative_spoken_language_modeling	/pdf/c69dd799bd7ab1e8b9c7ee90dcbad1713ddc87d5.pdf
g2oB_k-18b	2341	Measure the Predictive Heterogeneity	['data heterogeneity', 'predictive information', 'predictive heterogeneity']	In this work, we propose the predictive heterogeneity to measure the data heterogeneity that affects prediction. Theoretical analysis and empirical results validate the rationality of the proposed measure.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|measure_the_predictive_heterogeneity	/pdf/b8fa4865551f0871f310346d0a9d5cd092e70201.pdf
_p6enPE4Xa	2342	OCD: Learning to Overfit with Conditional Diffusion Models	['Local learning', 'hypernetworks', 'diffusion processes']	Local learning with a hypernetwork that employs a diffusion process	Deep Learning and representational learning	anonymous|ocd_learning_to_overfit_with_conditional_diffusion_models	/pdf/438ddc06836af267ebb6b907c7a9569414a3b168.pdf
ivwZO-HnzG_	2343	Recon: Reducing Conflicting Gradients From the Root For Multi-Task Learning	['Multi-task Learning', 'Conflicting Gradients']	We propose a very simple yet effective approach to reduce the occurrence of conflicting gradients for multi-task learning.	General Machine Learning (ie none of the above)	anonymous|recon_reducing_conflicting_gradients_from_the_root_for_multitask_learning	/pdf/c3bfeb4175a61b661d1d65a8049dd68da4912623.pdf
iZ3Qo_akPA	2344	Measuring Image Complexity as a Discrete Hierarchy using MDL Clustering	['image complexity', 'clustering']	The first image complexity measure that does not assign white noise high complexity, based on clustering and inspired by molecular assembly theory.	General Machine Learning (ie none of the above)	anonymous|measuring_image_complexity_as_a_discrete_hierarchy_using_mdl_clustering	/pdf/8625915d17a8204ac9ab99f6e393ac9832d5ab59.pdf
0uRm1YmFTu	2345	Predictive Inference with Feature Conformal Prediction	['conformal prediction', 'uncertainty']	Conformal inference in feature space. 	Deep Learning and representational learning	anonymous|predictive_inference_with_feature_conformal_prediction	/pdf/94cc5301f18d89a0f5d19d6d34700d979983de99.pdf
UrEwJebCxk	2346	On the Edge of Benign Overfitting: Label Noise and Overparameterization Level	['generalization', 'benign overfitting', 'mild overparameterization', 'implicit bias']	Provide a theoretical analysis for the phenomenon that ResNet model overfits benignly on Cifar10 but not benignly on ImageNet	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_edge_of_benign_overfitting_label_noise_and_overparameterization_level	/pdf/b67821b425760fed504f6a13b402fbf21b51cda7.pdf
EA6YF_qwVe	2347	Rate-Distortion Optimized Post-Training Quantization for Learned Image Compression	['learned image compression', 'post-training quantization', 'rate-distortion optimization']		Applications (eg, speech processing, computer vision, NLP)	anonymous|ratedistortion_optimized_posttraining_quantization_for_learned_image_compression	/pdf/dbbe894521767720bf7797f318b8942b3fbc62b8.pdf
iV0r9898C-	2348	Few-Shot Anomaly Detection on Industrial Images through Contrastive Fine-Tuning	['Anomaly Detection', 'Transfer Learning', 'Few-Shot Learning']	We proposed a few-shot anomaly detection approach towards industrial defect identification	Applications (eg, speech processing, computer vision, NLP)	anonymous|fewshot_anomaly_detection_on_industrial_images_through_contrastive_finetuning	/pdf/b10f112a639573532f5cb99f997153351ba64834.pdf
8E5Yazboyh	2350	Sharper Bounds for Uniformly Stable Algorithms with Stationary $\varphi$-mixing Process	['Algorithmic Stability', 'Non-I.I.D. Learning', 'Generalization Error', 'Learning Theory']	We develop stability and generalization bounds for learning with mixing sequences.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|sharper_bounds_for_uniformly_stable_algorithms_with_stationary_\varphimixing_process	/pdf/a080ed03e4cdee405714d543058f57ddea258296.pdf
sd90a2ytrt	2352	Semi-Implicit Variational Inference via Score Matching	['Semi-implicit variational inference', 'denoising score matching', 'minimax optimization']	A new semi-implict variational inference method using a score matching training objective	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|semiimplicit_variational_inference_via_score_matching	/pdf/19cd6ca87ceeaa3c84c9e34c81765952095099da.pdf
09hVcSDkea	2355	Corrupted Image Modeling for Self-Supervised Visual Pre-Training	['Self-supervised Learning', 'Representation Learning', 'Vision Transformer']		Unsupervised and Self-supervised learning	anonymous|corrupted_image_modeling_for_selfsupervised_visual_pretraining	/pdf/824b7cfda74e0ff1c8113a1d59ccb4cdd3e65277.pdf
4oYUGeGBPm	2356	TRANSFORMER-PATCHER: ONE MISTAKE WORTH ONE NEURON	['Sequential Model Editing']	A Sequential Model Editor to correct model's output on the specific input.	Applications (eg, speech processing, computer vision, NLP)	anonymous|transformerpatcher_one_mistake_worth_one_neuron	/pdf/752dcf12a7374d1d0f61d472cec4335724859e79.pdf
MQ2IvNeZJD	2358	Can you Trust your Disentanglement?	['deep learning', 'disentanglement']	by exposing problems in disentanglment metrics, and introducing new metrics and a new task, we make the case that existing disentangled models actually produce representations that are largely entangled	Deep Learning and representational learning	anonymous|can_you_trust_your_disentanglement	/pdf/14a2d81afee7a27be67b1b17983d289d1697e523.pdf
VgCqZL_N0a	2360	Bandit Learning in Many-to-one Matching Markets with Uniqueness Conditions	['matching markets', 'multi-armed bandit', 'many-to-one setting', 'uniqueness conditions']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|bandit_learning_in_manytoone_matching_markets_with_uniqueness_conditions	/pdf/c6e582e2a162e8eb5f4885fc68f77a80c4fa9cd0.pdf
EJPWfoJRba	2362	On the Importance of the Policy Structure in Offline Reinforcement Learning	['offline reinforcement learning', 'discrete latent representations']	We introduce a structure in a policy representation in offline reinforcement learning, which reduces the critic loss during the training and improves the resulting policy performance. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_importance_of_the_policy_structure_in_offline_reinforcement_learning	/pdf/97589484a75575b299e3b401da3df0f5358bddca.pdf
ezgCdnzApo	2363	Masked Vector Quantization	['generative models', 'dropout', 'vector quantization', 'autoencoder', 'discrete representations']	We proposed Masked Vector Quantization, a novel variant of Vector Quantization, which increases the representational capacity of each code vector by learning mask configurations via winner-takes-all training regime called Multiple Hypotheses Dropout.	Generative models	anonymous|masked_vector_quantization	/pdf/dc069780a3044980ed73f4d6adbe2d71a29c4b7e.pdf
lNQAXpf7rGu	2364	The Progressive Alignment-aware Multimodal Fusion with Easy2hard Strategy for Multimodal Neural Machine Translation	['Multimodal neural machine translation', 'Multi-modal alignment', 'Easy2hard', 'Progressive multi-modal fusion', 'Multi30K']		Applications (eg, speech processing, computer vision, NLP)	anonymous|the_progressive_alignmentaware_multimodal_fusion_with_easy2hard_strategy_for_multimodal_neural_machine_translation	/pdf/5a07344b23499036f5d6c5c406af4dcb8554442e.pdf
94WEPuo8D_a	2365	Joint Generator-Ranker Learning for Natural Language Generation	['natural language processing', 'natural language generation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|joint_generatorranker_learning_for_natural_language_generation	/pdf/516072c84a0c8e55e15c1f2d47c4eccb9ed0e69d.pdf
UROBiQEOLP	2368	E-Forcing: Improving Autoregressive Models by Treating it as an Energy-Based One	['autoregressive models', 'exposure bias', 'language modeling', 'neural machine translation']	we propose a unique method termed E-Forcing for training autoregressive generative models that takes advantage of a well-designed energy-based learning objective.	Generative models	anonymous|eforcing_improving_autoregressive_models_by_treating_it_as_an_energybased_one	/pdf/d81811ea0d49d5463ccd82b4eb5f24fd39d19529.pdf
6OxI4WqGr6	2369	Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|semisupervised_offline_reinforcement_learning_with_actionfree_trajectories	/pdf/76f6bf25f62ba792feaa08f6fd0a07f9fdbf9cdb.pdf
XtRJsuVsLU	2370	Benchmarking Approximate k-Nearest Neighbour Search for Big High Dimensional Dynamic Data	['Nearest Neighbour Search', 'Similarity Search', 'Indexing', 'Knowledge retrieval', 'Knowledge discovery', 'High Dimensional Data', 'Big Data', 'Large Scale', 'Hashing', 'Graph Traversal', 'Product Quantisation', 'Online Learning', 'Representation Learning', 'Metric Learning', 'Robotic Vision']	A novel framework for benchmarking Approximate k-Nearest Neighbour (ANN) methods on big high dimensional dynamic data that identifies suitable ANN methods for ML and other applications and will accelerate future ANN research.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|benchmarking_approximate_knearest_neighbour_search_for_big_high_dimensional_dynamic_data	/pdf/660d313a5f88b4b035f81ca3e0d92be16374d5ad.pdf
JTGimap_-F	2371	Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images	[]		Generative models	anonymous|rarity_score_a_new_metric_to_evaluate_the_uncommonness_of_synthesized_images	/pdf/399c623d14198b9aeb6bf96da5e724b04cc23546.pdf
Ubc74gTVo3	2372	Self-supervision through Random Segments with Autoregressive Coding (RandSAC)	[]		Unsupervised and Self-supervised learning	anonymous|selfsupervision_through_random_segments_with_autoregressive_coding_randsac	/pdf/a3afd5933b1b263a67112e4ef78746893a8ff53c.pdf
4PJUBT9f2Ol	2373	Generative Modelling with Inverse Heat Dissipation	['diffusion model', 'partial differential equation', 'inductive bias']	We propose a generative model that iteratively reverses the heat equation, increasing the effective resolution of the image	Generative models	anonymous|generative_modelling_with_inverse_heat_dissipation	/pdf/818aa2948553756e566bfe91e4b4dfe52af9a042.pdf
RtB4CXS1Jxv	2374	Data-Free Continual Graph Learning 	['continual learning', 'graph representation learning', 'graph neural networks', 'lifelong learning']	consider and study an important yet ignored case in existing continual graph learning works 	Deep Learning and representational learning	anonymous|datafree_continual_graph_learning	/pdf/5416846dcd78f467030501bfdfb514a6695ea88a.pdf
snjmwYRuqh	2376	MULTI-VIEW DEEP EVIDENTIAL FUSION NEURAL NETWORK FOR ASSESSMENT OF SCREENING MAMMOGRAMS	['Multi view fusion', 'Mammograms', 'Evidential learning', 'Deep learning']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|multiview_deep_evidential_fusion_neural_network_for_assessment_of_screening_mammograms	/pdf/4a0395d932654e9b8d385c3af1b5dc13f08299db.pdf
l4f-zJqY2s	2377	Label-distribution-agnostic Ensemble Learning on Federated Long-tailed Data	['fedearted learning', 'long-tailed learning']		Deep Learning and representational learning	anonymous|labeldistributionagnostic_ensemble_learning_on_federated_longtailed_data	/pdf/3a612c6e2d3ae69446a5684dc9fba2baad9c38d3.pdf
NWZOL5kZv6	2378	Analyzing adversarial robustness of vision transformers against spatial and spectral attacks	['Transformers', 'adversarial attack', 'Fourier transform']	We discover that Transformers are vulnerable to adversarial attacks perturbing phase information of images in the frequency domain.	Deep Learning and representational learning	anonymous|analyzing_adversarial_robustness_of_vision_transformers_against_spatial_and_spectral_attacks	/pdf/ba00c77e111b3202e4479ebde7fbd1523ae9a175.pdf
e20T84suZx	2379	Enhancing the Transferability of Adversarial Examples via a Few Queries and Fuzzy Domain Eliminating	['adversarial examples', 'transferability', 'deep neural network']	In this work, we propose a novel method called query prior-based method and the fuzzy domain eliminating technique to enhance the family of fast gradient sign methods and improve their attack transferability by using a few queries.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|enhancing_the_transferability_of_adversarial_examples_via_a_few_queries_and_fuzzy_domain_eliminating	/pdf/71fb7bb3bfc5045558f4bd6e2f4cc725acc12d7d.pdf
rEKl9rzR7S	2380	Unified Probabilistic Modeling of Image Aesthetic Rating Distributions towards Measuring Subjectivity	['image aesthetics', 'probabilistic modeling', 'subjective logic', 'subjective preference']	We propose a unified probabilistic framework for modeling and quantifying subjective aesthetic preference.	Applications (eg, speech processing, computer vision, NLP)	anonymous|unified_probabilistic_modeling_of_image_aesthetic_rating_distributions_towards_measuring_subjectivity	/pdf/22422ecfeb573d595f05f646e6004ebd4c4ba16d.pdf
cRxYWKiTan	2381	Better Generative Replay for Continual Federated Learning	['federated learning', 'continual learning']	introduce a new continual federated leanring setting with generative replay and solve an important technical problem to make it work	Deep Learning and representational learning	anonymous|better_generative_replay_for_continual_federated_learning	/pdf/edda411be53e99688c41f35e0dc4b111a8732215.pdf
e1WfacHtbj	2383	Selective Classifier Ensemble	['selective prediction', 'selective classification', 'ensemble learning']		Deep Learning and representational learning	anonymous|selective_classifier_ensemble	/pdf/8f775d12009da75c207874e7cbbc138805d78870.pdf
kcemndN1Tw	2384	Deep Generative Model based Rate-Distortion for Image Downscaling Assessment	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|deep_generative_model_based_ratedistortion_for_image_downscaling_assessment	/pdf/8b89158b8914be8e644fd70307ae9c2ec6cd1a07.pdf
6RWJe6lPbQ	2385	Deep Graph-Level Clustering Using Pseudo-Label-Guided Mutual Information Maximization Network	['Graph-level clustering', 'Graph representation learning', 'Deep learning', 'Unsupervised learning']		Unsupervised and Self-supervised learning	anonymous|deep_graphlevel_clustering_using_pseudolabelguided_mutual_information_maximization_network	/pdf/df6ada2a42c2d9a849579e2355a66a0d9617bd5a.pdf
e9-w5aLkZM	2386	Learning Object Affordance with Contact and Grasp Generation	['Object Affordance', 'Hand Grasps Generation', 'Conditional Variational Autoencoder', 'DLearning']		Deep Learning and representational learning	anonymous|learning_object_affordance_with_contact_and_grasp_generation	/pdf/75b56c427e7d463a8d89f46f61f3d15893c7820c.pdf
gaIMkuIFwCG	2388	ContextSpeech: Expressive and Efficient Text-to-Speech for Paragraph Reading	['Text-to-Speech', 'Contextual Modeling', 'Efficient Transformer']	We propose ContextSpeech with memory reuse mechanism ,broaden contextual semantic information and linearized attention for paragraph reading TTS.	Applications (eg, speech processing, computer vision, NLP)	anonymous|contextspeech_expressive_and_efficient_texttospeech_for_paragraph_reading	/pdf/84605a06fa180bf45b3b864a9687fa7dd7894a6a.pdf
qr0EbR8lH5	2391	Personalized Decentralized Bilevel Optimization over Stochastic and Directed Networks	['decentralized stochastic gradient descent: bilevel optimization: hyper-gradient: personalization: directed network: federated learning: distributed learning: fully-decentralized']	We propose a gradient-based bilevel optimization as a general approach of personalization and propose a decentralized hyper-gradient estimation altgorithm that runs on stochastic and directed communication networks.	General Machine Learning (ie none of the above)	anonymous|personalized_decentralized_bilevel_optimization_over_stochastic_and_directed_networks	/pdf/0b6aada69a1a23a36ece479ffd658dfab493745a.pdf
5iqzNK-Qeb	2392	CBLab: Scalable Traffic Simulation with Enriched Data Supporting	['Infrastructure', 'Traffic Policy', 'Traffic Simulation', 'Large-scale Dataset']	We present CBLab, a toolkit for scalable traffic simulation with enriched input data supporting.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|cblab_scalable_traffic_simulation_with_enriched_data_supporting	/pdf/159b27089c5b7f6a3c7b276d2792f28813419be0.pdf
HBLr-G1Zpn	2393	Deep Causal Generative Modeling for Tabular Data Imputation and Intervention	['tabular data', 'generative models', 'missing value imputation', 'causal knowledge']		Generative models	anonymous|deep_causal_generative_modeling_for_tabular_data_imputation_and_intervention	/pdf/e925ce964340f10cd714bf837253bb2b2926aede.pdf
sQ0TzsZTUn	2394	Semantic Category Discovery with Vision-language Representations	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|semantic_category_discovery_with_visionlanguage_representations	/pdf/47b924a824efe11108762f906efd57e0c33e9075.pdf
aGkxJtOxKx	2395	Global-Local Bayesian Transformer for Semantic Correspondence	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|globallocal_bayesian_transformer_for_semantic_correspondence	/pdf/a3387e92ed45ee606d99a41e7bedf95ef35e3c69.pdf
vny63BYDCS	2396	NSCL: Noise-Resistant Soft Contrastive Learning for Universal Domain Adaptation	['Universal Domain Adaptation', 'Contrastive Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|nscl_noiseresistant_soft_contrastive_learning_for_universal_domain_adaptation	/pdf/ca310ad4b6a1b640049adcfa48cd92c5376614b1.pdf
AGLG_ncNp0X	2397	Personalized Federated Hypernetworks for Privacy Preservation in Multi-Task Reinforcement Learning	['microgrid clusters', 'energy demand response', 'transactive energy control', 'neural networks', 'multi-agent reinforcement learning', 'reinforcement learning', 'multi-task learning', 'transfer learning', 'hypernetworks', 'federated learning', 'personalized federated learning', 'microgrids']	We use hypernetworks to aggregate learning across multiple reinforcement learning agents in a microgrid energy demand response setting while preserving privacy.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|personalized_federated_hypernetworks_for_privacy_preservation_in_multitask_reinforcement_learning	/pdf/95f1538dd8c7978a4fadb27f867038abfcabc382.pdf
UgLKEBoE3QP	2398	Least Disagree Metric-based Active Learning	['active learning', 'uncertainty', 'disagree metric', 'diversity']	The uncertainty-based active learning algorithm based on the least disagree metric, which is the smallest perturbation required to alter the sample prediction.	General Machine Learning (ie none of the above)	anonymous|least_disagree_metricbased_active_learning	/pdf/829efa15eed3c913265cf79f6e59bd61781a0865.pdf
7_3oRsaogr	2400	Style Balancing and Test-Time Style Shifting for Domain Generalization	['Domain generalization', 'Style mixing', 'Arbitrary style transfer']	We propose style balancing and test-time style shifting for domain generalization, to handle the imbalance issues and the issue on large style gap between source and target domains.	Deep Learning and representational learning	anonymous|style_balancing_and_testtime_style_shifting_for_domain_generalization	/pdf/4ec7870f7f44ae8113903b4e694a1fd1474fd833.pdf
Nk2pDtuhTq	2401	Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning	['Prompt Tuning', 'Multitask Learning', 'Transfer Learning']	We propose multitask prompt tuning which learns a single transferable prompt by decomposing and distilling knowledge from multiple task-specific source prompts.	Applications (eg, speech processing, computer vision, NLP)	anonymous|multitask_prompt_tuning_enables_parameterefficient_transfer_learning	/pdf/dd4d4674dcdd531e704e9e80ea186d9f492ffd33.pdf
kv6N5B_5gx	2403	Leveraging Hard Negative Priors for Automatic Medical Report Generation	['Medical Report Generation', 'Image Captioning', 'Hard Negatives']		Applications (eg, speech processing, computer vision, NLP)	anonymous|leveraging_hard_negative_priors_for_automatic_medical_report_generation	/pdf/a0ba20260a345b6c23d0ad77b3896684953fd154.pdf
m1oqEOAozQU	2406	Graph Neural Networks for Link Prediction with Subgraph Sketching	['Graph Neural Networks', 'Link Prediction', 'Data Sketching']	A method that solves the expressivity issues that plague most MPNNs for link prediction while being as efficient to run as GCN. This is achieved by passing subgraph sketches as messages.	Deep Learning and representational learning	anonymous|graph_neural_networks_for_link_prediction_with_subgraph_sketching	/pdf/502db1d88541dd777d5ee3dfa5823c933110ea23.pdf
9KmnrUpU2DG	2407	Lost Domain Generalization Is a Natural Consequence of Lack of Training Domains	['Domain Generalization', 'Domain Complexity']	We show a hardness result for the number of training domains required to achieve a small population error on the test domain.	General Machine Learning (ie none of the above)	anonymous|lost_domain_generalization_is_a_natural_consequence_of_lack_of_training_domains	/pdf/1e41fb31dd920c4e09dc827e0f60273776369dc8.pdf
Sc3Ylriwp4	2408	Learning Dynamical Characteristics with Neural Operators for Data Assimilation	['AI for science', 'data assimilation', 'generative models']	A new deep learning framework is proposed for data assimilation issues.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_dynamical_characteristics_with_neural_operators_for_data_assimilation	/pdf/ebfc67a47115ff2f73bdb5078ad7c01f5e38e06c.pdf
btmflCmNxDl	2411	Self-Consistent Learning: Cooperation between Generators and Discriminators	['Cooperative Closed-loop Training', 'Language Modeling', 'Sentence Semantic Matching']	This paper presents a self-consistent learning framework with a cooperative closed-loop form, achieving new state-of-the-art results on the sentence semantic matching task on both zero-shot and full-data settings.	Applications (eg, speech processing, computer vision, NLP)	anonymous|selfconsistent_learning_cooperation_between_generators_and_discriminators	/pdf/9dd6dd80f8d7c419dbe776bf5a2259bbbcbf2612.pdf
BGvOEUEMBzE	2412	Pareto Optimization for Active Learning under Out-of-Distribution Data Scenarios	['active learning', 'pareto optimization', 'out-of-distribution']		General Machine Learning (ie none of the above)	anonymous|pareto_optimization_for_active_learning_under_outofdistribution_data_scenarios	/pdf/60540064c6bb1d46f2c962df966994348e492206.pdf
gPgI6mStqTc	2413	Relative Contribution Mechanism: A Unified Paradigm for Disassembling Convolutional Neural Networks	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|relative_contribution_mechanism_a_unified_paradigm_for_disassembling_convolutional_neural_networks	/pdf/9e2d89933ff989e6fdf7e8db81141679ff85e40b.pdf
tF_iDkYA_Z5	2414	Gradient Deconfliction via Orthogonal Projections onto Subspaces For Multi-task Learning	['multi-task learning', 'deep learning']	We propose a multi-task learning method which not only solves all conflicts among the tasks, but can also effectively search for diverse solutions towards different trade-off preferences among the tasks.	Deep Learning and representational learning	anonymous|gradient_deconfliction_via_orthogonal_projections_onto_subspaces_for_multitask_learning	/pdf/5b6aa72f88e8dd4289051488159bc632f297f01e.pdf
jSXsRwdux_	2415	GPR-Net: Multi-view Layout Estimation via a Geometry-aware Panorama Registration Network	[]		Deep Learning and representational learning	anonymous|gprnet_multiview_layout_estimation_via_a_geometryaware_panorama_registration_network	/pdf/155318fe90704509f4e587073354e557248639ea.pdf
yCtxVkTaXg	2417	Deep Graph-Level Orthogonal Hypersphere Compression for Anomaly Detection	['Unsupervised learning']	A deep orthogonal graph-level anomaly detection method and its improvement.	General Machine Learning (ie none of the above)	anonymous|deep_graphlevel_orthogonal_hypersphere_compression_for_anomaly_detection	/pdf/299ebb0ee17add5b0893ac36ef7e7032fc9d84d7.pdf
3eQEil044E	2418	Momentum Tracking: Momentum Acceleration for Decentralized Deep Learning on Heterogeneous Data	['Decentralized Optimization', 'Non-Convex Stochastic Optimization', 'Momentum Acceleration']	In this work, we propose Momentum Tracking, which is the method with momentum acceleration whose convergence rate is proved to be independent of the data-heterogeneity.	Optimization (eg, convex and non-convex optimization)	anonymous|momentum_tracking_momentum_acceleration_for_decentralized_deep_learning_on_heterogeneous_data	/pdf/f1afaddc04805c5962d65da839d50e56dd1f35da.pdf
XwR41dpign	2419	Molecule Generation for Target Receptor Binding via Continuous Normalizing Flows	['molecule generative models', 'normalizing flows', 'equivariance']	We derive semi-equivariance conditions to yield invariant conditional distributions of ligand molecules given receptor molecules.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|molecule_generation_for_target_receptor_binding_via_continuous_normalizing_flows	/pdf/9199b57f3c36fafb22ffe11481b9cb2312ef1186.pdf
3vOtC1t1kF	2420	Efficient Personalized Federated Learning via Sparse Model-Adaptation	['Efficient Federated Learning', 'Personalization', 'Sparse Model-Adaptation']	We propose an efficient personalized FL method with theoretical analysis, which adaptively learns sparse local models, and achieves SOTA accuracy and efficiency simultaneously.	General Machine Learning (ie none of the above)	anonymous|efficient_personalized_federated_learning_via_sparse_modeladaptation	/pdf/abc5860c3ae8565dbb0c848565b61cdd574eacd7.pdf
O8EK-eWjUm	2421	Open Set Recognition by Mitigating Prompt Bias	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|open_set_recognition_by_mitigating_prompt_bias	/pdf/fe2751a0513d9508ccbf34c521a94ca5d208dc0e.pdf
x8NPd0MFTf	2425	Black-box Knowledge Distillation	['black-box model', 'knowledge distillation']	We introduce an approach for black-box knowledge distillation via prediction augmentations and multi-level prediction alignment.	Deep Learning and representational learning	anonymous|blackbox_knowledge_distillation	/pdf/b0e771dd9497c932ab862f86c24959f4718b7c6e.pdf
4RwkbKZhGV	2426	A Time-Consistency Curriculum for Learning from Instance-Dependent Noisy Labels	[]		Unsupervised and Self-supervised learning	anonymous|a_timeconsistency_curriculum_for_learning_from_instancedependent_noisy_labels	/pdf/2ea64fb7cad118e4d886589a4cf3df74e66aeff4.pdf
kzqRIEHBgH	2427	What's Behind the Mask: Estimating Uncertainty in Image-to-Image Problems	['uncertainty estimation', 'image-to-image']	We show how to estimate uncertainty in image-to-image problems by computing a mask such that the distance between the masked reconstructed image and the masked true image is guaranteed to be less than a specified threshold, with high  probability.	General Machine Learning (ie none of the above)	anonymous|whats_behind_the_mask_estimating_uncertainty_in_imagetoimage_problems	/pdf/eb3a8e31e5427f45a65fd9dd77e95fb97aeb27f4.pdf
pfuqQQCB34	2428	Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression as a Cherry on the Top	['byzantine robustness', 'variance reduction', 'communication compression']	We propose a new Byzantine-tolerant method with variance reduction, communication compression, and theoretical guarantees superior to previously known results	Optimization (eg, convex and non-convex optimization)	anonymous|variance_reduction_is_an_antidote_to_byzantines_better_rates_weaker_assumptions_and_communication_compression_as_a_cherry_on_the_top	/pdf/1e4126f142382385d4fba894a4ded9f8e80191d8.pdf
rPqxwpEm7M	2430	Dense Correlation Fields for Motion Modeling in Action Recognition	['Action recognition', 'Motion modeling', 'Video understanding']	In this paper, we present Dense Correlation Fields (DCF) which build up dense visual correlation volumes that preserves both fine local information provided in the lower layer and the high-level semantic information from the deeper layer.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dense_correlation_fields_for_motion_modeling_in_action_recognition	/pdf/b79e99bcf9183a99c191ada43c536aa35d0796f2.pdf
rFQfjDC9Mt	2431	Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|cleanimage_backdoor_attacking_multilabel_models_with_poisoned_labels_only	/pdf/6ab1b67ede3e3980f1ac0e1e4b79d6f0535fba27.pdf
cKAhbE-woN	2432	Adversarial Examples Guided Pseudo-label Refinement for Decentralized Domain Adaptation	['Domain Adaptation', 'Federated Learning']		Deep Learning and representational learning	anonymous|adversarial_examples_guided_pseudolabel_refinement_for_decentralized_domain_adaptation	/pdf/889fd80dc110969d46bf80e8c216faeb081b8dae.pdf
WFBksaezAs	2433	Multi-Prompt Alignment for Multi-source Unsupervised Domain Adaptation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|multiprompt_alignment_for_multisource_unsupervised_domain_adaptation	/pdf/7c157bc2dbe94a0223ba0d7449133c7dae5798db.pdf
w4eQcMZsJa	2434	Text-Driven Generative Domain Adaptation with Spectral Consistency Regularization	['GAN', 'StyleGAN', 'Clip', 'Domain Adaptation', 'Style Transfer']		Applications (eg, speech processing, computer vision, NLP)	anonymous|textdriven_generative_domain_adaptation_with_spectral_consistency_regularization	/pdf/9d93f89ef5368bff0496b56ac8787d77c2732292.pdf
7L2mgi0TNEP	2435	$\rm A^2Q$: Aggregation-Aware Quantization for Graph Neural Networks	['Graph Neural Networks', 'MPNN framework', 'Mixed-precision', 'Quantization']	We propose an Aggregation-Aware mixed-precision Quantization method that fully utilizes the  property of GNNs, achieving up to $2\times$ speedup and $11.4\%$ accuracy improvement compared to the state-of-the-art quantization method on GNNs.	Deep Learning and representational learning	anonymous|\rm_a^2q_aggregationaware_quantization_for_graph_neural_networks	/pdf/d37c957f6800c36211c0508e8980cc3660e0ecf4.pdf
lRdhvzMpVYV	2436	A Differential Geometric View and Explainability of GNN on Evolving Graphs	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_differential_geometric_view_and_explainability_of_gnn_on_evolving_graphs	/pdf/ffc3cc9bd87f0cf0406b8d182093b9a0ef931b07.pdf
cwf7nnoK5o	2438	Interval-based Offline Policy Evaluation without Sufficient Exploration or Realizability	['Offline policy evaluation', 'marginal importance sampling', 'offline reinforcement learning']	We characterize the minimax bias of OPE caused by the insufficiency of exploration and the lack of (strong) realizability, and propose a new estimator achieving it.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|intervalbased_offline_policy_evaluation_without_sufficient_exploration_or_realizability	/pdf/7175444e5eeb2d086e1ea3aaeab3d466eb7cbc06.pdf
-XC_lMynIT	2439	Signal to Sequence Attention-Based Multiple Instance Network for Segmentation Free Inference of RNA Modifications	['Multiple Instance Learning', 'Deep Learning', 'RNA Modification', 'Computational Biology']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|signal_to_sequence_attentionbased_multiple_instance_network_for_segmentation_free_inference_of_rna_modifications	/pdf/8f832ca13590998932788a705bf0750e0ec499c8.pdf
F5uYcwABMu	2440	Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models	['Language Modeling', 'Implicit Bias']	We study the role of implicit bias in language modeling	Unsupervised and Self-supervised learning	anonymous|same_pretraining_loss_better_downstream_implicit_bias_matters_for_language_models	/pdf/89080dcff2c13c4278b4cc92e52b2a111e1e9dab.pdf
zaEiQ2dgLv	2441	MetaFS: An Effective Wrapper Feature Selection via Meta Learning	['Meta Learning', 'feature selection']	We propose a meta-learning-based wrapper feature selection framewrok that doesn't require re-training plenty of models to evaluate different subsets.	Deep Learning and representational learning	anonymous|metafs_an_effective_wrapper_feature_selection_via_meta_learning	/pdf/b98a7d9de15fc7980217cd6085e01c9d2cdeebe6.pdf
v61jhmI2zz	2442	Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning	['robustness', 'failure discovery']	This work demonstrates the utility of large-scale generative models to automatically discover bugs in vision models in an open-ended manner.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|discovering_bugs_in_vision_models_using_offtheshelf_image_generation_and_captioning	/pdf/047049b8b2c0cc2d53fb0a262228fb6d4d8b3aab.pdf
4JoV9g5R1M	2443	Emergent Communication with Attention	['emergent communication', 'attention mechanism', 'compositionality', 'interpretability']	We study emergent language from attention agents with the referential game showing that their language is more compositional and interpretable.	General Machine Learning (ie none of the above)	anonymous|emergent_communication_with_attention	/pdf/86fcfeaf1c40d329f5ff2083d2a36b3f3bc2275a.pdf
1-B8dz847_	2444	Pairwise Confidence Difference on Unlabeled Data is Sufficient for Binary Classification	['Weakly supervised learning', 'binary classification', 'unbiased risk estimator']	The difference of confidence labels on unlabeled data pairs, as a novel type of weak supervision, is sufficient to train binary classifiers with theoretical guarantees.	General Machine Learning (ie none of the above)	anonymous|pairwise_confidence_difference_on_unlabeled_data_is_sufficient_for_binary_classification	/pdf/9760a357eb617cefc64e4d6883d6f7c93e02b268.pdf
_bP-uQzQ1T	2445	Addressing Variable Dependency in GNN-based SAT Solving	['Boolean Satisfiability', 'GNN', 'Variable Dependency']	We address the variable dependency problem in SAT solving by a new GNN-based model.	Applications (eg, speech processing, computer vision, NLP)	anonymous|addressing_variable_dependency_in_gnnbased_sat_solving	/pdf/c24c2426457492ef549bf90fa021b355943f4b09.pdf
ytLA65K3xJ	2446	CENTROID-BASED JOINT REPRESENTATION FOR HUMAN POSE ESTIMATION AND INSTANCE SEGMENTATION	['Representation Learning', 'Pose Estimation', 'Instance Segmentation', 'Clustering', 'Feature Extraction']		Applications (eg, speech processing, computer vision, NLP)	anonymous|centroidbased_joint_representation_for_human_pose_estimation_and_instance_segmentation	/pdf/6dd3a7aa3882caee3b1fd528af441cbfe7d9006b.pdf
TXH64IwWgS	2447	Inapplicable Actions Learning for Knowledge Transfer in Reinforcement Learning	['reinforcement learning', 'transfer learning']	This paper presents a framework to use, learn and reuse knowledge about sate-dependent inapplicable actions in order improve the sample efficiency of RL algorithms.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|inapplicable_actions_learning_for_knowledge_transfer_in_reinforcement_learning	/pdf/277643fc9201c1649285922e28c51990b66c0f6d.pdf
fKuGCzLoje	2448	Towards A Unified Policy Abstraction Theory and Representation Learning Approach in Markov Decision Processes	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_a_unified_policy_abstraction_theory_and_representation_learning_approach_in_markov_decision_processes	/pdf/533d5c06dde584eff1ac4794129357f7a46827f1.pdf
LGkmUauBUL	2450	Distributional Meta-Gradient Reinforcement Learning	['Reinforcement Learning', 'Meta Learning']	A model-free meta gradient RL algorithm with distributional return	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|distributional_metagradient_reinforcement_learning	/pdf/542b78433c51ce1b8e37d749b6274680cc86be6c.pdf
ymFhZxw70uz	2452	Classically Approximating Variational Quantum Machine Learning with Random Fourier Features	['Quantum Machine Learning', 'Variational Quantum Circuits', 'Random Fourier Features', 'Kernel Approximation', 'Quantum Computing']	We show theoretically and experimentally that models built from exponentially large quantum feature space can be classically reproduced by sampling a few frequencies to build an equivalent low dimensional kernel	General Machine Learning (ie none of the above)	anonymous|classically_approximating_variational_quantum_machine_learning_with_random_fourier_features	/pdf/3cac1e46de3ca07613e99c8f2a2295cc4db54422.pdf
9_pgtXEB652	2453	PBFormer: Capturing Complex Scene Text Shape with Polynomial Band Transformer	['Complex Shape Text Detection', 'Text Representation', 'Transformer', 'Computer Vision', 'Application']	This paper presents PBFormer, an efficient yet powerful scene text detector that unifies the transformer with a novel text shape representation, Polynomial  Band, which performs well for complex shape or crowded texts.	Applications (eg, speech processing, computer vision, NLP)	anonymous|pbformer_capturing_complex_scene_text_shape_with_polynomial_band_transformer	/pdf/97494537bffd7e04b8df32cdba0255fe5251fe31.pdf
WyXH_H0Pdtv	2454	DEEP ACCURATE SOLVER FOR THE GEODESIC PROBLEM	['Geodesic distance', 'Geometric Deep learning.']	Deep Local solver for approximating geodesic distances on manifolds. 	Deep Learning and representational learning	anonymous|deep_accurate_solver_for_the_geodesic_problem	/pdf/27a47c78d2b9f4fdd30463cb25a19815843c3986.pdf
A6MliD2e5Xp	2455	Window Projection Features are All You Need for Time Series Anomaly Detection	['time series', 'anomaly detection']	A simple hand-crafted representation combined with a Gaussian estimator obtains SOTA results in time series anomaly detection.	Unsupervised and Self-supervised learning	anonymous|window_projection_features_are_all_you_need_for_time_series_anomaly_detection	/pdf/4f02492689f20a39edd2fe095f97bae39d7dd27f.pdf
7frgl8pKJpY	2456	Supplementing Domain Knowledge to BERT with Semi-structured Information of Documents	['Domain adaptation', 'Semi-structured information', 'BERT', 'Pre-trained language model', 'Biomedical question answering']	A new domain adaptation method is proposed, which emphasize the importance of semi-structured information of documents for BERT capturing domain knowledge.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|supplementing_domain_knowledge_to_bert_with_semistructured_information_of_documents	/pdf/f2c0fe2153bfcf64e48106385f6029e104ab60ef.pdf
2nLeOOfAjK	2459	Versatile Neural Processes for Learning Implicit Neural Representations	['Implicit Neural Representations', 'Neural Processes', 'Variational Inference']	We propose a new neural process framework for efficient learning of the implicit neural representations w.r.t. various signals, including complex 3D scenes.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|versatile_neural_processes_for_learning_implicit_neural_representations	/pdf/ba1bc6883daabb8b5c0d55dbacf6256424aa6e89.pdf
akk2jh4nMN7	2460	Volumetric Disentanglement  for 3D Scene Manipulation	['3D Object Editing', 'Neural Radiance Fields', 'Disentanglement']	We propose a framework for disentangling a 3D scene into a foreground and background volumetric representations and show a variety of downstream applications involving 3D manipulation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|volumetric_disentanglement_for_3d_scene_manipulation	/pdf/a1b97fb007c0b2193205e2b4f7631374b89fb840.pdf
_QLsH8gatwx	2461	Simplicial Hopfield networks	['Hopfield network', 'associative memory', 'attention', 'computational neuroscience', 'simplicial complex', 'topology', 'memory capacity']	Without increasing the number of parameters, we improve the memory capacity of Hopfield networks by adding setwise connections embedded in a simplicial complex.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|simplicial_hopfield_networks	/pdf/d51b42e53de66ca26015fe46995550a0a6f6c4a8.pdf
u9sFrzSBRK8	2462	Learning Combinatorial Node Labeling Algorithms	['graph learning', 'reinforcement learning', 'combinatorial optimization']	We present the combinatorial node labeling framework and an accompanying neural network architecture to solve hard graph optimization problems.	Deep Learning and representational learning	anonymous|learning_combinatorial_node_labeling_algorithms	/pdf/edf088363332851d4c390ac45593eed366b94c7f.pdf
uagC-X9XMi8	2463	Are More Layers Beneficial to Graph Transformers?	['Transformer', 'Graph Representation', 'Depth']	We analyze and solve the depth bottleneck of graph transformers from the perspective of attention capacity.	Deep Learning and representational learning	anonymous|are_more_layers_beneficial_to_graph_transformers	/pdf/613363c5ad12fb5988c46118ceacf31465078edc.pdf
3lge0p5o-M-	2464	DiffEdit: Diffusion-based semantic image editing with mask guidance	['computer vision', 'image editing', 'diffusion models']		Generative models	anonymous|diffedit_diffusionbased_semantic_image_editing_with_mask_guidance	/pdf/fa0d700608955d36d13858d5de48e133bb6d8570.pdf
55Eet8WGJTv	2466	Lightweight Uncertainty for Offline Reinforcement Learning via Bayesian Posterior	['Offline reinforcement learning', 'Uncertainty quantification', 'Bayesian neural networks']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|lightweight_uncertainty_for_offline_reinforcement_learning_via_bayesian_posterior	/pdf/d05211f3e8b00c941e24441d39ac3fa87acc9cd1.pdf
Q-WfHzmiG9m	2467	Exact Group Fairness Regularization via Classwise Robust Optimization	['Group Fairness', 'DRO']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|exact_group_fairness_regularization_via_classwise_robust_optimization	/pdf/00c1241cd7f9407aa7f1433825299d0b8ed5274d.pdf
NgEuFT-SIgI	2468	ExtraMix: Extrapolatable Data Augmentation for Regression using Generative Models	['mixup', 'out-of-distribution', 'optimization', 'generative models', 'molecule']	We introduce a new data augmentation method of non-Euclidean data for regression tasks. This method exploits a mixup concept for generating extrapolated samples. Our method can not only generate reliable pseudo-labels, but also improve predictors.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|extramix_extrapolatable_data_augmentation_for_regression_using_generative_models	/pdf/edbda018eafe97291eaebdc7b9f4f96272d21c67.pdf
_CDixzkzeyb	2469	Prompt-to-Prompt Image Editing with Cross-Attention Control	['Image generation', 'Image editing', 'Diffusion models', 'Attention layer', 'Computer vision', 'Machine learning']		Generative models	anonymous|prompttoprompt_image_editing_with_crossattention_control	/pdf/6b62fd993b6968786932646d29c3ee828baf225d.pdf
xjxUjHa_Wpa	2470	VA-DepthNet: A Variational Approach to Single Image Depth Prediction	['Single Image Depth Estimation', 'Variational Approach.']		Applications (eg, speech processing, computer vision, NLP)	anonymous|vadepthnet_a_variational_approach_to_single_image_depth_prediction	/pdf/2edd7f5824c95b96d7bcf472234347072a547050.pdf
NhR0jUSuelq	2471	Improving Model Consistency of Decentralized Federated Learning via Sharpness Aware Minimization and Multiple Gossip Approaches	[]		Deep Learning and representational learning	anonymous|improving_model_consistency_of_decentralized_federated_learning_via_sharpness_aware_minimization_and_multiple_gossip_approaches	/pdf/43bbe5d63afdf962c008b502d3ab0fe8233cd66c.pdf
ZpiJj-PliJs	2472	Deep High-Frequency Extrapolation for Neuronal Spike Restoration	['implicit neural representation', 'neuronal spike reconstruction', 'super resolution', 'high frequency extrapolation', 'in vitro neuronal culture', 'in vivo neural activity']	Transformer reconstruction of high-frequency and high-resolution spikes from low-passed neuronal signals	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|deep_highfrequency_extrapolation_for_neuronal_spike_restoration	/pdf/a5def8330f36a7faa8fcbb669dc67c84fce011ba.pdf
sO1QiAftQFv	2473	E3Bind: An End-to-End Equivariant Network for Protein-Ligand Docking	['protein-ligand docking', 'end-to-end training', 'iterative refinement framework', 'geometric deep learning']	An end-to-end equivariant framework for protein-ligand docking through iterative coordinate refinement with careful consideration of the geometric constraints in docking and the local context of the binding site.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|e3bind_an_endtoend_equivariant_network_for_proteinligand_docking	/pdf/155a90ba2d52a1812fb596e061fcfa0a27ef4181.pdf
9AuIMiZhkL2	2474	Ti-MAE: Self-Supervised Masked Time Series Autoencoders	['Time-Series', 'Autoencoders', 'Representation Learning', 'Self-Supervised Learning']	Self-Supervised Masked Time Series Autoencoders for time series forecasting and classification	Deep Learning and representational learning	anonymous|timae_selfsupervised_masked_time_series_autoencoders	/pdf/4ee4faf4db2ef33459dabf3bbba6a1800812a265.pdf
yf8TiD7HpAN	2475	Revisiting Fast Adversarial Training	['adversarial training，model robustness', 'adversarial examples']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revisiting_fast_adversarial_training	/pdf/dc1187e69cbb0d5b5eb21429e22b395e344ba7c8.pdf
HiuupcGa-0g	2476	Continual Learning via Adaptive Neuron Selection	['continual learning', 'knowledge transfer', 'neural network', 'neuron selection', 'deep learning']	This paper presents a novel continual learning solution with adaptive neuron selection.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|continual_learning_via_adaptive_neuron_selection	/pdf/70887668eb5abc0f227a5efe6a95e91c29dbdcb0.pdf
zOHQGKO3WGY	2477	Bayesian semi-supervised learning with a principled likelihood from a generative model of data curation	['Bayesian deep learning', 'Bayesian neural networks', 'principled likelihoods']	We develop Bayesian semi-supervised learning, by showing that standard SSL objectives can be understood as lower bounds on a principled log-likelihood	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|bayesian_semisupervised_learning_with_a_principled_likelihood_from_a_generative_model_of_data_curation	/pdf/96c88ebc85cb346f5a2c3e4ad0ff7b1991da0e3d.pdf
jotL-ImpbF	2478	A Hierarchical Hyper-rectangle Mass Model for Fine-grained Entity Typing	['entity typing', 'hierarchical classification', 'hRMM', 'geometric embedding']		Applications (eg, speech processing, computer vision, NLP)	anonymous|a_hierarchical_hyperrectangle_mass_model_for_finegrained_entity_typing	/pdf/842fc5862fdc3cf810d4bbb472afb682c6068a58.pdf
j83rZLZgYBv	2479	FrAug: Frequency Domain Augmentation for Time Series Forecasting	['Time series forecasting', 'Data augmentation', 'Few shot learning']	A frequency domain data augmentation technique for time-series forecasting task	Deep Learning and representational learning	anonymous|fraug_frequency_domain_augmentation_for_time_series_forecasting	/pdf/1616885cf0f63f1026141edcc277a44ea8806ba1.pdf
dj_U5MZDia6	2481	The Importance of Suppressing Complete Reconstruction in Autoencoders for Unsupervised Outlier Detection	[]		General Machine Learning (ie none of the above)	anonymous|the_importance_of_suppressing_complete_reconstruction_in_autoencoders_for_unsupervised_outlier_detection	/pdf/98bfcbd296c60ae322b395451dd2d3185fc191a5.pdf
0jxPyVWmiiF	2482	A Convergent Single-Loop Algorithm for Gromov-Wasserstein in Graph Data 	['Gromov-Wasserstein', 'Graph Learning', 'Optimization']	We propose the first provable single-loop algorithm for computing the Gromov-Wasserstein (GW) distance.	Optimization (eg, convex and non-convex optimization)	anonymous|a_convergent_singleloop_algorithm_for_gromovwasserstein_in_graph_data	/pdf/756823f82c870a889abd6aaafd1304f32dd39793.pdf
Bd7GueaTxUz	2483	BAYES RISK CTC: CONTROLLABLE CTC ALIGNMENT IN SEQUENCE-TO-SEQUENCE TASKS	['CTC', 'alignment', 'sequence-to-sequence', 'speech recognition']	A Bayes risk function is applied to each CTC path to express the preference for selected paths and achieve controllable CTC alignment prediction	Applications (eg, speech processing, computer vision, NLP)	anonymous|bayes_risk_ctc_controllable_ctc_alignment_in_sequencetosequence_tasks	/pdf/59103e0aa8d8e91273e3c9194535a69db372cc2a.pdf
arg1dQSS6Mh	2484	Attribute Alignment and Enhancement for Generalized Zero-Shot Learning	['zero-shot learning', 'image classification', 'attribute alignment', 'graph neural network', 'attention network']		Deep Learning and representational learning	anonymous|attribute_alignment_and_enhancement_for_generalized_zeroshot_learning	/pdf/25de1c85a65d9bbe3278d0ab40413b53901ec5b8.pdf
hTCBqt7pgxf	2485	Efficient block contrastive learning via parameter-free meta-node approximation	['Contrastive', 'approximation', 'efficient', 'parameter-free', 'block', 'theory']	A simple block contrastive loss approximation technique to efficiently contrast all negative samples, in linear cluster time, at graph level	Unsupervised and Self-supervised learning	anonymous|efficient_block_contrastive_learning_via_parameterfree_metanode_approximation	/pdf/bdab8c28b740413d5ab287372068c4c1a6fabb86.pdf
-AdWUM183OU	2487	The Dynamic of Consensus in Deep Networks and the Identification of Noisy Labels	['Noisy Labels', 'Training Dynamics', 'Label Noise']	We propose a new way to detect label noise through the lens of model disagreement, and describe a method that improves the SOTA in supervised learning with noisy labels. 	Deep Learning and representational learning	anonymous|the_dynamic_of_consensus_in_deep_networks_and_the_identification_of_noisy_labels	/pdf/87e49a284e1ea3da6994f981920db79d2c3b6850.pdf
ZTK3SefE8_Z	2488	Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search	['symbolic regression', 'Monte Carlo tree search', 'governing equations', 'nonlinear dynamics']	Proposed a novel Symbolic Physics Learner (SPL) machine to discover the mathematical structure of nonlinear dynamics based on limited measurement data.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|symbolic_physics_learner_discovering_governing_equations_via_monte_carlo_tree_search	/pdf/97e82934dd95bd1263472039727979b3d5d0576d.pdf
3_NvTLGjDKy	2489	Unified neural representation model for physical and conceptual spaces	['Neuroscience', 'Grid cell', 'Concept cell', 'Spatial navigation', 'Reinforcement learning', 'Word embedding']	A single model explains how grid-like and concept-specific representations emerge and function in the entorhinal cortex.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|unified_neural_representation_model_for_physical_and_conceptual_spaces	/pdf/ad6f3412d77b40bfc2cee22950ebdced8639d501.pdf
mb7VM83DkyC	2490	On Uni-modal Feature Learning in Multi-modal Learning	['Supervised Multi-modal Late-fusion Learning']		Deep Learning and representational learning	anonymous|on_unimodal_feature_learning_in_multimodal_learning	/pdf/ce4a809486df7d204e9c7360470defe3819c0e5d.pdf
gB-WcoUyyTN	2493	Deep Gaussian Process State-Space Model for Motion Generation via Stochastic Expectation Propagation	['Deep GP-SSM', 'probabilistic model', 'dimension reduction', 'motion synthesis', 'Expectation Propagation']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|deep_gaussian_process_statespace_model_for_motion_generation_via_stochastic_expectation_propagation	/pdf/91f27f8cbf75322c1ab43779301e81c029c2d5e5.pdf
B7gBcrKQCl4	2494	Neural Layered Min-sum Decoders for Algebraic Codes	['Error correction code']	A neural min-sum decoder based on the layered min-sum algorithm with reduced weights and better error rates.	Applications (eg, speech processing, computer vision, NLP)	anonymous|neural_layered_minsum_decoders_for_algebraic_codes	/pdf/28bd9ba2983f9f5ac311dafb562fdfb5cd0625e6.pdf
SWPFPk9Tm81	2495	CLEEGN: A Convolutional Neural Network for Plug-and-Play Automatic EEG Reconstruction	['EEG', 'Brain-computer interface', 'EEG artifact removal', 'convolutional neural network']	A novel CNN model for training-free online EEG reconstruction with the SOTA performance.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|cleegn_a_convolutional_neural_network_for_plugandplay_automatic_eeg_reconstruction	/pdf/310dce44d46063e30144aff28d87d479e30ccdef.pdf
s1KljJpAukm	2496	PowerQuant: Automorphism Search for Non-Uniform Quantization	['deep learning', 'quantization', 'compression', 'acceleration', 'data-free']		Deep Learning and representational learning	anonymous|powerquant_automorphism_search_for_nonuniform_quantization	/pdf/7dd2cc601a4752eee5938cd1d7b1596d4a61e0fa.pdf
NSMlX2F21C7	2497	Contrastive Consistent Representation Distillation	['contrastive learning', 'knowledge distillation', 'model compression']	We propose Contrastive Consistent Representation Distillation (CoCoRD) to provide consistent representations for efficient contrastive-learning-based distillation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|contrastive_consistent_representation_distillation	/pdf/008d27dec41efe4fb6f9d829e09770039940cb5b.pdf
-kzQHkTvyMg	2498	On the Expressive Equivalence Between Graph Convolution and Attention Models	[]		Deep Learning and representational learning	anonymous|on_the_expressive_equivalence_between_graph_convolution_and_attention_models	/pdf/261ac4bc070d872b19d030e1dca03fc801519a35.pdf
nI2HmVA0hvt	2500	Unsupervised visualization of image datasets using contrastive learning	['data visualization', 'contrastive learning']		Unsupervised and Self-supervised learning	anonymous|unsupervised_visualization_of_image_datasets_using_contrastive_learning	/pdf/e2497c1bd8e2e9ccd7bf8d3c2ca0650d8d6c6279.pdf
PcR6Lir5mxu	2501	Planning With Uncertainty: Deep Exploration in Model-Based Reinforcement Learning	['Reinforcement learning', 'exploration', 'uncertainty', 'planning']	Demonstrating deep exploration with MuZero by planning optimistically with epistemic uncertainty	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|planning_with_uncertainty_deep_exploration_in_modelbased_reinforcement_learning	/pdf/5144e5f2d5ff1ff97d23260984118e218f870a08.pdf
KLrGlNoxzb4	2503	Video Scene Graph Generation from Single-Frame Weak Supervision	['computer vision', 'video scene graph generation', 'weakly-supervised learning']	We propose a novel method for weakly-supervised VidSGG task with only single-frame weak supervision.	Applications (eg, speech processing, computer vision, NLP)	anonymous|video_scene_graph_generation_from_singleframe_weak_supervision	/pdf/bc8400b928e62beb72d3f9c599f3d0ff6eef469e.pdf
Dvs-a3aymPe	2504	Searching Lottery Tickets in Graph Neural Networks: A Dual Perspective	['Lottery Tickets Hypothesis', 'Dual Lottery Tickets Hypothesis', 'Graph pooling', 'Graph information bottleneck']	This paper generalizes Dual Lottery Ticket Hypothesis (DLTH) to the graph to address information loss and aggregation failure issues caused by sampling-based GNN pruning algorithms	Deep Learning and representational learning	anonymous|searching_lottery_tickets_in_graph_neural_networks_a_dual_perspective	/pdf/46421a5d80d2c929ac9ffd79b866c58455a2aa50.pdf
05rBhFU3mLX	2505	Accelerated Riemannian Optimization: Handling Constraints to Bound Geometric Penalties	['Riemannian optimization', 'geodesic convexity', 'first-order accelerated methods']	We propose accelerated first-order methods for Riemannian optimization in Hadamard manifolds by using a proximal method that we design. We can work without undesirable assumptions previous accelerated works made	Optimization (eg, convex and non-convex optimization)	anonymous|accelerated_riemannian_optimization_handling_constraints_to_bound_geometric_penalties	/pdf/6d9fa0bc83e55612e44d6376b1bb3d324e18139f.pdf
Ojpb1y8jflw	2506	StyleMorph: Disentangling Shape, Pose and Appearance through 3D Morphable Image and Geometry Generation 	['3D-aware GAN', 'Template-based', 'Morphable', 'Disentanglement', 'Photorealistic', 'Neural Radiance Field', 'StyleGAN']	A deformable 3D-aware photorealistic image generator	Generative models	anonymous|stylemorph_disentangling_shape_pose_and_appearance_through_3d_morphable_image_and_geometry_generation	/pdf/b427c8a4d3f0c6b561299e13079f1cffdb342e23.pdf
9ts90B3xUvP	2507	Multiple Invertible and Equivariant Transformation for Disentanglement in VAEs	['Variational AutoEncoder (VAE)', 'Unsupervised Disentanglement Learning', 'Invertible and Equivariant function', 'Exponential Family']	We improve disentangled representation learning with Multiple Invertible and Equivariant transformation (MIE-transformation) in VAEs.	Deep Learning and representational learning	anonymous|multiple_invertible_and_equivariant_transformation_for_disentanglement_in_vaes	/pdf/09445934ef3e69e93a2def3fb9589261a736a868.pdf
dRjWsd3gwsm	2508	MixPro: Data Augmentation with MaskMix and Progressive Attention Labeling for Vision Transformer	[]		Deep Learning and representational learning	anonymous|mixpro_data_augmentation_with_maskmix_and_progressive_attention_labeling_for_vision_transformer	/pdf/2ec2007599d82269c6e30c9e1035535d06700cdd.pdf
fxC7kJYwA_a	2509	New Insights for the Stability-Plasticity Dilemma in Online Continual Learning	['Continual Learning', 'Online Continual Learning', 'Catastrophic Forgetting']	We propose a novel online continual learning framework that utilizes multi-scale feature maps in addition to a structure-wise distillation loss and a stability-plasticity normalization module to maintain high stability and plasticity simultaneously.	Deep Learning and representational learning	anonymous|new_insights_for_the_stabilityplasticity_dilemma_in_online_continual_learning	/pdf/01928204397e720e61dc4722b8e44962168e56a8.pdf
Yt-yM-JbYFO	2510	Efficient Offline Policy Optimization with a Learned Model	['Offline RL', 'Model-based RL']	We propose a regularized one-step model-based method that outperforms MuZero Unplugged on Atari benchmark.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|efficient_offline_policy_optimization_with_a_learned_model	/pdf/541e36666c86deb3e7fe9656052a34a3694bcf79.pdf
y_sZyxuuFh3	2512	RankCSE: Unsupervised Sentence Representations Learning via Learning to Rank	['sentence representations', 'self-supervised learning', 'learning to rank']	We learn semantically discriminative sentence representations by incorporating ranking consistency and ranking distillation with contrastive learning into a unified framework.	Applications (eg, speech processing, computer vision, NLP)	anonymous|rankcse_unsupervised_sentence_representations_learning_via_learning_to_rank	/pdf/6e156489b856a85152de2d3c55e79ee5521ab2a5.pdf
nP7f5XW4FVa	2513	Understanding Adversarial Transferability in Federated Learning	['federared learning', 'adversarial attack', 'transfer-based black-box attack']	This paper proposes a different, simpler but paratical setting for evaluating the robustness of federated learning. To understand the robustness of federated models, this paper investigates two core properties that relates to the transfer robustness.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|understanding_adversarial_transferability_in_federated_learning	/pdf/1ca62ca58aa6cc97690a53df06389ad1d9a051ad.pdf
snktGNQb-kD	2514	DropAut: Automatic Dropout Approaches to learn and adapt Drop Rates	['Deep Learning', 'Neural Networks', 'Dropout', 'Automatic Dropout']	Data-drive extensions of Dropout to automatically detect drop rates	Deep Learning and representational learning	anonymous|dropaut_automatic_dropout_approaches_to_learn_and_adapt_drop_rates	/pdf/d2bc3a1e27afbdbc5858528f1986590061a73449.pdf
6f47WT-HtuH	2515	Unfair geometries: exactly solvable data model with fairness implications	['statistical physics', 'statistical mechanics of learning', 'generalization model', 'modelling structured data', 'data imbalance', 'bias', 'fairness', 'bias mitigation']	We propose a generative model, exactly solvable using statistical physics, which emphasize the impact of data geometry in inducing bias in classification.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|unfair_geometries_exactly_solvable_data_model_with_fairness_implications	/pdf/3d19c3e775036d476d9462b4b6802f509b7977f4.pdf
3Bh6sRPKS3J	2516	Hyperbolic Self-paced Learning for Self-supervised Skeleton-based Action Representations	[]		Unsupervised and Self-supervised learning	anonymous|hyperbolic_selfpaced_learning_for_selfsupervised_skeletonbased_action_representations	/pdf/051414d3cf1c5da996da9040fa2c5fefdcc859da.pdf
gncu27b4elL	2517	Detecting Backdoor Attacks via Layer-wise Feature Analysis	['Backdoor Detection', 'Backdoor Defense', 'Backdoor Learning', 'Trustworthy ML', 'AI Security']	We find out that the feature difference between benign and poisoned samples tends to reach the maximum at a critical layer, based on which we propose a simple yet effective method to filter poisoned samples by analyzing the features at that layer.	Deep Learning and representational learning	anonymous|detecting_backdoor_attacks_via_layerwise_feature_analysis	/pdf/fceec6cedb5cbcb82297f2e5a861cdbf21aab7af.pdf
0YYQ_KKsIZ	2518	BrGANs: Stabilizing GANs' Training Process with Brownian Motion Control	['GAN', 'stability', 'control theory', 'Brownian motion']	We propose a higher order Brownian Motion Controller (BMC) for BrGANs to stablize GANs' training process 	Generative models	anonymous|brgans_stabilizing_gans_training_process_with_brownian_motion_control	/pdf/bc3e3b07691aa61dfa5aaa88aacecbec7a3d11f8.pdf
OjDkC57x5sz	2519	Blurring Diffusion Models	['blurring', 'diffusion', 'generative model']	We show that blurring can equivalently be defined through a Gaussian diffusion process with non-isotropic noise, bridging the gap between inverse heat dissipation and denoising diffusion	Generative models	anonymous|blurring_diffusion_models	/pdf/084976d3bf7c3c533c0dd38143055b5a77ade280.pdf
LOTGOB5_Xh2	2521	Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN	['Self-supervised Learning', 'Vision Transformer', 'Representation Learning', 'Unsupervised Learning']	We delve deep into masked image modeling (MIM) working mechanism and propose a generic pre-training framework (A$^2$MIM) for Transformers and CNNs.	Unsupervised and Self-supervised learning	anonymous|architectureagnostic_masked_image_modeling_from_vit_back_to_cnn	/pdf/19bee23aa47aa724d6d78be5e257347117d961c7.pdf
mfPEzfKJL4n	2523	Exploring Generalization of Non-Contrastive self-supervised Learning	['contrastive learning', 'representation learning']	We give an upper bound on the generalization error rateof non-contrastive learning methods represented by Barlow Twins and SimSiam.	Unsupervised and Self-supervised learning	anonymous|exploring_generalization_of_noncontrastive_selfsupervised_learning	/pdf/5f9d06e0c2554da5be67ea14e424c6986a0864f6.pdf
IUGwUr5_9wY	2527	DISCO-DANCE: Learning to Discover Skills with Guidance	['Unsupervised skill discovery', 'Reinforcement Learning']	This paper proposes a novel unsupervised skill learning algorithm GSD, which attempts to provide direct guidance in order to accelerate the learning process of diverse skills by encouraging further exploration.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|discodance_learning_to_discover_skills_with_guidance	/pdf/a0a54fa687a1dce4a87805d7caee98c0e9572444.pdf
sKHqgFOaFXI	2528	How Informative is the Approximation Error from Tensor Decomposition for Neural Network Compression?	['Tensor Decomposition', 'Convolutional Neural Networks', 'Compression']	We show empirically an approximation error resulting from compressing a network layer with tensor decomposition is correlated with the classification error, enabling the choice of layer, decomposition and rank to be based on the approximation error.	Deep Learning and representational learning	anonymous|how_informative_is_the_approximation_error_from_tensor_decomposition_for_neural_network_compression	/pdf/8feb9f050fbd0d2ed72fe4b5de23d05433b080dd.pdf
i2_TvOFmEml	2529	MultiViz: Towards Visualizing and Understanding Multimodal Models	['multimodal learning', 'representation learning', 'interpretation', 'visualization']	MultiViz is a framework for visualizing & understanding multimodal models across unimodal importance, cross-modal interactions, multimodal representations & multimodal prediction that enables model understanding, error analysis & model debugging.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|multiviz_towards_visualizing_and_understanding_multimodal_models	/pdf/87b216220e8583a07f161dca0add7d116438ef63.pdf
JjEtPDn0eRb	2533	MATS: Memory Attention for Time-Series forecasting	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|mats_memory_attention_for_timeseries_forecasting	/pdf/68696226f767c51b37a6910debbb094a33543392.pdf
U7LLhh3VFxH	2534	ESP: Exponential Smoothing on Perturbations for Increasing Robustness to Data Corruptions	['Deep Learning', 'Model Robustness', 'Domain Generalization', 'Common Corruption']	A high-level data augmentation method to increase model robustness against unforeseen data corruptions.	Deep Learning and representational learning	anonymous|esp_exponential_smoothing_on_perturbations_for_increasing_robustness_to_data_corruptions	/pdf/4f52caf40c3236934ec585392450b133d6e73240.pdf
H4xO3doonl-	2535	Optimising Event-Driven Spiking Neural Network with Regularisation and Cutoff	['Spiking Neural Network', 'Event-driven Neural Network', 'ANN-to-SNN Conversion']	Two novel optimisation techniques are presented to consider anytime optimal inference SNNs,  AOI-SNNs: a regularisation and a cutoff.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|optimising_eventdriven_spiking_neural_network_with_regularisation_and_cutoff	/pdf/26038235d41a00a33c80533e236a8b4e6b4ebe76.pdf
ib482K6HQod	2536	Model Obfuscation for Securing Deployed Neural Networks	['model obfuscation', 'AI safety', 'AI system']	"A model obfuscation method to make the AI model ""unreadable""."	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|model_obfuscation_for_securing_deployed_neural_networks	/pdf/38ec25c9f700085ae39830a0e47b0fa288b221b2.pdf
2lbtqs4enl	2537	Optimising 2D Pose Representation: Improving Accuracy, Stability and Generalisability inUnsupervised 2D-3D Human Pose Estimation	['Unsupervised Learning', '3D Human Pose Estimation', 'Data Representation', 'Adversarial Learning']	Investigating how the representation of a 2D pose can effect the 3D ordinate predictions during the unsupervised adversarial 2D-3D lifting cycle.	Applications (eg, speech processing, computer vision, NLP)	anonymous|optimising_2d_pose_representation_improving_accuracy_stability_and_generalisability_inunsupervised_2d3d_human_pose_estimation	/pdf/f009308a735989460c693ef695855bb9909718ab.pdf
aqvU0FfRqT	2538	Is Class Incremental Learning Truly Learning Representations Continually?	['continual learning', 'class-incremental learning', 'representation learning']		Deep Learning and representational learning	anonymous|is_class_incremental_learning_truly_learning_representations_continually	/pdf/508c782fde12fc49908f41d6dbc59925103170d7.pdf
f13bbIPM1hG	2539	Pixel-Level Task Helps Pruned Network Transfer to Downstream Tasks	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|pixellevel_task_helps_pruned_network_transfer_to_downstream_tasks	/pdf/50d2c5395aa1741d8d22756fe6192a57ff3530e5.pdf
bz3MAU-RhnW	2540	Where to Go Next for Recommender Systems? ID- vs. Modality-based recommender models revisited	[]		Deep Learning and representational learning	anonymous|where_to_go_next_for_recommender_systems_id_vs_modalitybased_recommender_models_revisited	/pdf/2f206b4dd0bc4aeda71dcb2a55ee43b41ac0a5b4.pdf
dYFg48Ye6rl	2541	Linear Scalarization for Byzantine-Robust Learning on non-IID data	['Byzantine SGD', 'Distributed Deep Learning', 'Non-IID']	An enhancing method for current Byzantine defenses when data between clients is unbalanced.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|linear_scalarization_for_byzantinerobust_learning_on_noniid_data	/pdf/badc3109e028b683335891f1693f765366c24bd9.pdf
zjSeBTEdXp1	2542	Deep Generative Wasserstein Gradient Flows	['deep generative modeling', 'gradient flow']	We scale Wasserstein gradient flows to high dimensional image generation tasks.	Generative models	anonymous|deep_generative_wasserstein_gradient_flows	/pdf/9a27c55ae26a6818035c243c1d92a9c82c986dbc.pdf
yyygh7OqdCQ	2543	Gradient-Informed Quality Diversity for the Illumination of Discrete Spaces	['Quality Diversity', 'Latent Space', 'Protein']	We present a method to use gradient information for Quality Diversity in the case where those functions are differentiable and the input variables are discrete.	General Machine Learning (ie none of the above)	anonymous|gradientinformed_quality_diversity_for_the_illumination_of_discrete_spaces	/pdf/57f1f7a0ace4393206d443c0b6802a84b7996678.pdf
AykEgQNPJEK	2546	Score-Based Graph Generative Modeling with Self-Guided Latent Diffusion	['Generative Model', 'Diffusion Model', 'Graph Generation']	We propose a novel and unified latent-based framework Score-Based Graph Generative Model powered by Self-Guided Latent Diffusion to promote graph generation in different scenarios.	Generative models	anonymous|scorebased_graph_generative_modeling_with_selfguided_latent_diffusion	/pdf/14a6af3ea8c3b9492e17cbc10eac048660a22c09.pdf
jBPvRLKP_n_	2547	Lossy Compression with Gaussian Diffusion	['diffusion', 'compression', 'information theory']	Theoretical and empirical results on a novel lossy compression approach using diffusion models	Generative models	anonymous|lossy_compression_with_gaussian_diffusion	/pdf/13e87d4a7ef21dc7d8cb31224fe6c8b8f94a32aa.pdf
t_OZ5jexnbH	2548	SDT: Specific Domain Training in Domain Generalization	['Deep learning', 'Computer vision', 'Domain generalization', 'Spurious features unfolding', 'Specific domain training']	we discern the spurious features by specific domain training.  	Applications (eg, speech processing, computer vision, NLP)	anonymous|sdt_specific_domain_training_in_domain_generalization	/pdf/1434bd95f55c300af19ec071316242ecd1b5d170.pdf
O4fNuE8F51T	2549	PMixUp: Simultaneous Utilization of Part-of-Speech Replacement and Feature Space Interpolation for Text Data Augmentation	['text augmentation', 'part-of-speech', 'feature space interpolation']	We propose novel text augmentation method that accomplishes cutting-edge state-of-the-art performance in various benchmark settings.	Applications (eg, speech processing, computer vision, NLP)	anonymous|pmixup_simultaneous_utilization_of_partofspeech_replacement_and_feature_space_interpolation_for_text_data_augmentation	/pdf/5d2124f5ada0bef09b41fcb1d7f8490b57ae303b.pdf
_E9ibRUQ1iq	2550	Uncovering the Effectiveness of Calibration on Open Intent Classification	['open intent classification', 'model calibration', 'label smoothing']	We propose novel calibration-based open intent classification approach and provide corresponding analyses in public benchmark settings	Applications (eg, speech processing, computer vision, NLP)	anonymous|uncovering_the_effectiveness_of_calibration_on_open_intent_classification	/pdf/3facaf4881d8d833cdcc9b518a99fa8a422d4ee9.pdf
BNsuf5g-JRd	2552	Solving Partial Label Learning Problem with Multi-Agent Reinforcement Learning	[]		Unsupervised and Self-supervised learning	anonymous|solving_partial_label_learning_problem_with_multiagent_reinforcement_learning	/pdf/d7bd458b34d72121a2a6cea8eb5e6af29e8ea8dc.pdf
xnscpQU6lvh	2553	Symmetrical SyncMap for Imbalanced General Chunking Problems	['Self-organization', 'Adaptive learning', 'Chunking', 'New learning paradigm', 'Bio-inspired learning', 'Structure learning']	Null	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|symmetrical_syncmap_for_imbalanced_general_chunking_problems	/pdf/44aab80c1447b0da996461015aa79c7b84c39e72.pdf
jTfflGKNEjb	2554	$\textrm{D}^3\textrm{Former}$: Debiased Dual Distilled Transformer for Incremental Learning	['Incremental Learning', 'Transformers']	Adapting a hybrid ViT for class incremental learning	Deep Learning and representational learning	anonymous|\textrmd^3\textrmformer_debiased_dual_distilled_transformer_for_incremental_learning	/pdf/5d062100fe2e6f38162eb5a866a359a49f163550.pdf
KDhFkA6MQsW	2555	Faster Gradient-Free Methods for Escaping Saddle Points	[]		Optimization (eg, convex and non-convex optimization)	anonymous|faster_gradientfree_methods_for_escaping_saddle_points	/pdf/1ceb5004b2bb8bf66c10f9c73607d3b6e8f4822e.pdf
WAgXmT8BeRj	2557	MARS: Meta-learning as Score Matching in the Function Space	['score estimation', 'meta-learning', 'bayesian neural networks']	Meta-learning in the function space by estimating the score function of the data-generating process marginals.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|mars_metalearning_as_score_matching_in_the_function_space	/pdf/2016e7373f3daad538fc2a8bb8ece47189db771b.pdf
M95oDwJXayG	2559	Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation	['Domain adaptation', 'parameter choice', 'model selection', 'aggregation', 'importance weighting']	A method for addressing the issue of hyper-parameter selection in unsupervised domain adaptation.	Deep Learning and representational learning	anonymous|addressing_parameter_choice_issues_in_unsupervised_domain_adaptation_by_aggregation	/pdf/a575847abe9fb1bec70be8019b0078fa9860bb3e.pdf
qpeAhwxTopw	2560	Identical Initialization: A Universal  Approach to Fast and Stable Training of Neural Networks	['Initialization', 'Idetity Matrix', 'Dynamical Isometry']	A simple and general method for stable training	Deep Learning and representational learning	anonymous|identical_initialization_a_universal_approach_to_fast_and_stable_training_of_neural_networks	/pdf/656287a900e14a4be2b682234203c8fcfd90c89e.pdf
9ImtNIZ7bYx	2561	Finding the global semantic representation in GAN through Fréchet Mean	['generative adversarial network', 'disentanglement', 'semantic factorization']	We propose the global basis for semantics in the latent space of GAN through Fréchet Mean.	Generative models	anonymous|finding_the_global_semantic_representation_in_gan_through_fréchet_mean	/pdf/638775bb96dc2b06bda319340a055541be6a26c7.pdf
tlhsswFz9x	2562	Learning Graph Neural Network Topologies	[]		Deep Learning and representational learning	anonymous|learning_graph_neural_network_topologies	/pdf/48868383be4fb6c14a1396585baddcc526fb4ed0.pdf
U4llPAUi4z	2563	Distill Vision Transformers to CNNs via Low-Rank Representation Approximation	['Knowledge Distillation', 'Low rank approximation', 'Transformer', 'Representation Learning']	Distill Vision Transformers to CNNs via Low-Rank Representation Approximation	Deep Learning and representational learning	anonymous|distill_vision_transformers_to_cnns_via_lowrank_representation_approximation	/pdf/18e8b35f8f0426021c074d90e2524e3065b01f86.pdf
2nocgE1m0A	2564	KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Low-Resource NLP	['Data Augmentation', 'Low-Resource NLP']	We propose a Knowledge Mixture Data Augmentation Model (KnowDA) that is trained with diverse NLP task knowledge. KnowDA could generate additional synthetic data to improve model performance in various low-resource NLP tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|knowda_allinone_knowledge_mixture_model_for_data_augmentation_in_lowresource_nlp	/pdf/23a2441a6ba4940cb107c9e4fd14871864153113.pdf
O7x_ldrlaO7	2565	Structural Privacy in Graphs	['Privacy', 'Graph Neural Networks', 'Differential Privacy', 'Graph Structure']	Make the structure of the graph private in addition to the privacy of node features and labels	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|structural_privacy_in_graphs	/pdf/f28f2d0c9e7e98f33503e4749ae64206a5d08c22.pdf
WmvIJJgt8L	2566	ADVERSARY-AWARE PARTIAL LABEL LEARNING WITH LABEL DISTILLATION	['weak supervised learning', 'partial label learning']		Deep Learning and representational learning	anonymous|adversaryaware_partial_label_learning_with_label_distillation	/pdf/f773929cf95d1df6fe8936379c3fbf6a77cdf10d.pdf
E94ID_k7CTA	2567	How and Why We Detect Distribution Shift: Critical Analysis of Methods and Benchmarks	['Open-set Recognition', 'Out of distribution Detection']	we aim to provide a consolidated view of the two largest sub-fields: open-set recognition (OSR) and out-of-distribution detection (OOD)	Deep Learning and representational learning	anonymous|how_and_why_we_detect_distribution_shift_critical_analysis_of_methods_and_benchmarks	/pdf/51b768c253c22796f340aabd22cea7f85709567d.pdf
3jBXX9Xb1iz	2568	Multi-Label Knowledge Distillation	[]		Deep Learning and representational learning	anonymous|multilabel_knowledge_distillation	/pdf/823e9515198900fe956eb348c75ba6e1284e0e79.pdf
ndYrOsNw_B2	2569	Dynamical Equations With Bottom-up Self-Organizing Properties Learn Accurate Dynamical Hierarchies Without Any Loss Function	['self-organization', 'dynamical systems', 'continual learning', 'dynamical hierarchy', 'adaptation']		General Machine Learning (ie none of the above)	anonymous|dynamical_equations_with_bottomup_selforganizing_properties_learn_accurate_dynamical_hierarchies_without_any_loss_function	/pdf/045d124650dc3f4b59bbd765b8148dfeba140e00.pdf
d77RVuVg-Mf	2570	UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video UniFormer	['Vision Transformer', 'Action Recognition', 'Video Learning']	We propose UniFormerV2, which aims to arm the well-pretrained vision transformer with efficient video UniFormer designs, and achieves state-of-the-art results on 8 popular video benchmarks.	Deep Learning and representational learning	anonymous|uniformerv2_spatiotemporal_learning_by_arming_image_vits_with_video_uniformer	/pdf/772c8ba58b97716393f6496eb19841588c1bad3e.pdf
Z4CUw1pIuor	2571	RotoGBML: Towards Out-of-Distribution Generalization for Gradient-Based Meta-Learning	[]		Deep Learning and representational learning	anonymous|rotogbml_towards_outofdistribution_generalization_for_gradientbased_metalearning	/pdf/8c1445fc13fff1fa452ec6dbb7a3f429efc416f3.pdf
3nfMmcditWu	2572	Breaking the Curse of Dimensionality for Parametric Elliptic PDEs	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|breaking_the_curse_of_dimensionality_for_parametric_elliptic_pdes	/pdf/6641f43116792c3c90c817cfcb1a8dde7b8b4965.pdf
n-bvaLSCC78	2573	EA-HAS-Bench: Energy-aware Hyperparameter and Architecture Search Benchmark	[]	We provide the first HAS dataset aware of the overall search energy cost	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|eahasbench_energyaware_hyperparameter_and_architecture_search_benchmark	/pdf/11101f99acb8cc5b2cb3cdb75e91bb429d1d0f32.pdf
zhl5bWOCD4v	2574	Efficient Point Cloud Geometry Compression Through Neighborhood Point Transformer	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|efficient_point_cloud_geometry_compression_through_neighborhood_point_transformer	/pdf/56b3668cfb498fef44a6fd3310a5bf4ff600825c.pdf
Ki_26lfEmey	2575	Joint Attention-Driven Domain Fusion and Noise-Tolerant Learning for Multi-Source Domain Adaptation	['Multi-source Unsupervised Domain Adaptation', 'Attention Mechanism', 'Noisy Label Learning']		Deep Learning and representational learning	anonymous|joint_attentiondriven_domain_fusion_and_noisetolerant_learning_for_multisource_domain_adaptation	/pdf/db7d0bcc0b97720a98b539db2977e306a59ef7c1.pdf
Gg5PaJRQbRw	2577	On Incremental Learning with Long Short Term Strategy	[]		Deep Learning and representational learning	anonymous|on_incremental_learning_with_long_short_term_strategy	/pdf/1e5666f2fe91c0960059887d1646d33b017036f5.pdf
xACeXHo4sf	2580	Vera Verto: Multimodal Hijacking Attack	['Hijacking Attack', 'Modal Hijacking', 'Computer Vision', 'Natural Language Processing']	We propose a new multimodal hijacking attack where the adversary can implement a hijacking task from a completely different domain.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|vera_verto_multimodal_hijacking_attack	/pdf/541919584ac76ebcc949f0fe91b5011e6e99c755.pdf
sIoED-yPK9l	2581	Massively Scaling Heteroscedastic Classifiers	[]		Deep Learning and representational learning	anonymous|massively_scaling_heteroscedastic_classifiers	/pdf/deacf791ce328c7288ac5622c5d51a93987faa93.pdf
jEV-GgJ6kRO	2582	Sinkhorn Discrepancy for Counterfactual Generalization	['causal inference', 'treatment selection bias']		Deep Learning and representational learning	anonymous|sinkhorn_discrepancy_for_counterfactual_generalization	/pdf/7e7af073b4ae0174257edfa25359fbb6709f37d5.pdf
FkSp8VW8RjH	2584	Language Modelling with Pixels	['representation learning', 'nlp', 'transformers', 'language model', 'masked autoencoder']	We train PIXEL, a language model that operates solely on images of rendered text, and show that it is possible to transfer representations across languages based on orthographic similarity or the co-activation of pixels.	Applications (eg, speech processing, computer vision, NLP)	anonymous|language_modelling_with_pixels	/pdf/0217ec0876c79f136f4ebc5cb1c004f3c12a3a87.pdf
Y9gIpiWNvtp	2585	Existence of a bad local minimum of neural networks with general smooth activation functions	['local minimum', 'smooth activation', 'neural networks']	We investigate the existence of a bad local minimum of neural networks with general smooth activation functions.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|existence_of_a_bad_local_minimum_of_neural_networks_with_general_smooth_activation_functions	/pdf/02832ae4cdb2a8f202f9c50573b373cc9e65b438.pdf
cnsHSSLnHVV	2586	Equivariant 3D-Conditional Diffusion Models for Molecular Linker Design	['Molecules', 'Drug Discovery', 'Molecular Linker Design', 'Equivariant', 'Diffusion Models']	We propose a conditional diffusion model for generating molecular linkers between disconnected fragments in 3D	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|equivariant_3dconditional_diffusion_models_for_molecular_linker_design	/pdf/d1d45be386a1a66f9df31e9347de6b1f804861e2.pdf
eqOVZS7MKPN	2587	Siamese Image Modeling for Self-Supervised Vision Representation Learning	[]		Unsupervised and Self-supervised learning	anonymous|siamese_image_modeling_for_selfsupervised_vision_representation_learning	/pdf/0deae851f2f4dcbf31595ac9ab8d2bd7419db1ac.pdf
YgC62m4CY3r	2589	Learning with Auxiliary Activation for Memory-Efficient Training	['Memory Efficient Training', 'Auxiliary Activation', 'Backpropagation', 'Deep Learning']	The proposed learning rule reduces training memory requirements without reduction in training speed while achieving high performance close to backpropagation.	Deep Learning and representational learning	anonymous|learning_with_auxiliary_activation_for_memoryefficient_training	/pdf/1eb4440f0383c5263f010b286d6ba26298a998bf.pdf
n9iRY8XFfXW	2590	FEAT: A general framework for Feature-aware Multivariate Time-series Representation Learning 	['multivariate time-series', 'representation learning', 'self-supervised learning', 'contrastive learning', 'gating', 'reconstruction']	A self-supervised framework for learning feature-aware multivariate time-series representation	Deep Learning and representational learning	anonymous|feat_a_general_framework_for_featureaware_multivariate_timeseries_representation_learning	/pdf/d800ccd81babc42aad4d681232d856d967bd4054.pdf
rWW2WAGjfOi	2591	learning hierarchical multi-agent cooperation with long short-term intention	['hierarchical multi-agent reinforcement learning', 'intention', 'communication', 'attention', 'behavior inference']	This paper proposes a new hierarchical multi-agent cooperation framework which leverages long short-term intention to improve agents' coordination	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_hierarchical_multiagent_cooperation_with_long_shortterm_intention	/pdf/1b9da6aeeb59ec2e3e8ff3b77e012055be349981.pdf
PEgBEB74JjB	2592	The Generalized Eigenvalue Problem as a Nash Equilibrium	['generalized eigenvalue problem', 'nash', 'riemannian optimization', 'canonical correlation analysis', 'independent component analysis', 'distributed computing']	We formulate the solution to the generalized eigenvalue problem as the Nash of a game, design an unbiased streaming-style algorithm to solve it, and analyze neural representations 1000x larger than before.	General Machine Learning (ie none of the above)	anonymous|the_generalized_eigenvalue_problem_as_a_nash_equilibrium	/pdf/d82e073ec1438e07753dcee0c8173adfba7855eb.pdf
z2kUV2XQBT2	2593	Name Your Colour For the Task: Artificially Discover Colour Naming via Colour Quantisation Transformer	['colour quantisation', 'image compression', 'artificial colour naming system']	a new colour quantistaion transformer to artificially discover and evolve colour naming system similar in human language	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|name_your_colour_for_the_task_artificially_discover_colour_naming_via_colour_quantisation_transformer	/pdf/0dbd438d2daa399457094d6cc4b1b20e73392d52.pdf
yBKkp5LT3FX	2594	Restricted Generative Projection for One-Class Classification and Anomaly detection	[]		General Machine Learning (ie none of the above)	anonymous|restricted_generative_projection_for_oneclass_classification_and_anomaly_detection	/pdf/ac4977674c68c504d6bf147295dc102d6d24b4d9.pdf
C-xa_D3oTj6	2595	DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems	['reinforcement learning', 'musculoskeletal', 'correlated exploration']	A technique from the self-organization literature is used to improve performance of RL agents on overactuated systems with up to 120 muscle actuators.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|deprl_embodied_exploration_for_reinforcement_learning_in_overactuated_and_musculoskeletal_systems	/pdf/f5bd69a7799bfbabdf252545001d1e40b404f083.pdf
Nn-7OXvqmSW	2596	Variance Covariance Regularization Enforces Pairwise Independence in Self-Supervised Representations	['Self-supervised learning', 'VICReg', 'Barlow Twins', 'HSIC']	We study how SSL methods such as VICReg and Barlow Twins enforce pairwise independence of representations via their Variance Covariance regularization (VCReg), improve VICReg using our findings and show VCReg to be beneficial outside of SSL.	Deep Learning and representational learning	anonymous|variance_covariance_regularization_enforces_pairwise_independence_in_selfsupervised_representations	/pdf/e3b60fb4dda7c61688455726e3fb7d56eae95543.pdf
96kgRrpnkgS	2598	Topic and Hyperbolic Transformer to Handle Multi-modal Dependencies	['Multi-modal search', 'Hyperbolic space', 'Hyperbolic geometry', 'Lorentz model', 'Transformer', 'Topic models']		Deep Learning and representational learning	anonymous|topic_and_hyperbolic_transformer_to_handle_multimodal_dependencies	/pdf/6d72d9a87c75d6b201e2d76df4ec3efa0fbfc39e.pdf
22z1JIM6mwI	2599	CAPE: Channel-Attention-Based PDE Parameter Embeddings for SciML	['machine learning', 'partial differential equation', 'attention', 'generalization']	a new parameter embedding module based on channel-attention for scientific machine learning	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|cape_channelattentionbased_pde_parameter_embeddings_for_sciml	/pdf/b01a3a95622425606309cccac5b20b1f8d997dcf.pdf
6K2RM6wVqKu	2600	A Universal 3D Molecular Representation Learning Framework	['Representation Learning', 'Large-Scale 3D Molecular Pretraining', 'Molecular Property', 'Protein-Ligand Complex']	A universal 3D molecular pretraining framework that significantly enlarges the representation ability and application scope in drug design.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_universal_3d_molecular_representation_learning_framework	/pdf/2b47ff18081f96efcecd1d2bb2f96de3eef4c6ae.pdf
aBFFLGhi381	2601	Deep Leakage from Model in Federated Learning	['Federated learning', 'model leakage', 'data security']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|deep_leakage_from_model_in_federated_learning	/pdf/3cac6244bfb7ce7d171ad00e7d3b9bc57726ac97.pdf
ZIkHSXzd9O7	2602	Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|dynamic_updatetodata_ratio_minimizing_world_model_overfitting	/pdf/6932bbef35f0d66afd25fa3a8277ab27145a2144.pdf
v8JIQdiN9Sh	2604	On the effectiveness of out-of-distribution data in self-supervised long-tail learning.	['self-supervised learning', 'long-tail learning', 'out-of-distribution data']		Unsupervised and Self-supervised learning	anonymous|on_the_effectiveness_of_outofdistribution_data_in_selfsupervised_longtail_learning	/pdf/31762d60a9ae2cef33e2738c1eadbee2a7d4ea52.pdf
uu1GBD9SlLe	2605	Simple and Scalable Nearest Neighbor Machine Translation	['Nearest Neighbor', 'Machine Translation']	We propose a simple and scalable nearest neighbor machine translation framework to drastically improve the decoding and storage efficiency of $k$NN-MT	Applications (eg, speech processing, computer vision, NLP)	anonymous|simple_and_scalable_nearest_neighbor_machine_translation	/pdf/987312151f58bf0380ff4c0f7e7790783f78a7c6.pdf
AeTl9sbF-VT	2606	Exploiting Certified Defences to Attack Randomised Smoothing	['adversarial', 'attack', 'certified robustness', 'machine learning']	Certified defences can be used to attack the models they certify, yielding smaller adversarial perturbations	General Machine Learning (ie none of the above)	anonymous|exploiting_certified_defences_to_attack_randomised_smoothing	/pdf/5b0c446e5303c7a2dd0e8f5844f33cedc7e347d1.pdf
ApNK_ApJoec	2608	Disentangling Writer and Character Styles for Handwriting Generation	[]		Generative models	anonymous|disentangling_writer_and_character_styles_for_handwriting_generation	/pdf/0f7d87e908a6c27ec01e4ea3b2bffc19c9f283d8.pdf
v4ePDrH91D	2610	Robust Manifold Estimation Approach for Evaluating Fidelity and Diversity	[]		Generative models	anonymous|robust_manifold_estimation_approach_for_evaluating_fidelity_and_diversity	/pdf/c5d2644c256ad4423901e1d8a5d7cfdaa3747c8b.pdf
BN_P4LNiK2	2611	TOAST: Topological Algorithm for Singularity Tracking	['topology', 'persistent homology', 'topological data analysis', 'tda', 'stratified spaces', 'singularities']	We develop a multi-scale score that characterises singularities of arbitrary (i.e. non-manifold) data spaces	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|toast_topological_algorithm_for_singularity_tracking	/pdf/71a758a65f70febbeaa8e3220ede68a3eade39ed.pdf
XE0cIoi-sZ1	2612	Can Single-Pass Contrastive Learning Work for Both Homophilic and Heterophilic Graph?	['Graph Contrastive Learning']		Deep Learning and representational learning	anonymous|can_singlepass_contrastive_learning_work_for_both_homophilic_and_heterophilic_graph	/pdf/1d438c6c95ddfe6e5da3fc4392aac18410c5ac6c.pdf
lUpjsrKItz4	2613	Unsupervised Manifold Alignment with Joint Multidimensional Scaling	['unsupervised manifold alignment', 'multidimensional scaling', 'optimal transport', 'graph matching']	A novel approach for unsupervised manifold alignment that only requires intra-domain pairwise dissimilarities as input.	General Machine Learning (ie none of the above)	anonymous|unsupervised_manifold_alignment_with_joint_multidimensional_scaling	/pdf/b8d314045afb76ebc48db64768a968e4b98dfb28.pdf
blCpfjAeFkn	2614	Addressing High-dimensional Continuous Action Space via Decomposed Discrete Policy-Critic	['reinforcement learning', 'continuous control', 'actor-critic', 'decomposed policy', 'discretized action']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|addressing_highdimensional_continuous_action_space_via_decomposed_discrete_policycritic	/pdf/0de7e1e41e5b9f6f6e67db3a865906b7b4f5c2db.pdf
ifaAztwEHIN	2616	Learning Basic Interpretable Factors from Temporal Signals via Physics Symmetry	['Physics Symmetry', 'Time series data', 'Self-supervised Learning', 'Representation Augmentation']	This study uses physics symmetry as an effective inductive bias to learn interpretable representations from time-series data in a self-supervised fashion. 	Deep Learning and representational learning	anonymous|learning_basic_interpretable_factors_from_temporal_signals_via_physics_symmetry	/pdf/0828b02e56cb4c84fd7fda929ef830c1a18ab264.pdf
zYWtq_HUCoi	2617	oViT: An Accurate Second-Order Pruning Framework for Vision Transformers	['neural network pruning', 'vision transformer', 'sparsity', 'model compression']	We have proposed a new framework for efficient compression of Vision Transformers with the novel pruning method leveraging second order information and optimization of the training procedure.	Deep Learning and representational learning	anonymous|ovit_an_accurate_secondorder_pruning_framework_for_vision_transformers	/pdf/0974efd43f8844d36c76876288cae9244d4bb148.pdf
SrC-nwieGJ	2618	Relative representations enable zero-shot latent space communication	['relative representation', 'zero-shot', 'stitching', 'invariance', 'latent communication', 'isometry', 'representation learning']	"Relative representations can be leveraged to enable solving tasks regarding ""latent communication"": from zero-shot model stitching to latent space comparison between diverse settings."	Deep Learning and representational learning	anonymous|relative_representations_enable_zeroshot_latent_space_communication	/pdf/47c406d5ef28a46e3761c5434264854d953adc81.pdf
-azium0cV9	2619	SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient	['distributed training', 'model-parallel training', 'model parallelism', 'fault-tolerant training', 'communication efficiency', 'volunteer computing']	We propose a model-parallel training algorithm designed for poorly connected, heterogeneous unreliable devices (i.e. preemptible instances or volunteer devices).	Deep Learning and representational learning	anonymous|swarm_parallelism_training_large_models_can_be_surprisingly_communicationefficient	/pdf/0bfb43ea44d14acaf3a442012901f2d0835f8b97.pdf
yTbNYYcopd	2620	Accurate Neural Training with 4-bit Matrix Multiplications at Standard Formats	['quantization', '4bit', 'acceleration', 'compression']	A method to quantize all training matrix multiplication in 4 bit with standard formats	Deep Learning and representational learning	anonymous|accurate_neural_training_with_4bit_matrix_multiplications_at_standard_formats	/pdf/47af824e1b08f1c8e088ebcb70185ae8c683fb16.pdf
FWPLpE981t	2621	Learning to Counter: Stochastic Feature-based Learning for Diverse Counterfactual Explanations	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_to_counter_stochastic_featurebased_learning_for_diverse_counterfactual_explanations	/pdf/64a95998ddbb4f5f8665d6217f46d699da539a2e.pdf
EzLtB4M1SbM	2622	Test-Time Adaptation via Self-Training with Nearest Neighbor Information	['test-time adaptation', 'domain adaptation', 'domain shift']	This work presents a simple and efficient test-time adaptation method to adapt trained classifiers by utilizing an ensemble of adaptation modules and self-training with nearest neighbor information.	Deep Learning and representational learning	anonymous|testtime_adaptation_via_selftraining_with_nearest_neighbor_information	/pdf/2a2aa831c182ba616227ba3b75a84a14aa3191f0.pdf
9OoFFWDPDQ	2623	Delving into the Openness of CLIP	['Contrastive Language-Image Pre-training', 'CLIP', 'Openness', 'Vision-and-Language']		Deep Learning and representational learning	anonymous|delving_into_the_openness_of_clip	/pdf/a14224e2210df9f3438ecd2ed54364649eb6fbfe.pdf
BcmrpOpUGN2	2624	Warped Convolutional Networks: Bridge Homography to $\mathfrak{sl}(3)$ algebra by Group Convolution	['SL(3)', 'Homography Learning', 'Lie algebra', 'Equivariance', 'Group Equivariant Architecture']	We propose a Warped Convolution Networks to effectively learn the homography on $\mathfrak{sl}(3)$ algebra with group convolution. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|warped_convolutional_networks_bridge_homography_to_\mathfraksl3_algebra_by_group_convolution	/pdf/b01bb3ba2e3cce474ba0d68d64839d5fea617f15.pdf
FZAKltxF4y2	2626	The Multiple Subnetwork Hypothesis: Enabling Multidomain Learning by Isolating Task-Specific Subnetworks in Feedforward Neural Networks	['Neural Networks', 'Multitask Learning', 'Pruning']	"In this paper, we test our ""Multiple Subnetwork Hypothesis,"" which proposes that it is possible to train unused weights within a pruned feedforward neural network to learn subsequent tasks."	Deep Learning and representational learning	anonymous|the_multiple_subnetwork_hypothesis_enabling_multidomain_learning_by_isolating_taskspecific_subnetworks_in_feedforward_neural_networks	/pdf/5f39699111b5254287325870171b2d1639fb90fe.pdf
XrMWUuEevr	2627	Context-enriched molecule representations improve few-shot drug discovery	[]	We introduce a new architecture for few-shot learning in drug discovery that enriches molecule representations by retrieving from a large set of known molecules.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|contextenriched_molecule_representations_improve_fewshot_drug_discovery	/pdf/e6d1757a92eb311fc2c8ac1554c50e585fccafde.pdf
WgvAB2ffyR	2628	Surrogate Gradient Design for LIF networks	['Surrogate Gradients', 'Spiking Networks', 'Neuromorphic Computing', 'Glorot Initialization']	We show how to choose the best surrogate derivative for a non differentiable spiking operation, by different experimental and theoretical means.	Applications (eg, speech processing, computer vision, NLP)	anonymous|surrogate_gradient_design_for_lif_networks	/pdf/180399f63a8b7aa129b215e1a27eb2d1dd10ece2.pdf
4Sp2v2DQcxX	2631	Skill Machines: Temporal Logic Composition in Reinforcement Learning	['Reinforcement Learning', 'Lifelong learning', 'Multi task learning', 'Transfer learning', 'Logical composition', 'Deep Reinforcement Learning']	A framework where an agent first learns a set of base skills in a reward-free setting, and then combines them with the learned skill machine to produce composite behaviours specified by any regular language, such as linear temporal logics.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|skill_machines_temporal_logic_composition_in_reinforcement_learning	/pdf/edfb641aaece56000bf35579c3b74bd9f8a1d0f1.pdf
ApV_xBR9UUC	2632	ML-ViG: Multi-Label Image Recognition with Vision Graph Convolutional Network	['Multi-Label Image Recognition', 'Graph Convolutional Network']	The first fully graph convolutional model for the task of multi-label image recognition.	Applications (eg, speech processing, computer vision, NLP)	anonymous|mlvig_multilabel_image_recognition_with_vision_graph_convolutional_network	/pdf/d1971bfac0c4fdb5477a593be0f469c9c5b33c7a.pdf
wtcud6HroZr	2633	Learning to Decompose Visual Features with Latent Textual Prompts	['CLIP', 'vision-language learning', 'visual prompt']		Deep Learning and representational learning	anonymous|learning_to_decompose_visual_features_with_latent_textual_prompts	/pdf/aa9f4291eecc2de06e2da38665d06903e8734785.pdf
sb-IkS8DQw2	2634	Accurate Bayesian Meta-Learning by Accurate Task Posterior Inference	['Bayesian Meta-Learning', 'Neural Processes', 'Variational Inference']	We show that accurate inference of the task posterior is all you need for accurate Bayesian meta-learning.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|accurate_bayesian_metalearning_by_accurate_task_posterior_inference	/pdf/4a768044492bbb1ec88e480a32814cd6f6d210d6.pdf
SdBfRJE9SX-	2635	What Does Vision Supervision Bring to Language Models? A Case Study of CLIP	['Contrastive Language-Image Pre-training', 'Vision-and-Language', 'Knowledge Probing']		Deep Learning and representational learning	anonymous|what_does_vision_supervision_bring_to_language_models_a_case_study_of_clip	/pdf/89cb13b26c721063feac7c27e487f45ff4f6e3c8.pdf
Hv57u3WQ0WZ	2636	Contrastive Hierarchical Clustering	['clustering', 'hierarchical clustering', 'contrastive learning', 'soft decision trees']	Hierarchical clustering model based on deep neural networks, which has been applied to large-scale image data	Unsupervised and Self-supervised learning	anonymous|contrastive_hierarchical_clustering	/pdf/10d3f29e46c90a2c2b2d875a60097ad50990d816.pdf
BrKY4Wr6dk2	2637	Revisiting Activation Function Design for Improving Adversarial Robustness at Scale	['adversarial training', 'activation function', 'neural network architecture']	ReLU significantly weakens adversarial training, but its smooth approximations can fix this issue	Deep Learning and representational learning	anonymous|revisiting_activation_function_design_for_improving_adversarial_robustness_at_scale	/pdf/d3ffd9f48bfa0b8356bd4c1a17580e6a25929282.pdf
AV_bv4Ydcr9	2639	Attention Enables Zero Approximation Error	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|attention_enables_zero_approximation_error	/pdf/2264fca1c743cf57960c3aac0888dbf7d54b095b.pdf
U7CMcGV6LYM	2640	A Simple, Yet Effective Approach to Finding Biases in Code Generation	['Code generation', 'Natural Language Processing', 'Reasoning', 'Biases']	Code generation models suffer from biases that we can expose with simple tricks	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_simple_yet_effective_approach_to_finding_biases_in_code_generation	/pdf/257ae333392b8cc699563d6cbcd19ca9e3bcc7d4.pdf
bvpkw7UIRdU	2641	On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation	['language generation', 'automatic evaluation', 'contextual embeddings']	We provide a theoretical and empirical analysis of why a recently-proposed automatic evaluation metric for language generators correlates well with human judgments. We identify its use of embeddings from pretrained language models as the main reason.	Applications (eg, speech processing, computer vision, NLP)	anonymous|on_the_usefulness_of_embeddings_clusters_and_strings_for_text_generation_evaluation	/pdf/ef643381158adad21131342361f6a5c0b0fec423.pdf
bkxynaG3Vm7	2642	Schedule-Robust Online Continual Learning	['Continual Learning', 'Online Class-incremental Learning', 'Meta-Learning']	We propose a new continual learning approach that is robust to arbitrary schedules (i.e. permutations of samples in sequences, batch sizes) of a data stream.	Deep Learning and representational learning	anonymous|schedulerobust_online_continual_learning	/pdf/379211f79a266fc66f1f9daa52d1782ac08376b7.pdf
HNcqEt0zuMo	2643	On the Role of Self-supervision in Deep Multi-view Clustering	['deep learning', 'multi-view clustering', 'self-supervised learning']	We investigate self-supervision in deep multi-view clustering, and present several new models and novel findings.	Unsupervised and Self-supervised learning	anonymous|on_the_role_of_selfsupervision_in_deep_multiview_clustering	/pdf/dd2184654dd401bdf99e787ede7d01fde66593d2.pdf
oBXFemWGPWN	2644	Source-Target Coordinated Training with Multi-head Hybrid-Attention for Domain Adaptive Semantic Segmentation	['domain adaptation', 'semantic segmentation']		Unsupervised and Self-supervised learning	anonymous|sourcetarget_coordinated_training_with_multihead_hybridattention_for_domain_adaptive_semantic_segmentation	/pdf/764c1da966f8841139f4a70076ca6c6d5748dbde.pdf
gRgCyyYBR4o	2647	ELBO-ing Stein Mixtures	['Particle-based variational inference', 'alpha-indexed Stein mixtures', 'ELBO-within-Stein']	Stein mixture can be viewed as matching variational- to target-posterior by the Renyi divergence. This leads to a whole class of inference methods using the Renyi divergence's order.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|elboing_stein_mixtures	/pdf/8673a51488f6c27e867a66764463efbd35586852.pdf
8u9eXwu5GAb	2648	Transferring Pretrained Diffusion Probabilistic Models	['transfer learning', 'diffusion probabilistic models', 'cross-attention', 'fine-tuning']	We propose a new tuning approach for transferring pretrained diffusion probabilistic models to new tasks with limited data and training resources.	Generative models	anonymous|transferring_pretrained_diffusion_probabilistic_models	/pdf/17e78b70aa46b9babe7b7c62805be033db8d7b27.pdf
W6t8U1eGvSj	2649	Leveraging Online Semantic Point Fusion for 3D-Aware Object Goal Navigation	['Reinforcement Learning', 'Robot', 'Navigation']	We propose a two-stage reinforcement learning framework that is powered by an online semantic point fusion algorithm.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|leveraging_online_semantic_point_fusion_for_3daware_object_goal_navigation	/pdf/b28b183a651240282e9261e6c287f26997c1c2c4.pdf
Dk7QQp8jHEo	2653	Batch Multivalid Conformal Prediction	['Conformal prediction', 'multicalibration', 'uncertainty quantification']	We give algorithms for conformal prediction in the batch setting that have coverage guarantees even when conditioning on group membership for intersecting groups and on the threshold used to produce the prediction set.	General Machine Learning (ie none of the above)	anonymous|batch_multivalid_conformal_prediction	/pdf/f51356e2e1f71dd4af62cfb16ce383a988901729.pdf
Ms1Zs8s7rg	2654	Demystifying Approximate RL with $\epsilon$-greedy Exploration: A Differential Inclusion View	['differential inclusion', 'epsilon-greedy exploration', 'function approximation', 'value-based RL', 'Q-learning', 'SARSA', 'policy oscillation', 'chattering', 'discontinuous policies', 'stability']	We provide the first framework  for analyzing value-based RL methods with function approximation and $\epsilon$-greedy exploration, answering a long standing open question.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|demystifying_approximate_rl_with_\epsilongreedy_exploration_a_differential_inclusion_view	/pdf/862f01c25d278ae9483e69627a8c8daa4a2dadf0.pdf
8xoV4ZrIgbk	2655	Homeomorphism Alignment in Two Spaces for Unsupervised Domain Adaptation	['Homeomorphism Alignment', 'Unsupervised Domain Adaptation', 'Self-supervised Learning']	A new appraoch uses Homeomorphism property to do Unsupervised Domain Adaptation.	Deep Learning and representational learning	anonymous|homeomorphism_alignment_in_two_spaces_for_unsupervised_domain_adaptation	/pdf/3b30ef33103cfb083051dd8ffa4d2f813895c09d.pdf
ctnmrjv6lU5	2656	RealSinger: Ultra-Realistic Singing Voice Generation via Stochastic Differential Equations	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|realsinger_ultrarealistic_singing_voice_generation_via_stochastic_differential_equations	/pdf/81183336697a51a546f782e46d3b400cdf2fb29a.pdf
F0KTk2plQzO	2657	Accelerating Guided Diffusion Sampling with Splitting Numerical Methods	['Splitting Numerical Methods', 'Guided Diffusion Models']	We accelerate guided diffusion sampling using splitting numerical methods.	Generative models	anonymous|accelerating_guided_diffusion_sampling_with_splitting_numerical_methods	/pdf/a8696eb089ecb7e0ad472b2aee3ddc82d855e6d3.pdf
0f-0I6RFAch	2658	Improving Out-of-distribution Generalization with Indirection Representations	['out-of-distribution generalization', 'indirection', 'representation']		Deep Learning and representational learning	anonymous|improving_outofdistribution_generalization_with_indirection_representations	/pdf/5cc205de913cdc59da35b5b485d45429e51ecd42.pdf
xFnban3-LC	2659	Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal Discovery	['causal discovery', 'experimental design', 'active learning', 'neural networks']	We propose GIT, a novel gradient-based intervention targeting method, which improves the performance of causal discovery, especially in the low data regime.	Deep Learning and representational learning	anonymous|trust_your_\nabla_gradientbased_intervention_targeting_for_causal_discovery	/pdf/33baaa5ac64db0c30b87e82e25d306fcddaff26a.pdf
72ICa7Wb4ui	2662	Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger	['deep learning', 'differential privacy', 'per-sample gradient clipping', 'convergence']	We propose automatic DP optimizers that do not need to tune the clipping threshold, with convergence proof and SOTA accuracy.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|automatic_clipping_differentially_private_deep_learning_made_easier_and_stronger	/pdf/5bafc610712d89700a8d86de1b85db95485950d1.pdf
XKQU-afvHOd	2663	Learning to mine approximate network motifs	['motif mining', 'combinatorics', 'unsupervised learning']	An evaluation framework and model for identifying frequent subgraphs with structural flexibility in large datasets.	General Machine Learning (ie none of the above)	anonymous|learning_to_mine_approximate_network_motifs	/pdf/177c01810c6dd88b3c691fefb9b5dab0d810867f.pdf
QB1dMPEXau5	2664	Does Deep Learning Learn to Abstract? A Systematic Probing Framework	['Abstraction Capability', 'Probing Tasks', 'Deep Learning', 'Pre-Trained Language Model']	We design a systematic probing framework along with a set of controlled probing tasks, providing strong evidence that PLMs have the abstraction capability. We conduct an in-depth analysis and provide insightful conclusions.	Deep Learning and representational learning	anonymous|does_deep_learning_learn_to_abstract_a_systematic_probing_framework	/pdf/5669e5170da32e93489610ab273090f5c47d5964.pdf
p8coElqiSDw	2665	Neural Architecture Design and Robustness: A Dataset	['dataset', 'robustness', 'architecture design']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|neural_architecture_design_and_robustness_a_dataset	/pdf/19e010592dd994a613aeeabbef5499d725b900d6.pdf
aS1Ef2vkIkR	2666	Variational Counterfactual Prediction under Runtime Domain Corruption	['Causal inference', 'treatment effect estimation', 'deep learning', 'variational inference', 'domain adaptation', 'domain shift', 'covariate shift', 'privacy concern.']	Proposed an upper bound and an adversarially unified variational method for run-time causal inference.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|variational_counterfactual_prediction_under_runtime_domain_corruption	/pdf/2a5d67b648a204fc06f348345bc80f6fb9efeefb.pdf
5ohslQBnxUw	2667	On the Convergence of Gradient Flow on Multi-layer Linear Models	['Multi-layer Linear Networks', 'Non-convex optimization', 'Gradient Flow', 'Training invariance']	We study how initialization affect the convergence of gradient flow on multi-layer linear networks	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_convergence_of_gradient_flow_on_multilayer_linear_models	/pdf/89408a419ee5e9607d9c9effcd65ba7c19458d94.pdf
cytNlkyjWOq	2668	Multi-Agent Multi-Game Entity Transformer	['reinforcement learning', 'multi-agent reinforcement learing', 'transformer', 'pretrained model']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multiagent_multigame_entity_transformer	/pdf/86a00f854ef18cc5c7f3fb77ef2995eada00bbb6.pdf
UY5zS0OsK2e	2669	HT-Net: Hierarchical Transformer based  Operator Learning Model for Multiscale PDEs	['hierarchical transformer', 'operator learning', 'multiscale PDE', 'nested self-attention', 'loss function', 'generalization error']	We design a hierarchical transformer based operator learning method, so that the accurate, efficient and robust computer simulation of multiscale PDE problems with an ensemble of input parameters becomes feasible.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|htnet_hierarchical_transformer_based_operator_learning_model_for_multiscale_pdes	/pdf/e699d98ad33246697d9a1f08d27c2df49adfa1e2.pdf
Mg5CLXZgvLJ	2671	SpeedyZero: Mastering Atari with Limited Data and Time	['Reinforcement Learning System', 'Distributed Training', 'Model-Based Reinforcement Learning']	SpeedyZero is a distributed model-based RL training system based on EfficientZero, featuring fast training speed and high sample efficiency.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|speedyzero_mastering_atari_with_limited_data_and_time	/pdf/ef84e5596f35d711d581a6f441115047d644ae07.pdf
jMtwOppbKOU	2672	Practical Real Video Denoising with Realistic Degradation Model	['Real Video Denoising', 'Degradation Model']	This paper proposes a new realistic video degradation model for practical real video denoising.	Applications (eg, speech processing, computer vision, NLP)	anonymous|practical_real_video_denoising_with_realistic_degradation_model	/pdf/5b6ee81436e1e4d6daa5e6833febfbde9bbae6fb.pdf
kjkdzBW3b8p	2673	Discovering Policies with DOMiNO	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|discovering_policies_with_domino	/pdf/57b7d02811346349d645831e68e213697f95b514.pdf
7KdrFjpmJf7	2674	Learning Sampling Policy to Achieve Fewer  Queries for  Zeroth-Order Optimization	['Zeroth-order optimization', 'reinforcement learning']	TL	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_sampling_policy_to_achieve_fewer_queries_for_zerothorder_optimization	/pdf/4ffb9fae5760a280a6e7aeccaa86008f5ccb8085.pdf
53yQBJNQVJu	2675	Worst-case Few-shot Evaluation: Are Neural Networks Robust Few-shot Learners?	['Distributional Robustness', 'few-shot evaluation']		Deep Learning and representational learning	anonymous|worstcase_fewshot_evaluation_are_neural_networks_robust_fewshot_learners	/pdf/2b5ae3634984ff91c4fcf9eb1459796fad4bb8bf.pdf
cri2n_3PJAw	2676	Token-level Fitting Issues of Seq2seq Models	['overfitting', 'underfitting', 'seq2seq model']	We find that seq2seq models trained with early-stopping suffer from overfitting and underfitting at the token level. We identify three major factors that influence token-level fitting.	Deep Learning and representational learning	anonymous|tokenlevel_fitting_issues_of_seq2seq_models	/pdf/188e5f79daa06e241c59edf5bb77258b512a3daa.pdf
jHc8dCx6DDr	2677	Memory Gym: Partially Observable Challenges to Memory-Based Agents	['Deep Reinforcement Learning', 'Memory', 'Benchmark', 'Proximal Policy Optimization', 'Gated Recurrent Unit', 'HELM']	Memory Gym is a novel challenge especially to memory-based agents.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|memory_gym_partially_observable_challenges_to_memorybased_agents	/pdf/cfe9ea728208ce73a9e118946d696a180f8894b5.pdf
WK22pk7bSFR	2679	Forward and Backward Lifelong Learning with Time-dependent Tasks	['Lifelong learning', 'Continual learning', 'Supervised Classification', 'Performance Guarantees', 'Minimax risk classification']	This paper presents lifelong learning methods based on minimax risk classifiers (LMRCs) that effectively exploit forward and backward learning and account for time-dependent tasks.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|forward_and_backward_lifelong_learning_with_timedependent_tasks	/pdf/89ef4f96beaed08e9d5ce32f7d46d42b46f2e410.pdf
vINj_Hv9szL	2680	Benchmarking Constraint Inference in Inverse Reinforcement Learning	['Inverse Reinforcement Learning', 'Constrained Reinforcement Learning', 'Variational Bayesian Inference']	We design a benchmark with important applications for Inverse Constrained Reinforcement Learning and propose a variational Bayesian approach for modeling the distribution of constraints.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|benchmarking_constraint_inference_in_inverse_reinforcement_learning	/pdf/67783ead0fe2efc4e0569c6d484455fa4291a03d.pdf
KiT3-iN8wHJ	2681	Uncertainty and Traffic Light Aware Pedestrian Crossing Intention Prediction	['deep learning', 'computer vision', 'recurrent neural networks', 'uncertainty estimation', 'intention prediction', 'attention mechanism', 'autonomous driving']	We improve pedestrian crossing intention model performance and robustness using traffic light status and predicting uncertainty estimation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|uncertainty_and_traffic_light_aware_pedestrian_crossing_intention_prediction	/pdf/569a45050d5aeaea2b37970f9bca09dc84f54b9b.pdf
3Z-xKxKc-R	2682	An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems	[]		Deep Learning and representational learning	anonymous|an_evolutionary_approach_to_dynamic_introduction_of_tasks_in_largescale_multitask_learning_systems	/pdf/c3be75df949afacbfaa64c6e84c0561ee17b9443.pdf
bSuY3hSRJPP	2684	SpectraNet: multivariate forecasting and imputation under distribution shifts and missing data	['time series', 'forecasting', 'missing values', 'deep-learning', 'interpolation', 'distribution shift']	We propose a novel encoderless multivariate time-series forecasting with SoTA performance and robust to missing-data and distribution shifts	Deep Learning and representational learning	anonymous|spectranet_multivariate_forecasting_and_imputation_under_distribution_shifts_and_missing_data	/pdf/eaab9e95097ab90b71cb02680f9376bc99b935d0.pdf
Z4Kexjh34vT	2685	Hypernetwork approach to Bayesian MAML	['few-shot learnirng', 'MAML', 'hypernetworks']	n this paper we propose a novel generalization of Bayesian MAML, which employs Bayesian principles along with Hypernetworks for MAML.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|hypernetwork_approach_to_bayesian_maml	/pdf/20e3a3cdab0d71d99ffda24167bb5a8679269807.pdf
0qnryNf6XwR	2686	When are smooth-ReLUs ReLU-like?	['ReLU', 'SWISH', 'GeLU', 'Critical Initialization', 'Fully Connected Neural Networks', 'Deep Networks']	We parametrize relaxations of ReLU and devise initialization schemes that retain ReLU-like properties while being differentiable, verified experimentally and confirmed during training.	Deep Learning and representational learning	anonymous|when_are_smoothrelus_relulike	/pdf/1e0e474bb597f0691ecab055f366eaac4fc33458.pdf
c2X1Qa9K3bD	2687	Where prior learning can and can't work in unsupervised inverse problems	['Inverse problems', 'unsupervised learning', 'dictionary learning', 'Deep Image Prior', 'Plug and Play']		Deep Learning and representational learning	anonymous|where_prior_learning_can_and_cant_work_in_unsupervised_inverse_problems	/pdf/71119bf007fe31ea2eb87a10dd059680d8c6b355.pdf
DClS-1HQ_0P	2688	Jointist: Simultaneous Improvement of Multi-instrument Transcription and Music Source Separation via Joint Training	['multi-task learning', 'automatic music transcription', 'music source separation', 'instrument recognition']	Joint training of music transcription and source separation improves the performance of both	Applications (eg, speech processing, computer vision, NLP)	anonymous|jointist_simultaneous_improvement_of_multiinstrument_transcription_and_music_source_separation_via_joint_training	/pdf/8824d1de90ffab318a9a2cf23d934c4f916b3412.pdf
p6qlG1zXs9v	2691	Critical Batch Size Minimizes Stochastic First-Order Oracle Complexity of Deep Learning Optimizer using Hyperparameters Close to One	['Adam', 'adaptive method', 'critical batch size', 'hyperparameters', 'learning rate', 'nonconvex optimization', 'stochastic first-order oracle complexity']	Critical batch size minimizes stochastic first-order oracle complexity of deep learning optimizer using hyperparameters close to one.	Optimization (eg, convex and non-convex optimization)	anonymous|critical_batch_size_minimizes_stochastic_firstorder_oracle_complexity_of_deep_learning_optimizer_using_hyperparameters_close_to_one	/pdf/ef9297282dacc36e717a4a271813efc92aa1068c.pdf
fCbTxKYJovs	2692	FedEED: Efficient Federated Distillation with Ensemble of Aggregated Models	['Federated Learning', 'Knowledge Distillation']		Deep Learning and representational learning	anonymous|fedeed_efficient_federated_distillation_with_ensemble_of_aggregated_models	/pdf/924d29b7a4101ab8f9f12492842d9d946281ebd2.pdf
PxohstFQm9q	2693	Simplicity bias in $1$-hidden layer neural networks	['Simplicity Bias', 'Neural Network', 'Gradient Descent']	Gradient Descent on 1-hidden-layer neural network learns a function of essentially a lower dimensional projection of the input.	Deep Learning and representational learning	anonymous|simplicity_bias_in_1hidden_layer_neural_networks	/pdf/8eefb1666fa1c0b6372c14352cb1ac24354af2e3.pdf
2XLRBjY46O6	2694	ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency	['Zero-shot semantic segmentation', 'Vision-Language Pretraining', 'Visual Self-Supervision', 'Consistent Semantics']	Discovering text-supervised segmentation masks via multi-view semantic consistency	Unsupervised and Self-supervised learning	anonymous|viewco_discovering_textsupervised_segmentation_masks_via_multiview_semantic_consistency	/pdf/8109900e5fe6867db854dcd0646acca9ee95644f.pdf
kD2J9vcfByo	2696	Label-Efficient Online Continual Object Detection in Streaming Video	['Online Continual Learning', 'Object Detection', 'Complementary Learning Systems', 'Streaming Video']	Towards label-efficient online continual object detection in video streams, our Efficient-CLS only uses 25% annotation costs while it still outperforms the best baseline.	Applications (eg, speech processing, computer vision, NLP)	anonymous|labelefficient_online_continual_object_detection_in_streaming_video	/pdf/837cee52015cd9adc8ea4a0a9026497d5b5bcb4e.pdf
PQfP-d9BWkF	2698	APLA: Class-imbalanced Semi-supervised Learning with Adapative Pseudo-labeling and Loss Adjustment	['semi-supervised learning', 'class-imbalanced learning', 'class-imbalanced semi-supervised learning']	We use Class-Aware Pseudo-label Thresholding and Class-Aware Loss Adjustment to improve the performance of existing SSL algorithm in Class-imbalanced setting.	Deep Learning and representational learning	anonymous|apla_classimbalanced_semisupervised_learning_with_adapative_pseudolabeling_and_loss_adjustment	/pdf/a664a560cb1fc9acfc524fc2efded909cb5230ea.pdf
_GstklGE4l	2699	Learning Discriminative Representations for Chromosome Classification with Small Datasets	['Chromosome classification', 'data representation learning', 'deep neural networks', 'discriminative representation', 'maximal coding rate reduction']		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_discriminative_representations_for_chromosome_classification_with_small_datasets	/pdf/bd243569a1ff27259a174c0e2b19e25d817235ef.pdf
3qvEPE6q4L	2700	FedMAE: Federated Self-Supervised Learning with One-Block Masked Auto-Encoder	['Federated Learning', 'Self-Supervised Learning', 'Masked AutoEncoder']	A novel federated self-supervised learning framework with a cascade design	Unsupervised and Self-supervised learning	anonymous|fedmae_federated_selfsupervised_learning_with_oneblock_masked_autoencoder	/pdf/2d58098c29159efdaa5b03abedd6e457923a1650.pdf
N9Pk5iSCzAn	2701	Towards Open Temporal Graph Neural Networks	['Temporal Graph Neural Networks', 'Open Temporal Graphs', 'Class-Incremental Learning']	In this paper, we propose a general and principled learning approach for open temporal graphs where the class set for nodes is open.	Deep Learning and representational learning	anonymous|towards_open_temporal_graph_neural_networks	/pdf/9c2badcfa466eef3e5ccbd7818fc9740c5152229.pdf
u9hnCwX99I1	2702	Centralized Training with Hybrid Execution in Multi-Agent Reinforcement Learning	['Multi-Agent Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|centralized_training_with_hybrid_execution_in_multiagent_reinforcement_learning	/pdf/8c14be438b22aea450e56fb201975928b6a27d83.pdf
7WiIzqeqBNL	2703	Multi-View Independent Component Analysis with Shared and Individual Sources	['multiview independent component analysis', 'independent component analysis', 'blind source separation', 'multiview representation learning']	We investigate the special setting of noisy linear ICA where the observations are split among different views, each of which receives a mixture of shared and individual sources. 	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|multiview_independent_component_analysis_with_shared_and_individual_sources	/pdf/3213ca32eb9fbb0e131dd4bdab59d86c518b99a5.pdf
XIIynqbMXgR	2704	GuoFeng: A Discourse-aware Evaluation Benchmark for Language Understanding, Translation and Generation	['Discourse', 'Evaluation Benchmark', 'Pre-trained Models', 'Natural Language Processing']	A discourse-aware benchmark for evaluating models across language understanding, translation and generation tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|guofeng_a_discourseaware_evaluation_benchmark_for_language_understanding_translation_and_generation	/pdf/a4648281b1f58492dad343d0e8cc82455f070eff.pdf
-9PVqZ-IR_	2705	Martingale Posterior Neural Processes	[]	Martingale Posterior Distribution, Neural Processes	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|martingale_posterior_neural_processes	/pdf/874e77607f76033506ee316e909febbf1c326531.pdf
wekD3L39fk	2706	Randomized Adversarial Style Perturbations for Domain Generalization	['Domain Generalization', 'Data Augmentation', 'Adversarial Attacks']		Deep Learning and representational learning	anonymous|randomized_adversarial_style_perturbations_for_domain_generalization	/pdf/4f2a5be805f07e9637dc60e7c2413dbe0df1c3c9.pdf
OboQ71j1Bn	2707	Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC	['Generative models', 'diffusion models', 'compositional generation']	We show how diffusion models can be composed together to create new models and demonstrate how to make them perform well at this task.	Generative models	anonymous|reduce_reuse_recycle_compositional_generation_with_energybased_diffusion_models_and_mcmc	/pdf/d6ca482e7736112a267254ab6053c149ee457b31.pdf
S5RYm-9Q4o	2708	Fine-Grained Source Code Vulnerability Detection via Graph Neural Networks	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|finegrained_source_code_vulnerability_detection_via_graph_neural_networks	/pdf/16becc6216f69322a5e26ef7924f602bb0912a9e.pdf
HHcl-5chhkt	2709	IT-NAS: Integrating Lite-Transformer into NAS for Architecture Seletion	['Neural Architecture Search', 'Transformer', 'Self-Attention']	This paper proposes to integrate Lite-Transformer into NAS for architecture selection, and introduces an additional indicator token (IT) to reflect the importance of each candidate operation.	Deep Learning and representational learning	anonymous|itnas_integrating_litetransformer_into_nas_for_architecture_seletion	/pdf/c1afd805431a86710f54bd774432b8c739db18a3.pdf
bcYZwYo-0t	2710	Decoupled Training for Long-Tailed  Classification With Stochastic Representations	['long-tailed learning', 'stochastic weight averaging']	We propose a novel classifier re-training algorithm for long-tailed classification.	Deep Learning and representational learning	anonymous|decoupled_training_for_longtailed_classification_with_stochastic_representations	/pdf/0a18dc70359b8d6d9882e21a2d343d0882e524ce.pdf
ZsCgBR1qvo	2711	A Curriculum Perspective to Robust Loss Functions	[]		Deep Learning and representational learning	anonymous|a_curriculum_perspective_to_robust_loss_functions	/pdf/d89e3aec8474d503aa190be35c681027728e871b.pdf
2skHw9HVf3	2712	TAPPFL: TASK-AGNOSTIC PRIVACY-PRESERVING REPRESENTATION LEARNING FOR FEDERATED LEARNING AGAINST ATTRIBUTE INFERENCE ATTACKS	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|tappfl_taskagnostic_privacypreserving_representation_learning_for_federated_learning_against_attribute_inference_attacks	/pdf/4a059b0d4d201f306904ba19ee2e971595c62f05.pdf
4NT3umNU3D0	2713	Backdoor or Feature? A New Perspective on Data Poisoning	[]	A new theoretical foundation of data poisoning, with a theory inspired defense algorithm	Deep Learning and representational learning	anonymous|backdoor_or_feature_a_new_perspective_on_data_poisoning	/pdf/b2755ed779b6e6f9a30bc9352266fecb77f097bc.pdf
bTy4D3KHwWU	2714	Normalizing Flows for Interventional Density Estimation	['causal inference', 'normalizing flows', 'treatment effect estimation', 'causal machine learning']	We propose a novel, fully-parametric deep learning method for estimating densities of potential outcomes, called Interventional Normalizing Flows	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|normalizing_flows_for_interventional_density_estimation	/pdf/76f7f42b7d66bc43dbc4b4bc1a93b04d41692b90.pdf
IVESH65r0Ar	2715	A Simple Yet Powerful Deep Active Learning With Snapshots Ensembles	['Active learning', 'Snapshot ensemble', 'Uncertainty estimation']		Deep Learning and representational learning	anonymous|a_simple_yet_powerful_deep_active_learning_with_snapshots_ensembles	/pdf/e71f0272505280c19834265700567fc771407d2b.pdf
7JsGYvjE88d	2716	Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search	['search', 'adaptive horizon', 'verification', 'deep learning', 'hierarchical planning']	We propose Adaptive Subgoal Search (AdaSubS), a search algorithm that adjusts the planning horizon to match the local complexity of the solved problems.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|fast_and_precise_adjusting_planning_horizon_with_adaptive_subgoal_search	/pdf/63988597831ae1275eee50a53d346e8206f0d747.pdf
KB1sc5pNKFv	2717	On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning	['model-based reinforcement learning', 'visual reinforcement learning']	We investigate the feasibility of pretraining and cross-task transfer in model-based RL, and improve sample-efficiency substantially over baselines on the Atari100k benchmark.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_feasibility_of_crosstask_transfer_with_modelbased_reinforcement_learning	/pdf/e9dea24348cc78b4f85524148741a5562a9a68ee.pdf
MpikUXtGQCI	2718	On the Convergence and Calibration of Deep Learning with Differential Privacy	['deep learning', 'differential privacy', 'calibration', 'convergence', 'neural tangent kernel']	We show that differentially private deep learning can be severely mis-calibrated due to the gradient clipping, which can be alleviated by a new clipping method.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_convergence_and_calibration_of_deep_learning_with_differential_privacy	/pdf/c31984e5f02a4c30e452715d704cf38769a48fb6.pdf
nd8Z_Xbdrfx	2719	Reducing Forgetting In Federated Learning with Truncated Cross-Entropy	['continual learning', 'catastrophic forgetting', 'distribution shifts', 'federated learning']	Inspired by methods in continual learning we propose and analyze a simple approach for supervised federated learning with non-iid data	Deep Learning and representational learning	anonymous|reducing_forgetting_in_federated_learning_with_truncated_crossentropy	/pdf/78a78c75c8f8671acd34e2dcd193c8f7ce4a4d56.pdf
x4XN_dP6mrQ	2720	Polite Teacher: Semi-Supervised Instance Segmentation with Mutual Learning and Pseudo-Label Thresholding	['semi-supervised learning', 'instance segmentation', 'semi-supervised instance segmentation']	We present Polite Teacher, a mutual learning framework with pseudo-label thresholding for single-stage semi-supervised instance segmentation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|polite_teacher_semisupervised_instance_segmentation_with_mutual_learning_and_pseudolabel_thresholding	/pdf/e009ca6f01821c2d6260bc42affd178ad78fcab1.pdf
Tg9AvNbTUJo	2721	$Q$-learning with regularization converges with non-linear non-stationary features	['Q-learning', 'Reinforcement Learning', 'Stochastic Approximation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|qlearning_with_regularization_converges_with_nonlinear_nonstationary_features	/pdf/c736a5eb1b3725f9b4f33606a1b8d964c4cbd9e8.pdf
VIwEYmMID9R	2723	DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning	['Communication in deep multi-agent reinforcement learning', 'Deep multi-agent reinforcement learning', 'Differential privacy', 'Game theory']	We make the first attempt to develop a privacy-preserving communication framework for MARL, named \textit{DPMAC}. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|dpmac_differentially_private_communication_for_cooperative_multiagent_reinforcement_learning	/pdf/9daeb42348ce59d12ca4cf4989941cbfffedcfcc.pdf
_QRMikPHXL	2724	Poisson Process for Bayesian Optimization	[]		General Machine Learning (ie none of the above)	anonymous|poisson_process_for_bayesian_optimization	/pdf/e604badc8b28d96611ce9bd7fafa9cf39519a7aa.pdf
cS45VNtZLW	2725	Traversing Between Modes in Function Space for Fast Ensembling	['deep ensemble', 'mode connectivity']	We propose a novel framework that predicts the outputs for the low-loss subspace to reduce the inference cost of deep ensembles by taking advantage of mode connectivity.	Deep Learning and representational learning	anonymous|traversing_between_modes_in_function_space_for_fast_ensembling	/pdf/4c28877e093bf83b18bf9c1d6473ee5a475add21.pdf
Uzng0zolM8	2726	Vectorial Graph Convolutional Networks	['GNN', 'GCN']		Deep Learning and representational learning	anonymous|vectorial_graph_convolutional_networks	/pdf/b73958d154dbca59a74db467684925b098cbd932.pdf
4WoJDxyCxq	2727	To be private and robust: Differentially Private Optimizers Can Learn Adversarially Robust Models	['deep learning', 'differential privacy', 'adversarial robustness', 'Pareto optimality']	We show that DP models can be adversarially robust with rigorous proof on linear models and empirical evidence on deep networks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|to_be_private_and_robust_differentially_private_optimizers_can_learn_adversarially_robust_models	/pdf/7fa26c3da59d94094470e0bec0183f350f96a3fd.pdf
aqIvCsRsYt	2728	CLIPPING: Distilling CLIP-based Models for Video-Language Understanding	['Knowledge Distillation', 'Vison-Language Understanding', 'Model Compression']	In this paper, we propose a novel knowledge distillation method that is specially designed for small vison-language models.	Deep Learning and representational learning	anonymous|clipping_distilling_clipbased_models_for_videolanguage_understanding	/pdf/ab85e2cc5d24e70f23f8838f9b470294abe703fe.pdf
XRPcmvMFFe	2729	Contrastive Value Learning: Implicit Models for Simple Offline RL	['reinforcement learning', 'contrastive learning', 'implicit density models', 'reward-free learning', 'offline reinforcement learning', 'metaworld']	Learning implicit value functions using noise-contrastive estimation in a model-free setting that can be partially pre-trained on reward-free data from related RL tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|contrastive_value_learning_implicit_models_for_simple_offline_rl	/pdf/584fd825075d2cd5c1b9a7e366a2b85f2fea9d50.pdf
r0otLtOwYW	2730	Equivariant Energy-Guided SDE for Inverse Molecular Design	['score-based model', 'diffusion model', 'inverse molecular design', 'energy guidance', 'molecule generation', 'equivariance']	Equivariant energy-guided stochastic differential equations for inverse molecular design.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|equivariant_energyguided_sde_for_inverse_molecular_design	/pdf/3ea9067de5e32c1b688e922d1846d82325c24b1b.pdf
tYIMtogyee	2731	Pre-training via Denoising for Molecular Property Prediction	['Molecular Property Prediction', 'Pre-training', 'Graph Neural Networks', 'Denoising', 'Molecules']	We describe a technique for pre-training models for molecular property prediction from 3D structures based on denoising and show that it achieves SOTA results for various tasks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pretraining_via_denoising_for_molecular_property_prediction	/pdf/58a0204bfdc284e20e5b89bb1e1e661695ce46f6.pdf
GNjzMAgawq	2732	CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Alignment	[]		Deep Learning and representational learning	anonymous|clipvip_adapting_pretrained_imagetext_model_to_videolanguage_alignment	/pdf/c0ab626a499a4d6dae6b5166fb8fd802cde9072d.pdf
P0bfBJaD4KP	2733	Universal Graph Neural Networks without Message Passing	[]		Deep Learning and representational learning	anonymous|universal_graph_neural_networks_without_message_passing	/pdf/0ee9837f24e74d282d19af6ae876f24e8b85e1a1.pdf
XfQlcpWESqV	2734	Differentially Private Optimization on Large Model at Small Cost	['deep learning', 'differential privacy', 'complexity', 'computation efficiency']	We propose a new implementation of differentially private deep learning, that substantially improves speed and memory cost to match standard non-private training.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|differentially_private_optimization_on_large_model_at_small_cost	/pdf/e038e18a1ed386e47133444e1ceab79598b126c1.pdf
H4Ncs5jhTCu	2735	Diminishing Return of Value Expansion Methods in Model-Based Reinforcement Learning	['Model-based Reinforcement Learning', 'Value Expansion']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|diminishing_return_of_value_expansion_methods_in_modelbased_reinforcement_learning	/pdf/fdaeeb2e51a26ae8c8ec03aecc6fa9b8a8cfc6fc.pdf
BPwIgvf5iQ	2736	Jointly Learning Visual and Auditory Speech Representations from Raw Data	['self-supervised learning', 'lipreading', 'speech recognition']	We propose a self-supervised audiovisual approach to jointly learn visual and auditory speech representations.	Unsupervised and Self-supervised learning	anonymous|jointly_learning_visual_and_auditory_speech_representations_from_raw_data	/pdf/9499388c08d8f9447900e181afc15646dd69fe2f.pdf
zoTUH3Fjup	2738	Differentially private Bias-Term Only Fine-tuning of Foundation Models	['deep learning', 'differential privacy', 'complexity', 'parameter efficiency', 'fine-tuning']	We propose a parameter efficient and private fine-tuning method, that trains 0.1% of the network (only the bias terms) and substantially improves the time/space complexity.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|differentially_private_biasterm_only_finetuning_of_foundation_models	/pdf/dde12aafb28a9c3c4da9303185416d68beb3c41a.pdf
aBIpZvMdS56	2739	Over-parameterized Model Optimization with Polyak-{\L}ojasiewicz Condition	['Over-parameterized Model', 'Model Optimization', 'Polyak-{\\L}ojasiewicz Condition.']	This work proposes a new regularized risk minimization for over-parameterized models with a novel PL regularization and implements it via network pruning guided by PL-based condition number. 	Deep Learning and representational learning	anonymous|overparameterized_model_optimization_with_polyak\lojasiewicz_condition	/pdf/b58fde95c439383a9e6d2d001e5db09c18fda744.pdf
BEpJFTH50iT	2740	Searching optimal adjustment features for treatment effect estimation	['treatment effect estimation', 'covariate separation', 'confounder balancing']	We construct a reinforcement-learning based framework to search the optimal adjustment features for more precise treatment effect estimation.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|searching_optimal_adjustment_features_for_treatment_effect_estimation	/pdf/0e68189769672422b2ae27990cf788ae39dd5b28.pdf
d1LQQzVFkSL	2741	Noether Embeddings: Fast Temporal Association Mining	"['temporal knowledge graph', 'association rule mining', 'representation learning', ""Noether's theorem""]"		Deep Learning and representational learning	anonymous|noether_embeddings_fast_temporal_association_mining	/pdf/42f4456918835a05f370baafc0f56e438ef2372a.pdf
hNmf1gnVllX	2742	Learning to Reason and Act in Cascading Processes	['cascading processes', 'intervention', 'reasoning', 'tree search']	We consider the task of controlling the behavior of a cascading process with an intervention at a single point in time. We propose to learn a principled probabilistic scoring function that allows searching efficiently over the space of interventions.	General Machine Learning (ie none of the above)	anonymous|learning_to_reason_and_act_in_cascading_processes	/pdf/8a7c5cf5b269f5cd36a8a7fc3408d117b8a40367.pdf
kPLzOfPfA2l	2743	Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning	['incremental few-shot learning', 'catastrophic forgetting', 'parameter space', 'weight space rotation']	This paper introduced a concept of weight space rotation which makes changes to parameter space itself for solving incremental few-shot learning problem.	Deep Learning and representational learning	anonymous|warping_the_space_weight_space_rotation_for_classincremental_fewshot_learning	/pdf/13f4a6e89087408b5c787ba5542cbb223557d4ef.pdf
Ew9gIwAQ7wr	2744	FFCV: Accelerating Training by Removing Data Bottlenecks	['infrastructure', 'data loading', 'fast training', 'library', 'usability']	We present FFCV, an easy-to-use yet highly optimized library for training machine learning models.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|ffcv_accelerating_training_by_removing_data_bottlenecks	/pdf/dd05929537b9415cea9092e6e6c51fd22655440a.pdf
aBWnqqsuot7	2745	D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory	['AI for Science', 'Quantum Chemisty', 'Density Functional Theory', 'Deep Learning', 'Kohn-Sham Equation.']	This paper propose a deep learning approch to solving Kohn-Sham Density Functional Theory.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|d4ft_a_deep_learning_approach_to_kohnsham_density_functional_theory	/pdf/86c2e1c97fce12e3ea9aa690c6dc5989f5269a13.pdf
UVAmFAtC5ye	2746	TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation	['Speech-to-speech translation', 'Multimodal challenge', 'Non-autoregressive generation']	We propose TranSpeech, a speech-to-speech translation model with bilateral perturbation to address multimodality and parallel decoding to reduce inference latency.	Applications (eg, speech processing, computer vision, NLP)	anonymous|transpeech_speechtospeech_translation_with_bilateral_perturbation	/pdf/3a608c521786b7a9f1d5c40e100d390aab10e582.pdf
P5ZTXA7zy6	2747	When Neural ODEs meet Neural Operators	[]		Deep Learning and representational learning	anonymous|when_neural_odes_meet_neural_operators	/pdf/e5a2215f7cdd0542005c904a1247d4ddbd33fd0c.pdf
-x5WuMO4APy	2749	FastDiff 2: Dually Incorporating GANs into Diffusion Models for High-Quality Speech Synthesis	['Speech synthesis', 'Neural vocoder', 'Diffusion probabilistic model', 'Generative adversarial network']	We propose FastDiff 2, a conditional diffusion model to trade off diversity for quality and speed by incorporating GANs into diffusion models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|fastdiff_2_dually_incorporating_gans_into_diffusion_models_for_highquality_speech_synthesis	/pdf/1df3606905c1c22ce8bab529e0a005a4d990f62e.pdf
hmpjFiUly1	2750	Knowledge-Driven Active Learning	['Active Learning', 'Knowledge-aided Learning', 'FOL', 'Human in the loop', 'Hybrid Model']	Exploiting simple domain-knowledge within an active learning strategy to minimize the amount of labelled data and whiten the labelling process.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|knowledgedriven_active_learning	/pdf/5cd157d6c7eb132644495a95024b35911e09543e.pdf
CS7dB_FnGx	2751	Incremental Unified Parameter Additional Tuning with Basic Memory Replaying	['class incremental learning', 'parameter-additional-tuning', 'basic memory replaying']	We propose a novel method for class incremental learning by tuning an unified additional parameter structure and replaying basic memory.	Deep Learning and representational learning	anonymous|incremental_unified_parameter_additional_tuning_with_basic_memory_replaying	/pdf/64af7018b440a0499f41e9e2a4a5223fecf34841.pdf
JInmhyuvn6	2752	Data Pricing Mechanism Based on Property Rights Compensation Distribution	['data valuation', 'game theory', 'data ownership', 'modern property rights theory']	This paper proposes the first data valuation mechanism based on modern property rights theory. We integrate ownership to clearify ownership and estimate its value while using the core instead of Shapley value to assign compensation.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|data_pricing_mechanism_based_on_property_rights_compensation_distribution	/pdf/0af3047503b205de86aa718f904cded9c0c774c0.pdf
WFe7IP-QOVk	2753	Distributionally Robust Offline Reinforcement Learning with Linear Function Approximation	['Offline Reinforcement Learning', 'Distributionally Robust']	We propose the first provable distributionally robust offline RL algorithms for two different dataset conditions with linear function approximation and provide corresponding theoretical guarantees.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|distributionally_robust_offline_reinforcement_learning_with_linear_function_approximation	/pdf/e1e61b3374631cc80c2b59c2ca33aef451dd229a.pdf
hRfJzvTYvD-	2754	Towards Estimating Transferability using Hard Subsets	['Transfer Learning', 'Transferability', 'Hard Subsets']	We propose HASTE, a strategy that ensures better transferability estimation using just a hard subset of target data.	Deep Learning and representational learning	anonymous|towards_estimating_transferability_using_hard_subsets	/pdf/6a45e8e4f3368f7bc00f257f43a8284157064e66.pdf
R4ETr5gcg5v	2755	Chopping Formers is what you need in Vision	['Transformers', 'Tensor Decomposition', 'Deep learning Architectures']	In this work, we unify prior methods and present a new efficient factorization for a general fully-connected and dynamic layer.	Deep Learning and representational learning	anonymous|chopping_formers_is_what_you_need_in_vision	/pdf/0f5b9470ec0666c13c6e0060e6dcc1976828ff20.pdf
rLguqxYvYHB	2756	A Neural Mean Embedding Approach for Back-door and Front-door Adjustment	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|a_neural_mean_embedding_approach_for_backdoor_and_frontdoor_adjustment	/pdf/b7fb48aa58f53b421671646af4086678bbb922b5.pdf
pOq1HuMI8Dz	2758	Reconciling feature sharing and multiple predictions with   MIMO Vision Transformers	['Deep learning', 'Computer vision', 'Vision transformers', 'Classification', 'Multi-input multi-output']	We propose MixViT, an inexpensive framework that improves vision transformers by training multiple subnetworks at the end of the model through multi-input multi-output training.	Deep Learning and representational learning	anonymous|reconciling_feature_sharing_and_multiple_predictions_with_mimo_vision_transformers	/pdf/6c0633e983597fb756645de130346e5e3fb9f978.pdf
aco19TMw9gA	2759	Adversarial Attack Detection Under Realistic Constraints	['Adversarial attacks', 'Detection', 'Vision transformers', 'Safety AI']	We propose a simple, real-time, softmax-based detection method for adversarial samples.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|adversarial_attack_detection_under_realistic_constraints	/pdf/efad5d0643750398d315eae990a86be04c017015.pdf
_02M2MYThLz	2760	Computational Doob h-transforms for Online Filtering of Discretely Observed Diffusions	['diffusion', 'filtering', 'monte-carlo', 'particle-filters', 'BSDE']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|computational_doob_htransforms_for_online_filtering_of_discretely_observed_diffusions	/pdf/1ea8e14bd60badedff5027db32a314e552f49599.pdf
3l9mLzLa0BA	2761	Signs in the Lottery: Structural Similarities Between Winning Tickets	['lottery ticket hypothesis', 'sparse networks', 'structural similarity', 'deep learning']	Winning tickets show structural similarities when taking signs of connections into account.	Deep Learning and representational learning	anonymous|signs_in_the_lottery_structural_similarities_between_winning_tickets	/pdf/dc9b36dd14875c504f871aee8cd67cff8af642f1.pdf
YnkGMIh0gvX	2762	A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification	['failure detection', 'out-of-distribution detection', 'predictive uncertainty quantification', 'selective classification', 'robustness', 'method evaluation']	We present a holistic perspective on the task of failure detection including a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and distribution shifts. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_call_to_reflect_on_evaluation_practices_for_failure_detection_in_image_classification	/pdf/cb4772d2578f24125555c65ce883603e6a264192.pdf
4yqxDCbzS98	2764	Weakly Supervised Knowledge Transfer with Probabilistic Logical Reasoning for Object Detection	['weak supervision', 'knowledge transfer', 'object detection', 'probabilistic logical reasoning']	In this work, we propose ProbKT, a framework based on probabilistic logical reasoning to train object detection models with weak supervision, by transferring knowledge from a source domain where instance-level annotations are available.	Applications (eg, speech processing, computer vision, NLP)	anonymous|weakly_supervised_knowledge_transfer_with_probabilistic_logical_reasoning_for_object_detection	/pdf/a190ff4c8ca270321d7db93305f5b243593661f5.pdf
sVU54nyaA9K	2765	Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition	['Reinforcement learning theory', 'Reinforcement learning with adversarial losses', 'Reinforcement learning with linear function approximation']	We make the first step to establish a provably efficient algorithm in adversarial linear mixture mdps with bandit feedback and unknown transition.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_adversarial_linear_mixture_markov_decision_processes_with_bandit_feedback_and_unknown_transition	/pdf/df404e02d9b85da2ecd7545750e8837676ceea59.pdf
ff_18Qwm13Bp	2766	Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations	['structured and unstructured knowledge integration', 'temporal knowledge embedding', 'pre-trained language model', 'temporal reasoning']	We use textual knowledge to enhance the time-evolving knowledge graph embedding, while preserving its temporal nature.	Deep Learning and representational learning	anonymous|enhanced_temporal_knowledge_embeddings_with_contextualized_language_representations	/pdf/1dd7def453e170a645065ffba94b8afb1f74d42b.pdf
8e5xTOIQpj7	2767	Confounder Identification-free Causal Visual Feature Learning	['Domain Generalization', 'Casual Learning', 'Front-door criterion', 'Confounder identification-free']	We propose a casual visual representation learning paradigm (CICF) for generalization without requiring to identify the existing confounders. 	Deep Learning and representational learning	anonymous|confounder_identificationfree_causal_visual_feature_learning	/pdf/6afaaa7d7886d71ac1bbed35ff74d2dbdc059169.pdf
dlQIh4mUtQ8	2768	On the Relationship Between Adversarial Robustness and Decision Region in Deep Neural Networks	['Decision Region', 'Adversarial Robustness', 'Robust Training']	We propose the novel concept of the Populated Region Set (PRS) and devise PRS regularizer leveraging the characteristics of PRS to improve the adversarial robustness without adversarial training.	Deep Learning and representational learning	anonymous|on_the_relationship_between_adversarial_robustness_and_decision_region_in_deep_neural_networks	/pdf/43b5adede3136c18c6ad4c9632f9003a1a1e78b3.pdf
NYjXrU_f20G	2769	Adversarial Attack Detection Through Network Transport Dynamics	['Adversarial Attacks', 'Deep Learning', 'Optimal Transport', 'Residual Networks', 'Regularization']	We propose a detector of adversarial attacks inspired by the dynamic viewpoint of neural networks and a regularization that improves detection of adversarial attacks and test accuracy.	Deep Learning and representational learning	anonymous|adversarial_attack_detection_through_network_transport_dynamics	/pdf/4387982610aafcee078e2d438cdb0f37ddcfec80.pdf
JRFSLFyYAII	2770	Population-Based Reinforcement Learning for Combinatorial Optimization Problems	['reinforcement learning', 'combinatorial optimization', 'population']	We present a population-based RL method for CO problems: the training procedure makes the agents complementary to maximize the population's performance.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|populationbased_reinforcement_learning_for_combinatorial_optimization_problems	/pdf/b7f7b679407a8fff3fb168f653c8b463410c9950.pdf
5N0wtJZ89r9	2771	Embedding Fourier for Ultra-High-Definition Low-Light Image Enhancement	['low-light image enhancement', 'high-resolution image processing', 'Fourier transform', 'benchmark']	In this paper,  we propose a new solution for UHD LLIE based on the characteristics of the Fourier domain.  We also propose the first real UHD LLIE dataset with diverse data.	Applications (eg, speech processing, computer vision, NLP)	anonymous|embedding_fourier_for_ultrahighdefinition_lowlight_image_enhancement	/pdf/39e89487e87684a86de75cd181b21c1dcd141d34.pdf
r90KYcuB7JS	2774	Approximation and non-parametric estimation of functions over high-dimensional spheres via deep ReLU networks	['Approximation Theory', 'Non-parametric regression', 'Asymptotic', 'Deep ReLU Neural networks', 'High-dimensional sphere']	We study the approximation and statistical estimation of deep ReLU feed-forward neural networks, when functions of interests are from Sobolev spaces over high-dimensional sphere.	Deep Learning and representational learning	anonymous|approximation_and_nonparametric_estimation_of_functions_over_highdimensional_spheres_via_deep_relu_networks	/pdf/e8e06337b44f72b3d84cdff6d7dd6a532a07d603.pdf
1KaSx3GrBBm	2775	Moving Beyond Handcrafted Architectures in Self-Supervised Learning	['NAS', 'Self-supervised learning']		Unsupervised and Self-supervised learning	anonymous|moving_beyond_handcrafted_architectures_in_selfsupervised_learning	/pdf/57172e4847555530418a1cedf327a69b8edd6e8d.pdf
QugfmhDu5Y4	2776	Self-Paced Learning  Enhanced Physics-informed Neural Networks for Solving Partial Differential Equations	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|selfpaced_learning_enhanced_physicsinformed_neural_networks_for_solving_partial_differential_equations	/pdf/0ab315bee6f442f8432a770dc489694d159af978.pdf
qWt3YobXdwe	2777	Robust Self-Supervised Learning with Lie Groups	['robustness', 'computer vision', 'generalization', 'self-supervised learning', 'out-of-domain generalization']	We explicitly model variation in data using Lie groups to improve self-supervised vision models' robustness to pose changes	Deep Learning and representational learning	anonymous|robust_selfsupervised_learning_with_lie_groups	/pdf/70d1c9e21c925c846399d29fffcc85c7885be5c5.pdf
y6EnaJlhcWZ	2778	Prosody-TTS: Self-Supervised Prosody Pretraining with Latent Diffusion For Text-to-Speech	['Text-to-speech', 'Prosody modeling', 'Self-supervised learning', 'Diffusion probabilistic model']	We propose Prosody-TTS, a TTS model to enhance prosody modeling by introducing self-supervised prosody pre-training and generative latent diffusion.	Applications (eg, speech processing, computer vision, NLP)	anonymous|prosodytts_selfsupervised_prosody_pretraining_with_latent_diffusion_for_texttospeech	/pdf/6ffa2cd0c77ecff6b140b77bde7b432ad080b962.pdf
1o5SGx71kAO	2779	FV-MgNet: Fully Connected V-cycle MgNet for Interpretable Time Series Forecasting	['long time series forecasting', 'multigrid', 'MgNet', 'V-cycle', 'fully connected layer']	By investigating iterative methods for a constrained linear model, we propose a new class of fully connected V-cycle MgNet  for long-term time series forecasting.	Deep Learning and representational learning	anonymous|fvmgnet_fully_connected_vcycle_mgnet_for_interpretable_time_series_forecasting	/pdf/045a2f34cb75d320eb9cd85752a558a56b4874b2.pdf
n6CXWcySQPm	2780	Latent-space disentanglement with untrained generator networks allows to isolate different motion types in video data	['video analysis', 'isolation of motion', 'generator networks', 'deep image prior']	The paper provides a novel approach to isolate different types of motion in video data using untrained generator networks with disentangled latent space variables	Deep Learning and representational learning	anonymous|latentspace_disentanglement_with_untrained_generator_networks_allows_to_isolate_different_motion_types_in_video_data	/pdf/c3339820a416ea397bab204e4580044742c3e84e.pdf
4GtbV7o7-6l	2781	SC2EGSet: StarCraft II Esport Replay and Game-state Dataset	['StarCraft II', 'esports', 'machine learning', 'dataset']	Infrastructure, and a dataset crucial for research in a new and developing field of esports.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|sc2egset_starcraft_ii_esport_replay_and_gamestate_dataset	/pdf/e13e6c44f307a7dd73aeedd47c3274288019325b.pdf
JHklpEZqduQ	2782	Non-parametric Outlier Synthesis	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|nonparametric_outlier_synthesis	/pdf/bb6e7e0328fa34751ce379df7e77dddda1388d27.pdf
Uuw51xL-ZHd	2783	Incorporating Explicit Uncertainty Estimates into Deep Offline Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|incorporating_explicit_uncertainty_estimates_into_deep_offline_reinforcement_learning	/pdf/deeaf750bd047d930498c297f10e06ff9f53d5b6.pdf
ZKDUlVMqG_O	2784	Self-supervised Geometric Correspondence for Category-level 6D Object Pose Estimation in the Wild	['Category-level 6D pose estimation', 'self-supervised learning', 'correspondence', 'computer vision']		Unsupervised and Self-supervised learning	anonymous|selfsupervised_geometric_correspondence_for_categorylevel_6d_object_pose_estimation_in_the_wild	/pdf/4a27619f27f7a05f43987e87c505a0f377696e3f.pdf
-4Maz7s3YXz	2785	Towards Understanding Robust Memorization in Adversarial Training	['adversarial robustness', 'adversarial training', 'robust generalization gap', 'robust overfitting', 'deep learning theory']	We provide a theoretical understanding of adversarial training by proposing a novel implicit bias called robust memorization.	Deep Learning and representational learning	anonymous|towards_understanding_robust_memorization_in_adversarial_training	/pdf/8d956d402af78ece53e8b1afefb9cb86bf610a6c.pdf
NPrsUQgMjKK	2786	Deep Transformers without Shortcuts: Modifying Self-attention for Faithful Signal Propagation	['signal propagation', 'neural networks and kernels', 'deep transformers', 'self-attention', 'residual connections', 'layer normalisation', 'rank collapse', 'positional encoding']	Understanding and improving signal propagation in self-attention layers to train deep transformers without skip connections and/or normalisation.	Deep Learning and representational learning	anonymous|deep_transformers_without_shortcuts_modifying_selfattention_for_faithful_signal_propagation	/pdf/896740484a467c4bdc8836526711a1151a771826.pdf
wVdbbVAVuIH	2787	Training via Confidence Ranking	['loss function']	We devise a series of loss function for training a new better model than deployed one in real-world machine learning system.	Applications (eg, speech processing, computer vision, NLP)	anonymous|training_via_confidence_ranking	/pdf/6219ac35d5f9bf4c787c4a2eb4cf176ce263614b.pdf
GpicUyuSdTr	2788	SynMotor: A Benchmark Suite for Object Attribute Regression and Multi-task Learning	['synthetic dataset', 'benchmark development', '3D point cloud', 'object attribute regression', 'multi-task learning']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|synmotor_a_benchmark_suite_for_object_attribute_regression_and_multitask_learning	/pdf/024b7961bf42fd50ddb860315a058615081b92d0.pdf
K2d8p6cjSe5	2789	Less is More: Rethinking Few-Shot Learning and Recurrent Neural Nets	[]		Deep Learning and representational learning	anonymous|less_is_more_rethinking_fewshot_learning_and_recurrent_neural_nets	/pdf/75b3017ee1bd5a9083a84158e2cb877909e495eb.pdf
rdfgqiwz7lZ	2790	A Learning Based Hypothesis Test for Harmful Covariate Shift	['Covariate Shift', 'Distribution Shift', 'Trustworthy Machine Learning', 'Statistics']	We propose the Detectron, a method based that detects covariate shift using an ensemble of classifiers trained to disagree with each other on unlabeled samples.	General Machine Learning (ie none of the above)	anonymous|a_learning_based_hypothesis_test_for_harmful_covariate_shift	/pdf/ee88bb0e43133a90d68b21711d6fe2b169a89c27.pdf
R4oodnmxb9m	2791	Offline Communication Learning with Multi-source Datasets	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_communication_learning_with_multisource_datasets	/pdf/524be93a3c3a1087419ac6c1a3430b5eed4a5cb5.pdf
-t4D61w4zvQ	2792	Temporal Coherent Test Time Optimization for Robust Video Classification	['Video Classification', 'Robustness', 'Test Time Optimization']		Applications (eg, speech processing, computer vision, NLP)	anonymous|temporal_coherent_test_time_optimization_for_robust_video_classification	/pdf/e5d0a486cef5df18151a9209981c61ca2aaabe62.pdf
Bgcp4BniE-U	2793	Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models	['generative models', 'diffusion models', 'membership inference']	Our work proposes a generalized membership inference against various generative models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|generated_distributions_are_all_you_need_for_membership_inference_attacks_against_generative_models	/pdf/c4a10d75e0de7042cad117d6ccb76d980d3e1b10.pdf
9XFX-DdkGp9	2794	SPI-GAN: Denoising Diffusion GANs with Straight-Path Interpolations	[]		Generative models	anonymous|spigan_denoising_diffusion_gans_with_straightpath_interpolations	/pdf/cf553b09a9eadf1c32c445bd0f0b7fd7f65def24.pdf
txlWziuCE5W	2796	MEDICAL IMAGE UNDERSTANDING WITH PRETRAINED VISION LANGUAGE MODELS: A COMPREHENSIVE STUDY	['Vision Language models', 'Multimodality', 'Medical images', 'Few-shot learning', 'zero-shot']	This paper discuss about how to leverage the trending vision language model to transfer to the medical domain, showing exciting performance on zero-shot and few-shot learning tasks.	Deep Learning and representational learning	anonymous|medical_image_understanding_with_pretrained_vision_language_models_a_comprehensive_study	/pdf/cd2c969d647612480a0fc4d0f1885919a359f12c.pdf
6qZC7pfenQm	2797	Improving Deep Policy Gradients with Value Function Search	['Deep Reinforcement Learning', 'Deep Policy Gradients']	We present a Value Function Search that employs a gradient-free population of perturbed value networks to improve Deep Policy Gradient primitives, leading to higher returns and better sample efficiency.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|improving_deep_policy_gradients_with_value_function_search	/pdf/0e3b92c71f68d55f931808f45550c8b2eee3866c.pdf
fkM4J9CnJBS	2799	Beyond re-balancing: distributionally robust augmentation against class-conditional distribution shift in long-tailed recognition	['Long-tailed recognition', 'data augmentation', 'distributionally robust optimization', 'im-balance']	Study the problem of unreliable class-conditional distribution estimation in long-tailed recognition and propose a data augmentation method to solve it	Deep Learning and representational learning	anonymous|beyond_rebalancing_distributionally_robust_augmentation_against_classconditional_distribution_shift_in_longtailed_recognition	/pdf/2419c11271fe252e496d4c13b8f9b6016f83a3a3.pdf
h5OpjGd_lo6	2800	Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning	['Pre-Trained Language Model', 'Prompt-Based Learning', 'Efficient Zero-Shot Learning']	This paper proposes a framework to automatically enhance the quality of PLM-generated data for efficient zero-shot learning, without relying on any human annotation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|selfguided_noisefree_data_generation_for_efficient_zeroshot_learning	/pdf/b7628dffc3b484487fe985ce0dcf937312cc37e3.pdf
ZxdkjTgK_Dl	2801	BSTT: A Bayesian Spatial-Temporal Transformer for Sleep Staging	['Spatial-Temporal Transformer', 'Sleep Staging', 'Bayesian Deep Learning']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|bstt_a_bayesian_spatialtemporal_transformer_for_sleep_staging	/pdf/dcabc541311dd96af5851a9300cbeb0d173023ea.pdf
Zob4P9bRNcK	2802	Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model	['mixed-integer linear programming', 'cut selection', 'deep reinforcement learning', 'sequence to sequence learning']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_cut_selection_for_mixedinteger_linear_programming_via_hierarchical_sequence_model	/pdf/308dd44c0d7d0a6fbf09f32136e6409f5b6f0e43.pdf
dqnNW2omZL6	2803	Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and Multi-Layer Perceptrons	['Graph Neural Networks', 'Generalization']		Deep Learning and representational learning	anonymous|graph_neural_networks_are_inherently_good_generalizers_insights_by_bridging_gnns_and_multilayer_perceptrons	/pdf/048837cc4bbcc636ca3c76613e28abb7a294b9a1.pdf
6qcYDVlVLnK	2804	Mitigating Memorization of Noisy Labels via Regularization between Representations	['learning with noisy labels', 'representation learning']	We theoretically show the memorization effect of DNN with resepct to the model capacity and propose a representation-based regularizer to mitigate the memorization effect. 	Deep Learning and representational learning	anonymous|mitigating_memorization_of_noisy_labels_via_regularization_between_representations	/pdf/9b32285b02618b7fd77c5a79c177677ddcf4f6db.pdf
B8_T6-8-tCU	2805	On The Implicit Bias of Weight Decay in Shallow Univariate ReLU Networks	['theory', 'implicit bias', 'generalization', 'interpolation', 'theoretical', 'shallow ReLU networks', 'ReLU networks', 'analysis of weight decay']	Minimal \ell_2-norm interpolation by univariate scalar one layer ReLU is completely characterized in terms of the convexity of the learned predictor, giving new sharp generalization bounds on 1d Lipschitz functions.	Deep Learning and representational learning	anonymous|on_the_implicit_bias_of_weight_decay_in_shallow_univariate_relu_networks	/pdf/de3ff6bce95187cc12e94ed2440e84c43c15c46d.pdf
-Y34L45JR6z	2806	Policy Expansion for Bridging Offline-to-Online Reinforcement Learning	[]	Bridging offline-to-online RL with Policy Expansion	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|policy_expansion_for_bridging_offlinetoonline_reinforcement_learning	/pdf/3df822cc34588856ead1330cf7cb657e54291891.pdf
2a5Ru3JtNe0	2807	From ChebNet to ChebGibbsNet	['Spectral Graph Convolutional Networks', 'Gibbs phenomenon', 'Gibbs damping factors', 'ChebNet']		Deep Learning and representational learning	anonymous|from_chebnet_to_chebgibbsnet	/pdf/3acfc61b812af1abc79ad684145ce881a8394a93.pdf
qF5G70FqURx	2808	Collaborative Symmetricity Exploitation for Offline Learning of Hardware Design Solver	['Symmetricity', 'Offline learning', 'Hardware design solver']	We propose offline learning method with symmetric learning for hardware design	Deep Learning and representational learning	anonymous|collaborative_symmetricity_exploitation_for_offline_learning_of_hardware_design_solver	/pdf/c322fa5b3dfd46f002c2129846bef4527684b32e.pdf
-1x2-lp1eZf	2809	Rethinking Deep Spiking Neural Networks: A Multi-Layer Perceptron Approach	['spiking neural network', 'multi-layer perceptron', 'image classification']	A multi-layer perceptron approach for deep spiking neural network, achieving state-of-the-art results on ImageNet.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|rethinking_deep_spiking_neural_networks_a_multilayer_perceptron_approach	/pdf/b92416887d638e427a2efd42b1f572416c0de291.pdf
jQj-_rLVXsj	2810	Sequence to sequence text generation with diffusion models	['diffusion model', 'sequence to sequence', 'text generation', 'diveristy']	We propose DiffuSeq: a diffusion model designed for sequence-to-sequence text generation tasks	Generative models	anonymous|sequence_to_sequence_text_generation_with_diffusion_models	/pdf/81e44ba90eed40edb63f924948e551552945284b.pdf
-I2nYWac2Id	2811	Uplift Modelling based on Graph Neural Network Combined with Causal Knowledge	['uplift modeling', 'Graph Neural Network', 'Knowledge Representation', 'Structure Learning']	Improve uplift modeling performance through causal knowledge representation and structural neighborhood learning	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|uplift_modelling_based_on_graph_neural_network_combined_with_causal_knowledge	/pdf/66b9e2e662739925d2b0d50669bafcbdda86f9d8.pdf
QC10RmRbZy9	2812	Gradient-based optimization is not necessary for generalization in neural networks	['generalization', 'regularization']	We empirically showed that a random optimizer performs just as well as SGD	General Machine Learning (ie none of the above)	anonymous|gradientbased_optimization_is_not_necessary_for_generalization_in_neural_networks	/pdf/7bda53653fdece6e802ef603d5bff96d3e685463.pdf
gVOXZproe-e	2814	How to prepare your task head for finetuning	['representation learning', 'finetune', 'transfer learning']	Features need mild adaptation during finetuning, so mildly update your task head and then finetune together.	Deep Learning and representational learning	anonymous|how_to_prepare_your_task_head_for_finetuning	/pdf/4b2c795e7404b0205fdd6c581f9d13484110b687.pdf
gUxSHy2mNUh	2815	TCNL: Transparent and Controllable Network Learning Via Embedding Human-Guided Concepts	['Transparency-Interpretability', 'Human-Guided Concepts']	Propose a novel method to improve interpretability of CNN by merging concept information  corresponding to human understanding	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|tcnl_transparent_and_controllable_network_learning_via_embedding_humanguided_concepts	/pdf/56582c4ddb344b6adc8ae0b7a82cf9e7b329fed1.pdf
oap4aDN9yS2	2816	Bi-Level Dynamic Parameter Sharing among Individuals and Teams for Promoting Collaborations in Multi-Agent Reinforcement Learning	['Multi-Agent Reinforcement Learning', 'Reinforcement Learning']	We propose a bi-level dynamic parameter sharing mechanism between individuals and teams, which can not only promote agents to learn diversified strategies, but also promote agents to form more stable and complementary cooperative relationships.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|bilevel_dynamic_parameter_sharing_among_individuals_and_teams_for_promoting_collaborations_in_multiagent_reinforcement_learning	/pdf/a5306aac11abd8d0df98e4099859e8b005f6ef17.pdf
QP02DQ-FG-8	2819	Incomplete to complete multiphysics forecasting - a hybrid approach for learning unknown phenomena	['neural physics simulations', 'multi-physics systems', 'reactive flows', 'differentiable PDE solvers']	This paper proposes a hybrid framework that combines neural network models with an incomplete PDE solver to account for the effects of unknown physics present in the system to predict a long-term temporal evolution of a complete, multiphysics system	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|incomplete_to_complete_multiphysics_forecasting_a_hybrid_approach_for_learning_unknown_phenomena	/pdf/cee69c7768cc9b3d78683646a3e59c8fea784291.pdf
LR_KWiUgS8F	2820	AD-NEGF: An End-to-End Differentiable Quantum Transport Simulator for Sensitivity Analysis and Inverse Problems	['Quantum Transport', 'Non-Equilibrium Green Function', 'Automatic Differentiation', 'Differentiable Programming', 'Deep Learning', 'Sensitivity Analysis', 'Inverse Design']	We provide to the best of our knowledge the first end-to-end differentiable quantum transport simulator, which can compute differential quantities and perform atomic level device optimization.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|adnegf_an_endtoend_differentiable_quantum_transport_simulator_for_sensitivity_analysis_and_inverse_problems	/pdf/0f6f32decd383755d1c115310d63b7e3ea70777a.pdf
fZb-Mg6Wip5	2823	KerDEQ: Optimization induced Deep Equilibrium models via Gaussian Kernel	[]		Deep Learning and representational learning	anonymous|kerdeq_optimization_induced_deep_equilibrium_models_via_gaussian_kernel	/pdf/8596ead6ab43593784132d92cd58265abf8a36fe.pdf
6MMOFoiWnDM	2824	GT-CausIn: a novel causal-based insight for traffic prediction	['spatiotemporal forecasting', 'causal discovery', 'graph neural networks']	A model fusing causal knowledge, space dependency and temporal dependency is proposed in this work.	Deep Learning and representational learning	anonymous|gtcausin_a_novel_causalbased_insight_for_traffic_prediction	/pdf/5e638a57da295f6636b3b32a9a55e014ac1cc0bb.pdf
FZCFlj2_c7z	2825	Jump-Start Reinforcement Learning	['reinforcement learning', 'offline reinforcement learning', 'fine-tuning']	Efficiently initializing reinforcement learning policies using a prior policy. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|jumpstart_reinforcement_learning	/pdf/6ee43bc6f0648ea734f5fa4dcf9ed9a99bbf067d.pdf
d3QNWD_pcFv	2826	"Neural Lagrangian Schr\""{o}dinger Bridge: Diffusion Modeling for Population Dynamics"	['Population Dynamics', 'Trajectory Inference', 'Neural SDEs', 'Stochastic Optimal Transport', 'Schrödinger Bridge']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neural_lagrangian_schr\odinger_bridge_diffusion_modeling_for_population_dynamics	/pdf/fa82b7ea6b3b51b15dc96797c71469c4abafa19a.pdf
j6zUzrapY3L	2827	Geometric Networks Induced by Energy Constrained Diffusion	['structured representation learning', 'diffusion model', 'optimization-induced model', 'node prediction']	We introduce an energy constrained diffusion model for semi-supervised representation learning, based on which a new class of nerual encoders is derived for efficiently and effectively learning inter-instance latent graphs	Deep Learning and representational learning	anonymous|geometric_networks_induced_by_energy_constrained_diffusion	/pdf/856bd01dba97640c12dcb169e4da5ecb85f4de28.pdf
Eo89g5X1m5g	2828	Sample Relationships through the Lens of Learning Dynamics with Label Information	['Sample Relationship', 'Iterated Learning', 'Generalisation', 'Neural Networks', 'Neural Tangent Kernel']	We propose a new kernel function for neural networks which can take the label information into consideration, and show that it helps to improve generalisation performance.	Deep Learning and representational learning	anonymous|sample_relationships_through_the_lens_of_learning_dynamics_with_label_information	/pdf/ec4e4bda771cdb2f4ab893fce2c655e5ba682ac1.pdf
UaAD-Nu86WX	2829	DiGress: Discrete Denoising diffusion for graph generation	['Graph generation', 'Denoising Diffusion Model', 'Molecule Generation', 'Permutation Equivariance', 'Discrete Diffusion']	We propose a discrete denoising diffusion model for generating graphs with categorical node and edge attributes. It is state-of-the-art on both abstract and molecular datasets.	Generative models	anonymous|digress_discrete_denoising_diffusion_for_graph_generation	/pdf/ab9c7361c1ff99e507a071ebce15329c82093245.pdf
PNyvODFNTkZ	2830	Lightweight CNNs Under A Unifying Tensor View	['compression', 'tensor decomposition', 'CNNs', 'FPGA']	A unifying tensor view is introduced, which provides an easy-to-understand graphical illustration of various lightweight CNN components. A novel shift layer pruning scheme is proposed in response to the framework.	Applications (eg, speech processing, computer vision, NLP)	anonymous|lightweight_cnns_under_a_unifying_tensor_view	/pdf/4243b29850fd7e8773b4a8724dad922cd0303418.pdf
eL1iX7DMnPI	2833	Privacy-Preserving Vision Transformer on Permutation-Encrypted Images	['vision transformer', 'privacy']	We propsoe a novel privacy-preserving learning paradigm that removes human-recognizable contents while preserves machine-learnable information.	Applications (eg, speech processing, computer vision, NLP)	anonymous|privacypreserving_vision_transformer_on_permutationencrypted_images	/pdf/5fcc704d6205c30678da896a5fd631f9ea16f2ea.pdf
4nrZXPFN1c4	2834	Energy Transformer	['Transformers', 'Hopfield Networks', 'Graph Anomaly Detection']	We propose a network, which describes the forward pass in a transformer as a gradient decent on an energy function. 	Deep Learning and representational learning	anonymous|energy_transformer	/pdf/56e8dd7f52713c844375e2876a698ce71d53238b.pdf
j3cUWIMsFBN	2835	Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States	[]		Deep Learning and representational learning	anonymous|unbiased_stochastic_proximal_solver_for_graph_neural_networks_with_equilibrium_states	/pdf/aec862fe1d0a1c805abfff87d3e7957ff21ed4c5.pdf
XWWAvqMMal5	2836	How Predictors Affect Search Strategies in Neural Architecture Search?	['Neural Architecture Search', 'Predictor-based Neural Architecture Search', 'Reinforcement Learning']	We study theoretically and empirically the impact of predictors on NAS search strategies.	Applications (eg, speech processing, computer vision, NLP)	anonymous|how_predictors_affect_search_strategies_in_neural_architecture_search	/pdf/f5e0a8b6a58e3d534293081034b9870a45624c74.pdf
ZbwqqxW2f-G	2837	RangeAugment:  Efficient Online Augmentation with Range Learning	['Automatic Augmentation']	Efficiently learn the range of magnitudes for each augmentation operation in a constant time	Applications (eg, speech processing, computer vision, NLP)	anonymous|rangeaugment_efficient_online_augmentation_with_range_learning	/pdf/72bb265d10fa95b160df1f9cc3cca6d69edb2bfc.pdf
xgFfr5IIuXP	2838	Clustering and Ordering Variable-Sized Sets: The Catalog Problem	['neural clustering', 'set-to-sequence', 'supervised clustering', 'structure prediction', 'set representation', 'learning to order']	A neural method for predicting an adaptive number of diverse, ordered clusters from any set is introduced and tested on synthetic and real-world datasets, demonstrating top performance on new and harder formulation of the PROCAT challenge.	Deep Learning and representational learning	anonymous|clustering_and_ordering_variablesized_sets_the_catalog_problem	/pdf/33dbec164decabd10f2ecd63e1fc9c52adb04912.pdf
mMNimwRb7Gr	2839	Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection	['out-of-distribution detection', 'federated learning', 'heterogeneity']		Deep Learning and representational learning	anonymous|turning_the_curse_of_heterogeneity_in_federated_learning_into_a_blessing_for_outofdistribution_detection	/pdf/eaa7582567d972e7a63b1ac9190761412c690edc.pdf
2sAVJZGwQRx	2840	EFFECTIVE FREQUENCY-BASED BACKDOOR ATTACKS WITH LOW POISONING RATIOS	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|effective_frequencybased_backdoor_attacks_with_low_poisoning_ratios	/pdf/7b68b04ba1f19cef7554d236f5e813b1279f055b.pdf
VUdMeSbExWg	2841	Imitation Learning for Mean Field Games with Correlated Equilibria	['Imitation Learning', 'Mean Field Games', 'Correlated Equilibria']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|imitation_learning_for_mean_field_games_with_correlated_equilibria	/pdf/d4111bac6410bffd72397fb42ee72091d2e42f7c.pdf
ReDQ1OUQR0X	2842	Human alignment of neural network representations	['Human Alignment', 'Robustness', 'Neural Network Representations', 'Human Concepts', 'Object Similarity', 'Computer Vision']	We evaluate the alignment of neural network representations with human judgments about object similarities in an odd-one-out triplet task, finding that dataset and objective function, but not model size or architecture, have a significant impact.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|human_alignment_of_neural_network_representations	/pdf/a2c679070d30fa2734532ebe28fea5945403817a.pdf
GF4A49QlqjN	2843	SuperWeight Ensembles: Automated Compositional Parameter Sharing Across Diverse Architechtures	['efficent ensembles', 'anytime inference']	 A novel efficient ensembling technique for ensembling models of different architechtures; enabling anytime inference	Deep Learning and representational learning	anonymous|superweight_ensembles_automated_compositional_parameter_sharing_across_diverse_architechtures	/pdf/96471385a6b08ca363f4f8fe067afc4b066ff18e.pdf
5Z1rblK1Be5	2844	A Risk-Averse Equilibrium for Multi-Agent Systems	['game theory', 'safe game theory', 'risk averse game theory', 'safe equilibrium', 'population learning', 'game theory equilibrium']	We introduce a novel risk-averse solution concept that allows the learner to accommodate low probability actions by finding the strategy with minimum variance, given any level of expected utility. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_riskaverse_equilibrium_for_multiagent_systems	/pdf/5959d8b2cc20a0962eb31b63b1ca17d99b1f9fb1.pdf
yHY9NbQJ5BP	2846	Sparsity-Constrained Optimal Transport	['optimal transport', 'sparsity']	We propose formulations for optimal transport with cardinality constraints and apply them to sparse mixture of experts.	Optimization (eg, convex and non-convex optimization)	anonymous|sparsityconstrained_optimal_transport	/pdf/75d542abafdb913c9ac59569d518b3f4a1b53d33.pdf
LfdEuhjR5GV	2847	Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks	['Adversarial Training', 'Monocular Depth Estimation', 'Adversarial Attack', 'Self-supervised Learning.']	Use self-supervised adversarial training to harden monocular depth estimation models against physical-world adversarial attacks.	Unsupervised and Self-supervised learning	anonymous|adversarial_training_of_selfsupervised_monocular_depth_estimation_against_physicalworld_attacks	/pdf/f2b344e92737e88be6a94e57d4573f86490193ac.pdf
8TjyUm_XarL	2848	Domain Generalization in Regression	['domain generalization', 'regression', 'meta-learning']	We propose a new domain generalization setting in regression scenario and a weighted meta-learning solution.	Deep Learning and representational learning	anonymous|domain_generalization_in_regression	/pdf/85e9eacfaf092eae64776e5093cc02372c16b5cb.pdf
7Di4aNrBAhv	2849	Contrastive Graph Few-Shot Learning	['Graph representation learning', 'Few-shot learning', 'Contrastive learning']	We propose CGFL, a general and effective framework to mitigate the distribution shift impact for learning more generalizable representations on graph few-shot-learning tasks.	Deep Learning and representational learning	anonymous|contrastive_graph_fewshot_learning	/pdf/ad3d1573c9677ad2e50a8be7395bd795f42e515e.pdf
98p5x51L5af	2854	Prompting GPT-3 To Be Reliable	['prompting', 'GPT-3', 'large language models', 'reliability', 'robustness', 'biases', 'calibration', 'knowledge updating']	We establish simple and effective prompting methods to make GPT-3 reliable in terms of: robustness, fairness, calibration, factuality. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|prompting_gpt3_to_be_reliable	/pdf/3651f9d6f2edc699503eca08deffeb0ee03315bf.pdf
PYSktOGKBkY	2855	Provable Sharpness-Aware Minimization with Adaptive Learning Rate 	['Adaptive learning rate', 'Sharpness aware minimization', 'mini-batch linear speedup']	We present the first convergence guarantee of the adaptive SAM method with a linear speedup property under the non-convex setting.	Optimization (eg, convex and non-convex optimization)	anonymous|provable_sharpnessaware_minimization_with_adaptive_learning_rate	/pdf/353568fae6172bfc348cf49e64c59da785a787c0.pdf
f_yTeb1v-GW	2856	Siamese DETR	['object detection', 'unsupervised learning', 'Transformer']		Unsupervised and Self-supervised learning	anonymous|siamese_detr	/pdf/0d7e5efab43ac43fd615b65f5691e842cbe6003e.pdf
iYvbPx8GTta	2857	SeedGNN: Graph Neural Network for Supervised Seeded Graph Matching	['seeded graph matching', 'Graph Neural Network (GNN)', 'percolation', 'multi-hop witnesses']	We propose a new supervised GNN method for seeded graph matching that can learn from a training set how to match unseen graphs with only a few seeds.	Deep Learning and representational learning	anonymous|seedgnn_graph_neural_network_for_supervised_seeded_graph_matching	/pdf/d98fa05531f1c87a1e7847d936de4a00f2e84bcf.pdf
b3k_8yKKdag	2858	Observational Robustness and Invariances in Reinforcement Learning via Lexicographic Objectives	['Robust Reinforcement Learning', 'Safe Reinforcement Learning', 'Lexicographic Optimization']	We use lexicographic optimization to induce robustness in RL policies in a safe way.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|observational_robustness_and_invariances_in_reinforcement_learning_via_lexicographic_objectives	/pdf/79c63f554755cb777e28774fc66acdd1f6feb48a.pdf
tkvyCt1PzpvP	2859	Class Interference of Deep Networks	['Minima sharpness', 'generalization', 'loss contour', 'visualization']	We show that there is a phenomenon of class interference with all deep neural networks.	Deep Learning and representational learning	anonymous|class_interference_of_deep_networks	/pdf/c71312e9021b26748b61be219b3a2a905296197e.pdf
GULFHQfgw0g	2860	Neural Agents Struggle to Take Turns in Bidirectional Emergent Communication	['language emergence', 'turn-taking', 'conversation', 'communication', 'neural agents', 'cooperative game', 'reinforcement learning']	Neural agents struggle to develop a turn-taking protocol when playing cooperative game for which they have to communicate.	General Machine Learning (ie none of the above)	anonymous|neural_agents_struggle_to_take_turns_in_bidirectional_emergent_communication	/pdf/55dd905248cc7e1d7167d53a2cc819e7a4317e91.pdf
GVSf7Z7DbYL	2861	Teacher Guided Training: An Efficient Framework for Knowledge Transfer	['Distillation', 'Semisupervised learning', 'Efficient machine learning', 'Generalization bounds', 'knowledge distillation']	We propose and theoretically analyze a novel way to improve the training efficiency of compact student models that better leverages the knowledge of pretrained generative (teacher) models compared to standard distillation methods.	Deep Learning and representational learning	anonymous|teacher_guided_training_an_efficient_framework_for_knowledge_transfer	/pdf/570375e50e62b4b1b75352e28760c227b1c5eb0b.pdf
-wDaB590pkt	2862	Coarse-to-fine Knowledge Graph Domain Adaptation based on Distantly-supervised Iterative Training	['Knowledge Graph Domain Adaptation', 'Knowledge Graph Construction', 'Named Entity Recognition', 'Relationship Extraction']		Applications (eg, speech processing, computer vision, NLP)	anonymous|coarsetofine_knowledge_graph_domain_adaptation_based_on_distantlysupervised_iterative_training	/pdf/c01d1176ab689b575b4b248a202df6e46be74d88.pdf
EMvG1Jdhw_8	2864	Disentangling Learning Representations with Density Estimation	['autoencoder', 'representation learning', 'disentanglement', 'density estimation']	We present GCAE, a scalable disentanglement method that uses the dual total correlation criterion	Deep Learning and representational learning	anonymous|disentangling_learning_representations_with_density_estimation	/pdf/9b30f501de58195e04808073ae28826d093fb3d4.pdf
1_jtWjhSSkr	2865	Exponential Generalization Bounds with Near-Optimal Rates for $L_q$-Stable Algorithms	['$L_q$-stability', 'Uniform stability', 'Moments inequality', 'Exponential generalization bound', 'Excess risk', 'Sparsity']	We presented a set of sharper and near-optimal exponential generalization bounds for $L_q$-stable learning algorithms	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|exponential_generalization_bounds_with_nearoptimal_rates_for_l_qstable_algorithms	/pdf/d005ab814d0dfe3ae0660591ab9e85a26a6a84b0.pdf
eoUsOflG7QD	2866	Deep Evidential Reinforcement Learning for Dynamic Recommendations	['recommender system', 'exploration', 'actor-critic']	we propose a novel deep evidential reinforcement learning (DERL) framework that learns a more effective recommendation policy by integrating both the expected reward and evidence-based uncertainty.	Applications (eg, speech processing, computer vision, NLP)	anonymous|deep_evidential_reinforcement_learning_for_dynamic_recommendations	/pdf/61b57e99a601e78dd9b49fda84caf91298215ead.pdf
Xt87fcPFArU	2867	Bidirectional global to local attention for deep metric learning.	['Deep Metric Learning', 'Visual Similarity Learning', 'Attention']		Deep Learning and representational learning	anonymous|bidirectional_global_to_local_attention_for_deep_metric_learning	/pdf/765cdc7f05f73152b5e76f1acca10d74c34b2c06.pdf
shzu8d6_YAR	2868	FaiREE: fair classification with finite-sample and distribution-free guarantee	['algorithmic fairness', 'distribution-free', 'finite-sample', 'classification']	We propose a fair classification algorithm which can satisfy the group fairness constraints with finite-sample and distribution-free guarantees.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fairee_fair_classification_with_finitesample_and_distributionfree_guarantee	/pdf/7a052eceb7a90f3e29cb1f75c01f87ffc0fd9f1b.pdf
7AwPeT4XbAh	2870	Multi-Modality Alone is Not Enough: Generating Scene Graphs using Cross-Relation-Modality Tokens	['scene graphs', 'transformers', 'fusion strategies', 'multi-modal']	Introducing a novel cross relational multi-modal token generation strategy for scene graphs	Deep Learning and representational learning	anonymous|multimodality_alone_is_not_enough_generating_scene_graphs_using_crossrelationmodality_tokens	/pdf/a8c82019196cd323ed47e6ee0d56983a6865f2b4.pdf
d5LLy8_6_YV	2871	Semi-Variance Reduction for Fair Federated Learning	['Federated Learning', 'Fairness']	We propose two new algorithms for fair federated learning based on variance and semi-variance regularization	General Machine Learning (ie none of the above)	anonymous|semivariance_reduction_for_fair_federated_learning	/pdf/6192167d828ed9782c3ee707862a67b62dd85daf.pdf
0nroZT5gHsS	2872	Generalization Properties of Retrieval-based Models	['Generalization bounds', 'retrieval-based models', 'local empirical risk minimization', 'semiparametric models', 'nonparametric models', 'kernel methods']	We present a novel theoretical analysis to study the generalization bounds for retrieval-based classification models.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|generalization_properties_of_retrievalbased_models	/pdf/485214e33f7c4ec6dd3f10eff789685210950194.pdf
zClyiZ5V6sL	2874	TiAda: A Time-scale Adaptive Algorithm For Nonconvex Minimax Optimization	['optimization', 'minimax optimization', 'adaptive algorithm']		Optimization (eg, convex and non-convex optimization)	anonymous|tiada_a_timescale_adaptive_algorithm_for_nonconvex_minimax_optimization	/pdf/860291072b9c6d1c8284e1a3d7903369e58e57d7.pdf
gJW8hSGBys8	2875	Compositional Semantic Parsing with Large Language Models	['large language models', 'prompting', 'compositional generalization', 'natural language processing']	Using an extension of least-to-most prompting we demonstrate strong performance on two benchmarks for compositional generalization, CFQ and COGS, and achieve state of the art on CFQ while using only 1% of the training data.	Applications (eg, speech processing, computer vision, NLP)	anonymous|compositional_semantic_parsing_with_large_language_models	/pdf/2e61528b2eb3ea34587781b99375e20478485615.pdf
mXwThfu1HQL	2876	Deep Patch Visual Odometry	['Visual Odometry', 'SLAM', 'Simultaneous Localization and Mapping', '3D', 'Structure from Motion']	We propose a new deep learning system for monocular Visual Odometry.	Applications (eg, speech processing, computer vision, NLP)	anonymous|deep_patch_visual_odometry	/pdf/df43c3c88adf8e5c30a2018f209529955748c694.pdf
w1hwFUb_81	2877	Sparse MoE with Random Routing as the New Dropout: Training Bigger and Self-Scalable Models	['Sparse Mixture-of-Experts', 'Random Routing', 'Transformer Training', 'Dropout']	A new plug-and-paly strategy for training over-parameterized transformer models, leverages SMoEs with random routings to empower scaling transformers to better performance in the full capacity settings without collapse.	Deep Learning and representational learning	anonymous|sparse_moe_with_random_routing_as_the_new_dropout_training_bigger_and_selfscalable_models	/pdf/a382315ccc5ca843f07bc0b3ab16092a2ad14f58.pdf
jAD0chIdt_	2878	Impulse Control Arbitration for A Dual System of Exploitation and Exploration	['reinforcement learning. exploration-exploitation tradeoff', 'impulse control switching']	We propose a plug-and-play framework with a learned impulse control switching mechanism for targeted arbitration between exploration and exploitation behaviour.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|impulse_control_arbitration_for_a_dual_system_of_exploitation_and_exploration	/pdf/4016512f524c9ec6a88b8cc9c98bb54c24a3a238.pdf
OqPD_6kukm	2879	Self-supervised Speech Enhancement using Multi-Modal Data	['multi-modal', 'selfsupervise', 'denoising', 'iterative algorithm', 'attention map', 'expectation maximization', 'IMU']	Using clean low resolution IMU data to supervise the multimodal denoiser	Unsupervised and Self-supervised learning	anonymous|selfsupervised_speech_enhancement_using_multimodal_data	/pdf/1b4db5f95515b41b37f7906795c6a1a151403ba3.pdf
uVcDssQff_	2880	REVISITING PRUNING AT INITIALIZATION THROUGH THE LENS OF RAMANUJAN GRAPH	['pruning at initialization', 'graph theory', 'Ramanujan Graph', 'sparse neural networks']		Deep Learning and representational learning	anonymous|revisiting_pruning_at_initialization_through_the_lens_of_ramanujan_graph	/pdf/45dfbe725c86444dec940eb63a0e9dac2f8e75ca.pdf
wq0luyH3m4	2881	Hard-Meta-Dataset++: Towards Understanding Few-Shot Performance on Difficult Tasks	['Few-shot learning', 'Meta-Dataset', 'Benchmarks', 'Evaluation']	We propose (i) a general and computationally efficient algorithm to extract difficult few-shot classification tasks from large-scale vision datasets, and (ii) a new test benchmark of these difficult tasks to stress test few-shot classifiers.	Deep Learning and representational learning	anonymous|hardmetadataset_towards_understanding_fewshot_performance_on_difficult_tasks	/pdf/0f2b34379798e2dd1c9d925d284ebc9668c30228.pdf
G6-oxjbc_mK	2882	Sharper Analysis of Sparsely Activated Wide Neural Networks with Trainable Biases	['Convergence analysis', 'sparse activation', 'neural tangent kernel', 'Rademacher complexity', 'generalization bound']	We study convergence and generalization of training one-hidden-layer neural networks with sparse activation. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|sharper_analysis_of_sparsely_activated_wide_neural_networks_with_trainable_biases	/pdf/8ba17609322f0a2d2d37bd7a3b5fbd5c6d4f878f.pdf
Sh97TNO5YY_	2883	Biases in Evaluation of Molecular Optimization Methods and Bias Reduction Strategies	[]	This paper analyzes biases in the evaluation of molecular optimization methods, and methods to alleviate them.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|biases_in_evaluation_of_molecular_optimization_methods_and_bias_reduction_strategies	/pdf/106dc37f05b949150cc78b90e79512c41069b3a9.pdf
M_c03_fU2cl	2884	Domain-Unified Prompt Representations for Source-Free Domain Generalization	['Source-free domain generalization', 'vision-language pretraining model']		Deep Learning and representational learning	anonymous|domainunified_prompt_representations_for_sourcefree_domain_generalization	/pdf/00575284b9a2b846ba606d51cfa5eff025a50dc4.pdf
FU2FX1wDN2x	2885	gGN: learning to represent nodes in directed graphs as low-rank Gaussian distributions	['knowledge graphs', 'representation learning', 'low-rank approximation', 'Gaussian distribution', 'deep learning']	Representing graph nodes using low-rank Gaussian distributions	Deep Learning and representational learning	anonymous|ggn_learning_to_represent_nodes_in_directed_graphs_as_lowrank_gaussian_distributions	/pdf/e6acc6af7b90687fd7b028c2ac25210b92eee9f8.pdf
sPCKNl5qDps	2886	Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework	['curvature', 'hypergraphs', 'graphs', 'Wasserstein distance', 'topological data analysis', 'random walks', 'probability measure']	We introduce a flexible framework for Ollivier-Ricci curvature on hypergraphs.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|ollivierricci_curvature_for_hypergraphs_a_unified_framework	/pdf/0e9249da49c8178b6099cb6f200e4beab9dddfc3.pdf
RiTjKoscnNd	2887	Equivariant Hypergraph Diffusion Neural Operators	['Hypergraph Neural Network', 'Hypergraph Diffusion', 'Equivariant Network']	In this work, we are inspired by hypergraph diffusion algorithms and design a novel HNN architecture that holds provable expressiveness while keeping efficiency.	Deep Learning and representational learning	anonymous|equivariant_hypergraph_diffusion_neural_operators	/pdf/7f1905cc0453b008a49cf5dbaf2a3746f1d50f75.pdf
g4OTKRKfS7R	2888	Liquid Structural State-Space Models	['state-space models', 'liquid neural networks', 'time series. memory', 'recurrent neural networks']	We use the recently proposed parametrization and memorization techniques for training state-space models in a linearized version of liquid neural networks, and achieve SOTA on sequence modeling tasks.	Deep Learning and representational learning	anonymous|liquid_structural_statespace_models	/pdf/c077230ceb3fd7879f8fd95c914ddafc943c017d.pdf
EPUWZhBd9Lb	2889	Interpolating Compressed Parameter Subspaces	[]		Deep Learning and representational learning	anonymous|interpolating_compressed_parameter_subspaces	/pdf/151f43d20efe2d35a6c9a8ff1a561727f710bc66.pdf
SMa9EAovKMC	2890	Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|draft_sketch_and_prove_guiding_formal_theorem_provers_with_informal_proofs	/pdf/1ac592e462031570d24e66540bd8e9033ff74df2.pdf
fkNZtv_-BeW	2891	Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|backdoors_stuck_at_the_frontdoor_multiagent_backdoor_attacks_that_backfire	/pdf/150b65c5f31f62a36049393cda88c5406f3043e2.pdf
dn6_PK73hAY	2892	Theoretical Characterization of How Neural Network Pruning Affects its Generalization	['pruning', 'neural network', 'gradient descent', 'generalization']	We study the effect of pruning under different rates on neural network generalization. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|theoretical_characterization_of_how_neural_network_pruning_affects_its_generalization	/pdf/a11efe7bdaaa31b8fe0a66886d2db2c3345b10cf.pdf
sCrnllCtjoE	2893	Scaleformer: Iterative Multi-scale Refining Transformers for Time Series Forecasting	['Time-series forecasting', 'Transformers']	Propose a new framework to improve recent state-of-the-arts on time-series forecasting using transformers.	Applications (eg, speech processing, computer vision, NLP)	anonymous|scaleformer_iterative_multiscale_refining_transformers_for_time_series_forecasting	/pdf/edc735c4eb2435aa0742ccb5ce357c19295001e9.pdf
ESR6hysKDsW	2894	Class-Incremental Learning with Repetition	['continual learning', 'lifelong learning', 'class-incremental learning', 'incremental learning']		Deep Learning and representational learning	anonymous|classincremental_learning_with_repetition	/pdf/de7989cec16145b574e42393c02263292ca5faaa.pdf
CJd-BtnwtXq	2895	A non-asymptotic analysis of oversmoothing in Graph Neural Networks	['graph neural networks', 'oversmoothing', 'representational power', 'theory', 'deep learning']	We precisely characterize the mechanism of overmoothing via a non-asymptotic analysis and answer why oversmoothing happens in shallow GNNs.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_nonasymptotic_analysis_of_oversmoothing_in_graph_neural_networks	/pdf/c03847549ab0054f526dd2f1959514cc2b9609c4.pdf
03sXXjL1um3	2896	Linear convergence for natural policy gradient with log-linear policy parametrization	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|linear_convergence_for_natural_policy_gradient_with_loglinear_policy_parametrization	/pdf/973a1eae9e570b7bfcee92d2fe899e096dddd09d.pdf
eEoSHelICSG	2897	Joint Embedding Self-Supervised Learning in the Kernel Regime	[]	We analyze and derive self-supervised learning algorithms using kernel methods	Unsupervised and Self-supervised learning	anonymous|joint_embedding_selfsupervised_learning_in_the_kernel_regime	/pdf/857c88b6005b1213abceb0dada3e843d2d660c3a.pdf
wlMDF1jQF86	2898	Which Layer is Learning Faster? A Systematic Exploration of Layer-wise Convergence Rate for Deep Neural Networks	['Deep neural networks', 'Convergence rate']	We empirically show that the shallower layers converge faster than the deeper layers in neural networks, and provide the theoretical justification and practical value of this finding.	Deep Learning and representational learning	anonymous|which_layer_is_learning_faster_a_systematic_exploration_of_layerwise_convergence_rate_for_deep_neural_networks	/pdf/91106df0586bb1fed00f3c75f2f2fc968d6b41d1.pdf
cy554rYBzMT	2899	How deep convolutional neural networks lose spatial information with training	['Deep Learning Theory', 'Convolutional Neural Networks', 'Curse of Dimensionality', 'Representation Learning', 'Feature Learning', 'Computer Vision', 'Pooling', 'Stability', 'Diffeomorphisms', 'Gaussian noise', 'Image Classification', 'Learning Invariants']	Deep nets perform image classification by aggregating information over space. We investigate the mechanisms by which this is achieved and propose a theory for an artificial scale-detection task.	Deep Learning and representational learning	anonymous|how_deep_convolutional_neural_networks_lose_spatial_information_with_training	/pdf/c8b92604636229ac74372977e054d48d705ce548.pdf
qRD7kqmr9HJ	2900	Pruning Parameterization with Bi-level Optimization for Efficient Semantic Segmentation on the Edge	['Segmentation', 'efficient deep learning', 'pruning']	We proposed a pruning parameterization method for real-time semantic segmentation on the edge.	Applications (eg, speech processing, computer vision, NLP)	anonymous|pruning_parameterization_with_bilevel_optimization_for_efficient_semantic_segmentation_on_the_edge	/pdf/53613ce44c70ee0f3f5f5fd548553de17c8018f1.pdf
TFMEqzfFrP_	2902	Input Perturbation Reduces Exposure Bias in Diffusion Models	['Generative Models', 'Diffusion Model']		Generative models	anonymous|input_perturbation_reduces_exposure_bias_in_diffusion_models	/pdf/929ae76de67910895114756e5532598849d05528.pdf
H73xwqPfW2f	2904	Multitask Reinforcement Learning by Optimizing Neural Pathways	['Multitask Learning', 'Online Reinforcement Learning', 'Offline Reinforcement Learning', 'Neural Pathways']	Proposing a novel multitask learning framework using task-specific neural pathways for online and offline reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multitask_reinforcement_learning_by_optimizing_neural_pathways	/pdf/534050f4e8df17aa5dcb687854dbe4bd3f17fdf8.pdf
J6F3lLg4Kdp	2905	Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!	['Sparse Neural Networks', 'Benchmark', 'Sparsity', 'Neural Network Pruning']	In this work, we assemble a large-scale, difficult and diverse benchmark for sparse neural networks, on which current SOTA sparse networks are actually prone to significant performance degradation, sometimes even at trivial sparsity levels, e.g., 5%.	Deep Learning and representational learning	anonymous|sparsity_may_cry_let_us_fail_current_sparse_neural_networks_together	/pdf/742b7fdecdb5f32393adb5e12ce8c7a27d5e0661.pdf
W6topEXC2-v	2906	Do Perceptually Aligned Gradients Imply Robustness?	['Adversarial Robustness', 'Perceptually Aligned Gradients']		General Machine Learning (ie none of the above)	anonymous|do_perceptually_aligned_gradients_imply_robustness	/pdf/a7cac514ce85cf2da303b45459f346940ec8ccd3.pdf
oqSKdRyYO1g	2907	Performance Disparities Between Accents in Automatic Speech Recognition	['bias', 'automatic speech recognition', 'natural language processing', 'artificial intelligence', 'machine learning', 'accent', 'dialect', 'english', 'language', 'speech', 'fairness', 'audit']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|performance_disparities_between_accents_in_automatic_speech_recognition	/pdf/b7fe02daebf882d0c105b9180647ff7cc4aa9f8c.pdf
LVum7knUA7g	2908	Stationary Deep Reinforcement Learning with Quantum K-spin Hamiltonian Equation	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|stationary_deep_reinforcement_learning_with_quantum_kspin_hamiltonian_equation	/pdf/acf5ccd14befa4104c73182df74233f444fb6458.pdf
-WiOF7FTt-n	2909	Rethinking Positive Sampling for Contrastive Learning with Kernel	['contrastive learning', 'kernel theory', 'representation learning', 'deep learning']	Improving positive sampling in contrastive learning using kernel	Deep Learning and representational learning	anonymous|rethinking_positive_sampling_for_contrastive_learning_with_kernel	/pdf/6fe4bbfb313664cbc5fc4cdc8f19548da3d0934e.pdf
7zxPlqOT5us	2910	Learning Critically in Federated Learning with Noisy and Heterogeneous Clients	['Federated learning', 'Noisy labels', 'Class imbalance']		Deep Learning and representational learning	anonymous|learning_critically_in_federated_learning_with_noisy_and_heterogeneous_clients	/pdf/f1ca667964f81e10882744755e01472c3da8b44c.pdf
6G1MXNU8VtV	2911	Black-Box Adversarial Attack Guided by Model Behavior for Programming Pre-trained Language Models	['black-box', 'adversarial attack', 'pre-trained models for programming languages', 'code model']	We use the uncertainty of model outputs to guide searching for adversarial examples by the variable name replacement.	Applications (eg, speech processing, computer vision, NLP)	anonymous|blackbox_adversarial_attack_guided_by_model_behavior_for_programming_pretrained_language_models	/pdf/8f5c141803cd84b9dc348bdbfa31c23df68f5a9b.pdf
DJEEqoAq7to	2913	RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch	['Deep Reinforcement Learning', 'Lottery Ticket Hypothesis', 'Model Compression', 'Value Learning']	We propose a new framework for training an efficient DRL agent from scratch with an ultra-sparse network with strong performanc without performance degradation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|rlx2_training_a_sparse_deep_reinforcement_learning_model_from_scratch	/pdf/27d180056eb8d240a6267c239f876b399f15ff28.pdf
sCYXJr3QJM8	2914	Few-shot Cross-domain Image Generation via Inference-time Latent-code Learning	['generative domain adaptation', 'generative adversarial network']	Adapt a GAN trained on a single large-scale source dataset to multiple target domains containing very few examples without re-training the pretrained source generator.	Generative models	anonymous|fewshot_crossdomain_image_generation_via_inferencetime_latentcode_learning	/pdf/571353f114781ce879030a5c9a057a1f4a157ee9.pdf
NCNT1r62-UV	2915	Projected Latent Distillation for Data-Agnostic Consolidation in Multi-Agent Continual Learning	['continual learning', 'knowledge distillation']		Deep Learning and representational learning	anonymous|projected_latent_distillation_for_dataagnostic_consolidation_in_multiagent_continual_learning	/pdf/94dc21dd6ede36e6f809b08f169dd7cb52a40e6b.pdf
ek6kvkKb7wm	2916	On Structural Expressive Power of Graph Transformers	['graph representation learning', 'graph isomorphism testing', 'graph Transformer']	Investigating the expressive power of graph Transformers.	Deep Learning and representational learning	anonymous|on_structural_expressive_power_of_graph_transformers	/pdf/f539cab63f7ab059bc13949b13a433eb69f19769.pdf
m8fizQRZLUu	2917	FLEXPOOLING WITH SIMPLE AUXILIARY CLASSI- FIERS IN DEEP NETWORKS	['Flex pooling', 'Simple auxiliary classifiers']	In this paper, we propose a simple yet effective adaptive pooling method, referred to as FlexPooling, which generalizes the concept of average pooling by learning a weighted average pooling over the activations jointly with the rest of the network	Deep Learning and representational learning	anonymous|flexpooling_with_simple_auxiliary_classi_fiers_in_deep_networks	/pdf/da0dc0272e3248d95818657f00d0c876f30a1f62.pdf
W4HBwaybWedX	2918	Language-Aware Soft Prompting for Vision & Language Foundation Models	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|languageaware_soft_prompting_for_vision_language_foundation_models	/pdf/5c6f4cdf47a3d1284aa473b25cf810adaaaea7d0.pdf
bXNl-myZkJl	2919	More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity	['51x51 kernel', 'Large kernel convolution', 'convolutional neural networks', 'sparsity', 'backbone']	We propose Sparse Large Kernel Network (SLaK), a pure CNN architectures equipped with 51x51 kernels that can perform on par with or better than the state-of-the-art hierarchical Transformers and modern ConvNets.	Deep Learning and representational learning	anonymous|more_convnets_in_the_2020s_scaling_up_kernels_beyond_51x51_using_sparsity	/pdf/103a5330f165b050106bf8e2cb8aade59d486f91.pdf
ZLvwIqjMJtO	2920	When to Trust Aggregated Gradients: Addressing Negative Client Sampling in Federated Learning	['federated learning', 'client sampling']	We find that existing federated optimization suffers from the unreliable aggregated gradients caused by the negative client sampling results, and propose a gradient similarity–aware learning rate adaptation mechanism to address this problem.	Deep Learning and representational learning	anonymous|when_to_trust_aggregated_gradients_addressing_negative_client_sampling_in_federated_learning	/pdf/c057ac2dbe2d09a43b09b14e2807c05d9838bd36.pdf
2iKvo44-Bya	2921	System Identification as a Reinforcement Learning Problem	['System Identification', 'Reinforcement Learning', 'Offline Reinforcement Learning', 'Forward Models']	System Identification as a Reinforcement Learning Problem	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|system_identification_as_a_reinforcement_learning_problem	/pdf/c145257e427f03243c05e82d3b5b718b0658ee81.pdf
jDOE5xirIJb	2923	GOING BEYOND 1-WL EXPRESSIVE POWER WITH 1-LAYER GRAPH NEURAL NETWORKS	['graph neural networks', 'expressivity', 'memory-efficient']	A fast and memory-efficient method to enhance the expressive power of GNNs	Deep Learning and representational learning	anonymous|going_beyond_1wl_expressive_power_with_1layer_graph_neural_networks	/pdf/a59e6329aafca2b81c6350ff3cd19d7d9026df85.pdf
7DtgxVZGj-y	2924	Contrastive Unsupervised Learning of World Model with Invariant Causal Features	['world models', 'causality', 'contrastive learning', 'model-based reinforcement learning', 'reinforcement learning', 'out-of-distribution generalisation', 'sim-to-real transfer', 'robot navigation']	We present a world model, which learns the causal features using invariance principle and achieves state-of-the-art performance on out-of-distribution generalisation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|contrastive_unsupervised_learning_of_world_model_with_invariant_causal_features	/pdf/8ab734199874dbb876b509103ceb83ac8c327746.pdf
-EHqoysUYLx	2925	Generalization Bounds for Federated Learning: Fast Rates, Unparticipating Clients and Unbounded Losses	['Federated learning', 'Generalization error', 'Risk bound', 'Unbounded losses', 'Learning theory']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|generalization_bounds_for_federated_learning_fast_rates_unparticipating_clients_and_unbounded_losses	/pdf/dfce61071029b2f67f16353c18a33d8d0d646f26.pdf
O8Vc52xFSUR	2926	Quasi-optimal Learning with Continuous Treatments	['Continuous Treatments', 'Markov Decision Process', 'Safe Action Allocation']	The paper proposes a novel learning algorithm for reliable continuous action allocations.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|quasioptimal_learning_with_continuous_treatments	/pdf/68197c1f303eefc55cb264851475184f669437fe.pdf
7hvbaJ1AbaM	2927	Formal Interpretability with Merlin-Arthur Classifiers	['interpretability', 'explainable ai']	We introduce a new type of interpretable classifier with theoretical guarantees based on the Merlin-Arthur protocol from Interactive Proof Systems.	Deep Learning and representational learning	anonymous|formal_interpretability_with_merlinarthur_classifiers	/pdf/3f51da8f297277808c745d74270a633fca5abc4d.pdf
7QTldIMkkqX	2928	Masked Autoencoders Enable Efficient Knowledge Distillers	['Transformer', 'Pretraining', 'Knowledge Distillation']	This paper studies the potential of distilling knowledge from self-supervised pre-trained models, especially Masked Autoencoders	Unsupervised and Self-supervised learning	anonymous|masked_autoencoders_enable_efficient_knowledge_distillers	/pdf/1c1ffa09817d7b62d90462db99fad16e7c8549c0.pdf
XlKwprKzOZ	2929	SDMuse: Stochastic Differential Music Editing and Generation via Hybrid Representation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|sdmuse_stochastic_differential_music_editing_and_generation_via_hybrid_representation	/pdf/5146ef4b4d4db215cb2a7f74c726aed46c2ee4bc.pdf
ig4E0Y11pX	2930	Theoretical  Characterization of Neural Network Generalization with Group Imbalance	['Group imbalance', 'Sample complexity', 'Generelization analysis', 'Gaussian mixture model', 'Empirical risk minimization']	A theoretical characterization of generalization and sample complexity of training neural networks with group imbalance	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|theoretical_characterization_of_neural_network_generalization_with_group_imbalance	/pdf/e43f17e700e3883be739cc1c5bd0b18adf882f23.pdf
zoz7Ze4STUL	2931	Energy-based Out-of-Distribution Detection for Graph Neural Networks	['graph neural networks', 'out-of-distribution detection', 'semi-supervised node classification', 'energy model']	We propose an energy-based model as a provably effective OOD discriminator from a GNN classifier trained in semi-supervised learning on graphs	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|energybased_outofdistribution_detection_for_graph_neural_networks	/pdf/fd52112c0866a359d07f0e49392cf5fca6552fec.pdf
-nm-rHXi5ga	2932	On the Data-Efficiency with Contrastive Image Transformation in Reinforcement Learning	['Reinforcement Learning', 'Data Augmentation', 'Self-Supervised Learning', 'Representation Learning']	CoIT is a learnable image transformation for sample-efficiency improvement.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_dataefficiency_with_contrastive_image_transformation_in_reinforcement_learning	/pdf/ca3d6b21551fb1c52a0f73e676aa6d7e2de5ddcb.pdf
u2e4grt3aKm	2933	Multimodal Open-Vocabulary Video Classification via Vision and Language Models	['open-vocabulary', 'multimodal', 'video', 'optical flow', 'audio']	We propose a method for open-vocabulary video classification leveraging pre-trained vision and language models and multimodal signals like optical flow and audio to improve the performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|multimodal_openvocabulary_video_classification_via_vision_and_language_models	/pdf/e8ecdca67c51f65dceb7d8649ec82c2998a36b9d.pdf
69MODRAL5u8	2934	A Theory of Equivalence-Preserving Program Embeddings	['Programming Languages', 'Program Embeddings', 'Code', 'Big Code']	We develop a theory of program embeddings that preserve semantic equivalence and show when they are tractable to compute	Deep Learning and representational learning	anonymous|a_theory_of_equivalencepreserving_program_embeddings	/pdf/5521b60704e960712cd100f5270eac1b02129ae5.pdf
7sWLxZBLPO5	2935	Multiple Modes for Continual Learning	[]		Deep Learning and representational learning	anonymous|multiple_modes_for_continual_learning	/pdf/0767a38d17ed03447fa27a1411d6649292394fe8.pdf
nZ2NtpolC5-	2936	The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks	['Deep Learning Theory', 'Learning Rules', 'Representations']	A theoretical analysis of deep networks and their representations when trained with a variety of learning rules.	Deep Learning and representational learning	anonymous|the_influence_of_learning_rule_on_representation_dynamics_in_wide_neural_networks	/pdf/b8487bc9949c01b58b2eeb5009a0a4b25ba329e7.pdf
tMg5hKRiW-2	2937	ReD-GCN: Revisit the Depth of Graph Convolutional Network	['graph convolutional network', 'the depth of graph convolutional network']	Extend the depth of GCN from positive integer domain ($\mathbb{N}+$) to real number domain ($\mathbb{R}$). A novel problem of automatic GCN depth tuning for graph homophily/heterophily detection is formulated. 	Deep Learning and representational learning	anonymous|redgcn_revisit_the_depth_of_graph_convolutional_network	/pdf/5ea3cd928e6a2743ae93eead1659bbfbc4afb62a.pdf
54F8woU8vhq	2938	Context and History Aware Other-Shaping	['Shaping', 'Multi-Agent', 'Reinforcement Learning', 'Meta Reinforcement Learning']	A scalable shaping algorithm which can be used in complex environments.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|context_and_history_aware_othershaping	/pdf/e2b454829a19418fa51d2fa7382429eff0d43535.pdf
FEBCwrGzR3j	2939	PromptSum: Planning with Mixed Prompts for Parameter-Efficient Controllable Abstractive Summarization	['summarization', 'controllability', 'parameter-efficiency', 'prompt-tuning', 'pre-training', 'multi-tasking']	A new prompting mechanism which enables controllable, parameter-efficient and data-efficient summarization. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|promptsum_planning_with_mixed_prompts_for_parameterefficient_controllable_abstractive_summarization	/pdf/652586b4436536db84a4667f4718f1f8a9578e9f.pdf
U9HW6vyNClg	2940	Towards Minimax Optimal Reward-free Reinforcement Learning in Linear MDPs	['Reinforce Learning', 'Reward-Free Exploration', 'Linear MDPs', 'Learning Theory']	We propose a computationally-efficient algorithm for reward-free exploration in linear MDPs reaching a minimax optimal sample complexity up to an $H$ and logarithm factor.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|towards_minimax_optimal_rewardfree_reinforcement_learning_in_linear_mdps	/pdf/fa229e610d69df81993e13eaf6c1355dda7e96bb.pdf
2WklawyeI08	2942	Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid Learning in RNNs	['synaptic plasticity', 'meta-learning', 'Hebbian learning', 'few-shot learning', 'recurrent neural networks']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|hebbian_and_gradientbased_plasticity_enables_robust_memory_and_rapid_learning_in_rnns	/pdf/334b2352d776236ad8b77c0501bd7b2fe84cf691.pdf
WWYHBZ1wWzp	2943	Faster Reinforcement Learning with Value Target Lower Bounding	['Reinforcement Learning', 'Bellman equation', 'value improvement', 'sample efficiency']	Lower bounding the Bellman value target turns out to be simple, efficient and effective in improving RL efficiency and RL performance both in theory and practice.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|faster_reinforcement_learning_with_value_target_lower_bounding	/pdf/25d8747455528f72ac2a34e31c475e1cd7c0625a.pdf
CYK7RfcOzQ4	2944	AudioGen: Textually Guided Audio Generation	['text-to-audio', 'audio generation']	We propose a text-to-audio generation model	Applications (eg, speech processing, computer vision, NLP)	anonymous|audiogen_textually_guided_audio_generation	/pdf/b0d6653841d8ce22aaeaf3dd34c7cc1847e030ae.pdf
k71IGLC8cfc	2945	A Unified Algebraic Perspective on Lipschitz Neural Networks	['Deep Learning', 'Lipschitz neural networks', 'Robustness']	We present a novel algebraic perspective unifying various types of 1-Lipschitz neural networks, and show that AOL and CPL can be re-derived and generalized using exactly the same semidefinite programming (SDP) condition.	Deep Learning and representational learning	anonymous|a_unified_algebraic_perspective_on_lipschitz_neural_networks	/pdf/1b03df98e1a185f9b6bbabbe867b12be70e1214a.pdf
ZRkHGPMY3dd	2946	Fairness of Federated Learning with Dynamic Participants	['Federated Learning', 'Dynamic Fairness', 'Benefit', 'Normalized SGD']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fairness_of_federated_learning_with_dynamic_participants	/pdf/6056795691d24014b633b422a608211c9d4b71c8.pdf
AFhaaOZTkKA	2947	Populating memory in Continual Learning with Consistency Aware Sampling	['Continual Learning', 'Learning Consistency', 'Populating Memory', 'Memory-based Continual Learning']		General Machine Learning (ie none of the above)	anonymous|populating_memory_in_continual_learning_with_consistency_aware_sampling	/pdf/54bba4846e387a1bbfe3587d23053855f3f1f044.pdf
b1g6e7enW5o	2948	QUANTIZATION AWARE FACTORIZATION FOR DEEP NEURAL NETWORK COMPRESSION	['tensor methods', 'compression', 'quantization']	We propose a novel approach to neural network compression that performs tensor factorization and quantization simultaneously.	General Machine Learning (ie none of the above)	anonymous|quantization_aware_factorization_for_deep_neural_network_compression	/pdf/7d4cbd66c965981ff7db42644e36bbe2b964df1a.pdf
6sQr2-BlARv	2949	Learning Top-k Classification with Label Ranking	[]		General Machine Learning (ie none of the above)	anonymous|learning_topk_classification_with_label_ranking	/pdf/c0bcd2f7a129c691bd651bf3e5feefd5ca7e5997.pdf
q_u6UVhenn7	2950	G-CEALS: Gaussian Cluster Embedding in Autoencoder Latent Space for Tabular Data Representation	['embedding clustering', 'tabular data', 'Gaussian clusters', 'autoencoder', 'representation learning']	This paper proposes an unsupervised learning method to improve embedding clustering of tabular data	Unsupervised and Self-supervised learning	anonymous|gceals_gaussian_cluster_embedding_in_autoencoder_latent_space_for_tabular_data_representation	/pdf/57f95145de0fa581fc89ed9c912dad721020ee13.pdf
EHi_B2stiNs	2951	Change Detection for bi-temporal images classification based on Siamese Variational AutoEncoder and Transfer Learning	['Feature extraction', 'Variational Auto-Encoder', 'Change Detection', 'Siamese structure', 'Transfer Learning', 'Desertification']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|change_detection_for_bitemporal_images_classification_based_on_siamese_variational_autoencoder_and_transfer_learning	/pdf/a062f0356d30c8c23d8c9dfc66870f9fd64d2bad.pdf
1tfGKiwnJRJ	2952	Risk-aware Bayesian RL for Cautious Exploration	['Reinforcement learning', 'Bayesian inference', 'Safe learning', 'Risk', 'Safety Specification']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|riskaware_bayesian_rl_for_cautious_exploration	/pdf/a33aa2bc920620770d7bb203eb30ac18c9684707.pdf
fhcu4FBLciL	2953	Efficient Model Updates for Approximate Unlearning of Graph-Structured Data	['machine unlearning', 'graph unlearning', 'privacy']	We study the approximate unlearning problem for graph-structured data with theoretical guarantees.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|efficient_model_updates_for_approximate_unlearning_of_graphstructured_data	/pdf/72a8ba41412134dbe77945ae06176e624d3d0e23.pdf
wZxuiDFEtyR	2954	Task Regularized Hybrid Knowledge Distillation For Continual Object Detection	['Knowledge Distillation', 'Continual Learning', 'Continual Object Detection', 'Class Incremental Object Detection']	Task Regularized Hybrid Knowledge Distillation Method For Class Incremental Objects Detection	Deep Learning and representational learning	anonymous|task_regularized_hybrid_knowledge_distillation_for_continual_object_detection	/pdf/7f914413e01f520a2432327405334a311d99a733.pdf
XhgbD4ZNKFA	2955	Internal Purity: A Differential Entropy based Internal Validation Index for Clustering Validation	[]		Unsupervised and Self-supervised learning	anonymous|internal_purity_a_differential_entropy_based_internal_validation_index_for_clustering_validation	/pdf/f32c4c28b64e341e85d9ea4622ad7e539921944c.pdf
0uHNy9jmR7z	2956	CWATR: Generating Richer Captions with Object Attributes	['image captioning', 'vision and language pretraining', 'object attributes', 'machine learning', 'deep learning', 'computer vision']	We propose a method to generate richer and more grounded image captions by integrating attributes of the objects in the scene to the generated caption.	Applications (eg, speech processing, computer vision, NLP)	anonymous|cwatr_generating_richer_captions_with_object_attributes	/pdf/c02a09e443a6657be1408dd1f5fcf53893005db2.pdf
jK02XX9ZpJkt	2957	CAMA: A New Framework for Safe Multi-Agent Reinforcement Learning  Using Constraint Augmentation	['Safe', 'Multi-agent Reinforcement Learning', 'Augmentation']	CAMA can combine any SOTA non-safe MARL algorithms to ensure they satisfied added constraints without strong assumptions and complex implementations.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|cama_a_new_framework_for_safe_multiagent_reinforcement_learning_using_constraint_augmentation	/pdf/0dff5503849a026424015cc294e1168f2e39d0b0.pdf
7mgUec-7GMv	2958	Mitigating Dataset Bias by Using Per-Sample Gradient	['Dataset bias', 'Debiasing', 'Gradient-norm based debiasing']	We solve the dataset bias problem by using the per-sample gradient. Furthermore, we provide the mathematical background of the proposed algorithm.	Deep Learning and representational learning	anonymous|mitigating_dataset_bias_by_using_persample_gradient	/pdf/703b69336090d6ec535781c7993f4c893834509a.pdf
3HnIBTjlXTS	2959	Visual Prompt Tuning For Test-time Domain Adaptation	['deep learning', 'test-time domain adaptation', 'unsupervised learning', 'visual prompt tuning', 'vision transformer', 'self-supervision']	Vision Transformer can generalize better during testing by tuning a set of visual prompts with only a little unlabeled target domain data.	Deep Learning and representational learning	anonymous|visual_prompt_tuning_for_testtime_domain_adaptation	/pdf/da2597fea019f6540a4c80478b6da3123a3860e7.pdf
1nZelVKqpks	2960	Disentangled (Un)Controllable Features	['Representation Learning', 'Reinforcement Learning']	Separation of Controllable and Uncontrollable Features in Latent Space	Deep Learning and representational learning	anonymous|disentangled_uncontrollable_features	/pdf/61e0803c9414e2c89c60039d3fd4584f29ae3e34.pdf
8CDeu0f4i2	2966	REDUCING OVERSMOOTHING IN GRAPH NEURAL NETWORKS BY CHANGING THE ACTIVATION FUNCTION	['Graph Neural Networks', 'Oversmoothing']		Deep Learning and representational learning	anonymous|reducing_oversmoothing_in_graph_neural_networks_by_changing_the_activation_function	/pdf/e3810e78a4bc5181bf801c0208dcc217a0916219.pdf
1mNssCWt_v	2968	STaSy: Score-based Tabular data Synthesis	['Score-based generative model', 'Tabular data', 'Self-paced learning']	We design a score-based generative model for tabular data and apply two training strategies, including the self-paced learning and the proposed fine-tuning method, to stabilize the denoising score matching training.	Generative models	anonymous|stasy_scorebased_tabular_data_synthesis	/pdf/50abcfaedb433fc88788aa9e9056040bf5d087ce.pdf
vk2855b0aT	2969	O-ViT: Orthogonal Vision Transformer	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|ovit_orthogonal_vision_transformer	/pdf/e7e94065bd87498d26150aaeaa1c87380f8705d1.pdf
Pqi9ZxxdjM	2970	Leveraging the Third Dimension in Contrastive Learning	['contrastive learning', 'depth', 'self-supervised learning']	Depth signal improves contrastive learning	Deep Learning and representational learning	anonymous|leveraging_the_third_dimension_in_contrastive_learning	/pdf/de0a8f823dfbd0ca156ee21fbce524efe396de97.pdf
P7h7UT9uDzb	2972	CBP-QSNN: Spiking Neural Networks Quantized Using Constrained Backpropagation	['Quantized spiking neural network', 'Constrained backpropagation', 'Binary weight', 'Lagrange multiplier method', 'Weight constraint']	We propose a method to quantize FP32 weights in spiking neural networks using constrained backpropagation.	Deep Learning and representational learning	anonymous|cbpqsnn_spiking_neural_networks_quantized_using_constrained_backpropagation	/pdf/d063dd57873c6f1e3f057dce573f03f701ecfbc9.pdf
AW0i0lOhzqJ	2973	First-order Context-based Adaptation for Generalizing to New Dynamical Systems	['physical system modeling', 'differential equation', 'generalization', 'context', 'adaptation']	We propose FOCA, a learning framework to model sets of systems governed by common but unknown laws that differentiate themselves by their context and train FOCA with a simple and efficient EMA-based method.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|firstorder_contextbased_adaptation_for_generalizing_to_new_dynamical_systems	/pdf/51d794ca31205d3b76cb373df9d242eee8f6aa6c.pdf
NVZvalzCLg	2974	LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification	['Quantization', 'Model Compression', 'Sparsity', 'Pruning']		Deep Learning and representational learning	anonymous|lilnetx_lightweight_networks_with_extreme_model_compression_and_structured_sparsification	/pdf/3560a24cbdcdd1771a8f163e6607d0d1e4355896.pdf
hQ9V5QN27eS	2975	Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning	['reinforcement learning', 'exploration', 'action noise', 'continuous control']	Pink noise, a temporally correlated noise type, outperforms other action noise types on standard continuous control benchmarks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pink_noise_is_all_you_need_colored_noise_exploration_in_deep_reinforcement_learning	/pdf/d1d847b76da54dda71c12e21fa7bd215c958424a.pdf
PEuxUXIMLlA	2976	Compositional Law Parsing with Latent Random Functions	[]		Generative models	anonymous|compositional_law_parsing_with_latent_random_functions	/pdf/325af4462c67d124d1534cdc5d840ae114b0791b.pdf
iUdSB2kK9GY	2977	PandA: Unsupervised Learning of Parts and Appearances in the Feature Maps of GANs	['GANs', 'interpretability', 'local image editing']		Generative models	anonymous|panda_unsupervised_learning_of_parts_and_appearances_in_the_feature_maps_of_gans	/pdf/3f3aa45b316f1b40986c3b11b930c099e2eb4a35.pdf
ZcnzsHC10Y	2978	Learning to CROSS exchange to solve min-max vehicle routing problems	[]		General Machine Learning (ie none of the above)	anonymous|learning_to_cross_exchange_to_solve_minmax_vehicle_routing_problems	/pdf/0564ec7c85c746c3a0d2e77f574eca7357894892.pdf
NEtep2C7yD	2981	Learning Simultaneous Navigation and Construction in Grid Worlds 	['Navigation', 'Localization', 'Construction', 'Deep reinforcement learning', 'Representation learning']	Position-related representation learning improves DRL consistently when addressing the localization-planning interdependence challenge in the proposed mobile construction tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_simultaneous_navigation_and_construction_in_grid_worlds	/pdf/2d4423d5819f7f22407f035ffbbf446907f4ba7e.pdf
uAmv2zRAWn	2982	Perturbation Analysis of Neural Collapse	['deep learning theory', 'neural collapse']	We propose a new model for exploring practical NC behavior and establish, via perturbation analysis, results that could not have been obtained by existing (idealized) models.	Deep Learning and representational learning	anonymous|perturbation_analysis_of_neural_collapse	/pdf/c509b3ed7efab76b0031f381704b98fb82db9c20.pdf
ppxKnb1SIB	2983	Towards Explaining Distribution Shifts	['Distribution Shifts', 'Explainable AI']	We use interpretable distributional mappings to explain how a source distribution shifted to a target distribution, usable on both tabular and image-based distribution shifts.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_explaining_distribution_shifts	/pdf/00415f0985de3ffad0264bfad4e5db4b15a98750.pdf
K9RHxPpjn2	2984	Active Image Indexing	['Indexing', 'Copy detection', 'Image similarity search', 'Watermarking']	In the context of image tracing, instead of watermarking an image with an ID, we slightly modify it to make its representation more indexing-friendly, which makes plain content-based indexing much more robust (62% → 100% accuracy for some settings).	Applications (eg, speech processing, computer vision, NLP)	anonymous|active_image_indexing	/pdf/083ccb76daa2decc29bef990c41afd4a448df101.pdf
w2P7fMy_RH	2985	Expressive Monotonic Neural Networks	['monotonic', 'lipschitz']	This paper introduces a new method to universally approximate lipschitz functions that are monotonic in any subset of their inputs.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|expressive_monotonic_neural_networks	/pdf/3bb6416ca1c95f5eaca5ae948e2f57617c4852eb.pdf
f6cywgfd11	2986	Perceive, Ground, Reason, and Act: A Benchmark for General-purpose Visual Representation	['general-purpose vision', 'benchmark', 'visual representation']	We propose a comprehensive benchmark for holistic evaluation of general-purpose visual representations, as well as a general framework to mitigate gaps among visual tasks and accommodate arbitrary representations	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|perceive_ground_reason_and_act_a_benchmark_for_generalpurpose_visual_representation	/pdf/98d61a9d08f83dc6742da5fedbc4c6b3e0df56ca.pdf
kQxry8Z6Fd9	2988	Statistical Guarantees for Consensus Clustering	['consensus clustering', 'unsupervised label aggregation', 'spectral clustering', 'barycenter problem', 'Frechet mean', 'semidefinite relaxation']	We propose spectral algorithms for aggregating labels from multiple clustering algorithms without knowing the optimal matching between clusters, and we provide theoretical performance bounds. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|statistical_guarantees_for_consensus_clustering	/pdf/d511d968cd3f9fb34b9eeb1183208223367ba02e.pdf
rwo-ls5GqGn	2989	ZiCo: Zero-shot NAS via inverse Coefficient of Variation on Gradients	['Neural Architecture Search', 'Zero-shot NAS', 'Gradient Analysis', 'Training Convergence']	A theoretically grounded SOTA proxy for zero-shot NAS under various inference budgets.	Deep Learning and representational learning	anonymous|zico_zeroshot_nas_via_inverse_coefficient_of_variation_on_gradients	/pdf/077dfbf8601ffdfb0ce4e8acf1669e80d6f7cd4e.pdf
ndYXTEL6cZz	2991	Extremely Simple Activation Shaping for Out-of-Distribution Detection	['out-of-distribution', 'out-of-distribution detection', 'activation pruning', 'post hoc', 'sparsity', 'activation shaping']	We develop an extremely simple, post hoc, on-the-fly, and plug-and-play activation shaping method for out-of-distribution detection.	Deep Learning and representational learning	anonymous|extremely_simple_activation_shaping_for_outofdistribution_detection	/pdf/d0e4a19252dd1f80e4431e1071ff1317af778486.pdf
yzHn1QejdT4	2992	Learning Efficient Models From Few Labels By Distillation From Multiple Tasks	['transfer learning', 'semi-supervised learning', 'multi-source distillation']	We create an efficient model for a novel task via task similarity-weighted multi-source distillation. 	Deep Learning and representational learning	anonymous|learning_efficient_models_from_few_labels_by_distillation_from_multiple_tasks	/pdf/02d9c24274113b8698618a44ffea1916a9cdf40f.pdf
CgCmwcfgEdH	2993	PGrad: Learning Principal Gradients For Domain Generalization	[]		Deep Learning and representational learning	anonymous|pgrad_learning_principal_gradients_for_domain_generalization	/pdf/ae710676b57df4fb82f93465eb8dd85135a5262e.pdf
IXsI73NDuqN	2994	Asymmetric Certified Robustness via Feature-Convex Neural Networks	['robustness', 'certification', 'convex', 'machine learning']	We propose a novel, convexity-based learning architecture which enables closed-form adversarial robustness certificates for all norm balls in an asymmetric robustness setting.	General Machine Learning (ie none of the above)	anonymous|asymmetric_certified_robustness_via_featureconvex_neural_networks	/pdf/8ef294e44d6190d5519ae37d65057a248e63a7f4.pdf
bAMTaeqluh4	2995	Part-Based Models Improve Adversarial Robustness	['adversarial robustness', 'adversarial examples', 'computer vision', 'part-based model']	Using an auxiliary task and richer annotation in the form of part segmentation can improve robustness of neural networks by a large margin.	Deep Learning and representational learning	anonymous|partbased_models_improve_adversarial_robustness	/pdf/7222e8d9c53a79f76692ec26143bbd958c075b09.pdf
6BdJ5G5wEdp	2996	MSQ-BioBERT: Ambiguity Resolution to Enhance BioBERT Medical Question-Answering	['Question answering', 'Question augmentation', 'BioBERT', 'Matrix approximation']	A way to improve BioBERT Question-answering using multiple synonymous questions.	Applications (eg, speech processing, computer vision, NLP)	anonymous|msqbiobert_ambiguity_resolution_to_enhance_biobert_medical_questionanswering	/pdf/c84583da8ef3a3d92a777d6b1c5a0f921f1987ce.pdf
sW4dg6x_sGv	2997	Biological connectomes as a representation for the architecture of artificial neural networks	['neural architecture', 'biologically inspired', 'connectomes', 'neuro-AI']	We map the neural circuitry of a nematode taken from neuroscience literature into an ANN and show that it works well on certain tasks but not others.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|biological_connectomes_as_a_representation_for_the_architecture_of_artificial_neural_networks	/pdf/01768bb7f65df9c462fa0301b7b6361bcb027195.pdf
H0HGljkxQFN	2998	MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models	[]		Deep Learning and representational learning	anonymous|moat_alternating_mobile_convolution_and_attention_brings_strong_vision_models	/pdf/735bc7e13e308902db82db304ca119c18970f3b6.pdf
ApF0dmi1_9K	2999	NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning	['Robotics', 'Motion Planning', 'Neural Fields', 'Implicit Neural Representation', 'Physics Informed Deep Learning']	A physics-informed neural time fields model for robot motion planning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|ntfields_neural_time_fields_for_physicsinformed_robot_motion_planning	/pdf/d083f87c586c39891eecce0121e62d5bf8b64568.pdf
6xXtM8bFFJ	3001	SGDA with shuffling: faster convergence for nonconvex-PŁ minimax optimization	['minimax optimization', 'SGDA', 'without-replacement sampling', 'random reshuffling', 'Polyak-Łojasiewicz']	We study the convergence bounds of (mini-batch) SGDA with random reshuffling for nonconvex-PŁ and primal-PŁ-PŁ problems.	Optimization (eg, convex and non-convex optimization)	anonymous|sgda_with_shuffling_faster_convergence_for_nonconvexp_minimax_optimization	/pdf/fb66959753d68e599c3da42fe0bd30bcc9a02299.pdf
sz_iMI6IPM	3002	PRANC: Pseudo RAndom Networks for Compacting deep models	['Computer Vision', 'Compacting Deep Models']	A method to compress networks for sharing knowledge and storage	Deep Learning and representational learning	anonymous|pranc_pseudo_random_networks_for_compacting_deep_models	/pdf/ef19a8c3f04cddaee412d9684bf3d136aaa409c6.pdf
AsOLzq1S-p	3003	Offline Policy Comparison with Confidence: Benchmarks and Baselines	['offline reinforcement learning', 'reinforcement learning', 'benchmark', 'uncertainty', 'model based reinforcement learning']	We introduce a benchmark and baselines to study uncertainty estimation via policy comparisons in offline reinforcement learning datasets.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_policy_comparison_with_confidence_benchmarks_and_baselines	/pdf/5d4606667efe6b0ce28f8ad68378ab4a4a390729.pdf
8znaO_qG0H	3004	Federated Training of Dual Encoding Models on Small Non-IID Client Datasets	['dual encoding models', 'federated learning', 'representation learning', 'self-supervised learning', 'federated self-supervised learning']	Novel approach for training dual encoding models on distributed data composed of many small, non-IID client datasets.	Unsupervised and Self-supervised learning	anonymous|federated_training_of_dual_encoding_models_on_small_noniid_client_datasets	/pdf/4e037ca3c2867cc0fb12facb302d6b01c43785a0.pdf
Su84ELBdm5U	3005	How does overparametrization affect performance on minority groups?	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|how_does_overparametrization_affect_performance_on_minority_groups	/pdf/c9194d148520037b0e24ba22a4dbcbcc887f39e8.pdf
noJYC9HMP42	3006	REAP: A Large-Scale Realistic Adversarial Patch Benchmark	['adversarial examples', 'adversarial patch', 'benchmark', 'traffic sign detection']	We create a realistic benchmark for evaluating adversarial patch attacks and defenses containing over 14k traffic signs on driving scenes where the signs are annotated with realistic geometric and lighting transforms.	Deep Learning and representational learning	anonymous|reap_a_largescale_realistic_adversarial_patch_benchmark	/pdf/6aaec4dc0608394f43b0cf89fd443f3286942469.pdf
q9VherQJd8_	3007	Matching receptor to odorant with protein language and graph neural networks	['Olfaction', 'protein-ligand binding', 'olfactory receptors', 'computational biology', 'protein language modelling', 'graph neural networks']	We leverage recent advances in protein representation learning and graph neural networks to predict olfactory receptor-molecule binding.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|matching_receptor_to_odorant_with_protein_language_and_graph_neural_networks	/pdf/c0c194e5eee0b659baf987d47e530c8a062db9f3.pdf
wkU9ezzXbHk	3008	Attentional Context Alignment for Multimodal Sequential Learning	['Multimodal', 'Attentional Context', 'Alignment']		Applications (eg, speech processing, computer vision, NLP)	anonymous|attentional_context_alignment_for_multimodal_sequential_learning	/pdf/764fc9fec5bfa63f6d0ec1fd1c4c5d6bfe9927b3.pdf
lLp-C5nTdJG	3009	Static Prediction of Runtime Errors by Learning to Execute Programs with External Resource Descriptions	['program analysis', 'graph neural networks', 'recurrent networks', 'attention mechanisms', 'source code', 'program execution']	For statically predicting runtime errors, the IPA-GNN scales to complex programs, models exception handling, and executes resource descriptions; it performs well and surprisingly localizes errors despite training without location supervision.	Applications (eg, speech processing, computer vision, NLP)	anonymous|static_prediction_of_runtime_errors_by_learning_to_execute_programs_with_external_resource_descriptions	/pdf/f87edff019032b65d0413d53a2d8961806af346a.pdf
zMVCSe945x	3010	Taming Policy Constrained Offline Reinforcement Learning for Non-expert Demonstrations	['Contaminated Datasets', 'Robust Offline Reinforcement Learning']	The performance losses of policy constraint-based offline RL algorithms on contaminated datasets can be alleviated by gradient penalty and constraint relaxation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|taming_policy_constrained_offline_reinforcement_learning_for_nonexpert_demonstrations	/pdf/d492db6b045e70e65ccdd89bf292165101929011.pdf
SZynfVLGd5	3012	Boosting Adversarial Transferability using Dynamic Cues	['Adversarial attacks', 'Transferability', 'Prompt learning', 'Dynamic video modeling']	A new approach for optimizing temporal prompts through frozen image models to capture motion dynamics for better transferability	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|boosting_adversarial_transferability_using_dynamic_cues	/pdf/0d8700d3ba8527c1058555ce872744e82ae1b56f.pdf
E8mzu3JbdR	3013	ChordMixer: A Scalable Neural Attention Model for Sequences with Different Length	['Mixer', 'Attention', 'Scalable']		Deep Learning and representational learning	anonymous|chordmixer_a_scalable_neural_attention_model_for_sequences_with_different_length	/pdf/a6d8afe955380cdc23ef96223364258d65455d1e.pdf
v71SH44HD8	3014	Spatially Resolved Temporal Networks: Online Unsupervised Representation Learning of High Frequency Time Series	['High frequency time series', 'Representation Learning', 'Online Learning']	Unsupervised representation Learning to generate clinically interpretable waveforms. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|spatially_resolved_temporal_networks_online_unsupervised_representation_learning_of_high_frequency_time_series	/pdf/fa46ab65db76439eebea81d899eaa81f494b9d2d.pdf
ZqK0Hnlqo-	3015	Bi-Stride Multi-Scale Graph Neural Network for Mesh-Based Physical Simulation	['GNN', 'physics-based simulation']	A robust yet simple pooling strategy for improving multi-scale GNNs for predicting physical simulations	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|bistride_multiscale_graph_neural_network_for_meshbased_physical_simulation	/pdf/30e76cfc2049a695cabcbfd27ce3f58957dd8d35.pdf
8re-nA0wDxW	3016	The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and their Empirical Equivalence	['meta-learning', 'machine learning', 'transfer learning', 'deep learning']	when the task diversity of few-shot learning benchmarks is low and comparison is fair, MAML and transfer learning perform the same -- opposite of claims that transfer learning is better	Deep Learning and representational learning	anonymous|the_curse_of_low_task_diversity_on_the_failure_of_transfer_learning_to_outperform_maml_and_their_empirical_equivalence	/pdf/f9c76a22b5d39448ac5ddb96d179c7ecc5476503.pdf
Af43zsue7kw	3017	StructViT: Learning Correlation Structures for Vision Transformers	['transformer', 'self-attention', 'image classification', 'video classification', 'correlation']	We introduce structural self-attention (StructSA) that exploits geometric structures of query-key correlations and the proposed network StructViT achieves state-of-the-art results on various image and video classification benchmarks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|structvit_learning_correlation_structures_for_vision_transformers	/pdf/9adc2b5760eefb7f324f49adf26e810073bb3483.pdf
sWSWudSpYy	3018	Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer Embedding Training	[]		Deep Learning and representational learning	anonymous|enhancing_crosscategory_learning_in_recommendation_systems_with_multilayer_embedding_training	/pdf/6cff87a403f48910aa076b7ad8cd0d1c9af2f328.pdf
x70_D-KGEMx	3019	A sampling framework for value-based reinforcement learning	['Reinforcement learning', 'Bayesian sampling', 'Stochastic gradient MCMC', 'Value function approximation']	  We propose an efficient and scalable sampling framework for reinforcement learning, which enables uncertainty quantification and addresses the local trap issue suffered by the existing training approaches. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_sampling_framework_for_valuebased_reinforcement_learning	/pdf/a827dc1a4c51a8d6fc976cec750f4de4fd0172af.pdf
PHtzmXK8am	3020	TAN without a burn: Scaling laws of DP-SGD	[]	Computationally friendly hyper-parameter search with DP-SGD for new state-of-the-art performance on ImageNet.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|tan_without_a_burn_scaling_laws_of_dpsgd	/pdf/8adf4a23edebf1ad08b0c9790377ab8458e5bdd4.pdf
dN70O8pmW8	3022	Memory-efficient Trajectory Matching for Scalable Dataset Distillation	['dataset condensation', 'dataset distillation', 'imagenet-1k', 'deep learning', 'dataset synthesis']	we propose a memory-efficient method that scales dataset distillation to ImageNet-1K with IPC 10 and 50 for the first time and achieves state of the art performances	Deep Learning and representational learning	anonymous|memoryefficient_trajectory_matching_for_scalable_dataset_distillation	/pdf/e68d08df6309545bc66514a2a6ad230bda58a602.pdf
tK9UwBsQK9	3023	Isometric Representations in Neural Networks Improve Robustness	['Isometry', 'Deep Learning', 'Robustness', 'Adversarial Attacks', 'Continuous Representation', 'Classification']	Adding Isometric regularization to classification loss, enforces continuous representations which improve robustness against adversarial attacks.	Deep Learning and representational learning	anonymous|isometric_representations_in_neural_networks_improve_robustness	/pdf/a3475c7ce89f1a3e20503172bc41b21886a22cc7.pdf
9F_xlC7sk9	3024	Generalization and Estimation Error Bounds for Model-based Neural Networks	['Model based neural networks', 'Generalization error', 'Estimation error', 'Local Rademacher complexity.']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|generalization_and_estimation_error_bounds_for_modelbased_neural_networks	/pdf/3566f9e876e00079a21693420c75c2aced12249a.pdf
bsZULlDGXe	3025	The Dark Side of AutoML: Towards Architectural Backdoor Search	['backdoor attack and defense', 'neural architecture search']	This paper presents EVAS, a new attack to leverage NAS to find neural architectures with exploitable backdoor vulnerability.	Deep Learning and representational learning	anonymous|the_dark_side_of_automl_towards_architectural_backdoor_search	/pdf/11f25209455a0bc51603a2df417e3565eb7fd621.pdf
oJZ8bPtCar	3026	STOCHASTIC NO-REGRET LEARNING FOR GENERAL GAMES WITH VARIANCE REDUCTION	['game theory']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|stochastic_noregret_learning_for_general_games_with_variance_reduction	/pdf/247f3304fce3244a3d49cc85af94085bbd9dad35.pdf
xE-LtsE-xx	3027	Is Attention All That NeRF Needs?	['Neural Radiance Field', 'Transformer', 'Neural Rendering']	We present Generalizable NeRF Transformer (GNT), a pure, unified transformer-based architecture that efficiently reconstructs Neural Radiance Fields (NeRFs) on the fly.	Applications (eg, speech processing, computer vision, NLP)	anonymous|is_attention_all_that_nerf_needs	/pdf/1e5a6a4bd859de8751a15b3897f1e6edada8924c.pdf
ZljQYfl8SJ	3028	Abstracting Imperfect Information Away from Two-Player Zero-Sum Games	['imperfect information', 'public belief states', 'decision-time planning', 'regularized equilibria']	A reduction from imperfect information two-player zero-sum games to perfect information two-player zero-sum games	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|abstracting_imperfect_information_away_from_twoplayer_zerosum_games	/pdf/2cbe2e4d8ff856f30c5629f43a8705c12e646216.pdf
z37tDDHHgi	3029	Red PANDA: Disambiguating Anomaly Detection by Removing Nuisance Factors	['Anomaly Detection', 'Disentanglement']	Proposing a new anomaly detection setting when the operator specifies a nuisance attribute to be ignored	Applications (eg, speech processing, computer vision, NLP)	anonymous|red_panda_disambiguating_anomaly_detection_by_removing_nuisance_factors	/pdf/555fbe5093434a9d2e38ce3ee5f131caefe6c3c3.pdf
nIGza1_wxk	3030	Model Transferability with Responsive Decision Subjects 	['transferability', 'responsive decision subjects', 'induced distribution shift', 'human-ML interaction', 'performance bound']	This paper studies model transferability when human decision subjects respond to a deployed machine learning model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|model_transferability_with_responsive_decision_subjects	/pdf/369c017bd27e2cb6a5a7568a3a49e6672c55cb3a.pdf
sRQNwKcE2X	3031	Representation Learning via Consistent Assignment of Views over Random Partitions	['representation learning', 'unsupervised learning', 'self-supervised learning', 'computer vision']	An unsupervised representation learning method for visual data based on self-supervised clustering. 	Deep Learning and representational learning	anonymous|representation_learning_via_consistent_assignment_of_views_over_random_partitions	/pdf/4cb3e5909e61fb65acda740aa30997547ac9f021.pdf
jPVAFXHlbL	3032	Calibrating Transformers via Sparse Gaussian Processes	['Transformers', 'Gaussian processes', 'Bayesian neural networks', 'uncertainty estimation', 'variational inference']	This paper proposes to improve the uncertainty calibration for transformers by performing Bayesian inference for the outputs of multi-head attention blocks using sparse Gaussian processes.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|calibrating_transformers_via_sparse_gaussian_processes	/pdf/afa6906e79859977201bf7dbbddaa2495a5ad899.pdf
MFD2b2cwr5d	3033	 Learning from Others: Similarity-based Regularization for Mitigating Artifacts	['NLP', 'robustness', 'spurious correlations', 'Dataset bias', 'natural language understanding', 'shortcut learning']	Similarity regularization reduces intrinsic and extrinsic bias in NLU models	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_from_others_similaritybased_regularization_for_mitigating_artifacts	/pdf/2e65a09286698ce05c1271c5750b3e1f50b322bc.pdf
HTKSDFhGYhQ	3034	Identifiability of Label Noise Transition Matrix 	['identifiability', 'label noise transition matrix', 'noisy labels']	This paper provides understandings for when a label noise transition matrix is identifiable, and what factors contribute to its identifiability. 	General Machine Learning (ie none of the above)	anonymous|identifiability_of_label_noise_transition_matrix	/pdf/6da1aa64e1f544e6074c892bfeccae06e1e194c4.pdf
AYvLkPnDguL	3035	The power of choices in decision tree learning	['Decision Trees', 'Decision Tree Learning', 'Top-k', 'ID3', 'Greedy Algorithms']	We propose a simple generalization of greedy decision tree learning algorithms which parameterizes the greediness in these algorithms by a parameter $k$, and validate the effectiveness of having this parameter, both theoretically and empirically.	General Machine Learning (ie none of the above)	anonymous|the_power_of_choices_in_decision_tree_learning	/pdf/ab4ab82608326faeec8ef49ce3177dbc105edd0f.pdf
HQ67mj5rJdR	3038	Perfectly Secure Steganography Using Minimum Entropy Coupling	['Information-Theoretic Steganography', 'Minimum Entropy Coupling']	A scalable, perfect security approach to information-theoretic steganography based on minimum entropy coupling 	Applications (eg, speech processing, computer vision, NLP)	anonymous|perfectly_secure_steganography_using_minimum_entropy_coupling	/pdf/22d3589127fbafe9ca6b26ec7bd6558a8c49baac.pdf
jCHRWpXk1pD	3039	Federated Learning with Openset Noisy Labels	['Federated Learning', 'OpenSet Classification', 'Noisy Label']	A framework for openset noisy label classification in federated learning	General Machine Learning (ie none of the above)	anonymous|federated_learning_with_openset_noisy_labels	/pdf/2700469c4f0e51319426f4f246470704844de717.pdf
nJuzV-izmPJ	3040	Generative Adversarial Training for Neural Combinatorial Optimization Models	['Vehicle Routing Problems', 'Combinatorial Optimization', 'Deep Reinforcement Learning']	We propose a general framework to improve the generalization ability of deep learning models for Combinatorial Optimization Problems.	Applications (eg, speech processing, computer vision, NLP)	anonymous|generative_adversarial_training_for_neural_combinatorial_optimization_models	/pdf/f53f10e2031b9ab21b36ddf4c0fb7374f3101254.pdf
uqLDy0HGPR7	3041	Risk Control for Online Learning Models	['Conformal Prediction', 'Uncertainty Quantification', 'Time Series', 'Online Learning']	A flexible tool for constructing uncertainty estimates with a rigorous long-range risk control (such as coverage, false negative rate, or F1 score) in an online learning setting, where the distribution can vary greatly over time.	General Machine Learning (ie none of the above)	anonymous|risk_control_for_online_learning_models	/pdf/6e19df70a472c659a2ea0b98e72512dd8a82c2ff.pdf
ZrEbzL9eQ3W	3042	Scaling Laws for a Multi-Agent Reinforcement Learning Model	['Neural scaling laws', 'Multi-agent reinforcement learning', 'AlphaZero']	We examine scaling laws for AlphaZero.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|scaling_laws_for_a_multiagent_reinforcement_learning_model	/pdf/1084ff83c387e8d23774da028bfc34855d82ce64.pdf
ovZE0KsbM3S	3043	Pitfalls of Gaussians as a noise distribution in NCE	['NCE', 'Noise Contrastive Estimation', 'Generative Models', 'statistical efficiency', 'theory']	We show that using Gaussians as the noise distribution in Noise Contrastive Estimation can lead to exponentially bad statistical and algorithmic complexity.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|pitfalls_of_gaussians_as_a_noise_distribution_in_nce	/pdf/57bcee91d3617537d9f197e7b342f0aa648467ca.pdf
2outcw5N9wH	3044	Safer Reinforcement Learning with Counterexample-guided Offline Training	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|safer_reinforcement_learning_with_counterexampleguided_offline_training	/pdf/603d8a3015fe1d866409c90fccf911602eb559eb.pdf
fZxdcpfwTQb	3045	Learning to Act through Activation Function Optimization in Random Networks	['artificial neural networks', 'activation functions', 'neural diversity']	We optimize parameterized activation functions in fixed random networks to solve reinforcement learning tasks.	Deep Learning and representational learning	anonymous|learning_to_act_through_activation_function_optimization_in_random_networks	/pdf/841060037ca5616f8bddb0b1f6c645fd06b8689c.pdf
W0VPud1QV69	3046	DiP-GNN: Discriminative Pre-Training of Graph Neural Networks	[]	We propose a discriminative pre-training framework for graph neural networks (DiP-GNN), where we train a discriminator to distinguish edges generated by a generator from the original graph's edges.	Deep Learning and representational learning	anonymous|dipgnn_discriminative_pretraining_of_graph_neural_networks	/pdf/329c82cac8679d582d3a357a33c729a7c7853e86.pdf
tC_2Ej6pbaRq	3047	Basis for Intentions: Efficient Inverse Reinforcement Learning using Past Experience	['inverse reinforcement learning', 'successor features', 'multi-task reinforcement learning']	leveraging prior RL experience for faster inverse RL 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|basis_for_intentions_efficient_inverse_reinforcement_learning_using_past_experience	/pdf/506944ad70867c403cc3228843ce49d48850ae4b.pdf
VHyurNEKJBh	3048	Dynamics-aware Skill Generation from Behaviourally Diverse Demonstrations	['Learning from Demonstration', 'Reinforcement Learning']	Learning a diverse set of policies using states-only demonstrations collected from different individuals, where each individual performs the task differently, being influenced by their own preferences or expertise.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|dynamicsaware_skill_generation_from_behaviourally_diverse_demonstrations	/pdf/659d551c7d974d0e5705b860b56bd38d2655f22d.pdf
DpE5UYUQzZH	3050	A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games	['reinforcement learning', 'quantal response equilibria', 'two-player zero-sum games', 'mirror descent', 'variational inequalities', 'Nash equilibria', 'algorithmic game theory', 'proximal gradient']	A single algorithm for both single-agent reinforcement learning and approximating quantal response and Nash equilibria in two-player zero-sum games.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_unified_approach_to_reinforcement_learning_quantal_response_equilibria_and_twoplayer_zerosum_games	/pdf/3925889b2a72009e219ae6f2d2991a20b39e110a.pdf
zZXwDQFxwib	3051	Integrating Episodic and Global Novelty Bonuses for Efficient Exploration	['reinforcement learning', 'exploration', 'generalization']	We study when episodic and global novelty bonuses are useful in contextual MDPs, and find that it depends on the amount of shared structure across contexts; by combining them, we get SOTA results on MiniHack.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|integrating_episodic_and_global_novelty_bonuses_for_efficient_exploration	/pdf/9dde3000f7f12a5743ecc138e571b6c02d19c369.pdf
lu6qxw6-QEV	3053	Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|enforcing_hard_constraints_with_soft_barriers_safe_reinforcement_learning_in_unknown_stochastic_environments	/pdf/6d17a7a1584d8c0b8acdec0c0edfbcb8bf3f39c1.pdf
4wXotzMJ7Wo	3054	Towards Representative Subset Selection for Self-Supervised Speech Recognition	['subset selection', 'self-supervised speech recognition', 'active learning', 'data pruning']	A new data subset selection method for self-supervised speech recognition that performs better than existing dataset pruning strategies.	Applications (eg, speech processing, computer vision, NLP)	anonymous|towards_representative_subset_selection_for_selfsupervised_speech_recognition	/pdf/31fa6836e6b677d6cd96970a14a1f92717a13ae9.pdf
mkJm5Uy4HrQ	3055	Leveraging Incompatibility to Defend Against Backdoor Poisoning	['data poisoning', 'defense']	We observe that training with poisoned data does not improve clean accuracy (and vice-versa), and develop a defense that exploits this property.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|leveraging_incompatibility_to_defend_against_backdoor_poisoning	/pdf/c98089b0758c752dfec6efeb7e7cd4ae7ff652b5.pdf
sWOsRj4nT1n	3056	Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks	['Domain Generalization', 'Sequential Learning Model', 'Dynamic Neural Network']	A novel framework is proposed to dynamically model how neural networks evolve across domains for characterizing the distribution drift across time in temporal domain generalization.	General Machine Learning (ie none of the above)	anonymous|temporal_domain_generalization_with_driftaware_dynamic_neural_networks	/pdf/7c7a29b03a36ab70ed98f62283f1d7e6d09778c2.pdf
mTOB_VK_BWk	3057	StarGraph: Knowledge Representation Learning based on Incomplete Two-hop Subgraph	['Knowledge Representation Learning', 'Knowledge Graph Embedding', 'Knowledge Graph', 'Self-Attention Network']	knowledge representation learning based on incomplete local subgraph	Deep Learning and representational learning	anonymous|stargraph_knowledge_representation_learning_based_on_incomplete_twohop_subgraph	/pdf/61f0070bf9483a08617733e2fa3884b02341fc92.pdf
zGy_wqpRGTa	3059	Private Data Stream Analysis for Universal Symmetric Norm Estimation	['differential privacy', 'norm estimation']	We provide a differentially private algorithm that approximate an arbitrary number of symmetric norms on a data stream	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|private_data_stream_analysis_for_universal_symmetric_norm_estimation	/pdf/ddb89f8c8fa5928669303654830145924fc41ad8.pdf
8thVleggPV_	3060	AUTOJOIN: EFFICIENT ADVERSARIAL TRAINING FOR ROBUST MANEUVERING VIA DENOISING AUTOEN- CODER AND JOINT LEARNING	['autonomous driving', 'machine learning', 'robust training']		Applications (eg, speech processing, computer vision, NLP)	anonymous|autojoin_efficient_adversarial_training_for_robust_maneuvering_via_denoising_autoen_coder_and_joint_learning	/pdf/d874bbc4c039734cd54bba6fd3b56a7afd6c86cd.pdf
ip0ENxmhIja	3061	Approximate Conditional Coverage via Neural Model Approximations	['distribution-free uncertainty quantification', 'split-conformal prediction sets', 'Venn Predictors']	We construct prediction sets over Transformer networks, via KNN-based approximations, obtaining reliable assumption- and parameter-light approximate conditional coverage.	Deep Learning and representational learning	anonymous|approximate_conditional_coverage_via_neural_model_approximations	/pdf/41b291e718e1f75cff8362251d226be80eb08357.pdf
fvvcpsEl3Z6	3062	Taming the Long Tail of Deep Probabilistic Forecasting	['Deep probabilistic forecasting', 'Long tail error', 'Time Series forecasting', 'Trajectory forecasting']	We propose novel loss augmentation approaches to mitigate long tail in error of deep probabilistic forecasting and achieve significantly better results than the base model and baseline methods.	Deep Learning and representational learning	anonymous|taming_the_long_tail_of_deep_probabilistic_forecasting	/pdf/108af2fc300ab5ff41f3fa09320ca6fd4731cf98.pdf
Ih0fKoIUyEh	3063	Wide Graph Neural Network	['Graph neural networks', 'represenation learning', 'dictionary learning']	This paper proposes a unified view to understend GNNs, and it motivates a new model called wide graph neural network.	Deep Learning and representational learning	anonymous|wide_graph_neural_network	/pdf/115db2e7db0995afcf0d86b5249acadc5ee1a7f9.pdf
JtC6yOHRoJJ	3064	Human-level Atari 200x faster	['Reinforcement Learning', 'Data-efficiency', 'Exploration', 'Off-policy']	We propose an RL agent 'MEME' that achieves human-level performance on all 57 Atari games within 390M environment frames, only 1/200 of the experience required by Agent57.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|humanlevel_atari_200x_faster	/pdf/fee5f7212c5aceca1f37c894e5c51e47f1f3c4a0.pdf
rnN4pHyf6jD	3065	Scaling Convex Neural Networks with Burer-Monteiro Factorization	['burer-monteiro', 'convex optimization', 'neural networks', 'stationary points', 'global optima', 'relu activation']	We apply the Burer-Monteiro factorization to two-layer ReLU (fully-connected, convolutional, self-attention) neural networks by leveraging their implicit convexity, and provide insights into stationary points and local optima of these networks.	Optimization (eg, convex and non-convex optimization)	anonymous|scaling_convex_neural_networks_with_burermonteiro_factorization	/pdf/7c158795355834bd8f4e915786a8c2efbbdbdde0.pdf
3UHoYrglYkG	3066	Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model	['differential privacy', 'heavy hitters', 'streaming algorithms', 'sliding window model']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|differentially_private_l_2heavy_hitters_in_the_sliding_window_model	/pdf/8cf3518475276ac85011bf9a46a0fc1b7b1d0106.pdf
nYOlSqq9nv2	3067	Learning Intuitive Policies Using Action Features	['multi-agent coordination', 'attention', 'inductive bias']	We show that certain network architectures encourage reinforcement learning algorithms to respect semantic relationships between actions and observations.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_intuitive_policies_using_action_features	/pdf/9a5c1813c2fbb8a175df4d6191a697a73c55bb39.pdf
jpR98ZdIm2q	3068	Efficient Edge Inference by Selective Query	['efficient edge inference', 'low-capacity model', 'large scale prediction', 'dynamic neural networks', 'adaptive neural networks']	Low-complexity model(edge) performs poorly on large-scale tasks; For efficient inference, it must learn to identify examples that benefit by querying; it has to identify both hard-to-classify examples and those that the cloud model would misclassify.	Deep Learning and representational learning	anonymous|efficient_edge_inference_by_selective_query	/pdf/fe69f87f50daa7cb5f559491d5b41a7bb04e9456.pdf
V5NFgHyNBI8	3069	Q-Ensemble for Offline RL: Don't Scale the Ensemble, Scale the Batch Size	['Offline Reinforcement Learning', 'Q-Ensemble', 'Large Batch Optimization', 'Ensemble Based Reinforcement Learning']	Large Batch Optimization for SAC-N allows to reduce size of the Q-ensemble and improves convergence time by 2.5x times on average	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|qensemble_for_offline_rl_dont_scale_the_ensemble_scale_the_batch_size	/pdf/be5e2e7236fcd00e10791a167a108214402c4fce.pdf
gmSZ-GPNY6	3070	Noise Injection Node Regularization for Robust Learning	['Reguralization', 'Input corruption', 'Noise Injection', 'Deep Learning']	We provide analytical and empirical evidence indicating that training using a large amount of adaptive noise injection results in an emergent regularization scheme, improving robustness against a number of tests.	Deep Learning and representational learning	anonymous|noise_injection_node_regularization_for_robust_learning	/pdf/970a155a5ac477f6615f666625cdb5c39ef880da.pdf
CEhy-i7_KfC	3071	Pretraining the Vision Transformer using self-supervised methods for vision based Deep Reinforcement Learning	['Deep Reinforcement Learning', 'Transformers', 'Self-Supervised Learning', 'Pre-training']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pretraining_the_vision_transformer_using_selfsupervised_methods_for_vision_based_deep_reinforcement_learning	/pdf/317bcf77999d9e8b9e976658b9d35be13c76897b.pdf
1z9VTrxCgf	3073	Semantic Image Manipulation with Background-guided Internal Learning	['semantic image manipulation', 'internal learning', 'scene-graph driven image editing']		Applications (eg, speech processing, computer vision, NLP)	anonymous|semantic_image_manipulation_with_backgroundguided_internal_learning	/pdf/c8d91583a8684fc87efe4c41fade61c97d8f7275.pdf
GUMLIArCIwB	3074	Reconciling Security and Communication Efficiency in Federated Learning	['Federated Learning', 'Secure Aggregation', 'Compression', 'Efficiency', 'Product Quantization']	Uplink communication effiency with a high privacy and security bar	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|reconciling_security_and_communication_efficiency_in_federated_learning	/pdf/874c3afed4512bd7517a5ff9c56c4b017e9b05af.pdf
H0gdPxSwkPb	3075	Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation	['Diffusion model', 'Adversarial learning', 'Self-supervised learning', 'Vessel segmentation']		Unsupervised and Self-supervised learning	anonymous|diffusion_adversarial_representation_learning_for_selfsupervised_vessel_segmentation	/pdf/6530ad70d96eb79e3fef692986508f4c1da7b77e.pdf
e0GcQ9l4Dh	3076	Defending against Reconstruction attacks using Rényi Differential Privacy	['Rényi Differential Privacy', 'Reconstruction Attacks', 'Information Theory']	Quantify the information leakage using better reconstruction bounds backed by experimental testing	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|defending_against_reconstruction_attacks_using_rényi_differential_privacy	/pdf/d8b06c5c72e947d3618477bcec0e4e47de5d50e6.pdf
u7ugqk7VBP8	3077	Prefix Conditioning Unifies Language and Label Supervision	['Vision-language contrastive learning', 'Zero-shot recognition']	Prefix conditioning technique to train vision-language model with image-caption and image-classification dataset. 	Deep Learning and representational learning	anonymous|prefix_conditioning_unifies_language_and_label_supervision	/pdf/c7b7242cc5fd2d1b62b35a7adb4ce8507e5496a9.pdf
YuXt90f4Kb7	3079	ModReduce: A Multi-Knowledge Distillation Framework with Online Learning	['Knowledge distillation', 'Deep neural networks', 'Model Compression', 'Knowledge transfer', 'Online Learning']		Deep Learning and representational learning	anonymous|modreduce_a_multiknowledge_distillation_framework_with_online_learning	/pdf/97091df5f130c0de6e4c2a5ad6764792cd89ed03.pdf
ETKGuby0hcs	3080	Discovering Latent Knowledge in Language Models Without Supervision	['AI safety', 'AI alignment', 'truthfulness', 'large language models', 'honesty', 'interpretability']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|discovering_latent_knowledge_in_language_models_without_supervision	/pdf/69e1a0a63f152c5403a58d5238218529809861ef.pdf
hzjQWjPC04A	3081	VIMA: General Robot Manipulation with Multimodal Prompts	['Robot Learning', 'Foundation Model', 'Transformer', 'Language Model', 'Multi-Task Learning']	We design a transformer agent, VIMA, that ingests *multimodal* prompts and solves a wide variety of robot manipulation tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|vima_general_robot_manipulation_with_multimodal_prompts	/pdf/cb36ec3f27751ba7c222583d9ad580d18ae89ec1.pdf
99XwOpGYAH	3082	Structural Adversarial Objectives for Self-Supervised Representation Learning	[]		Deep Learning and representational learning	anonymous|structural_adversarial_objectives_for_selfsupervised_representation_learning	/pdf/1b3cea9eecca797ad650788f641159f2fc67b5bd.pdf
oXKawaVcG1	3084	Spatiotemporal-Memory-Guided Machine Perception for Augmented Reality	['Augmented Reality', 'machine perception', '4D spatial memory map']		Applications (eg, speech processing, computer vision, NLP)	anonymous|spatiotemporalmemoryguided_machine_perception_for_augmented_reality	/pdf/3d6a43938cbffc3d65bcdd83779dba741e86896f.pdf
jwdqNwyREyh	3085	Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Better Representations	['Mask Image Modeling', 'Contrastive learning']	We proposed a simple yet principled combination for MIM and CL that can merge both merits of them.	Unsupervised and Self-supervised learning	anonymous|layer_grafted_pretraining_bridging_contrastive_learning_and_masked_image_modeling_for_better_representations	/pdf/c8967990191cb2cf3ca92611b9dd3f2a84608cff.pdf
kJUS5nD0vPB	3086	Out-of-Distribution Detection and Selective Generation for Conditional Language Models	['Out-of-distribution Detection', 'Natural Language Generation', 'Selective Generation', 'Uncertainty']	A simple, fast, effective method for out-of-distribution detection and selective generation for conditional language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|outofdistribution_detection_and_selective_generation_for_conditional_language_models	/pdf/669187a306fc5a798d9d26b5cb3f4bc4bc62e486.pdf
K1Z-P0Le0DT	3087	Recurrent Real-valued Neural Autoregressive Density Estimator for Online Density Estimation and Classification of Streaming Data	['density estimation', 'online learning', 'streaming data', 'classification']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|recurrent_realvalued_neural_autoregressive_density_estimator_for_online_density_estimation_and_classification_of_streaming_data	/pdf/21ee454f7a986d75f2e134372e9c2fb5b25a1848.pdf
ch_t8OpXaa	3088	LSTM-BASED-AUTO-BI-LSTM for Remaining Useful Life (RUL) Prediction: the first round of test results	['Remaining Useful Life', 'Predictive Maintenance', 'Machine Learning', 'Deep Learning', 'Autoencoder']	The paper describes prelimirary test results of LSTM-BASED-AUTO-BI-LSTM architecture	General Machine Learning (ie none of the above)	anonymous|lstmbasedautobilstm_for_remaining_useful_life_rul_prediction_the_first_round_of_test_results	/pdf/ad601a361b25782155d13cc888f6835e968e2c8f.pdf
653nhbKy6yE	3089	Graph in Graph Neural Network	['Graph Neural Network', 'Deep Learning', 'Sub-graph']		Deep Learning and representational learning	anonymous|graph_in_graph_neural_network	/pdf/d4ef4c4b712bd0a92e801f297c434f998b7f2ceb.pdf
YsAbPH2VWKE	3091	Unpacking Large Language Models with Conceptual Consistency	['Conceptual Consistency', 'Theory of Mind', 'Zero Shot Prompting', 'Large Language Models', 'Semantic Consistency', 'Unsupervised Question Answering', 'Background Knowledge Extraction']	Conceptual consistency measures whether knowledge of relevant background information is consistent with ability to answer questions correctly in large language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|unpacking_large_language_models_with_conceptual_consistency	/pdf/17274c7a838376f4f8f75b19342671f10cfcc676.pdf
KajSampr4_	3092	Communication-Optimal Distributed Graph Clustering under Duplication Models	['Graph Clustering', 'Distributed Computation', 'Communication Complexity', 'Duplication Models']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|communicationoptimal_distributed_graph_clustering_under_duplication_models	/pdf/959d7a8129616c003e7c5358af77484ce4d94702.pdf
TkQ1sxd9P4	3093	Interpretable Debiasing of Vectorized Language Representations with Iterative Orthogonalization	['bias', 'fairness', 'ethics', 'debiasing', 'static embeddings', 'pre-trained contextualized embeddings', 'natural language processing']	Our proposed debiasing technique significantly improves the amount of debiasing while retaining relevant information in the embedding representation. It can also be extended to multiple subspace debiasing.	Deep Learning and representational learning	anonymous|interpretable_debiasing_of_vectorized_language_representations_with_iterative_orthogonalization	/pdf/057c64203ee895d8f67e293c7db83c982395c014.pdf
klK17OQ3KB	3094	How to Train your HIPPO: State Space Models with Generalized Orthogonal Basis Projections	['Deep learning', 'sequence model', 'state space model', 'S4', 'HiPPO']	We develop a new theoretical interpretation of S4 and generalize it to other basis functions	Deep Learning and representational learning	anonymous|how_to_train_your_hippo_state_space_models_with_generalized_orthogonal_basis_projections	/pdf/1888faf66097504e4ddb4ed358e32b7b4ea690f7.pdf
HO2q49XYRC	3095	SaMoE: Parameter Efficient MoE Language Models via Self-Adaptive Expert Combination	['Mixture-of-Expert', 'Autoregressive language model', 'Parameter efficiency.']	SaMoE is a parameter efficient MoE architecture design that enables parameter savings on MoE while achieving comparable or better accuracy.	Deep Learning and representational learning	anonymous|samoe_parameter_efficient_moe_language_models_via_selfadaptive_expert_combination	/pdf/40e219a5b1a3bc047a08109548edb4fa8afdc621.pdf
1zaoVA_z8Q	3096	SemSup-XC: Semantic Supervision for Extreme Classification	['Extreme classification', 'zero-shot inference', 'few-shot learning']	We propose a new model for extreme classification over very large label spaces and achieve SOTA results on three popular benchmarks.	Deep Learning and representational learning	anonymous|semsupxc_semantic_supervision_for_extreme_classification	/pdf/ffeb95ed432e91230077afe78ff743420250bdd5.pdf
xWwbnbtJd5	3098	Waveformer: Linear-Time Attention with Forward and Backward Wavelet Transform	['transformer', 'efficient attention', 'long range reasoning']	We propose a model with linear complexity achieving SOTA results on a set of long-range tasks, under a new paradigm to learn attention in wavelet space which boosts accuracies of various attention methods without increasing time complexity.	Applications (eg, speech processing, computer vision, NLP)	anonymous|waveformer_lineartime_attention_with_forward_and_backward_wavelet_transform	/pdf/659883ef372c8360527a91f5fd9b7096a95b71d2.pdf
_4n3k3d1ob	3099	Continuous-time identification of dynamic state-space models by deep subspace encoding	['Continuous-time', 'State-space', 'Artificial Neural Networks']	This work proposes a method for the estimation of continuous-time nonlinear state-pace models parameterized by ANN's which is robust and well theoretically motivated.	Deep Learning and representational learning	anonymous|continuoustime_identification_of_dynamic_statespace_models_by_deep_subspace_encoding	/pdf/f6227f393eb7b1f662258b66f1ddba98f5a5d548.pdf
8uf1JIb07M	3100	MERMADE: $K$-shot Robust Adaptive Mechanism Design via Model-Based Meta-Learning	['Mechanism design', 'Robustness', 'Meta-learning', 'Adaptive agents', 'Simulation based learning']	We propose MERMADE, a deep RL approach to mechanism design that learns a world model together with a meta-learned mechanism which can be quickly adapted to perform well on unseen test agents that learn.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|mermade_kshot_robust_adaptive_mechanism_design_via_modelbased_metalearning	/pdf/6b2dff1ef52ec06f16391a81bd4a78f1daf35323.pdf
HehQobsr0S	3101	Text Summarization with Oracle Expectation	['Text Summarization', 'NLP']		Applications (eg, speech processing, computer vision, NLP)	anonymous|text_summarization_with_oracle_expectation	/pdf/c05b80af8ddb43adeae0590dd92586884b28d6f4.pdf
QAV2CcLEDh	3102	MaskViT: Masked Visual Pre-Training for Video Prediction	['Video Prediction', 'Masked Visual Modeling', 'Visual MPC', 'Transformers']	We propose to learn a Transformer based video prediction model via masked visual modeling. 	Generative models	anonymous|maskvit_masked_visual_pretraining_for_video_prediction	/pdf/f5b70ad0ad9895f0c5852679f11255fd099da880.pdf
TVAFpPEWSn7	3104	On the Activation Function Dependence of the Spectral Bias of Neural Networks	[]		Deep Learning and representational learning	anonymous|on_the_activation_function_dependence_of_the_spectral_bias_of_neural_networks	/pdf/ae1f0e1e523e83b0ede8b37e416ec5432591f736.pdf
XG_LmeoU8Xq	3106	Graduated Non-Convexity for Robust Self-Trained Language Understanding	[]	Robust self-trained language understanding against pseudo labeling noises, data imbalance, overfitting, and adversarial evaluation data.	Unsupervised and Self-supervised learning	anonymous|graduated_nonconvexity_for_robust_selftrained_language_understanding	/pdf/d8bc48e5a2ef033c362b6903335211d8d3c07f15.pdf
CvnKNdZQsxb	3108	Leveraging Human Features at Test-Time	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|leveraging_human_features_at_testtime	/pdf/fb682f85445a3e14c342f3f1c188922990fcd29e.pdf
7bJizxLKrR	3109	Measuring Forgetting of Memorized Training Examples	['forgetting', 'memorization', 'membership inference', 'canary extraction', 'nondeterminism', 'convexity']	When models are trained on large datasets, we show that privacy attacks become less effective on examples seen early in training, and investigate why.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|measuring_forgetting_of_memorized_training_examples	/pdf/02f92235f5cf620b7270347b5adbd7aa808475f6.pdf
9jW_Oynp0au	3110	PointConvFormer: Revenge of the Point-Based Convolution	[]	We introduce PointConvFormer, a novel building block using transformer attention to improve point convolution.	Deep Learning and representational learning	anonymous|pointconvformer_revenge_of_the_pointbased_convolution	/pdf/7ac2079c55fa7351ea7dbd01d99ab78aa61c9a03.pdf
Qc_OopMEBnC	3111	Learning to Segment from Noisy Annotations: A Spatial Correction Approach	[]		Deep Learning and representational learning	anonymous|learning_to_segment_from_noisy_annotations_a_spatial_correction_approach	/pdf/86d31bd8d58204dd5f4a3dbe83302e3769cd52f7.pdf
_fiHdKjxfR	3112	ContraSim -- A Similarity Measure Based on Contrastive Learning	['Interpretability', 'similarity measure', 'analysis', 'language models', 'multilingual', 'image captioning']	We develop a new similarity measure based on contrastive learning	Applications (eg, speech processing, computer vision, NLP)	anonymous|contrasim_a_similarity_measure_based_on_contrastive_learning	/pdf/da46a108afbb687399b43b54a5affc5703c2bae7.pdf
bNPth9YMqZ	3113	Federated Self-supervised Learning for Heterogeneous Clients	['Federated Learning', 'Self-supervised Learning']	We propose a new and systematic framework for performing self-supervised federated learning when the clients are diverse and cannot train models of identical architectures.	General Machine Learning (ie none of the above)	anonymous|federated_selfsupervised_learning_for_heterogeneous_clients	/pdf/7bb2c5f130dd8faac65fb0feec7e187a30b6510e.pdf
AWZgXGmsbA	3114	Powderworld: A Platform for Understanding Generalization via Rich Task Distributions	['reinforcement learning', 'environment', 'generalization', 'out-of-distribution', 'multi-task']	Powderworld is an environment supporting the study of generalization by providing diverse tasks arising from the same core rules.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|powderworld_a_platform_for_understanding_generalization_via_rich_task_distributions	/pdf/ac3112510b3c4b1a5f1755fc8464fa7961567772.pdf
TatRHT_1cK	3116	Quantifying Memorization Across Neural Language Models	['memorization', 'large language models', 'duplication']	Model size, duplication, and context length all impact how easy it is to extract training data from large language models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|quantifying_memorization_across_neural_language_models	/pdf/acc45dbd252a5edf80b9dfbf37e2331a7d4c1692.pdf
dmWMfJeZMM	3117	uGLAD: A deep learning model to recover conditional independence graphs	['Graphical Lasso', 'Deep Learning', 'Unrolled Algorithms', 'Conditional Independence graphs', 'Sparse graphs']	An unsupervised deep learning method based on unrolled algorithm technique to recover conditional independence graphs. 	Deep Learning and representational learning	anonymous|uglad_a_deep_learning_model_to_recover_conditional_independence_graphs	/pdf/bc80a9227fea49be8184c7c7b8337a59e740d921.pdf
5pU6126YRp	3118	TT-Rules: Extracting & Optimizing Exact Rules of a CNN-Based Model - Application to Fairness	['global & exact interpretability', 'convolutional neural-networks', 'rule-based model for fairness']	In this work, we proposed an optimized new CNN-based framework for global and exact interpretability with application to healthcare and fairness tabular datasets.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|ttrules_extracting_optimizing_exact_rules_of_a_cnnbased_model_application_to_fairness	/pdf/990c708a78e640bb714e49ad8f932996017c5c09.pdf
PvOo1sHKzf	3119	Counterfactual Memorization in Neural Language Models	['memorization', 'influence', 'language models']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|counterfactual_memorization_in_neural_language_models	/pdf/e024437d05007b7e0b35ec24c411c40053095ba3.pdf
vw-5EgYbJZr	3120	A Non-monotonic Self-terminating Language Model	['non-terminating sequences', 'language modeling', 'sequence completion', 'decoding', 'consistency', 'self-terminating']	We propose a new method to prevent language models from non-terminating sequences resulting from incomplete decoding algorithms.	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_nonmonotonic_selfterminating_language_model	/pdf/5e8e040963c61339a02cc238d7eeaf13c71c7290.pdf
Wc5bmZZU9cy	3121	Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|drspider_a_diagnostic_evaluation_benchmark_towards_texttosql_robustness	/pdf/43a02356ba3171d99dc3129317b76adb984e5d54.pdf
tJbbQfw-5wv	3122	A critical look at evaluation of GNNs under heterophily: Are we really making progress?	['GNN', 'graph', 'node classification', 'heterophily', 'benchmark']	We show that popular heterophilous datasets for node classification have serious drawbacks, propose several new ones, and show that, at this moment, standard GNNs outperform most of the specialized models on these datasets.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|a_critical_look_at_evaluation_of_gnns_under_heterophily_are_we_really_making_progress	/pdf/2ff9f1266b41fefadb29f8d4ef9ce9a8fe0f3280.pdf
xSsW2Am-ukZ	3123	Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?	['linear mode connectivity', 'iterative magnitude pruning', 'loss landscape geometry', 'lottery ticket hypothesis', 'sparsity']	We provide an error landscape perspective on what information is encoded in a winning ticket's mask and how Iterative Magnitude Pruning finds matching subnetworks.	Deep Learning and representational learning	anonymous|unmasking_the_lottery_ticket_hypothesis_whats_encoded_in_a_winning_tickets_mask	/pdf/1863f3152616b767ace3df050fe0c9d31d848601.pdf
Tvms8xrZHyR	3124	Characterizing the spectrum of the NTK via a power series expansion	['neural tangent kernel', 'power series', 'Hermite coefficient', 'activation function', 'spectrum', 'input Gram matrix']	We characterize the NTK spectrum via a power series representation in terms of the Hermite coefficients of the activation function, the depth, and the effective rank of the input Gram. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|characterizing_the_spectrum_of_the_ntk_via_a_power_series_expansion	/pdf/083df6dd1fda3036131f5bd1488c0b7878e7751e.pdf
_o4JUv2lmD	3125	Bridging the Gap between Semi-supervised and Supervised Continual Learning via Data Programming	['continual learning', 'lifelong learning', 'semi-supervised learning']	We built a semi-supervised continual learning (SSCL) framework to approach the performance of supervised, via self-taught data programming. Results show we not only obtain similar performance as supervised, but also defeat existing SSCL methods.	General Machine Learning (ie none of the above)	anonymous|bridging_the_gap_between_semisupervised_and_supervised_continual_learning_via_data_programming	/pdf/8274b6a02ad506d9a0d9652ae529b6e1a9404375.pdf
bjMNguuxbH	3126	Peaks2Image: Reconstructing fMRI Statistical Maps from Peaks	[]	Peaks2Image allows the reconstruction of statistical maps from coordinates in neuroscientific studies, and leverage them to decode any concept from the studies vocabulary.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|peaks2image_reconstructing_fmri_statistical_maps_from_peaks	/pdf/3424ebdf076fc3fbdb3750db5d3c2d926dbb96e3.pdf
C0q9oBc3n4	3127	Temporal Dependencies in Feature Importance for Time Series Prediction	['time series', 'recurrent', 'explainability']	New explainability method for multivariate time series predictions	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|temporal_dependencies_in_feature_importance_for_time_series_prediction	/pdf/8925463b2e6404da078f999fe5d702b01e0e4b39.pdf
4zGai1tFQE	3128	Deep Dependency Networks for Action Classification in Video	['probabilistic graphical models', 'action classification', 'multi-label classification', 'combining probabilistic models with deep learning', 'end-to-end learning']	A new approach that jointly learns a conditional dependency network and a deep neural network for activity classification in video	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|deep_dependency_networks_for_action_classification_in_video	/pdf/3cca5497a64cb6c0ccb917d2a14c2fd094704565.pdf
dNyDCl2FsvM	3129	Meta-learning from demonstrations improves compositional generalization	['meta-learning', 'grounded language learning', 'compositional generalization']	We extend meta-seq2seq to grounded environments by generating environment relevant meta-training supports.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|metalearning_from_demonstrations_improves_compositional_generalization	/pdf/8c189edca46991bf92ab2558c473e7d132ee55af.pdf
y81ppNf_vg	3130	AutoTransfer: AutoML with Knowledge Transfer - An Application to Graph Neural Networks	['Graph Neural Networks', 'AutoML', 'Knowledge Transfer']	We propose AutoTransfer, an AutoML solution that improves search efficiency by transferring the known architectural design knowledge to the novel task of interest.	Deep Learning and representational learning	anonymous|autotransfer_automl_with_knowledge_transfer_an_application_to_graph_neural_networks	/pdf/99fd65b01da5061e6354db685a0391a0d2f3c84e.pdf
R98ZfMt-jE	3131	Efficient Discrete Multi Marginal Optimal Transport Regularization	"['optimal transport', 'multi-marginal', ""earth mover's distance"", 'fairness']"	Using a fast algorithm for computing generalized earth mover's distances, we solve practical discrete multi-marginal optimal transport problems in neural network learning applications.	Optimization (eg, convex and non-convex optimization)	anonymous|efficient_discrete_multi_marginal_optimal_transport_regularization	/pdf/36852034bcf8225c6ea2d7adc721bff6603a8006.pdf
45FFlw8N47	3132	AUGMENTING ZERO-SHOT DENSE RETRIEVERS WITH PLUG-IN MIXTURE-OF-MEMORIES	['Retrieval Augmented Language Model', 'Zero-shot Dense Retrieval', 'Mixture of Memory']	We explore the potential of augmenting lanuguage models with mixture-of-memory and plugging in new corpus during inference, which leads to their enhanced generalization ability on the zero-shot dense retrieval task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|augmenting_zeroshot_dense_retrievers_with_plugin_mixtureofmemories	/pdf/5c4b78b30b13a729e329035471777ac42ef3d6a6.pdf
UA34f_shAO	3133	Neural Graphical Models	['Graphical models', 'Deep learning', 'Learning Representations']	A neural network based graphical model with efficient learning, inference and sampling algorithms	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|neural_graphical_models	/pdf/34d08dbaae8304bf5dd79e73f6484f80095d8aa1.pdf
rDVb_OgcQP	3134	Rule-based policy regularization for reinforcement learning-based building control	['deep reinforcement learning', 'batch reinforcement learning', 'buildings', 'HVAC']	A unified method to incorporate rule-based policy into online and offline reinforcement learning algorithm	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|rulebased_policy_regularization_for_reinforcement_learningbased_building_control	/pdf/433ffca9d0b7c86eb4aacbe8aff32e35d8297e02.pdf
m8ll6ILyZW	3135	Multi-Segmental Informational Coding for Self-Supervised Representation Learning	['self-supervised learning', 'representation learning', 'unsupervised learning', 'deep learning']		Unsupervised and Self-supervised learning	anonymous|multisegmental_informational_coding_for_selfsupervised_representation_learning	/pdf/8bc6c5f648e88b146c1715edbe44d8d3b41a0b1b.pdf
jbd0I0-sdE	3136	TRIDE: A Temporal, Robust, and Informative Data Augmentation Framework for Disease Progression Modeling	['Temporal robustness', 'data augmentation', 'representation learning', 'language modeling', 'electronic health records']		Applications (eg, speech processing, computer vision, NLP)	anonymous|tride_a_temporal_robust_and_informative_data_augmentation_framework_for_disease_progression_modeling	/pdf/07edd185639dd5c9336bc60e065569b5fe525029.pdf
xYy2l4tiOe	3137	Towards Causal Concepts for Explaining Language Models	['NLP explainability', 'concept-based explanations', 'causality']	A framework that derives causal and concept-based explanations for complex NLP models	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_causal_concepts_for_explaining_language_models	/pdf/6e0e854a2a9c2c00f9b02c17356e077c0a737034.pdf
igF77jrKri	3138	Unsupervised learning of features and object boundaries from local prediction	['unsupervised learning', 'segmentation', 'prediction', 'Markov random field', 'objects']	Using a contrastive loss for a local prediction, we learn a representation of both features and segmentation, which is similar to the human visual system.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|unsupervised_learning_of_features_and_object_boundaries_from_local_prediction	/pdf/58329b9e616f40c2687ff0a50abb4306458b51df.pdf
-z7O7fk_Cs	3140	Invertible normalizing flow neural networks by JKO scheme	['Normalizing flow', 'invertible neural networks', 'JKO scheme']	We propose JKO-Flow to train normalizing flow neural ODE model block-wise with time reparametrization, and experimentally show JKO-Flow reaches competitive performance while greatly reduce computation	Generative models	anonymous|invertible_normalizing_flow_neural_networks_by_jko_scheme	/pdf/39becc32a142b4b760ca8684c5a8b372435841de.pdf
yzE6LtZSHo	3141	Have Missing Data? Make It Miss More! Imputing Tabular Data with Masked Autoencoding	['Imputation', 'Tabular Data', 'Masked Autoencoder']	We present ReMasker, an extremely simple yet effective method for imputing missing values in tabular data.	Deep Learning and representational learning	anonymous|have_missing_data_make_it_miss_more_imputing_tabular_data_with_masked_autoencoding	/pdf/e1172070898439bb55832a34794ee1752760ad3e.pdf
4QTrtR181T	3142	An alternative approach to train neural networks using monotone variational inequality	['monotone variational inequality', 'graph neural networks', 'neural network training']	We investigate training neural networks with monotone variation inequality, yielding performance guarantees and competitive/better performance than widely-used stochastic gradient descent methods, especially during initial training phases.	Optimization (eg, convex and non-convex optimization)	anonymous|an_alternative_approach_to_train_neural_networks_using_monotone_variational_inequality	/pdf/21346a0eaf1569e9d12a6bb02672e3617bfac7e0.pdf
2iu9NhxX23	3144	Conceptual SCAN: Learning With and About Rules	['reasoning', 'compositional generalization', 'rule learning', 'semantic parsing', 'consistency']		Applications (eg, speech processing, computer vision, NLP)	anonymous|conceptual_scan_learning_with_and_about_rules	/pdf/9439cb8ef16c8dd7894ca54fd3e033cef190eeed.pdf
TUBpc5rqGA	3145	Neural Design for Genetic Perturbation Experiments	['genetiic perturbation experiments', 'gene disco', 'optimism', 'neural optimism']	We introduce and analyze many tractable methods for noiseless optimistic arm elimination with applications in genetic perturbation experiments.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neural_design_for_genetic_perturbation_experiments	/pdf/d65405fae21513efc33196a205627f25b3428b4c.pdf
xYWqSjBcGMl	3146	Anamnesic Neural Differential Equations with Orthogonal Polynomial Projections	['Neural ODEs', 'Time Series', 'Orthogonal Polynomials', 'Long-term memory', 'Representation Learning']	Long-term memory Neural ODEs archictecture using orthogonal polynomials projections.	General Machine Learning (ie none of the above)	anonymous|anamnesic_neural_differential_equations_with_orthogonal_polynomial_projections	/pdf/21ff39f600236ec2119ab19221004d8fb04dc2b1.pdf
SZdfz5k7cd1	3147	Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors	['Algorithmic Fairness', 'Causality', 'Dynamic Modeling', 'Long-term Fairness']	We formulate and investigate a long-term fairness notion that captures decision-distribution interplay via a detailed modeling over both observed and latent causal factors.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|tier_balancing_towards_dynamic_fairness_over_underlying_causal_factors	/pdf/4312c300cdc1d007595a524d09ccbab430bd9899.pdf
VEqj2fNC2Fw	3148	Explaining  Image Classification through Knowledge-aware Neuron Interpretation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|explaining_image_classification_through_knowledgeaware_neuron_interpretation	/pdf/508bf4ca8a35335778c5585805ff1398c6a8dcf6.pdf
OpC-9aBBVJe	3149	Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier	['reinforcement learning', 'sample efficiency', 'resets']	The combination of a large number of updates and resets drastically improves the sample efficiency of deep RL algorithms.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|sampleefficient_reinforcement_learning_by_breaking_the_replay_ratio_barrier	/pdf/844c79e37119c0b44384c3004ba7b2c97a467f0a.pdf
tKMLGb7MWC	3150	A Reinforcement Learning Approach to Estimating Long-term Treatment Effects	['reinforcement learning', 'off-policy evaluation', 'A/B testing']	We propose a reinforcement learning approach to estimating the long-term treatment effect from short-term data.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_reinforcement_learning_approach_to_estimating_longterm_treatment_effects	/pdf/abcd3e7ab632487759c5d490f03edd9900fc3e2a.pdf
OIe3kpwl40D	3151	SMART: Sentences as Basic Units for Text Evaluation	['summarization', 'evaluation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|smart_sentences_as_basic_units_for_text_evaluation	/pdf/28aa221b96075a77e4ef3e35a730ee4d8b6ca690.pdf
iAPs7yMjjyQ	3152	Evaluating Counterfactual Explainers	['Explainability', 'Counterfactuals', 'XAI']		Deep Learning and representational learning	anonymous|evaluating_counterfactual_explainers	/pdf/4eabf6dfd46292927de6bcde8af4a1ee0c225fa4.pdf
FDlfFbnI7AR	3153	Countering the Attack-Defense Complexity Gap for Robust Classifiers	['adversarial attacks', 'adversarial robustness', 'computational complexity', 'dataset']	We provide a formal rationale for why attacks are more efficient than defenses and introduce a new defensive technique that sidesteps this asymmetry.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|countering_the_attackdefense_complexity_gap_for_robust_classifiers	/pdf/ee865bdfa2455010bc7ad1ec1b4968dad590f889.pdf
aRTKuscKByJ	3155	Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness	['Adversarial Robustness', 'margin maximization', 'dynamical system']		Deep Learning and representational learning	anonymous|exploring_and_exploiting_decision_boundary_dynamics_for_adversarial_robustness	/pdf/35a118159dd98ff785d07569b88b11b4d9f532df.pdf
dQNL7Zsta3	3156	Malign Overfitting: Interpolation and Invariance are Fundamentally at Odds	['Invariance', 'Overparameterization', 'Fairness', 'Robustness', 'Benign Overfitting']	Proof that interpolating classifiers cannot satisfy common invariance and fairness criteria; Provides insight on empirical observations and possible effective solutions	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|malign_overfitting_interpolation_and_invariance_are_fundamentally_at_odds	/pdf/c833ee00bcd67f1657f7b56e90c7a6bbbc838385.pdf
p-cx6fK0rW9	3157	Deep Invertible Approximation of Topologically Rich Maps between Manifolds	['Manifold Learning', 'Universality', 'Inversion', 'Topology']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|deep_invertible_approximation_of_topologically_rich_maps_between_manifolds	/pdf/1ca5b21dd5d82c8caeb0fa70eb780a6b64f33ff9.pdf
jIu4hk04776	3158	On the Geometry of Reinforcement Learning in Continuous State and Action Spaces	['geometry', 'deep reinforcement learning', 'manifold']	We prove that the state space is a low dimensional manifold and show that DDPG can effectively learn in this low dimensional space	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_geometry_of_reinforcement_learning_in_continuous_state_and_action_spaces	/pdf/c1f8b3380394e14d1557b4c7831b9f8824734173.pdf
oFoRPrl9CYX	3159	Polarity is all you need to learn and transfer faster	['Weight Polarity', 'Learning Efficiency', 'Transfer Learning', 'Bio-inspired AI']	Transfer and fix weight polarities to learn faster with less data	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|polarity_is_all_you_need_to_learn_and_transfer_faster	/pdf/e0a7dc5e6c0b257cef99caf592e82f4746874e5d.pdf
2L9gzS80tA4	3160	Does Decentralized Learning with Non-IID Unlabeled Data Benefit from Self Supervision?	['Decentralized Learning', 'Heterogeneous and Unlabeled Data', 'Federated Learning', 'Self-Supervised Learning', 'Representation Learning']	We study decentralized learning with non-IID unlabeled data, and try to understand the robustness and communication efficiency of decentralized self-supervised learning, through extensive experiments and theoretical analysis.	General Machine Learning (ie none of the above)	anonymous|does_decentralized_learning_with_noniid_unlabeled_data_benefit_from_self_supervision	/pdf/c174de1fb1e1aceaaed498c4dee06975ead5e993.pdf
6ve2CkeQe5S	3161	MEDFAIR: BENCHMARKING FAIRNESS FOR MEDICAL IMAGEING	['Fairness', 'Bias Mitigation', 'Medical Imaging', 'Benchmark']	We develop a fairness benchmark for medical imaging and find that the state-of-the-art bias mitigation algorithm does not significantly outperform ERM.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|medfair_benchmarking_fairness_for_medical_imageing	/pdf/e9aaf10efbacff9c7a0f25aece9df5e7c9349b7a.pdf
katAmwuUGc	3162	A Deep Reinforcement Learning Approach for Finding Non-Exploitable Strategies in Two-Player Atari Games	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_deep_reinforcement_learning_approach_for_finding_nonexploitable_strategies_in_twoplayer_atari_games	/pdf/8b8746a52097b5113112d35b0945287ca6ab50e7.pdf
P3PJokAqGW	3163	Learning with Stochastic Orders	['optimal transport', 'stochastic order', 'Choquet order', 'convex function', 'input convex neural network', 'integral probability metric', 'image generation', 'statistical rates']	We propose and study discrepancies and distances between probability measures that arise from the convex or Choquet order, which capture dominance constraints and are useful in applications like image generation.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|learning_with_stochastic_orders	/pdf/5fa7c3ca3c24f5e8d276c4843b53af3a450608e0.pdf
PXVGer7hmJ	3164	Offline Congestion Games: How Feedback Type Affects Data Coverage Requirement	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|offline_congestion_games_how_feedback_type_affects_data_coverage_requirement	/pdf/f5c6fe113564bc60350dca5eab0a12548b8c4468.pdf
0Wu7vlNZ8f	3165	Graph Attention Retrospective	['Graph attention', 'graph neural networks']	We characterize the power of graph attention mechanism for distinguishing inter-class from intra-class edges over contextual stochastic block models.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|graph_attention_retrospective	/pdf/efeac45434d46b3becace78fdf860a60aa634e02.pdf
zKvm1ETDOq	3166	Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?	['Data poisoning', 'adversarial training', 'indiscriminative features', 'adaptive defenses', 'robust vs. non-robust features']	We propose an indiscriminative feature-based poisoning approach to substantially degrade adversarial training, which was previously considered to be impossible.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|is_adversarial_training_really_a_silver_bullet_for_mitigating_data_poisoning	/pdf/2bf6b0f4f02384df5920f24d82d938bdbb9e8935.pdf
RePt5K6wPux	3169	Code Means More Than Plain Language: Bringing Syntax Structure Awareness To Algorithmic Problem Solution Generation	['program synthesis', 'transformer', 'syntax structure']	The first work to introduce syntax tree structure in programming synthesis	Deep Learning and representational learning	anonymous|code_means_more_than_plain_language_bringing_syntax_structure_awareness_to_algorithmic_problem_solution_generation	/pdf/08bbef4f05186a5e23f57b48b73bf7a1c38f6433.pdf
TAtAJFo35lc	3170	Learning Object-Centric Dynamic Modes from Video and Emerging Properties	['Koopman theory', 'dynamics', 'video representation learning', 'dynamic mode decomposition', 'video manipulation', 'object-centric decomposition']	We propose a model for dynamics interpretability and manipulation by means of object-centric dynamic mode decomposition, directly from pixels.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_objectcentric_dynamic_modes_from_video_and_emerging_properties	/pdf/e5bb0f470a750c300c7e502a591885c61c952025.pdf
3mji6eUxzY	3171	Cortically motivated recurrence enables task extrapolation	['cognitive science', 'recurrent neural networks', 'task extrapolation', 'out of distribution generalization', 'visual routines', 'path integration']	Biologically inspired recurrent network solves (easy and) hard instances of a task with (less and) more iterations.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|cortically_motivated_recurrence_enables_task_extrapolation	/pdf/1b1e1d69ca81da368ea441830d31d23f09d200ed.pdf
ZAzSf9pzCm	3172	Efficient Sequence Packing without Cross-contamination: Accelerating Large Language Models without Impacting Performance	['deep learning', 'BERT', 'IPU', 'GPU', 'hardware-acceleration', 'padding', 'Wikipedia', 'NLP', 'bin-packing']	Speed up BERT phase 2 pretraining by 2x (and other models, too) by avoiding padding without impacting accuracy in contrast to existing approaches.	Applications (eg, speech processing, computer vision, NLP)	anonymous|efficient_sequence_packing_without_crosscontamination_accelerating_large_language_models_without_impacting_performance	/pdf/79e371aa048e197982bb685b88e932927adf365d.pdf
KJ8iuccbPB	3173	Representing Latent Dimensions Using Compressed Number Lines	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|representing_latent_dimensions_using_compressed_number_lines	/pdf/a923bf1cbf41e5cfc802413904711045969671ae.pdf
BAakXAV6Cf	3174	Break the Wall Between Homophily and Heterophily for Graph Representation Learning	['Graph Neural Networks', 'Graph Homophily', 'Graph Heterophily']	This work proposes a new GNN model called OGNN (Omnipotent Graph Neural Network) that extracts different aspects of graph representations to generalize well on the whole spectrum of homophily.	Deep Learning and representational learning	anonymous|break_the_wall_between_homophily_and_heterophily_for_graph_representation_learning	/pdf/ef215e343e9aa2a3463b9e1a4588eead39f5d11c.pdf
hmuLHC5MrG	3175	Stable Optimization of Gaussian Likelihoods	['Gaussian', 'Likelihood', 'Optimization', 'Uncertainty', 'Stabilization']	We analyze the instability of Gaussian likelihood optimization and propose a gradient-based optimizer demonstrating less volatile optimization especially for contextual, multivariate target distributions with full covariances.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|stable_optimization_of_gaussian_likelihoods	/pdf/193b1896055f351c318c15dfb18834d06de13f97.pdf
b8f2YGWebo	3176	Self-supervised Continual Learning based on Batch-mode Novelty Detection	['Continual Learning', 'Gradients-based', 'Mahalanobis Distance', 'Novelty Detection', 'out-of-distribution', 'self-supervised']	A unified approach of continual learning and novelty detection. Each new out-of-distribution class is first detected and then merged into the previous knowledge.	Unsupervised and Self-supervised learning	anonymous|selfsupervised_continual_learning_based_on_batchmode_novelty_detection	/pdf/6d8b8448984fff75216c098b5af97aae216580a4.pdf
oo-X0K4XAn	3177	Neural Constraint Inference: Inferring Energy Constraints in Interacting Systems	['relational inference', 'energy-based models', 'energy constraints', 'trajectory prediction', 'graph neural networks']	We propose an approach that discovers a set of relational constraints, represented as energy functions, which when optimized reconstruct a given original trajectory.	Unsupervised and Self-supervised learning	anonymous|neural_constraint_inference_inferring_energy_constraints_in_interacting_systems	/pdf/4d15309a1047766ee2bcee939ebdc56349dcfd05.pdf
PWKs1IpMpv	3178	Epistemological Bias As a Means for the Automated Detection of Injustices in News Media	['testimonial injustice', 'character injustice', 'framing bias', 'epistemological bias', 'news media']	We leverage the combined use of a fine-tuned epistemological detection model, two stereotype detection models, and a lexicon-based approach to show that epistemological biases can assist with the automatic detection of injustices in text.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|epistemological_bias_as_a_means_for_the_automated_detection_of_injustices_in_news_media	/pdf/779f837975995fe16bedd6858e11fcd18eaf9db9.pdf
g05Epey82Ft	3179	Characterizing neural representation of cognitively-inspired deep RL agents during an evidence accumulation task	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|characterizing_neural_representation_of_cognitivelyinspired_deep_rl_agents_during_an_evidence_accumulation_task	/pdf/3c5e83709450fcd06fce7617ca5b2060420fbf61.pdf
oyzMyylgINj	3180	LT-SNN: Self-Adaptive Spiking Neural Network for Event-based Classification and Object Detection	['Spiking neural networks', 'efficient neuromorphic computing', 'spatial-temporal adjustment', 'separate surrogate gradient path', 'output regularization and self-adaptive and learnable potential threshold.']	Learnable threshold based spiking neural network.	Deep Learning and representational learning	anonymous|ltsnn_selfadaptive_spiking_neural_network_for_eventbased_classification_and_object_detection	/pdf/8171275d319cdfb9d2bf00ef9a89f4870a3864db.pdf
WA35e2vPlFT	3181	Neural Implicit Manifold Learning for Topology-Aware Generative Modelling	['Manifold Learning', 'Unsupervised Learning', 'Density Estimation', 'Topology', 'Differential Geometry', 'Generative Modelling']	We propose a new model for probability distributions on topologically complex data manifolds which learns manifolds implicitly as the set of zeros of a neural network and then learns the distribution within using a constrained energy-based model.	Generative models	anonymous|neural_implicit_manifold_learning_for_topologyaware_generative_modelling	/pdf/24f8008772887d2a345bebc8b5a675d77f5b064a.pdf
K-3Qq-CC78	3182	BYPASSING THE STABILITY-PLASTICITY TRADEOFF TO REDUCE PREDICTIVE CHURN	['Preditive churn', 'Stability', 'Distillation', 'Ensembles']		Deep Learning and representational learning	anonymous|bypassing_the_stabilityplasticity_tradeoff_to_reduce_predictive_churn	/pdf/4910a49b8b1c4597ba146dece07fb3e0c659766e.pdf
skThRS3MA-0	3183	Adversarial Representation Learning for Canonical Correlation Analysis	['Representation Learning', 'Canonical Correlation Analysis', 'Adversarial Learining']	A reformulation of CCA under the adversarial framework for efficient canonical representation learning.	Deep Learning and representational learning	anonymous|adversarial_representation_learning_for_canonical_correlation_analysis	/pdf/bb49204821ee69ebb18c397271e37618b9ec455c.pdf
QLVvgqcyuj	3184	Noise$^+$2Noise: Co-taught De-noising Autoencoders for Time-Series Data	['De-noising', 'Co-teaching', 'Noise recovery', 'Time-series', 'self-supervised', 'RNN']	We combine Co-teaching and De-noising Autoencoders to recover clean signals from only noisy data in a time series setting.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|noise^2noise_cotaught_denoising_autoencoders_for_timeseries_data	/pdf/03e88d5a8a9bcb6851603bc08714b593c8336c16.pdf
AtWKqgziLF	3185	Show and Write: Entity-aware Article Generation with Image Information	['image-to-text generation', 'language modeling', 'named entity recognition']		Applications (eg, speech processing, computer vision, NLP)	anonymous|show_and_write_entityaware_article_generation_with_image_information	/pdf/1a2e583bacd2039e5337dda1a3d0ce5d5bbb0458.pdf
_BSowr-_ED	3186	Capsa: A Unified Framework for Quantifying Risk in Deep Neural Networks	['uncertainty estimation', 'robustness', 'risk-aware ML']	A simple, scalable, and composable framework for creating risk-aware models	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|capsa_a_unified_framework_for_quantifying_risk_in_deep_neural_networks	/pdf/0074f5d951c160d3e846abcd37ac2a1a9894edf5.pdf
U9yFP90jU0	3187	FedFA:  Federated Feature Augmentation	['federated learning', 'feature augmentation']	We propose a simple, flexible, effective, and robust method, named as FedFA, to solve federated learning from a novel perspective of federated feature augmentation.	Deep Learning and representational learning	anonymous|fedfa_federated_feature_augmentation	/pdf/f09d633cc440c2dbd531eb8bba38d0920c62af9f.pdf
lMgFRIILVB	3188	SlenderGNN: Accurate, Robust, and Interpretable GNN, and the Reasons for its Success	['Graph neural networks', 'Linear models', 'Node classification', 'Heterophily graphs', 'Lightweight models']	We propose SlenderGNN, a linear GNN whose motivations are derived from comprehensive linearization on existing models.	General Machine Learning (ie none of the above)	anonymous|slendergnn_accurate_robust_and_interpretable_gnn_and_the_reasons_for_its_success	/pdf/677e587f0c82ec2117b77f5c954c7ef139f81176.pdf
aCQt_BrkSjC	3189	Learning Hyper Label Model for Programmatic Weak Supervision	['Programmatic Weak Supervision', 'Data Programming', 'Label Model']	A hyper label model to aggregate weak labels from multiple weak supervision sources to infer the ground-truth labels in a single forward pass	General Machine Learning (ie none of the above)	anonymous|learning_hyper_label_model_for_programmatic_weak_supervision	/pdf/afc202eb132f57c262c69408719eca90cf458886.pdf
g7TXnKjn3Y	3190	Tabular Data to Image Generation: Benchmark Data, Approaches, and Evaluation	[]	We study the problem of generating a set of images from an arbitrary tabular dataset	Applications (eg, speech processing, computer vision, NLP)	anonymous|tabular_data_to_image_generation_benchmark_data_approaches_and_evaluation	/pdf/f140ddc959fc74ac79e2b8b31d804ae61fb6663a.pdf
GPPmQdU3k7	3191	A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC 	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|a_probabilistic_approach_to_selfsupervised_learning_using_cyclical_stochastic_gradient_mcmc	/pdf/1c1ce43a842257c28d58762d869b0eca88fe490d.pdf
W0deqi42HD	3192	CURE: A Pre-training Framework on Large-scale Patient Data for Treatment Effect Estimation	[]		Deep Learning and representational learning	anonymous|cure_a_pretraining_framework_on_largescale_patient_data_for_treatment_effect_estimation	/pdf/15e7c722005ac5afa6aeb4b9cd57e120cd319b55.pdf
F_EhNDSamN	3193	Parametrizing Product Shape Manifolds by Composite Networks	['shape spaces', 'product manifolds', 'nonlinear statistics', 'low-dimensional data manifolds']		Deep Learning and representational learning	anonymous|parametrizing_product_shape_manifolds_by_composite_networks	/pdf/a8a11f4bc3384ba069cebd6f741edd15fc7e539c.pdf
EnrY5TOrbQ	3194	Agnostic Learning of General ReLU Activation Using Gradient Descent	['agnostic learning', 'learning ReLU', 'global convergence', 'learning theory']	We provide a convergence analysis of gradient descent for the problem of agnostically learning a single ReLU function under Gaussian distributions that achieves loss of O(OPT). 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|agnostic_learning_of_general_relu_activation_using_gradient_descent	/pdf/9416f054ce1c46137791b0970a22f65291b48496.pdf
xb333aboIu	3195	Critical Initialization of Wide and Deep Neural Networks through Partial Jacobians: General Theory and Applications	['Criticality', 'Gaussian Process', 'Jacobian', 'LayerNorm', 'Residual connections']	We introduce a new diagnostic for critical initialization in deep neural networks; and show that a combination of LayerNorm and residual connections leads to everywhere critical architectures.	Deep Learning and representational learning	anonymous|critical_initialization_of_wide_and_deep_neural_networks_through_partial_jacobians_general_theory_and_applications	/pdf/ff1143e5bea12ded6a03ce0c2e62f5bd4d66969c.pdf
o58JtGDs6y	3197	The Surprising Computational Power of Nondeterministic Stack RNNs	['formal languages', 'pushdown automata', 'language modeling', 'RNN']	We show that nondeterministic stack RNNs can learn non-CFLs and languages with surprisingly large alphabets, and we propose a new version that models a stack of vector embeddings.	Deep Learning and representational learning	anonymous|the_surprising_computational_power_of_nondeterministic_stack_rnns	/pdf/2d5b15332cf548cadbc55ea0d227b1550fe6a7f3.pdf
zfodIZGVWW	3198	Amos: An Adam-style Optimizer with Adaptive Weight Decay towards Model-Oriented Scale	['optimization', 'asymptotic behavior of stochastic optimization', 'learning-rate decay', 'weight decay', 'language model pre-training', 'Transformer pre-training']	An optimizer that consistently converges faster (<=70% training steps) than AdamW for pre-training Transformer variants.	Optimization (eg, convex and non-convex optimization)	anonymous|amos_an_adamstyle_optimizer_with_adaptive_weight_decay_towards_modeloriented_scale	/pdf/43cf528f1bd0f6e15f9f781e7ae0afca8a88d5b2.pdf
B-z41MBL_tH	3199	Causal Imitation Learning via Inverse Reinforcement Learning	['Causal Inference', 'Graphical Models']	This paper proposes novel inverse reinforcement learning methods to learn effective imitating policies from the expert's demonstrations when unobserved confounders are present.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|causal_imitation_learning_via_inverse_reinforcement_learning	/pdf/9f57ce35b391f5920f8da74e06cac94f1e0a6ee9.pdf
zZhX4eYNeeh	3200	Achieving Sub-linear Regret in Infinite Horizon Average Reward Constrained MDP with Linear Function Approximation	['Reinforcement Learning Theory', 'Infinite horizon Average Reward', 'Theory of Constrained Reinforcement Learning', 'Linear MDP', 'Model-free RL', 'Soft-max']	We provide the first sub-linear regret and sub-linear constraint violation for constrained MDP for linear function approximation using model-free RL algorithm	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|achieving_sublinear_regret_in_infinite_horizon_average_reward_constrained_mdp_with_linear_function_approximation	/pdf/1b474b2a57214685bc6ffa3e80f132110f95cfb8.pdf
mWVoBz4W0u	3201	PaLI: A Jointly-Scaled Multilingual Language-Image Model	[]		Deep Learning and representational learning	anonymous|pali_a_jointlyscaled_multilingual_languageimage_model	/pdf/232dc6310f500675d8c7a4e65f10ba1d84bfe3c5.pdf
iTtGCMDEzS_	3202	BigVGAN: A Universal Neural Vocoder with Large-Scale Training	['audio synthesis', 'speech synthesis', 'waveform generation', 'universal neural vocoder']		Applications (eg, speech processing, computer vision, NLP)	anonymous|bigvgan_a_universal_neural_vocoder_with_largescale_training	/pdf/949015c3e7c80921343fc360904154ff1474cff1.pdf
Mpa3tRJFBb	3204	Where to Begin? Exploring the Impact of Pre-Training and Initialization in Federated	['federated learning', 'optimization']	Stop worrying about heterogeneity and start from pre-trained weights.	Deep Learning and representational learning	anonymous|where_to_begin_exploring_the_impact_of_pretraining_and_initialization_in_federated	/pdf/966a0a266c8a1237fbfeced0ac0adaca052ab1fe.pdf
6SRDbbvU8s	3205	Learning Multimodal Data Augmentation in Feature Space	[]		Deep Learning and representational learning	anonymous|learning_multimodal_data_augmentation_in_feature_space	/pdf/8a29bf44176361a8db0e28049b5949b7a8432483.pdf
NN1sraxIyZ	3206	Global Counterfactual Explanations Are Reliable Or Efficient, But Not Both	['Global', 'counterfactual', 'explanations', 'recourse', 'fairness', 'efficiency', 'reliability', 'black box']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|global_counterfactual_explanations_are_reliable_or_efficient_but_not_both	/pdf/a688cf2598191f54dca7ef270f481778e3599960.pdf
oLIZ2jGTiv	3207	Tuning Frequency Bias in Neural Network Training with Nonuniform Data	['frequency bias', 'neural networks', 'training', 'nonuniform', 'Sobolev norms', 'Neural Tangent Kernel']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|tuning_frequency_bias_in_neural_network_training_with_nonuniform_data	/pdf/4104e0d00a672b97c6c973beaeb11aa492e74733.pdf
RYRUJEjcCY	3208	HEAV: Hierarchical Ensembling of Augmented Views for Image Captioning	['image captioning', 'vision and language']	We tackle the problem of how to efficiently and effectively leverage and ensemble heterogeneous views for image captioning	Applications (eg, speech processing, computer vision, NLP)	anonymous|heav_hierarchical_ensembling_of_augmented_views_for_image_captioning	/pdf/c418733b46b2bef6afd390a377f96ee6f2919dcc.pdf
QcffIcjq8bl	3209	Dynamic Pretraining of Vision-Language Models	['pretraining', 'vision language', 'sampling', 'curriculum learning']	We propose a dynamic pretraining resampling of tasks that learns faster and better models	Applications (eg, speech processing, computer vision, NLP)	anonymous|dynamic_pretraining_of_visionlanguage_models	/pdf/8764f2671dd5a817543348fc1132cd5483cf1cbf.pdf
pJ9Kg_K8ufd	3210	Discretization Invariant Learning on Neural Fields	['discretization invariance', 'neural fields', 'universal approximation', 'numerical integration', 'quasi-Monte Carlo']	We design a discretization invariant framework for learning various tasks on neural fields of arbitrary parameterization.	Deep Learning and representational learning	anonymous|discretization_invariant_learning_on_neural_fields	/pdf/82b64b969ce8ede03e583feed4d2d0bffb24cb95.pdf
3ZGJVocZ2XQ	3212	Building compact representations for image-language learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|building_compact_representations_for_imagelanguage_learning	/pdf/08160716a01b6d1277f075c9bb3a2ac179a1e659.pdf
3VFQfAG3vwi	3213	Variational Latent Branching Model for Off-Policy Evaluation	['Model-Based Off-policy Evaluation', 'Reinforcement Learning', 'Variational Inference']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|variational_latent_branching_model_for_offpolicy_evaluation	/pdf/23f14557af4f3c3aae023b1526acd89002fc6959.pdf
FELWgMjxZJj	3214	Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP	['vision-language models', 'open-vocabulary', 'image segmentation']	For the first time, zero-shot segmentation model matches the supervised model on ADE-20k without seeing any single training images.	Applications (eg, speech processing, computer vision, NLP)	anonymous|openvocabulary_semantic_segmentation_with_maskadapted_clip	/pdf/fbbae2a9250464469b17cda25ad7963b1afa8b21.pdf
hxEIgUXLFF	3215	PerFedMask: Personalized Federated Learning with Optimized Masking Vectors	['Computational capability', 'Data heterogeneity', 'Masking vectors', 'Personalized federated learning']	 We propose PerFedMask to address both the data and device heterogeneity issues in federated learning.	Deep Learning and representational learning	anonymous|perfedmask_personalized_federated_learning_with_optimized_masking_vectors	/pdf/0a378fcfb737793bb0b55a5a35d9af9ebd96bb3b.pdf
6R1unINH63	3216	Variance Double-Down: The Small Batch Size Anomaly in Multistep Deep Reinforcement Learning	['Reinforcement Learning', 'Deep Reinforcement Learning', 'Value based', 'Batch Size', 'Multi step learning']	We perform an exhaustive investigation into the interplay of batch size and update horizon and uncover a surprising phenomenon: when increasing the update horizon, it is more beneficial to decrease the batch size	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|variance_doubledown_the_small_batch_size_anomaly_in_multistep_deep_reinforcement_learning	/pdf/cd9d8ef529f43f9e974f166d92afd8c641a5cfb0.pdf
_4F4CDK9Mo	3217	RainProof: An Umbrella to Shield Text Generator from Out-Of-Distribution Data	['NLP', 'OOD detection', 'natural language generation']	Out of distribution detection for natural language generation	Applications (eg, speech processing, computer vision, NLP)	anonymous|rainproof_an_umbrella_to_shield_text_generator_from_outofdistribution_data	/pdf/b05e90f55da94d3a88a0777ddb2d62eb6d0999d0.pdf
oX3tGygjW1q	3218	Minimum Description Length Control	['multitask reinforcement learning', 'RL', 'reinforcement learning', 'MDL']	We propose a novel framework for multitask reinforcement learning which seeks to distill shared structure among tasks into a low-complexity representation, which is then leveraged to accelerate convergence on new tasks. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|minimum_description_length_control	/pdf/bd0cbc3df652d074544f8ecd50fb5f1fe96b7a91.pdf
lTjtY1HOUI6	3219	Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot Classification	[]		Deep Learning and representational learning	anonymous|adaptive_parametric_prototype_learning_for_crossdomain_fewshot_classification	/pdf/e1899e3784527782b8afb7dea4a871114e13e0eb.pdf
NTCYXulK9qm	3220	Co-Evolution As More Than a Scalable Alternative for Multi-Agent Reinforcement Learning	['reinforcement learning', 'multi-agent reinforcement learning', 'policy search', 'co-evolution', 'evolutionary algorithm']	Evolutionary Algorithms can be competitively used for policy search in multi-agent reinforcement and can scale to a high number of agents.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|coevolution_as_more_than_a_scalable_alternative_for_multiagent_reinforcement_learning	/pdf/ef90a358c1b140d624af9e72ce4070931d4ad77a.pdf
RIcaT3C0wP	3221	A Simple Unsupervised Data Depth-based Method to Detect Adversarial Images	['Adversarial attacks', 'Detection', 'Vision transformers', 'Safety AI']	We crafted a simple detection method for adversarial samples based on data depths which is especially designed for vision transformers architectures	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_simple_unsupervised_data_depthbased_method_to_detect_adversarial_images	/pdf/21641b8f2638e7a92c2cc25e6ae5a640077b483e.pdf
9bVBH1GD5sr	3222	FOCUS: Fairness via Agent-Awareness for Federated Learning on Heterogeneous Data	['federated learning', 'fairness', 'data heterogeneity', 'clustering', 'expectation–maximization (EM)']	We propose a formal definition of fairness via agent-awareness for FL (FAA) on heterogeneous data and a fair FL training algorithm based on agent clustering (FOCUS) to achieve FAA.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|focus_fairness_via_agentawareness_for_federated_learning_on_heterogeneous_data	/pdf/e9702f7ed9f776335df466fb1e0c31cf92f98d78.pdf
C1ns08q9jZ	3223	MetaGL: Evaluation-Free Selection of Graph Learning Models via Meta-Learning	['evaluation-free model selection', 'automatic graph learning', 'link prediction', 'meta-learning']	We present a meta-learning based framework that tackles the new problem of selecting a graph learning model without any evaluation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|metagl_evaluationfree_selection_of_graph_learning_models_via_metalearning	/pdf/67d0d3b4a0cbfd9257270114295a9495b1da9b37.pdf
Jw5ivmKS2C	3224	Posthoc Privacy guarantees for neural network queries	['data privacy', 'differential privacy', 'privacy preserving machine learning', 'adversarial learning']	We present a framework for achieving formal privacy guarantees in adversarially trained ML models	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|posthoc_privacy_guarantees_for_neural_network_queries	/pdf/e8eaa6d2654bfd9c7bb83771cad843bdf099e614.pdf
CKTmsDxRPn	3225	On Convergence of Federated Averaging Langevin Dynamics	['Langevin dynamics', 'federated learning', 'posterior inference', 'MCMC', 'stochastic gradient Langevin dynamics', 'differential privacy']	A federated averaging Langevin algorithm (FA-LD) for uncertainty quantification and mean predictions in federated learning.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|on_convergence_of_federated_averaging_langevin_dynamics	/pdf/a7e274c8de43ee2871c0827bb37b01eae818e637.pdf
e3lYU9cD8y	3226	SPIDR: SDF-based Neural Point Fields for Illumination and Deformation	[]		Deep Learning and representational learning	anonymous|spidr_sdfbased_neural_point_fields_for_illumination_and_deformation	/pdf/0112de255abd7a8ac6f6e63bf732a9cc0f3199e3.pdf
nulUqBMpBb	3227	Uncertainty-Driven Exploration for Generalization in Reinforcement Learning	['Deep reinforcement learning', 'exploration', 'generalization', 'procgen', 'crafter']	We found that exploration is crucial for generalization in contextual MDPs and proposed the first value-based deep RL algorithm that achieves state-of-the-art performance on Procgen.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|uncertaintydriven_exploration_for_generalization_in_reinforcement_learning	/pdf/3e4011e9f81dfac3bfb5b41f76e57a595f065650.pdf
kUmdmHxK5N	3228	Koopman Neural Operator Forecaster for Time-series with Temporal Distributional Shifts	['Time series forecasting', 'Temporal distributional shifts', 'Koopman Theory']		Deep Learning and representational learning	anonymous|koopman_neural_operator_forecaster_for_timeseries_with_temporal_distributional_shifts	/pdf/28cfa69e9db7f33bebd234edbce66e7b5d0311c5.pdf
PINRbk7h01	3229	Restricted Strong Convexity of Deep Learning Models with Smooth Activations	[]		Deep Learning and representational learning	anonymous|restricted_strong_convexity_of_deep_learning_models_with_smooth_activations	/pdf/f59453872e79277fd1e6ce600811444bd715f7f4.pdf
_wSHsgrVali	3230	Revisiting the Assumption of Latent Separability for Backdoor Defenses	['Backdoor Attacks']	Adaptive Backdoor Attacks against Latent Separation Based Defenses	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revisiting_the_assumption_of_latent_separability_for_backdoor_defenses	/pdf/6bf4c9d1c1c32c831559d16edf5f65f48bf19142.pdf
UmU9mydWRV3	3233	Neural DAEs: Constrained neural networks	['neural networks', 'differential algebraic equations', 'constraints']	We add constraints to neural networks	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neural_daes_constrained_neural_networks	/pdf/31a8d71c7983fafb342736a1828d1de79007f0f0.pdf
GbFK7JJJVTz	3235	Contrastive Graph Representation Learning with Cross-view Reconstruction	['Graph Neural Network', 'Graph Contrastive Learning']	Our paper propose a new contrastive learning framework to learn graph representation in accordance with the information bottleneck principle.	Unsupervised and Self-supervised learning	anonymous|contrastive_graph_representation_learning_with_crossview_reconstruction	/pdf/6d84283cc312b3be27cbf271204603055b4acdb2.pdf
G2GpzH1l9AC	3236	Learned Neural Network Representations are Spread Diffusely with Redundancy	['representation learning', 'redundancy', 'transfer learning', 'fairness']	We show that a randomly selected fraction of neurons from a pre-trained representation achieve similar performance as the full representation.	Deep Learning and representational learning	anonymous|learned_neural_network_representations_are_spread_diffusely_with_redundancy	/pdf/33d7094959a13a737a61a5af24c1468e74be72bd.pdf
MIMwy4kh9lf	3237	Open-Vocabulary Object Detection upon Frozen Vision and Language Models	['open-vocabulary recognition', 'object detection', 'vision and language']	We propose a novel open-vocabulary detection approach by building upon frozen vision and language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|openvocabulary_object_detection_upon_frozen_vision_and_language_models	/pdf/eff04254627ace8856f6bc566d7e9f6d002401ba.pdf
wKIxJKTDmX-	3238	Value-Based Membership Inference Attack on Actor-Critic Reinforcement Learning	['Privacy', 'Membership Inference Attack', 'Value Function', 'Actor-Critic', 'Reinforcement Learning']	We introduce a new membership inference attack focusing on the value function of the actor-critic algorithm.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|valuebased_membership_inference_attack_on_actorcritic_reinforcement_learning	/pdf/e17bc6b41db37e72fb6eb14ab8cd7dc46e21436f.pdf
ArPM-xtsFrk	3241	Gated Neural ODEs: Trainability, Expressivity and Interpretability	['Computational Neuroscience', 'Dynamical Systems', 'Differential Equations', 'Neural ODEs', 'Gating', 'Interpretability']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|gated_neural_odes_trainability_expressivity_and_interpretability	/pdf/20c3e9546ba8cee68aadefec2ef026b76e156839.pdf
PbfgkZ2HdbE	3242	Learning Controllable Adaptive Simulation for Multi-scale Physics	['adaptive', 'multi-scale', 'error vs. computation', 'controllable']	We introduce a method jointly learns the surrogate model and dynamically selects appropriate spatial resolutions that devote more compute to the highly dynamic regions	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_controllable_adaptive_simulation_for_multiscale_physics	/pdf/3901c2fb73d420195bcd7b7c888589e3445debeb.pdf
TfBHFLgv77	3244	Hyperbolic Deep Reinforcement Learning	['Reinforcement learning', 'Hyperbolic space', 'Representation learning', 'Machine learning']	We use hyperbolic space to model the latent representations of deep RL algorithms, attaining great performance and generalization benefits.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|hyperbolic_deep_reinforcement_learning	/pdf/935a5c336226f1f2546f53e5a7d8b2af30093038.pdf
_X12NmQKvX	3245	TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|tilp_differentiable_learning_of_temporal_logical_rules_on_knowledge_graphs	/pdf/971675e06ba46111047f24c003158835726f3d25.pdf
g-qWfKQlL3	3247	Conditional Permutation Invariant Flows	['Permutation invariance', 'continuous normalizing flows', 'traffic scene generation', 'object location']	We present a novel, conditional generative probabilistic model of set-valued data with a tractable log density.	Generative models	anonymous|conditional_permutation_invariant_flows	/pdf/830cdc91a6c30bf90a9fc1ed8c5b73c22b923bb3.pdf
3lr-ESFLUO	3248	Toward Discovering Options that Achieve Faster Planning	['Option Discovery', 'Temporal Abstraction', 'Planning', 'Reinforcement Learning']	We propose a new objective for option discovery that emphasizes the computational advantage of using options in planning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|toward_discovering_options_that_achieve_faster_planning	/pdf/a6da10071a53ed1e01e834f40fc36f2e39d3cc7b.pdf
nhKHA59gXz	3250	Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability	['gradient descent', 'optimization', 'edge of stability', 'implicit regularization', 'implicit bias']	We explain the mechanism behind the edge of stability phenomenon, where full batch gradient descent non-monotonically decreases the loss in the presence of instability.	Deep Learning and representational learning	anonymous|selfstabilization_the_implicit_bias_of_gradient_descent_at_the_edge_of_stability	/pdf/22713efb93a11de9a12e9d497ba050260a2f1752.pdf
KQ-ipHOmBc	3251	Few-Shot Text Classification with Dual Contrastive Consistency Training	['Few-Shot Learning', 'Contrastive Learning', 'Consistency Training']		Applications (eg, speech processing, computer vision, NLP)	anonymous|fewshot_text_classification_with_dual_contrastive_consistency_training	/pdf/749d566e6fa21cd64e291793f3ae53d6c508a25f.pdf
MYEap_OcQI	3252	Does Zero-Shot Reinforcement Learning Exist?	['controllable agents', 'zero-shot RL', 'self-supervised representation learning', 'successor representation', 'offline RL']	We revisit zero-shot RL based on successor representations, we introduce improved losses and new models and evaluate them systematically on the unsupervised RL benchmark.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|does_zeroshot_reinforcement_learning_exist	/pdf/b8a3fe6e051c07d56858ee86ab6ec1aa0ce02f04.pdf
zWy7dqOcel	3253	Sampling with Mollified Interaction Energy Descent	[]	Unconstrained and constrained sampling by minimizing a new class of mollified interaction energies.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|sampling_with_mollified_interaction_energy_descent	/pdf/cbe9c37e6344ef57a61355e371aeeacc3caa92d1.pdf
n70oyIlS4g	3254	An Extensible Multi-modal Multi-task Object Dataset with Materials	['Multi-task', 'multi-modal', 'dataset', 'materials', 'weak supervision']	We develop a dataset of Amazon product listings. The dataset includes images, text, price, mass, materials, and categories + others. We also show how to quickly add custom binary attributes to the dataset.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|an_extensible_multimodal_multitask_object_dataset_with_materials	/pdf/d1fedd4c317ad49e03df1b16f24a7c9f28b3e7ae.pdf
mdECGh-qlK	3255	OTCOP: Learning optimal transport maps via constraint optimizations	['optimal transport', 'constraint optimization', 'Monge problem']	 We integrates constraint optimization algorithm and neural networks for the computation of optimal transport maps based on the  Monge formulation.	Deep Learning and representational learning	anonymous|otcop_learning_optimal_transport_maps_via_constraint_optimizations	/pdf/acccc8e40262ed3e1927a6eb2f6b701a92e824e1.pdf
eZLdhVUG1hg	3256	Mixed Federated Learning: Joint Decentralized and Centralized Learning	['federated learning', 'decentralized learning', 'privacy', 'security', 'distribution shift', 'distribution skew', 'mobile computing']	Federated learning (FL) is good (better privacy, higher accuracy), and 'mixed FL' (concurrent joint FL and centralized learning) can make it even better, by mitigating distribution shifts and saving bandwidth and compute.	General Machine Learning (ie none of the above)	anonymous|mixed_federated_learning_joint_decentralized_and_centralized_learning	/pdf/d10bd2f0114ee987248f4c677ffaf2688696ef93.pdf
VBmeysLYDN	3257	CoMoE: Contrastive Mixture-of-Experts are Efficient Representation Learners	['Contrastive learning', 'sparse Mixture of Expert']	We study scaling contrastive learning with mixture of experts and improve its performance with a novel regularization.	Unsupervised and Self-supervised learning	anonymous|comoe_contrastive_mixtureofexperts_are_efficient_representation_learners	/pdf/e8f27ebf738c41997a8c4cdd90919bdc0c24e149.pdf
6taykzqcPD	3258	Neural Networks Efficiently Learn Low-Dimensional Representations with SGD	['feature learning', 'generalization', 'compressibility', 'sgd', 'neural networks']	We prove that SGD on neural networks can learn low-dimensional features in certain settings, and use this to derive novel generalization and excess risk bounds.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|neural_networks_efficiently_learn_lowdimensional_representations_with_sgd	/pdf/fa9601a8ac8c3844fb00a6d26430e556cbdf1266.pdf
1w_Amtk67X	3259	Constraining Representations Yields Models That Know What They Don't Know	['Rejecting classifiers', 'Selective classification', 'Uncertainty estimation', 'Robust classification', 'Out-of-distribution detection']	We introduce a model class able to provide confidence scores indicating how likely it is that it is making an erroneous prediction.	Deep Learning and representational learning	anonymous|constraining_representations_yields_models_that_know_what_they_dont_know	/pdf/8fec4e7ad2efd8d38e5ad8d3bb79175c29c04828.pdf
TjY9fl2Bcs	3262	FedCUAU: Clustered Federated Learning using weight divergence	['Federated Learning']	This work uses the relative weight divergence between each client update and their aggregated update to cluster clients and govern the knowledge transfer between clusters to improve both the initial and personalized performance.	General Machine Learning (ie none of the above)	anonymous|fedcuau_clustered_federated_learning_using_weight_divergence	/pdf/f019835a63a5788e6cf8f9a3b91e3b3c61c9b528.pdf
_01dDd3f78	3263	Concept Gradient: Concept-based Interpretation Without Linear Assumption	['Interpretability', 'Concept-based interpretation', 'XAI']	Extending concept-based gradient interpretation to non-linear concept functions.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|concept_gradient_conceptbased_interpretation_without_linear_assumption	/pdf/ad58cde4cc2c959fe737de96b276d9855b2c4800.pdf
XSRSWxyJIC	3264	Parameter-Efficient Fine-Tuning Design Spaces	['parameter-efficient fine-tuning', 'design spaces']		Applications (eg, speech processing, computer vision, NLP)	anonymous|parameterefficient_finetuning_design_spaces	/pdf/34fd30d2786528a05dc9ffa8a8b1b72db3543988.pdf
cYijsVZhb5	3265	Is a Caption Worth a Thousand Images? A Study on Representation Learning	['CLIP', 'transfer learning', 'contrastive learning', 'multi-modal']	Our work performs a systematic investigation into whether additional language supervision (in CLIP) helps models learn more transferrable representations.	Deep Learning and representational learning	anonymous|is_a_caption_worth_a_thousand_images_a_study_on_representation_learning	/pdf/0e431504b4d534036c248f9e04bbdfa998c92a14.pdf
u2Pd6x794I	3266	When Source-Free Domain Adaptation Meets Learning with Noisy Labels	['Source-Free Domain Adaptation', 'Unsupervised Domain Adaptation', 'Noisy Label Learning']		Unsupervised and Self-supervised learning	anonymous|when_sourcefree_domain_adaptation_meets_learning_with_noisy_labels	/pdf/e54ad40d1a180bb9f0ede77cbd6864b598543e39.pdf
iEVpHXjV4jj	3267	Emb-GAM: an Interpretable and Efficient Predictor using Pre-trained Language Models	['Interpretability', 'Explainability', 'Additivity', 'Generalized additive model', 'Linearity']	By using pre-trained language models to extract fixed-size representations, we can learn much more effective linear ngram models without sacrificing interpretability	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|embgam_an_interpretable_and_efficient_predictor_using_pretrained_language_models	/pdf/d7f26312764cdca2ceb92272dbc0828363043b0f.pdf
tAfyE2V7oye	3268	Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification	['robustness', 'distribution shift', 'nonparametric classification', 'minimax lower bounds', 'undersampling', 'label shift', 'covariate shift']	We show that learning is fundamentally constrained by a number of minority group samples in the setting of nonparametric classification with distribution shift. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|undersampling_is_a_minimax_optimal_robustness_intervention_in_nonparametric_classification	/pdf/6f5a5cc901f4374655d80206bf3de64255d24460.pdf
nA5AZ8CEyow	3269	Post-hoc Concept Bottleneck Models	['concepts', 'interpretability', 'concept bottleneck models', 'model editing']	We present a method to turn any neural network into a concept bottleneck model without sacrificing model performance, retaining interpretability benefits along with easy model editing.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|posthoc_concept_bottleneck_models	/pdf/3ba405d0a46995881aafed81e123639bcd1a418d.pdf
vjSKpocWeGf	3270	Lipschitz regularized gradient flows and latent generative particles	['probability divergences', 'generative models', 'Lipschitz regularization', 'gradient flows', 'autoencoders', 'particle algorithms']	We construct gradient flows, in real and latent spaces, as a generative tool to evolve empirical distributions in terms of a particle algorithm.	Generative models	anonymous|lipschitz_regularized_gradient_flows_and_latent_generative_particles	/pdf/80fbab09b4124036d7b44ab5a49eb76150706949.pdf
GvMuB-YsiK6	3272	Explaining Patterns in Data  with  Language Models via Interpretable Autoprompting	['Interpretability', 'explainability', 'XAI', 'AI for science']	We introduce interpretable autoprompting, a simple approach to *understand a dataset* by finding a semantically meaningful prompt for a large language model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|explaining_patterns_in_data_with_language_models_via_interpretable_autoprompting	/pdf/2607a064389bdde9d47bd61f38b952fb58cb49c2.pdf
EKpMeEV0hOo	3273	SimPer: Simple Self-Supervised Learning of Periodic Targets	['Periodic learning', 'Self-supervised learning', 'Representation learning', 'Periodic targets', 'Periodicity']	A simple contrastive self-supervised framework for learning periodic targets and tasks.	Unsupervised and Self-supervised learning	anonymous|simper_simple_selfsupervised_learning_of_periodic_targets	/pdf/68ba6c7b753f931024d965116d701431782b31e1.pdf
P-73JPgRs0R	3275	Effects of Graph Convolutions in Multi-layer Networks	['graph neural networks', 'node classification', 'classification threshold', 'contextual stochastic block model']	Theoretical and empirical insights into the performance of graph convolutions in multi-layer networks	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|effects_of_graph_convolutions_in_multilayer_networks	/pdf/d77b504c3a4fccc72241ecdab57b7b643b79bec9.pdf
PuEOL1hhyrF	3276	Active Sampling for Node Attribute Completion on Graphs	['Graph Neural Network', 'Node Attribute Completion', 'Active Sampling']		Deep Learning and representational learning	anonymous|active_sampling_for_node_attribute_completion_on_graphs	/pdf/eee00e0f0cb28195c27021a65f0e3566f79dbb60.pdf
mbxz9Cjehr	3277	A CMDP-within-online framework for Meta-Safe Reinforcement Learning	['Meta-Reinforcement learning', 'Constrained MDPs', 'online learning', 'safe RL', 'dynamic regret']	We study the problem of meta-reinforcement learning (meta-RL) for constrained Markov decision processes (CMDPs) through the inexact CMDP-within-online framework.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_cmdpwithinonline_framework_for_metasafe_reinforcement_learning	/pdf/4fbfbb98dea389bd3564710b0782d932af3848bf.pdf
nbGCPw8Rry	3278	Deep Biological Pathway Informed Pathology-Genomic Multimodal Survival Prediction	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|deep_biological_pathway_informed_pathologygenomic_multimodal_survival_prediction	/pdf/5b93cc6394bfdae0e48ca056ca4c7926dc2be649.pdf
5MR1OGvCtH	3279	A Sample Based Method for Understanding The Decisions of Neural Networks Semantically	['Machine Learning Interpretability', 'Bias', 'ImageNet', 'AlexNet', 'ResNet', 'VGG-16', 'Inception', 'CNNs', 'Bag of Words']	This paper introduces a semantic interpretability framework that is used to understand how CNN models and their robust counterparts manipulate image regions.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_sample_based_method_for_understanding_the_decisions_of_neural_networks_semantically	/pdf/e8dd7c90816d2a65e9d912485427b72ea15aff1e.pdf
LOMA7vSa2Y	3280	MetaMD: Principled Optimiser Meta-Learning for Deep Learning	['Meta-learning', 'Optimiser Learning']	We proposed a meta-learning based algorithm, learning optimisers under the mirror descent framework.	Deep Learning and representational learning	anonymous|metamd_principled_optimiser_metalearning_for_deep_learning	/pdf/f4f984fc97307cd287849f6855c6de490797cffd.pdf
zzqBoIFOQ1	3283	Guiding Safe Exploration with Weakest Preconditions	['reinforcement learning', 'safe learning', 'safe exploration']	We use an online, weakest-precondition-based approach to ensure safety during exploration without interfering with performance.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|guiding_safe_exploration_with_weakest_preconditions	/pdf/ff25562b9fca8e8ce35e37ea47b4205b233c8e88.pdf
vmjctNUSWI	3284	Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics	['Embodied AI', 'Adaptation', 'Visual Navigation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|moving_forward_by_moving_backward_embedding_action_impact_over_action_semantics	/pdf/cf1ab6367a0977af76d88a9bf72a75e8737974af.pdf
fk7RbGibe1	3285	Domain Generalization via Heckman-type Selection Models 	['Domain Generalization', 'Sample Selection', 'Bias Correction', 'Heckman']	A non-random sample selection framework for solving domain generalization, and a set of Heckman-type estimators for various types of outcomes.	General Machine Learning (ie none of the above)	anonymous|domain_generalization_via_heckmantype_selection_models	/pdf/5ed1f087842ebc1add2c84a7b351cffbb2ab76ff.pdf
q_7TgV0ugq	3286	A Deep Learning Framework for Musical Acoustics Simulations	['Datasets', 'acoustics simulation', 'numerical modeling', 'deep learning', 'neural operators', 'benchmarking']	An open-access/open-source framework designed for the generation of numerical musical acoustics datasets and for the training/benchmarking of acoustics neural operators.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_deep_learning_framework_for_musical_acoustics_simulations	/pdf/6b0d50345fc7a78e1b862b49b11df13bb29f1089.pdf
JsrvkgM8gO2	3287	Large Learning Rate Matters for Non-Convex Optimization	['large learning rates', 'GD', 'SGD', 'non-convex optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|large_learning_rate_matters_for_nonconvex_optimization	/pdf/dfe38e5de9e409abd5d1ac3a7204d02508e79e62.pdf
HjzWIMEWipV	3288	Actionable Recourse Guided by User Preference	['Actionable recourse']	Capturing user preference and suggesting actionable recourse for adversely affected individuals by a machine learning model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|actionable_recourse_guided_by_user_preference	/pdf/fba26360c650a1f2e3dc5a135a5732ec42b4c9c0.pdf
TSqRwmrRiOn	3289	Bias Amplification Improves Worst-Group Accuracy without Group Information	['spurious correlation', 'worst-group accuracy', 'group robustness']	We propose a novel two-stage training algorithm that achieves the state-of-the-art worst-group accuracy on test data without group information.	Deep Learning and representational learning	anonymous|bias_amplification_improves_worstgroup_accuracy_without_group_information	/pdf/6ebcd2c41612968e25deba3628b1a9f06d750a83.pdf
n05upKp02kQ	3290	Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms	['reinforcement learning theory', 'POMDPs', 'predictive state representations', 'partially observable reinforcement learning']	We propose a unified structural condition for sample-efficient partially observable RL (POMDPs/PSRs), and establish substantially sharper learning results than existing ones.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|partially_observable_rl_with_bstability_unified_structural_condition_and_sharp_sampleefficient_algorithms	/pdf/301caa7f3871c9fb0c43cda39b93e2bb0c61cd2b.pdf
whfYRamFiOL	3291	DOT: Fast Cell Type Deconvolution by Optimal Transport	['Optimal Transport', 'Frank-Wolfe', 'Cell type deconvolution', 'Spatial data']	Fast Optimal Transport for robust cell type mapping in high and low resolution spatial data 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|dot_fast_cell_type_deconvolution_by_optimal_transport	/pdf/a25475808613bc9c50830d0f61189e901da79dcd.pdf
CL-sVR9pvF	3294	Weighted Ensemble Self-Supervised Learning	['self-supervised learning', 'ensemble', 'representation learning']	We efficiently ensemble SSL methods and train them with new objectives to get SOTA results on ImageNet-1K SSL evaluations.	Unsupervised and Self-supervised learning	anonymous|weighted_ensemble_selfsupervised_learning	/pdf/439eab93018d93e59504aec437413a7d0916454a.pdf
qSjf5zf5tv	3295	Neural Network Approximation of Lipschitz Functions in High Dimensions with Applications to Inverse Problems	['approximation theory', 'neural networks', 'deep learning', 'Johnson-Lindenstrauss embedding', 'inverse problems']	We provide neural network approximation guarantees for Lipschitz functions on low-complexity sets in high dimensions.	Deep Learning and representational learning	anonymous|neural_network_approximation_of_lipschitz_functions_in_high_dimensions_with_applications_to_inverse_problems	/pdf/d1c3548e02fee5fe2055243e0fbc41c68eb11843.pdf
Si_XWk8umO	3296	Towards Large Scale Transfer Learning for Differentially Private Image Classification	['Differential Privacy', 'Understanding Differential Privacy', 'Image Classification', 'Deep Learning']	We perform comprehensive exploration of Differentially Private training on ImageNet. Combined with large scale transfer learning and a few insights, we obtain state of the art private results with minimal computational overhead.	Deep Learning and representational learning	anonymous|towards_large_scale_transfer_learning_for_differentially_private_image_classification	/pdf/b960633907b78171bef9bdd55b8e03427219d26e.pdf
n3RFM5cBB4	3297	Learning Efficient Hybrid Particle-continuum Representations of Non-equilibrium N-body Systems	['multi-scale', 'hybrid representation', 'particle-continuum', 'n-body', 'plasma']	We introduce a method for Learning Hybrid Particle-Continuum models that enables an efficient and accurate coupling between fluid and kinetic representations of N-body systems.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_efficient_hybrid_particlecontinuum_representations_of_nonequilibrium_nbody_systems	/pdf/89d0e617814c48ae2e25be81cdf2396be837f126.pdf
TTduM2sE0Ja	3299	Exp-$\alpha$: Beyond Proportional Aggregation in Federated Learning	['Federated Learning']	We theoretically study properties of proportional aggregation and propose a novel aggregation strategy for faster convergence under Non-IID setting.	Deep Learning and representational learning	anonymous|exp\alpha_beyond_proportional_aggregation_in_federated_learning	/pdf/dc23ce1ae5ffda4585152265c13619d91105cee8.pdf
9HiGqC9C-KA	3300	simpleKT: A Simple But Tough-to-Beat Baseline for Knowledge Tracing	['knowledge tracing', 'assessment', 'ai for education']	We propose \textsc{simpleKT}, a simple but tough-to-beat KT baseline that is simple to implement, computationally friendly and robust to a wide range of KT datasets across different domains	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|simplekt_a_simple_but_toughtobeat_baseline_for_knowledge_tracing	/pdf/16982025eb0134e13e337b0b55ab66ef893d980c.pdf
dNdOnKy9YNs	3301	Why Self Attention is Natural for Sequence-to-Sequence Problems? A Perspective from Symmetries	['Self attention', 'sequence-to-sequence function', 'orthogonal equivairance', 'permutation equivariance']		Deep Learning and representational learning	anonymous|why_self_attention_is_natural_for_sequencetosequence_problems_a_perspective_from_symmetries	/pdf/e43f863f2cc59e543677b9ad50db895fcda7c408.pdf
jpq0qHggw3t	3302	Partial Label Unsupervised Domain Adaptation with Class-Prototype Alignment	['Partial label learning', 'label noise', 'domain adaptation']	This is the first partial label learning method that handles partial label learning and unsupervised domain adaptation simultaneously.	General Machine Learning (ie none of the above)	anonymous|partial_label_unsupervised_domain_adaptation_with_classprototype_alignment	/pdf/9f5c4f29357d60276e8aaf97e9425aa40898ae05.pdf
0eSq84hbXhe	3303	The Graph Learning Attention Mechanism: Learnable Sparsification Without Heuristics	['graph structure learning', 'graph attention networks']	We introduce a drop-in, differentiable graph structure learning layer for use with GNNs.	Deep Learning and representational learning	anonymous|the_graph_learning_attention_mechanism_learnable_sparsification_without_heuristics	/pdf/c1b96a807d8d5fd4bac3ec07f6dc8f87c081087b.pdf
EUrxG8IBCrC	3304	Mutual Partial Label Learning with Competitive Label Noise	['Partial label learning', 'label noise', 'classification']		General Machine Learning (ie none of the above)	anonymous|mutual_partial_label_learning_with_competitive_label_noise	/pdf/ff035ddfc895be60f555a65574c60ad483d0cde0.pdf
UDbNL0_W-3x	3305	A Quasistatic Derivation of Optimization Algorithms' Exploration on Minima Manifolds	['Implicit bias', 'minima manifold', 'time-scale separation', 'Adam']		Optimization (eg, convex and non-convex optimization)	anonymous|a_quasistatic_derivation_of_optimization_algorithms_exploration_on_minima_manifolds	/pdf/c47fcafe684cb5a7c3ed80a4b9a94efd0249d8f1.pdf
383GRAoNhzb	3306	Examining the Difference Among Transformers and CNNs with Explanation Methods	['Explanation', 'transformers', 'multiple explanations']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|examining_the_difference_among_transformers_and_cnns_with_explanation_methods	/pdf/632c2bc7a3681186a40dd168b785d7e5a3806ed7.pdf
jg9ELHRfHD7	3309	REV: Information-Theoretic Evaluation of Free-Text Rationales	['free-text rationales', 'conditional V-information', 'evaluation metric', 'explainable AI']	This paper proposes an evaluation metric based on conditional $\mathcal{V}$-information to measure the information in free-text rationales.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|rev_informationtheoretic_evaluation_of_freetext_rationales	/pdf/5e168b609804e5782a2a4541e332cb154dd90c91.pdf
4k95LUAcqi	3310	Assessing Neural Network Robustness via Adversarial Pivotal Tuning of Real Images	['Robustness', 'Adversarial Examples', 'StyleGAN', 'Generative Models']	Utilizing StyleGAN's full capacity to manipulate images semantically so as to fool image classifiers through a process called Adversarial Pivotal Tuning.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|assessing_neural_network_robustness_via_adversarial_pivotal_tuning_of_real_images	/pdf/90e1861878ce8bc48b80d04a4a05f29029b15fb2.pdf
ElC6LYO4MfD	3312	Faster federated optimization under second-order similarity	['federated learning', 'distributed optimization', 'hessian similarity', 'client sampling', 'stochastic proximal point', 'proximal point method', 'distributed learning']		Optimization (eg, convex and non-convex optimization)	anonymous|faster_federated_optimization_under_secondorder_similarity	/pdf/ebb7b625bb087fbe6cbee9c476fb2072bbae39d1.pdf
NdFKHCFxXjS	3313	CAN MACHINE TELL THE DISTORTION DIFFERENCE? A REVERSE ENGINEERING STUDY OF ADVERSARIAL ATTACKS	['adversarial learning', 'reverse engineering', 'deep learning', 'neural network']		Deep Learning and representational learning	anonymous|can_machine_tell_the_distortion_difference_a_reverse_engineering_study_of_adversarial_attacks	/pdf/46dbb34714b8b59b630ababb61ad4d4b4702669f.pdf
0cpM2ApF9p6	3314	Score-based Generative 3D Mesh Modeling	['generative model', 'diffusion model', '3D mesh', 'shape generation']	Diffusion model on 3D meshes of arbitrary topology by direct parametrizing meshes with tetrahedral grids	Generative models	anonymous|scorebased_generative_3d_mesh_modeling	/pdf/9064dd911fc011ccbd9190c7d88417211f395b7a.pdf
Q0XkE_srKnG	3316	Learning from Labeled Images and Unlabeled Videos for Video Segmentation	['Video', 'Segmentation', 'Representation']		Unsupervised and Self-supervised learning	anonymous|learning_from_labeled_images_and_unlabeled_videos_for_video_segmentation	/pdf/ce4e39583e5e8f6dc2badef0b8cb7ced030a08b1.pdf
6TugHflAGRU	3317	Eigenvalue Initialisation and Regularisation for Koopman Autoencoders	['koopman', 'deep learning', 'dynamical systems', 'autoencoders', 'physics-constrained learning', 'neural networks']	Using eigenvalues to regularise and initialise Koopman autoencoders improves performance significantly	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|eigenvalue_initialisation_and_regularisation_for_koopman_autoencoders	/pdf/348785bf86bf7a346d409abddd59cbee80e4479c.pdf
462z-gLgSht	3318	DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability	['disentanglement', 'identifiability', 'representation learning']	We extend the DCI framework for evaluating disentangled representations and connect it to identifiability.	Deep Learning and representational learning	anonymous|dcies_an_extended_disentanglement_framework_with_connections_to_identifiability	/pdf/5d23f5ced7f1c01cf63a77998ea0122a8fc6d392.pdf
m4f7Wl93fzT	3319	Learning Listwise Domain-Invariant Representations for Ranking	['learning to rank', 'domain adaptation', 'text ranking']	We establish a domain adaptation generalization bound for ranking and propose a method based on learning listwise invariant representations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_listwise_domaininvariant_representations_for_ranking	/pdf/364dfc9873b066e797a60a599f8ad102dc233375.pdf
Ai8Hw3AXqks	3320	Simplified State Space Layers for Sequence Modeling	['sequence models', 'state space', 'S4', 'RNN', 'transformers', 'long range arena']	We introduce a new state space sequence modeling layer, building on the recent S4 layer, that increases the state of the art on many long-range benchmark tasks.	Deep Learning and representational learning	anonymous|simplified_state_space_layers_for_sequence_modeling	/pdf/92cc245ea5f90a78f3599e5920a0a0fedfe9a65f.pdf
Hu4r-dedqR0	3321	Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic	['Neural Fuzzy Logic', 'Weakly Supervised Reasoning', 'Natural Language Inference', 'Explainability and Interpretability']		Applications (eg, speech processing, computer vision, NLP)	anonymous|weakly_supervised_explainable_phrasal_reasoning_with_neural_fuzzy_logic	/pdf/595f7edffb806e927c5b7e2c9f72f7d23ff98ca2.pdf
3i9EgUss-Vs	3322	Graph Convolutional Normalizing Flows for Semi-Supervised Classification and Clustering	['graph convolutional network', 'normalizing flow', 'generative model']	A normalizing flow architecture based on graphs is developed for semi-supervised learning, producing high-quality classification and clustering.	Deep Learning and representational learning	anonymous|graph_convolutional_normalizing_flows_for_semisupervised_classification_and_clustering	/pdf/c3b14ffd06503504378ce31682902c8c249be1b8.pdf
UawwAryavZI	3323	Towards Solving Industrial Sequential Decision-making Tasks under Near-predictable Dynamics via Reinforcement Learning: an Implicit Corrective Value Estimation Approach	[]	We decouple the data dynamics of industrial sequential decision-making tasks and design a bi-critic framework to solve the state transition uncertainty.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_solving_industrial_sequential_decisionmaking_tasks_under_nearpredictable_dynamics_via_reinforcement_learning_an_implicit_corrective_value_estimation_approach	/pdf/1110feb57d952e6965824437d69fe2ca0660fed3.pdf
eb_cpjZZ3GH	3325	Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO) Convolutions	['Spherical CNNs', 'rotational equivariance', 'efficient algorithms']	A discrete-continuous (DISCO) spherical CNN framework that is simultaneously rotationally equivariant and computationally scalable and achieves state-of-the-art on numerous benchmarks	Deep Learning and representational learning	anonymous|scalable_and_equivariant_spherical_cnns_by_discretecontinuous_disco_convolutions	/pdf/de07920570c5dfdb637903609c2423e19d31d5df.pdf
Idusfje4-Wq	3326	Diffusion Models for Causal Discovery via Topological Ordering	['Diffusion Models', 'Causal Discovery', 'Topological Ordering', 'Score-based Methods']	We use diffusion models for causal discovery by iteratively finding and removing leaves in causal graph, resulting in a efficient topological ordering algorithm for high-dimensional graphs.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|diffusion_models_for_causal_discovery_via_topological_ordering	/pdf/dddf4edca5e963d7c45a0940cf8362de905d48be.pdf
ALbEpTC4hBp	3327	Revisiting Instance-Reweighted Adversarial Training	['Adversarial training', 'Adversarial robustness', 'Instance-reweighted']	We clarify a weakness of previous methods and propose a method to resolve the weakness by transforming margins into an appropriate representation.	Deep Learning and representational learning	anonymous|revisiting_instancereweighted_adversarial_training	/pdf/bd76298327954855dea995fc6d01b6ef1cb2afed.pdf
MMiaF8KppTZ	3328	Logical view on fairness of a binary classification task	['binary classification', 'fairness', 'first-order logic', 'decidability']	The fairness of a binary classifier is a logical phenomenon since its loss is not expressible in the first-order logic of a suitable model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|logical_view_on_fairness_of_a_binary_classification_task	/pdf/87e62402da1dac5d291fb5bb615c70e235981e87.pdf
zxCI2whLfXB	3329	Faster Optimization on Sparse Graphs via Neural Reparametrization	['graph neural networks', 'energy minimization', 'AI for science']	We show that in certain optimization problems on sparse graphs, using graph neural networks to encode node states can reduce convergence time. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|faster_optimization_on_sparse_graphs_via_neural_reparametrization	/pdf/064e431de9b01433a30aac6c52d68447996235fa.pdf
9IaN4FkVSR1	3330	Deconstructing Distributions: A Pointwise Framework of Learning	['understanding deep learning', 'empirical investigation', 'distribution shift']	"We propose a new lens for studying the pointwise performance of learning algorithms which reveals new insights into their behavior and goes beyond traditional notions of in-distribution and ""out-of-distribution"" learning. "	General Machine Learning (ie none of the above)	anonymous|deconstructing_distributions_a_pointwise_framework_of_learning	/pdf/cad2622f8f0a9e9d57cc61084423eb4dc6932152.pdf
flap0Bo6TK_	3331	Graph Neural Network-Inspired Kernels for Gaussian Processes in Semi-Supervised Learning	['graph neural network', 'Gaussian process', 'semi-supervised learning']	Graph-based Gaussian process kernels are developed based on graph neural networks, showing competitive semi-supervised learning performance and timing advantage.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|graph_neural_networkinspired_kernels_for_gaussian_processes_in_semisupervised_learning	/pdf/4f67d45a3f23473659d6fd4a17785980c96023a4.pdf
-aEuKX6zQKmr	3332	EmbedDistill: A geometric knowledge distillation for information retrieval	['Knowledge distillation', 'dual encoder', 'cross encoder', 'information retrieval', 'query generation', 'embedding matching', 'retrieval', 're-ranking']	We propose a novel distillation approach to train dual encoder information retrieval models that goes beyond score-matching and aims to explicitly align embedding spaces of teacher and student models.	Deep Learning and representational learning	anonymous|embeddistill_a_geometric_knowledge_distillation_for_information_retrieval	/pdf/e13eecd9e165f67642b5ac126892e00860294c8d.pdf
QZfdDpTX1uM	3333	Meta Temporal Point Processes	['Temporal Point Process', 'Asynchronous Time Series', 'Meta-learning']	We present a novel approach to train temporal point processes in a meta learning framework.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|meta_temporal_point_processes	/pdf/eca8cc78581f051338d5e212e01e07f694aa64cf.pdf
mjzm6btqgV	3334	Efficiently Computing Nash Equilibria in Adversarial Team Markov Games	['multiagent-reinforcement-learning.marl', 'rl', 'reinforcement-learning', 'learning-in-games', 'optimization', 'game-theory', 'policy-gradient']	Nash equlibrium can be computed effieciently in Markov games where a single player competes against multiple agents who share a common interest.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|efficiently_computing_nash_equilibria_in_adversarial_team_markov_games	/pdf/b6f6798e4b446fe6f068f2a5b51cda22da80751c.pdf
vk96czrH2Y	3335	Learning-Based Radiomic Prediction of Type 2 Diabetes Mellitus Using Image-Derived Phenotypes	['Tabular Data', 'Disease Prediction', 'Machine Learning for Health', 'Out-of-Domain Generalization', 'Classification']	Tabular learning models can predict patient diabetes risk from a combination of noninvasive physical examination and CT imaging data.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learningbased_radiomic_prediction_of_type_2_diabetes_mellitus_using_imagederived_phenotypes	/pdf/c77a683c1f23b070ba93417fa16a5b3e8f158816.pdf
WHgGpgHFNT	3336	TrajGRU-Attention-ODE: Novel Spatiotemporal Predictive Models	['Spatiotemporal predictive model', 'convolutional recurrent neural network', 'attention mechanism', 'neural ordinary differential equation', 'irregularly sampled time series.']	This paper presents novel deep learning models for spatiotemporal predictive tasks.	Deep Learning and representational learning	anonymous|trajgruattentionode_novel_spatiotemporal_predictive_models	/pdf/503770ea8d9cbd0c81f9a78e5f63f6a374298752.pdf
WL8FlAugqQ	3338	Neural DAG Scheduling via One-Shot Priority Sampling	['Combinatorial Optimization', 'Directed Acyclic Graph', 'Scheduling', 'Graph Neural Network', 'Reinforcement Learning']	We propose a novel ML scheduler that uses a one-shot neural network encoder to sample node priorities which are converted by list scheduling to the final schedules.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|neural_dag_scheduling_via_oneshot_priority_sampling	/pdf/7ddb9865b0991b0ea7684ad40c67432cb1ddfbd6.pdf
Qamz7Q_Ta1k	3339	Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs	['temporal', 'networks', 'graphs', 'embedding']	We propose a line graph-based method for temporal networks which directly embeds temporal edges.	General Machine Learning (ie none of the above)	anonymous|direct_embedding_of_temporal_network_edges_via_timedecayed_line_graphs	/pdf/c879837c9eeafae0c9479710a8483cd34a969738.pdf
1pGmKJvneD7	3340	LVQ-VAE:End-to-end Hyperprior-based Variational Image Compression with Lattice Vector Quantization	['Image Compression', 'Variational Autoencoder', 'Vector Quantization', 'Lattice']		Deep Learning and representational learning	anonymous|lvqvaeendtoend_hyperpriorbased_variational_image_compression_with_lattice_vector_quantization	/pdf/49355116bdf7b6dfa491d10edc2ab081557b973c.pdf
Do9MOlwWHu0	3342	Learning Sparse Group Models Through Boolean Relaxation	['Structured sparisity', 'Convex relaxation', 'Cardinality-constrained program', 'Small sample size']		General Machine Learning (ie none of the above)	anonymous|learning_sparse_group_models_through_boolean_relaxation	/pdf/1aea353b7962a2de690ef58c0633de4ba3d0761c.pdf
xZSRTER-2Qv	3344	Deep Direct Discriminative Decoders for High-dimensional Time-series Data Analysis	['Dynamical Model', 'State-space Model (SSM)', 'Neural Decoding', 'Deep neural network (DNN)']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|deep_direct_discriminative_decoders_for_highdimensional_timeseries_data_analysis	/pdf/7eb13094d1a56849c811b6efb802c69bb4515eb1.pdf
6qeBuZSo7Pr	3345	Planning Goals for Exploration	['model-based reinforcement learning', 'exploration', 'goal-conditioned reinforcement learning', 'planning', 'intrinsic motivation', 'reinforcement learning']	We use world models to generate goals for exploration.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|planning_goals_for_exploration	/pdf/2ec2d0b4e6e66ea06826c6d2c653295a4e5bedf3.pdf
f8zhJ1jAfIq	3346	Live in the Moment: Learning Dynamics Model Adapted to Evolving Policy	['Reinforcement Learning', 'Model-based Reinforcement Learning', 'State-action Visitation Distribution', 'Distribution Shift', 'Policy-adapted Dynamics Model Learning']	We theoretically analyze how the distribution of historical policies affects the model learning and model rollouts and propose a novel model learning method for model-based RL.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|live_in_the_moment_learning_dynamics_model_adapted_to_evolving_policy	/pdf/9a181c889f052ca6a6d0d1ae5304c8126961213e.pdf
PjT1TJ62vJW	3347	Exploring semantic information in disease: Simple Data Augmentation Techniques for Chinese Disease Normalization	['Data Augmentation', 'Medicine', 'Disease', 'Disease Normalization', 'Deep Learning', 'Natural Language Processing', 'Representation Learning']	A novel data augmentation method in NLP to address the problem of Chinese Disease Normalization.	Deep Learning and representational learning	anonymous|exploring_semantic_information_in_disease_simple_data_augmentation_techniques_for_chinese_disease_normalization	/pdf/7baf2db5656d17f46faf12a3555f7e125cf76a7e.pdf
DlpCotqdTy	3348	Provably Auditing Ordinary Least Squares in Low Dimensions	['stability', 'linear regression', 'ordinary least squares', 'robustness']	We develop provable and efficient algorithms for estimating stability of OLS to dropping samples in the low-dimensional regime.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|provably_auditing_ordinary_least_squares_in_low_dimensions	/pdf/cd569aadbd962f210b606ad23500b582582b7461.pdf
4-oNRO0Fqy	3350	Model ChangeLists: Characterizing Changes in ML Prediction APIs	['model evaluation', 'model comparison', 'machine learning as a service', 'robustness']	In this work, we study MLaaS API updates. We introduce, Mocha, a new framework for describing model updates. Then we use Mocha to demonstrate how subtle, but significant, shifts are commonly introduced by updates.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|model_changelists_characterizing_changes_in_ml_prediction_apis	/pdf/0f3ee3cee8646b63bf25306d8b388f2f2b925443.pdf
1sN_4ROgel	3351	A Scalable and Exact Gaussian Process Sampler via Kernel Packets	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|a_scalable_and_exact_gaussian_process_sampler_via_kernel_packets	/pdf/eb7050687b1de225369989f0f9abd1c41ae59cd5.pdf
upJ3vrFKaL	3352	Collecting The Puzzle Pieces: Disentangled Self-Driven Human Pose Transfer by Permuting Textures	['person image generation', 'human pose transfer', 'image synthesis']	Present a self-driven human pose transfer method by permuting textures.	Applications (eg, speech processing, computer vision, NLP)	anonymous|collecting_the_puzzle_pieces_disentangled_selfdriven_human_pose_transfer_by_permuting_textures	/pdf/1314724f636a6da7a119fc3cccf97df4c69db64a.pdf
8xuFD1yCoH	3353	TuneUp: A Training Strategy for Improving Generalization of Graph Neural Networks	['Graph Neural Networks', 'Curriculum learning', 'Tail nodes']	We develop a curriculum learning strategy to train GNNs with high generalization performance especially on tail nodes.	Deep Learning and representational learning	anonymous|tuneup_a_training_strategy_for_improving_generalization_of_graph_neural_networks	/pdf/c5982cdb3e0c273dad8fb6f958648bce953853bc.pdf
5U3xzYJoThy	3354	A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning	['vision and language navigation']	A new path to improving instruction following agents using pure imitation learning (no RL) and large scale in-domain data augmentation 	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_new_path_scaling_visionandlanguage_navigation_with_synthetic_instructions_and_imitation_learning	/pdf/2acf10683fb7e19dfcc056bfd90263bea2b40cb5.pdf
ZUXy6d49JNJ	3355	Skill-Based Reinforcement Learning with Intrinsic Reward Matching	['Unsupervised Reinforcement Learning', 'Reinforcement Learning', 'Deep Learning']	We unify unsupervised RL skill pretraining and downstream finetuning phases of learning by leveraging the skill discriminator as a task specifier.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|skillbased_reinforcement_learning_with_intrinsic_reward_matching	/pdf/239268df1753565c85bd8dd943a738399a744173.pdf
N-eul1pdagX	3356	Exact Representation of Sparse Networks with Symmetric Nonnegative Embeddings	['graph', 'network', 'embeddings', 'arboricity', 'factorization', 'model', 'community', 'nonnegative']	We expand on previous bounds for exact factorization of undirected graphs and extend them to our proposed model, which is more interpretable.	General Machine Learning (ie none of the above)	anonymous|exact_representation_of_sparse_networks_with_symmetric_nonnegative_embeddings	/pdf/07dd1e669a1ac3f7b5fb2107ede6d54bfb879e1b.pdf
Z8qk2iM5uLI	3357	Vector Quantized Wasserstein Auto-Encoder	[]		Deep Learning and representational learning	anonymous|vector_quantized_wasserstein_autoencoder	/pdf/7040c454aa4695afbfd48bf9cc7d197a9346c22d.pdf
eoqfMQJogx0	3358	Distributional Signals for Node Classification in Graph Neural Networks	['Graph neural networks', 'graph signal processing', 'regularization', 'smoothness', 'node classification']	In this paper, we introduce the new notion of distributional graph signals and use it to design a GNN regularization scheme. 	General Machine Learning (ie none of the above)	anonymous|distributional_signals_for_node_classification_in_graph_neural_networks	/pdf/234f0c6069996be9199c9b0e420046b5a67c06e0.pdf
pvLMBZ5w9eg	3359	Quantum 3D graph structure learning with applications to molecule computing	[]		Deep Learning and representational learning	anonymous|quantum_3d_graph_structure_learning_with_applications_to_molecule_computing	/pdf/ff1de388071ddb8d0ad1d94fa3b4bf4d7f60e28c.pdf
Ab8hkaJSJI	3360	Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning	['differential privacy', 'matrix mechanism', 'machine learning', 'artificial intelligence', 'private learning']	We enable generation of factorization-based methods under multi-participations, which enables us to achieve new SOTA results in private training without amplification.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|multiepoch_matrix_factorization_mechanisms_for_private_machine_learning	/pdf/0bc9d3d8897258b69c0cd3a474c57e7d6ec89788.pdf
jCdoLxMZxf	3361	Copula Conformal Prediction for Multi-step Time Series Forecasting	['Conformal Prediction', 'time series', 'uncertainty quantification', 'calibration', 'RNN']	significantly improve efficiency/sharpness of conformal prediction confidence intervals, for time series forecasting, by modeling dependence of time steps using copulas	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|copula_conformal_prediction_for_multistep_time_series_forecasting	/pdf/c872a9dc977bc8755384ed91cd9ce4fbab3b35cb.pdf
EW00yKKLiX	3362	K-SAM: Sharpness-Aware Minimization at the Speed of SGD	['deep learning', 'efficient training']	We propose an efficient sharpness-aware minimization by subsampling training data with highest k losses in both gradient calculation steps.	Deep Learning and representational learning	anonymous|ksam_sharpnessaware_minimization_at_the_speed_of_sgd	/pdf/a7b09f0448c059b3d9b9f831422e277a835829d5.pdf
vKEMum01xu	3363	Learning Unsupervised Forward Models from Object Keypoints	[]		Unsupervised and Self-supervised learning	anonymous|learning_unsupervised_forward_models_from_object_keypoints	/pdf/de39196c048041462f7e3ea0aa29c401e3106e56.pdf
AjC0KBjiMu	3364	Contrastive Learning Can Find An Optimal Basis For Approximately View-Invariant Functions	['contrastive learning', 'self-supervised learning', 'representation learning', 'kernel', 'kernel PCA', 'positive definite', 'eigenfunction', 'spectral clustering', 'invariance', 'Markov chain', 'minimax optimal']	"We show that existing contrastive objectives approximate a ""positive-pair kernel"", and that applying Kernel PCA produces a representation that is provably optimal for supervised learning of functions that assign similar values to positive pairs."	Unsupervised and Self-supervised learning	anonymous|contrastive_learning_can_find_an_optimal_basis_for_approximately_viewinvariant_functions	/pdf/74d0a1da78605856444f9bfc882bca792e11dc30.pdf
c0UQacrBmFB	3366	Transfer Learning with Context-aware Feature Compensation	[]		Deep Learning and representational learning	anonymous|transfer_learning_with_contextaware_feature_compensation	/pdf/91ab6fdfe6335a64307e55f0b3f45990de8d51f2.pdf
yC8PKpNl4f	3367	AlphaDesign: A graph protein design method and benchmark on AlphaFold DB	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|alphadesign_a_graph_protein_design_method_and_benchmark_on_alphafold_db	/pdf/d1cdb0f1144f5de2f166b078147bede7296f75fd.pdf
jClGv3Qjhb	3368	A Theoretical Understanding of Vision Transformers: Learning, Generalization, and Sample Complexity	['Vision transformer', 'Learning', 'Generalization', 'Sample comeplxity', 'Token sparsification', 'Theory']	A theoretical characterization of generalization and sample complexity of training three-layer Vision Transformers.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_theoretical_understanding_of_vision_transformers_learning_generalization_and_sample_complexity	/pdf/e1f5563d9d94ab64f0c61d9f417b002148c9a816.pdf
oMsN9TYwJ0j	3370	PiFold: Toward effective and efficient protein inverse folding	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pifold_toward_effective_and_efficient_protein_inverse_folding	/pdf/0ad8f2fafb83e7c1b1b5c3234b15fd30f7e3df18.pdf
wtr-9AKxCI5	3372	MobileViTv3: Mobile-Friendly Vision Transformer with Simple and Effective Fusion of Local, Global and Input Features	['Deep Learning', 'Vision Transformers', 'Convolutional Neural Networks', 'Mobile Vision Transformers', 'Light-weight neural network']	Mobile-Friendly Vision Transformer with Simple and Effective Fusion of Local, Global and Input Features	Applications (eg, speech processing, computer vision, NLP)	anonymous|mobilevitv3_mobilefriendly_vision_transformer_with_simple_and_effective_fusion_of_local_global_and_input_features	/pdf/078627da3a27069da9c589496c84a81592d0e450.pdf
N7Tv4aZ4Cyx	3373	SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks	[]		Deep Learning and representational learning	anonymous|sgd_and_weight_decay_provably_induce_a_lowrank_bias_in_neural_networks	/pdf/c24029cc804db4275f93cef93be5f36179e5958c.pdf
OmpIgSvg7-Z	3375	Prometheus: Endowing Low Sample and Communication Complexities to Constrained Decentralized Stochastic Bilevel Learning	[]		Optimization (eg, convex and non-convex optimization)	anonymous|prometheus_endowing_low_sample_and_communication_complexities_to_constrained_decentralized_stochastic_bilevel_learning	/pdf/c68078d215241e4cc8910d96b27317604e94ca37.pdf
MJSIkA72S4k	3376	On the Implicit Bias Towards Depth Minimization in Deep Neural Networks	[]		Deep Learning and representational learning	anonymous|on_the_implicit_bias_towards_depth_minimization_in_deep_neural_networks	/pdf/4fbc54a7fe37c5c5c5fe6a104eb619a749878fa8.pdf
4dsIu9DOFNB	3378	Generating Features with Increased Crop-Related Diversity for Few-shot Object Detection	['Few-shot Object Detection']	We transform the latent space such that the latent norm represents a data property, allowing controllable feature generation. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|generating_features_with_increased_croprelated_diversity_for_fewshot_object_detection	/pdf/85c5cbfd35c6212934fdfa7c13bd5ed2e792c0fe.pdf
8-aqFHleFyC	3379	On $\mathcal{O}(1/K)$ Convergence and Low Sample Complexity for Single-Timescale Policy Evaluation with Nonlinear Function Approximation	[]		Optimization (eg, convex and non-convex optimization)	anonymous|on_\mathcalo1k_convergence_and_low_sample_complexity_for_singletimescale_policy_evaluation_with_nonlinear_function_approximation	/pdf/d613dd271b78c9d9d27c20f5db79049b274281c0.pdf
5wa-ueGGI33	3380	Shortcut Learning Through the Lens of Early Training Dynamics	['shortcut learning', 'spurious correlations', 'convolutional neural networks', 'deep learning', 'machine learning', 'computer vision', 'training dynamics']	Potential shortcuts can be found by monitoring the easy features learned by the initial layers of a DNN early during the training using suitable instance difficulty metrics.	General Machine Learning (ie none of the above)	anonymous|shortcut_learning_through_the_lens_of_early_training_dynamics	/pdf/2db9fd2aba6633f82b915365d06466dc900b92e2.pdf
lRXSMYJtXwT	3381	MET : Masked Encoding for Tabular data	['Tabular Data', 'Self Supervised Learning', 'Masked Auto-Encoder']	Masking based algorithm for SSL on tabular datasets. Key idea: there exists a latent graphical model that captures relations between different coordinates and classification in latent space is easy. Masking based SSL learns this latent structure.	Unsupervised and Self-supervised learning	anonymous|met_masked_encoding_for_tabular_data	/pdf/17c2c8e83791ac65d426875ee1f36623c75de04d.pdf
vPS7yxt6oNE	3382	Goal-Space Planning with Subgoal Models	['Reinforcement Learning', 'Model-Based Reinforcement Learning', 'Planning', 'Temporal Abstraction']	A new approach to model-based RL where planning operates in an abstract subgoal space	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|goalspace_planning_with_subgoal_models	/pdf/de6517e8204b7209eac34fff660445b1664302a7.pdf
EKdBD-1qHW6	3383	Implicit regularization via Spectral Neural Networks and non-linear matrix sensing	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|implicit_regularization_via_spectral_neural_networks_and_nonlinear_matrix_sensing	/pdf/ecc6cc24e626e4d3a817f2581c49af679d0fec4c.pdf
hlwmtSw5KC	3384	On the Mysterious Optimization Geometry of Deep Neural Networks	['deep learning', 'optimization geometry', 'nonconvex optimization']	Reveal a mysterious type of geometry in deep learning optimization.	Optimization (eg, convex and non-convex optimization)	anonymous|on_the_mysterious_optimization_geometry_of_deep_neural_networks	/pdf/5fe10eac1fe9cb9390bca4812bd2f173551d077b.pdf
cVEOiBz2Em	3385	Deep Bayesian Active Learning for Accelerating Stochastic Simulation	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|deep_bayesian_active_learning_for_accelerating_stochastic_simulation	/pdf/54de46261cdf6f4f56c45c1006f3547ce081ba12.pdf
9XFSbDPmdW	3386	Progress measures for grokking via mechanistic interpretability	['interpretability', 'grokking', 'progress measures', 'mechanistic interpretability', 'circuits']	We fully reverse engineer how one-layer transformers implement modular addition, and use this knowledge to explain grokking. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|progress_measures_for_grokking_via_mechanistic_interpretability	/pdf/f0a9276e2e2685e5875a8b2201f8f06d755d3626.pdf
g_H6fj4OGZ	3387	Thrust: Adaptively Propels Large Language Models with External Knowledge	['knowledge-intensive natural language processing', 'pre-trained language models', 'instance-level adaptive knowledge usage']	We design a novel metric, Thrust, that can decide if we use external knowledge for each instance and observe significant improvement on both cost-efficiency and performance for various knowledge-intensive natural language processing tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|thrust_adaptively_propels_large_language_models_with_external_knowledge	/pdf/cfdea847a9327360f11b6dd2094e8d221a545ea9.pdf
cw8FeirkIfU	3388	Distributed Differential Privacy in Multi-Armed Bandits	['Multi-armed Bandits', 'Differential Privacy']	We achieve pure DP for the first time in the distributed trust model while maintaining the same regret under the central model	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|distributed_differential_privacy_in_multiarmed_bandits	/pdf/918f767e2eaa0ed245836e4c8638c3ada803176a.pdf
9Jaz4APHtWD	3389	Link Prediction with Non-Contrastive Learning	['graph learning', 'graph neural networks', 'non-contrastive learning', 'link prediction']	We evaluate the performance of non-contrastive methods on link prediction and propose a new method to improve its performance in the inductive setting.	Unsupervised and Self-supervised learning	anonymous|link_prediction_with_noncontrastive_learning	/pdf/d04fd0b92843abdd4f62542cdc79e52c0696783b.pdf
locB7rYBzTw	3390	Fast Adaptation via Human Diagnosis of Task Distribution Shift	['human-ai interaction', 'human-in-the-loop']	We develop a human-in-the-loop framework to help humans diagnose and fix goal-conditioned policy failures.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fast_adaptation_via_human_diagnosis_of_task_distribution_shift	/pdf/98e6e571a7908569017dd119ace1ffca1f97a006.pdf
4bH8SxYNcI	3391	Towards Adversarially Robust Deepfake Detection: An Ensemble Approach	['Deepfakes', 'Ensembles', 'Adversarial Subspace', 'Frequency', 'Defense']	We present - Disjoint Deepfake Detection (D3), an ensemble based technique for deepfake detection and provide theoretical and empirical evidence for it's robustness.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_adversarially_robust_deepfake_detection_an_ensemble_approach	/pdf/83901a0d02c93bd0d096a81443bd5b1ccc5e4786.pdf
Qd0p0bl-A9t	3392	Provably Efficient Lifelong Reinforcement Learning with Linear Representation	['Lifelong RL', 'Contextual MDP', 'Regret', 'Planning calls', 'Computation sharing', 'Streaming sequence of adversarial tasks']	We study lifelong RL, where the agent needs to solve a streaming sequence of tasks. We propose an algorithm with provable sublinear regret using sublinear number of planning calls for any sequence of tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|provably_efficient_lifelong_reinforcement_learning_with_linear_representation	/pdf/1bcfea0b6dd167a9bca6ccbf1a86fa28be73e0ee.pdf
xYNOuQh1Z7Y	3393	Magnum: Tackling High-Dimensional Structures with Self-Organization	['self-organization', 'chunking', 'time-series data']		General Machine Learning (ie none of the above)	anonymous|magnum_tackling_highdimensional_structures_with_selforganization	/pdf/e507f545a3a116d5d31af5a9414b3c0e1c4b1b48.pdf
lXBzOtKn20t	3394	BiViT: Exploring Binary Vision Transformers	['quantization', 'binary quantization', 'vision transformer', 'distillation', 'classification', 'imagenet']	We introduce BiViT, a the first fully binary quantized binary vision transformer with both 1-bit weights and activations.	Deep Learning and representational learning	anonymous|bivit_exploring_binary_vision_transformers	/pdf/0c425cf42524b9f49aaf3fca2a250dc2c5768512.pdf
XSEBx0iSjFQ	3396	Re-Imagen: Retrieval-Augmented Text-to-Image Generator	['Diffusion Model', 'Information Retrieval', 'Knowledge Grounding', 'Image Generation']	A text-to-image generation model that can retrieve from external knowledge base to generate more faithful images.	Applications (eg, speech processing, computer vision, NLP)	anonymous|reimagen_retrievalaugmented_texttoimage_generator	/pdf/cbe587cb2d5b0379367f0ccef0d71390de3e4607.pdf
jpsw-KuOi7r	3397	Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs	['Reward Free Exploration', 'Representation Learning', 'Sample Complexity', 'Model-Based RL']	We propose a novel reward free reinforcement learning algorithm under low-rank MDPs, which improves the sample complexity of previous work. We also provide a lower bound. Finally we study representation learning via reward free reinforement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|improved_sample_complexity_for_rewardfree_reinforcement_learning_under_lowrank_mdps	/pdf/74400ba8797cbb8649649f6f2267e68391b23897.pdf
ZKEhS93FjhR	3399	What Deep Representations Should We Learn? -- A Neural Collapse Perspective	['representation learning', 'neural collapse', 'transfer learning']	n/a	Deep Learning and representational learning	anonymous|what_deep_representations_should_we_learn_a_neural_collapse_perspective	/pdf/d2dd6b007c0d68f5abf8c9ec63d2969da0acac99.pdf
4j7TG4gD_RM	3400	Trusted Aggregation (TAG): Model Filtering Backdoor Defense In Federated Learning	['federated learning', 'backdoor attack', 'robust aggregation']	TAG is a novel defense against Backdoor Attacks in Federated Learning	Deep Learning and representational learning	anonymous|trusted_aggregation_tag_model_filtering_backdoor_defense_in_federated_learning	/pdf/c6549c8b846b42dc80a3dabf04f9d992e8bb5344.pdf
TTLLGx3eet	3403	Sequential Attention for Feature Selection	['feature selection', 'attention']	Sequential feature selection using the attention mechanism, with provable guarantees.	General Machine Learning (ie none of the above)	anonymous|sequential_attention_for_feature_selection	/pdf/8e5512ff9e053af68a21fbc2175088f12ccfbccd.pdf
em4xg1Gvxa	3405	Overthinking the Truth: Understanding how Language Models process False Demonstrations	['Large Language Models', 'Interpretability', 'Safety', 'Mechanistic Interpretability', 'Science of ML']		Deep Learning and representational learning	anonymous|overthinking_the_truth_understanding_how_language_models_process_false_demonstrations	/pdf/14ed7a84b8aeafc7fdc995ce149d44d21ddb786d.pdf
k7qRYoxUlB	3406	Structural Code Representation Learning for Auto-Vectorization	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|structural_code_representation_learning_for_autovectorization	/pdf/9961a38b203df00af1136bfabf76e165f8cffc34.pdf
Vo1MVffQED	3407	Oracles and Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning	['Multi-Agent Reinforcement Learning', 'Game Theory', 'Security Games', 'Mechanism Design', 'Stackelberg Equilibrium', 'Indirect Mechanism Design']	We show a general framework for learning Stackelberg Equilibrian in multi-agent reinforcement learning	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|oracles_and_followers_stackelberg_equilibria_in_deep_multiagent_reinforcement_learning	/pdf/a2804222e3ada84a89a66f17d6cbddacc6c14ff7.pdf
hw4XagZJuw	3408	Seq2Seq Pre-training with Dual-channel Recombination for Translation	['neural machine translation', 'transformer', 'sequence to sequence pre-training']		Applications (eg, speech processing, computer vision, NLP)	anonymous|seq2seq_pretraining_with_dualchannel_recombination_for_translation	/pdf/58c9692f2ba1ce7abc6de05b1b39c59690f2bc52.pdf
LE5LxBgjB4V	3409	Disentangling the Mechanisms Behind Implicit Regularization in SGD	['deep learning', 'generalization', 'implicit regularization', 'sgd']		General Machine Learning (ie none of the above)	anonymous|disentangling_the_mechanisms_behind_implicit_regularization_in_sgd	/pdf/c3250e9485f84245f3840f336b95c0fd0f053684.pdf
pNZkow3k3BH	3410	Attention-Guided Backdoor Attacks against Transformers	['Natural Language Processing', 'Transformer', 'Backdoor Attack', 'Trojan Attack', 'Trojan Attention Loss']	We propose a novel Trojan Attention Loss, which enhances the Trojan behavior by directly manipulating the attention pattern.	Applications (eg, speech processing, computer vision, NLP)	anonymous|attentionguided_backdoor_attacks_against_transformers	/pdf/76f7cb06d26c5f129f491c825facd702bb12a2c8.pdf
pKRYZpCDr-p	3411	Node Importance Specific Meta Learning in Graph Neural Networks	['Meta Learning', 'Graph Neural Network', 'Node Importance']	This paper focuses on the few-shot node classification problem in graph; theoretically studies the influence of node importance on the model accuracy and proposes a node importance calculation method to implement on meta learning GNNs.	Deep Learning and representational learning	anonymous|node_importance_specific_meta_learning_in_graph_neural_networks	/pdf/c41aa2a9391beb9535a9d9968bb900208b171049.pdf
dCOL0inGl3e	3412	Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication	['certifiable robustness', 'reinforcement learning', 'multi-agent system', 'adversarial communication', 'adversarial attack']	We propose a defense method such that an agent receiving communication in an multi-agent system can be certifiably robust when a subset of communication messages get (arbitrarily) perturbed.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|certifiably_robust_policy_learning_against_adversarial_multiagent_communication	/pdf/6a1a23ff0ffdfe00362b991afadc0c2bf8074742.pdf
g4RxrIB52M9	3413	Unleashing the Potential of Data Sharing in Ensemble Deep Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|unleashing_the_potential_of_data_sharing_in_ensemble_deep_reinforcement_learning	/pdf/7016a1f6073553be11bb24d878cdba7c751de708.pdf
ymt1zQXBDiF	3414	SoftMatch: Addressing the Quantity-Quality Tradeoff in Semi-supervised Learning	['Semi-Supervised Learning', 'Semi-Supervised Classification']	This paper revisit the quantity-quality tradeoff with a unified sample weighting function of pseudo-labeling/consistency loss. From the analysis, we propose SoftMatch, which better utilizes unlabeled data while reducing the enrolled error rate. 	Deep Learning and representational learning	anonymous|softmatch_addressing_the_quantityquality_tradeoff_in_semisupervised_learning	/pdf/c3600c5b156257866f1caf2f15a7df5286a3ea5e.pdf
c-h2XSi-vEM	3415	On the Importance of Calibration in Semi-supervised Learning	[]	We propose a family of new methods that optimize for calibration in semi-supervised learning and demonstrate improvements on popular vision benchmarks and on real-world applications.	Deep Learning and representational learning	anonymous|on_the_importance_of_calibration_in_semisupervised_learning	/pdf/e36c93241d0696313bdbdae300235e91171e780a.pdf
baRatYtGBXp	3416	BAT-Chain: Bayesian-Aware Transport Chain for Topic Hierarchies Discovery	['Topic modeling', 'hierarchical representation', 'optimal transport', 'conditional transport', 'concept learning']	We in this paper propose a novel model to mine hierarchical topics and document representation under the conditional transport framework	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|batchain_bayesianaware_transport_chain_for_topic_hierarchies_discovery	/pdf/b0677366938a3f1e15fbb63a6527252a8cc1ae88.pdf
Ix4Ytiwor4U	3417	DITTO: Offline Imitation Learning with World Models	['world models', 'imitation learning', 'reinforcement learning']	Completely offline imitation learning with world models, using RL on a latent matching objective in the model.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|ditto_offline_imitation_learning_with_world_models	/pdf/4e9cc020531739a8ef0c02ebaf35588cb6ced3da.pdf
fYzLpCsGZVf	3419	On Accelerated Perceptrons and Beyond	['Perceptron', 'game', 'optimistic online learning', 'implicit bias', 'margin maximization']	We provide a unified analysis for accelerated Perceptrons, and obtain improved results for a series of other problems.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_accelerated_perceptrons_and_beyond	/pdf/551013ad16850145700df98c3af1f8e10a703041.pdf
FBMLeaXpZN	3420	Spectral Decomposition Representation for Reinforcement Learning	['Spectral Representation', 'Markov Decision Processes', 'Reinforcement Learning']	We propose a new spectral representation learning method that gets rid of the policy dependency and can be easily applied in downstream tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|spectral_decomposition_representation_for_reinforcement_learning	/pdf/de7c68290180305341e784ac24a5d4627a23d95f.pdf
ZA_F5AU-byh	3421	Towards Class-Balanced Transductive Few-Shot Learning	['Few-shot classification', 'Transductive learning', 'Class-imbalanced Prediction']	We develop transductive fine-tuning with margin-based uncertainty weighting and class-balanced normalization to tackle the issue of class imbalanced predictions in few-shot learning.	Deep Learning and representational learning	anonymous|towards_classbalanced_transductive_fewshot_learning	/pdf/ebd4cf979cb284eea4d9c154d9732c72363b0cf3.pdf
sOXU-PEJSgQ	3422	Confidence Estimation Using Unlabeled Data	[]		Deep Learning and representational learning	anonymous|confidence_estimation_using_unlabeled_data	/pdf/0fb8bbdaeabf9978fede9507238d427d600ea0e6.pdf
kPL4YzdDqWE	3423	Training image classifiers using Semi-Weak Label Data	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|training_image_classifiers_using_semiweak_label_data	/pdf/78a9f373d0561d9e03a2e9ce9206c1c2085d4555.pdf
XUqTyU9VlWp	3424	The Impact of Neighborhood Distribution in Graph Convolutional Networks	['Graph convolutional networks', 'graph neural networks', 'homophily', 'heterophily']	We find the distinguishability of neighborhood distribution plays a more important role in the performance of GCN than homophily and propose GCN-PND to promote neighborhood distinguishability.	Deep Learning and representational learning	anonymous|the_impact_of_neighborhood_distribution_in_graph_convolutional_networks	/pdf/8fd4c69d76ca7f37591511be421c69e032e615c7.pdf
PDrUPTXJI_A	3426	FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning	['Semi-Supervised Learning', 'Semi-Supervised Classification']	We propose FreeMatch to define and adjust the confidence threshold in a self-adaptive manner for semi-supervised learning.	Deep Learning and representational learning	anonymous|freematch_selfadaptive_thresholding_for_semisupervised_learning	/pdf/9f6a48f9bd9009b8e4c02baf81a7c1e46198979c.pdf
9RDD2hefT94	3428	An interpretable contrastive logical knowledge learning method for sentiment analysis	['interpretable sentiment analysis', 'Talmudic public announcement logic', 'contrastive logical knowledge learning', 'knowledge reasoning']	We present a novel contrastive logical knowledge learning (CLK) method to learn interpretable TPK models and generate explanations for sentiment analysis tasks. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|an_interpretable_contrastive_logical_knowledge_learning_method_for_sentiment_analysis	/pdf/e059332bea624f15cec279680685b35ec8a5c6bb.pdf
AR4rOT4sECN	3430	Offline RL of the Underlying MDP from Heterogeneous Data Sources	['RL Theory', 'Offline RL', 'Underlying MDP', 'Heterogeneous Data Sources', 'Provable Efficiency']	This work investigated the problem of learning an underlying MDP with offline datasets from heterogeneous sources and proposed several provably efficient designs.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_rl_of_the_underlying_mdp_from_heterogeneous_data_sources	/pdf/982623cda47fdff9bad78c8e18640b68460e7780.pdf
DSKD610FRN1	3431	Decentralized Federated Learning via Overlapping Data Augmentation	['federated learning', 'personalized federated learning', 'decentralized federated learning']	This paper studies the scenario of selective partial sharing in federated learning.	Deep Learning and representational learning	anonymous|decentralized_federated_learning_via_overlapping_data_augmentation	/pdf/ccaf3c1e3740c57caa3705d1223fbb86e589d6c6.pdf
sxLL8K3E39G	3432	Block-Diagonal Structure Learning for Subspace Clustering	[]		Unsupervised and Self-supervised learning	anonymous|blockdiagonal_structure_learning_for_subspace_clustering	/pdf/ce4815d3ad024d34c41186a179f590d2f6e16cf1.pdf
tWOoSXyW0KE	3433	A Novel Fast Exact Subproblem Solver for Stochastic Quasi-Newton Cubic Regularized Optimization	['optimization', 'quasi-newton']		Optimization (eg, convex and non-convex optimization)	anonymous|a_novel_fast_exact_subproblem_solver_for_stochastic_quasinewton_cubic_regularized_optimization	/pdf/cc0efa69a8f5fcef239a3ac80a5d0a05bb55e8d3.pdf
bWhEJ0lF5L9	3435	Graph Contrastive Learning with Reinforced Augmentation	['Graph contrastive learning', 'graph neural network', 'graph classification', 'reinforcement learning']	In this paper, we design a novel GA2C model making the augmented views evolves well to energize graph contrastive learning and outperforms the SOTA methods..	Unsupervised and Self-supervised learning	anonymous|graph_contrastive_learning_with_reinforced_augmentation	/pdf/af80cefd3d89ea329e1e1f92b5d7fd41d8baa12e.pdf
O-G91-4cMdv	3436	Words are all you need? Language as an approximation for representational similarity	['cognitive science', 'language', 'perception', 'representational similarity']	We show that machine embeddings of text descriptions can predict human similarity judgments better than models trained from images, audio and video.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|words_are_all_you_need_language_as_an_approximation_for_representational_similarity	/pdf/6d6f78adb56beade64d47a7438fe313da2744e01.pdf
XOl_9AU0EV	3438	Spatial reasoning as Object Graph Energy Minimization	['Energy Based Model', 'Robotics', 'Goal Generation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|spatial_reasoning_as_object_graph_energy_minimization	/pdf/7e5c6b305364cf7aecac4dbc2f5ada1182b1fd1d.pdf
2r6YMqz4Mml	3439	ROCO: A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs	['Combinatorial Optimization', 'Robustness', 'Graph Neural Networks', 'Reinforcement Learning']		Optimization (eg, convex and non-convex optimization)	anonymous|roco_a_general_framework_for_evaluating_robustness_of_combinatorial_optimization_solvers_on_graphs	/pdf/cd02000658a4374b789dd7d967ef156105625e80.pdf
kLvYYV-YK_j	3440	RLSBench: A Large-Scale Empirical Study of Domain Adaptation Under Relaxed Label Shift	['domain adaptation', 'distribution shift', 'label shift', 'large scale study']	A large scale study of popular domain adaptation methods under scenarios where both label distribution and conditionals p(x|y) may shift, highlights brittleness of existing methods and simple fixes that improves the performance.	General Machine Learning (ie none of the above)	anonymous|rlsbench_a_largescale_empirical_study_of_domain_adaptation_under_relaxed_label_shift	/pdf/a73305e430d3fdeddb05f0dd7cd40056d6f9dfaf.pdf
pQL-sBfD4I	3441	Precision Collaboration for Federated Learning	['federated learning', 'personalized federated learning']	This paper investigates a precision collaboration mechanism for federated learning.	Deep Learning and representational learning	anonymous|precision_collaboration_for_federated_learning	/pdf/e79777ce1a7a095e8cce28ac61e2e27946a81ff5.pdf
pzH2Sltp2--	3442	Look in The Mirror: Molecular Graph Contrastive Learning with Line Graph	[]		Unsupervised and Self-supervised learning	anonymous|look_in_the_mirror_molecular_graph_contrastive_learning_with_line_graph	/pdf/fa6acc2f5b2f69a5f39ebbc46665326e3f656bdf.pdf
mQpmZVzXK1h	3443	Latent Variable Representation for Reinforcement Learning	['Latent Variable Model', 'Markov Decision Processes', 'Reinforcement Learning']	We show how the latent variable model can be used for representation learning in reinforcement learning, that can have superior empirical performance as well as complete sample complexity analysis.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|latent_variable_representation_for_reinforcement_learning	/pdf/7578852961d32dd22abf0212c7f1777a3d0f0c22.pdf
R1U5G2spbLd	3444	Federated Nearest Neighbor Machine Translation	['Machine Translation', 'Federated Learning', 'Memorization Augmentation']	We propose a novel federated nearest neighbor machine translation framework to build low-overhead privacy-preserving MT systems in FL settings.	Applications (eg, speech processing, computer vision, NLP)	anonymous|federated_nearest_neighbor_machine_translation	/pdf/beedc997432016efafcb4f6df047ccff956579b5.pdf
lyjMArzIxH6	3445	CAREER: Transfer Learning for Economic Prediction of Labor Data	['economics', 'transfer learning']	We develop CAREER, a transformer-based model of job sequence data, which is pretrained on large resume datasets and fine-tuned to survey datasets widely used by labor economists.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|career_transfer_learning_for_economic_prediction_of_labor_data	/pdf/fa1b23d30bcd547cae28c576fbdbae8f8e89f062.pdf
pmUH7A8wZz	3448	Autoencoding Hyperbolic Representation for Adversarial Generation	['deep learning', 'hyperbolic neural network', 'numerical stability', 'generative models']	A hyperbolic generative network numerically stable for generating complex data.	Deep Learning and representational learning	anonymous|autoencoding_hyperbolic_representation_for_adversarial_generation	/pdf/85963453fb2c66b6152beca95101a417ab1b3c27.pdf
SJ0Lde3tRL	3449	Extreme Q-Learning: MaxEnt RL without Entropy	['reinforcement learning', 'offline reinforcement learning', 'statistical learning', 'extreme value analysis', 'maximum entropy rl', 'gumbel']	Introduce a novel framework for Q-learning that models the maximal soft-values without needing to sample from a policy and reaches SOTA performance on online and offline RL settings.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|extreme_qlearning_maxent_rl_without_entropy	/pdf/fc3eac2a082ca2fe5f4836ae0faa0d5a74c87fe9.pdf
NQuCQoHqqSY	3450	Temporally Consistent Video Transformer for Long-Term Video Prediction	['video generation', 'video prediction', 'generative modeling', 'latent dynamics models']	An efficient temporally consistent video prediction model able to generate long videos referencing hundreds of frames of past context in complex 3D environments and Kinetics-600.	Generative models	anonymous|temporally_consistent_video_transformer_for_longterm_video_prediction	/pdf/30089f8b41542472d011ef07db33cdbbb93e6812.pdf
UqmL1Oc4bCw	3451	A comparison of dataset distillation and active learning in text classification	['knowledge distillation', 'dataset distillation', 'active learning', 'text classification']		Applications (eg, speech processing, computer vision, NLP)	anonymous|a_comparison_of_dataset_distillation_and_active_learning_in_text_classification	/pdf/f996beb8789514f15e6b816c10d160e7dcb648da.pdf
fI3y_Dajlca	3452	Time-Transformer AAE: Connecting Temporal Convolutional Networks and Transformer for Time Series Generation	['Time Series Generation', 'Adversarial Autoencoder', 'Temporal Convolutional Networks', 'Transformer']	A novel time series generative model, bridging Temporal Convolutional Networks and Transformer via a layer-wise parallel structure	Generative models	anonymous|timetransformer_aae_connecting_temporal_convolutional_networks_and_transformer_for_time_series_generation	/pdf/9f2fbb5e0b5ea9cb43a67ada9fda57ecea2ac83d.pdf
hPdMskOKGX6	3453	Effectively Clarify Confusion via Visualized Aggregation and Separation of Deep Representation	['Data Insufficiency', 'Class Imbalance', 'Evidience Unclearity', 'Confusion', 'Representation Learning']		Deep Learning and representational learning	anonymous|effectively_clarify_confusion_via_visualized_aggregation_and_separation_of_deep_representation	/pdf/9f76eaf0a8c626fe925d489a6f277b1866bcc786.pdf
7D5EECbOaf9	3454	Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning	[]		Deep Learning and representational learning	anonymous|moderate_coreset_a_universal_method_of_data_selection_for_realworld_dataefficient_deep_learning	/pdf/3aae96986e89a570f508e557908de537aabe9630.pdf
--qiQPsCV94	3455	Unsupervised Manifold Linearizing and Clustering	['Clustering', 'Manifold Embedding', 'Manifold Clustering']		Deep Learning and representational learning	anonymous|unsupervised_manifold_linearizing_and_clustering	/pdf/f8ba98d6fc8dd7ddf61063058a83031739017690.pdf
8VvQ4SpvZVi	3456	Dual personalization for federated recommendation on devices	['federated learning', 'personalization', 'recommmendation system']		General Machine Learning (ie none of the above)	anonymous|dual_personalization_for_federated_recommendation_on_devices	/pdf/da08a3aef1543f8af8b1c0002d91cff114af6114.pdf
iMy1hOrqiVE	3457	Exclusive Supermask Subnetwork Training for Continual Learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|exclusive_supermask_subnetwork_training_for_continual_learning	/pdf/724ca35397daaea3bfc3a4f1ab3ea0ac83411159.pdf
YP4QEmqh6Ia	3458	Which Invariance Should We Transfer? A Causal Minimax Learning Approach	['robustness', 'minimax', 'subset selection', 'causal model', 'g-equivalence']	This paper proposes to identify the optimal subset of invariance to transfer, in order to achieve robustness in supervised regression scenario.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|which_invariance_should_we_transfer_a_causal_minimax_learning_approach	/pdf/ecb8eb06b64ee0d4374ddf3087e5b2b16d5f3926.pdf
aCCRmE3Pglv	3459	Energy-based Predictive Representation for Reinforcement Learning	['Energy-based Models', 'Predictive State Representation', 'Partially Observable Markov Decision Process', 'Reinforcement Learning']	We propose a novel predictive state representation with energy-based models, that shows superior performance on POMDPs.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|energybased_predictive_representation_for_reinforcement_learning	/pdf/cd54eb1f885125e291f889b1d9351e3de4eee92e.pdf
1DOS0kifqeP	3460	Eigen Memory Trees	['Episodic Memory', 'Contextual Bandits', 'Sequential Learning']	We create an episodic memory model for online learning and evaluate it for solving contextual bandit problems. 	General Machine Learning (ie none of the above)	anonymous|eigen_memory_trees	/pdf/154b9abe730f678c40d7226d7cb9eebbcc0aebf2.pdf
bvwZ43dY2xj	3461	Rethinking Identity in Knowledge Graph  Embedding	['Knowledge Graph Embedding', 'Knowledge Graph Completion', 'Bilinear Based Models']	We scrutinize the identity relation in knowledge graphs, find that bilinear based models fail to uniquely model it, and propose a solution with other good properties.	Deep Learning and representational learning	anonymous|rethinking_identity_in_knowledge_graph_embedding	/pdf/bd2bdee04c6c2146326ca3e1e090934027d056fb.pdf
J3_WcZW3oV1	3462	Dataset Projection: Finding Target-aligned Subsets of Auxiliary Data	['datasets', 'auxiliary data', 'dataset projection']	We project datasets to find subsets of auxiliary datasets that are most aligned with a target dataset.	General Machine Learning (ie none of the above)	anonymous|dataset_projection_finding_targetaligned_subsets_of_auxiliary_data	/pdf/31ca15c5c848669d77990aa8da259dddb771dcce.pdf
10tgIzcC2vY	3464	Upcycled-FL: Improving Accuracy and Privacy with Less Computation in Federated Learning	['Federated Learning', 'Differential Privacy']	We propose a federated learning framework that improves accuracy-privacy tradeoff with less computation.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|upcycledfl_improving_accuracy_and_privacy_with_less_computation_in_federated_learning	/pdf/1dfc9f0e145a08b1ef7f16f4f15e881a232c855b.pdf
ml8_xBoTnVA	3465	On Assimilating Learned Views in Contrastive Learning	['Contrastive Learning', 'Self-Supervised Learning', 'Generative Models', 'Mutual Information']		Unsupervised and Self-supervised learning	anonymous|on_assimilating_learned_views_in_contrastive_learning	/pdf/c32e2d536b3de5c04a2023a82d6f830136ee5cbf.pdf
IAIrNRktVWR	3466	Multimedia Generative Script Learning for Task Planning	['multimedia generative script learning', 'contrastive learning', 'retrieval-augmented generation', 'selective multimedia encoding', 'procedure planning']	We introduce a new multimedia generative script learning task with a new benchmark; novel visually trackable, inductive, diverse script learning methods; and a new multimodal-retrieval-based metric.	Applications (eg, speech processing, computer vision, NLP)	anonymous|multimedia_generative_script_learning_for_task_planning	/pdf/7018838bc73c60059e37e30bbdd0484028b343ae.pdf
rmU3K_ekONM	3468	SplitMixer: Fat Trimmed From MLP-like Models	['deep learning architectures', 'MLP-Mixer', 'model compression', 'visual classification']	We present a simple and lightweight isotropic MLP-like architecture, for visual recognition that performs on par with existing models but much less computation.	Deep Learning and representational learning	anonymous|splitmixer_fat_trimmed_from_mlplike_models	/pdf/24f7afbb6e02b902907869ceafa54d46c573277d.pdf
QcTbkoBycwk	3469	Efficient Shapley Values Estimation by Amortization for Text Classification	['text classification', 'model interpretation', 'amortization']	We recognize the stability issue in model interpretation for text classifier and propose an amortized approach to generate stable interpretation efficiently.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|efficient_shapley_values_estimation_by_amortization_for_text_classification	/pdf/5b8dd9a716cf9f708eac03a23e3382587f4bef26.pdf
q0nmYciuuZN	3472	Learning on Large-scale Text-attributed Graphs via Variational Inference	['Language Model', 'Graph Neural Network', 'Node Classification']	We propose a GLEM framework to effectively fuse GNN and LM with scalability, SOTA results are achieved on OGB datasets.	Deep Learning and representational learning	anonymous|learning_on_largescale_textattributed_graphs_via_variational_inference	/pdf/db77dae82be6020d6efb666db8a7b32894cf6471.pdf
Ogh8umAChpo	3473	Denoising MCMC for Accelerating Diffusion-Based Generative Models	['Markov Chain Monte Carlo', 'Diffusion Models', 'Score-Based Models']	We combine MCMC and diffusion models to accelerate score-based sampling.	Generative models	anonymous|denoising_mcmc_for_accelerating_diffusionbased_generative_models	/pdf/28ccd9725ee44f056716fe068a038d946c0c4ff8.pdf
k4fevFqSQcX	3475	SAM as an Optimal Relaxation of Bayes	['bayesian deep learning', 'sharpness-aware minimization', 'variational bayes', 'convex duality']	We show that SAM can be seen as a relaxation of Bayes, by using Fenchel conjugates.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|sam_as_an_optimal_relaxation_of_bayes	/pdf/4b869c2f6ee083f2d55ff1a499f347eaef633b62.pdf
-4Z25gkP7Oi	3476	Counterfactual Contrastive Learning for Robust Text Classification	['Contrastive Learning', 'Representation Learning', 'Structural Causal Model']		Deep Learning and representational learning	anonymous|counterfactual_contrastive_learning_for_robust_text_classification	/pdf/19e5c1b1c9bc128ffc50c1f34447d5ef47779ea2.pdf
Su04-8n0ia4	3477	HAS IT REALLY IMPROVED? KNOWLEDGE GRAPH BASED SEPARATION AND FUSION FOR RECOMMENDATION	['recommendation', 'knowledge-graph', 'graph neural network']		Applications (eg, speech processing, computer vision, NLP)	anonymous|has_it_really_improved_knowledge_graph_based_separation_and_fusion_for_recommendation	/pdf/8c7e9f3a0a17ff1a9ff30f06c27dab855d2c98bb.pdf
PY1wvNgwhPC	3478	HSVC: Transformer-based Hierarchical Distillation for Software Vulnerability Classification	['Transformers-based models', 'Knowledge distillation', 'Long-tailed learning', 'Software vulnerability classification']		Deep Learning and representational learning	anonymous|hsvc_transformerbased_hierarchical_distillation_for_software_vulnerability_classification	/pdf/f5cc862e8be7a35fbb9604a18bca0ce4399a8987.pdf
bHpOeIXvSX2	3479	On the Interplay Between Misspecification and Sub-optimality Gap: From Linear Contextual Bandits to Linear MDPs	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_interplay_between_misspecification_and_suboptimality_gap_from_linear_contextual_bandits_to_linear_mdps	/pdf/1d1ec42bbe29bd7e5248faf27a6455e56482a724.pdf
row6cEJ2aBT	3480	Scalable feature selection via sparse learnable masks	['Feature selection', 'mutual information', 'end-to-end learning', 'sparse mask']	SLM is an end-to-end feature selection method using a sparse learnable mask and a novel mutual information maximizer.	Deep Learning and representational learning	anonymous|scalable_feature_selection_via_sparse_learnable_masks	/pdf/63f56734f042ec2234d7957ff1d9b0d39caab3ff.pdf
RsSJ2_M2Nk4	3481	SpaceEvo: Searching Hardware-Friendly Search Space for Efficient Int8 Inference	['Neural Architecture Search', 'Search Space Design', 'INT8 Quantization', 'Edge Hardware']	We introduce techniques to search a quantization-friendly search space for a given device	Deep Learning and representational learning	anonymous|spaceevo_searching_hardwarefriendly_search_space_for_efficient_int8_inference	/pdf/8613aff1fa84a2a38208a827797a9bf0df896954.pdf
HUCgU5EQluN	3483	Effective Self-Supervised Transformers For Sparse Time Series Data	['Representation learning', 'Transformers', 'Sparse Time Series']	We propose a Transformer based model for sparse time series that utilizes an input binning scheme to aggregate the time series inputs.	Deep Learning and representational learning	anonymous|effective_selfsupervised_transformers_for_sparse_time_series_data	/pdf/661daa2c44defe30ae95bf045a844ddbe2b88beb.pdf
3M1JnCdz-5F	3485	Learning to Generate Pseudo Anomalies	['anomaly detection', 'generative model', 'pseudo anomaly', 'autoencoder']	We propose learning mechanism to generate pseudo anomalies for one-class classification in anomaly detection.	Deep Learning and representational learning	anonymous|learning_to_generate_pseudo_anomalies	/pdf/5b31ebc7cc1e9e366d987da08483bfab21b8f071.pdf
HcUf-QwZeFh	3487	Control Graph as Unified IO for Morphology-Task Generalization	['Morphology-Task Generalization', 'Behavior Distillation', 'Supervised RL', 'Reinforcement Learning']	We explore a method for learning a single policy that manipulates various forms of agents to various goal positions by distilling a large amount of proficient behavioral data.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|control_graph_as_unified_io_for_morphologytask_generalization	/pdf/752e0fb72b2b29569bd2a9530516bee143884d22.pdf
w5q6tHO1dl1	3488	Brainformers: Trading Simplicity for Efficiency	[]		Deep Learning and representational learning	anonymous|brainformers_trading_simplicity_for_efficiency	/pdf/6bb88229c7fe6fa12239b37b135cbaf4be0a0415.pdf
balnyoGkYfW	3490	Semi-Supervised Segmentation-Guided Tumor-Aware Generative Adversarial Network for Multi-Modality Brain Tumor Translation	['brain tumor translation', 'multi-modality']	Tumor-aware multi-modality brain tumor translation.	Deep Learning and representational learning	anonymous|semisupervised_segmentationguided_tumoraware_generative_adversarial_network_for_multimodality_brain_tumor_translation	/pdf/060f013f0f867dbbb35bb7d5e2c1f4bbb5130eb0.pdf
VzwfoFyYDga	3491	Machine Unlearning of Federated Clusters	['federated learning', 'federated clustering', 'machine unlearning', 'secure aggregation']	We propose the first known unlearning mechanism for federated clustering with privacy criteria that support simple, provable, and efficient data removal at the client and server level.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|machine_unlearning_of_federated_clusters	/pdf/fbc1f2975df67b2c74fcf76f127ff5bde63b1bea.pdf
YHCR6CFAK6v	3492	Annealed Training for Combinatorial Optimization on Graphs	['combinatorial optimization', 'graph neural networks', 'unsupervised learning', 'simulated annealing']	A simple but effective annealed training framework for unsupervised learning of combinatorial optimization problems over graphs	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|annealed_training_for_combinatorial_optimization_on_graphs	/pdf/b1efff181903a355ff64e29d737cad7a4d4f3aab.pdf
ScEfNWshH3B	3493	Adaptive Weight Decay: On The Fly Weight Decay Tuning for Improving Robustness	['weight decay', 'regularization', 'robust overfitting', 'adversarial robustness', 'noisy label', 'adversarial', 'pruning']	We tune the hyper-parameter for weight decay during each iteration to stabilize training networks with smaller weight-norms which results in more robustness to adversarial examples and label noise, and less sensitivity to choices of learning rate.	Deep Learning and representational learning	anonymous|adaptive_weight_decay_on_the_fly_weight_decay_tuning_for_improving_robustness	/pdf/e382a98b036e118eaa3221b00d5fc33f8ca1a87c.pdf
RvV2xvoML7G	3494	Treatment Effect Estimation with Collider Bias and Confounding Bias	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|treatment_effect_estimation_with_collider_bias_and_confounding_bias	/pdf/6aeaf8d4601f99dd1c57950961c00a82e11beec9.pdf
fzberKYWKsI	3495	An efficient encoder-decoder architecture with top-down attention for speech separation	['encoder-decoder', 'top-down attention', 'speech separation']	We propose an encoder-decoder speech separation structure with top-down attention, which can improve separation efficiency while ensuring the separation performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|an_efficient_encoderdecoder_architecture_with_topdown_attention_for_speech_separation	/pdf/e692576c60a2b6b3bc4f47137849f141430eec90.pdf
5ZarS9RX5I-	3496	Enforcing zero-Hessian in meta-learning	['meta learning', 'Gradient based meta learning', 'GBML', 'kernel gradient descent', 'metric-based learning', 'optimization-based meta-learning']	This paper argues linearity in the inner loop is the key gradient-based meta learning, thereby suggests algorithms which exploits this prior.	Deep Learning and representational learning	anonymous|enforcing_zerohessian_in_metalearning	/pdf/dbccac517c376fc7ab1654d3b052cfaae8cde96a.pdf
5NTt8GFjUHkr	3497	Automatic Chain of Thought Prompting in Large Language Models	['Chain of Thought Prompting', 'Large Language Models', 'In-context Learning', 'Few-shot Learning', 'Arithmetic Reasoning', 'Commonsense Reasoning', 'Symbolic Reasoning.']	We propose an automatic prompting method (Auto-CoT) to elicit chain-of-thought reasoning in large language models without needing manually-designed demonstrations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|automatic_chain_of_thought_prompting_in_large_language_models	/pdf/54920c16820094e0fbc9e791cdee44b6885ed92e.pdf
cHf1DcCwcH3	3498	LipsFormer: Introducing Lipschitz Continuity to Vision Transformers	['Lipschitz Continuity', 'Vision Transformer', 'Transformer']	We propose a Lipschitz continuous Transformer.	Optimization (eg, convex and non-convex optimization)	anonymous|lipsformer_introducing_lipschitz_continuity_to_vision_transformers	/pdf/d7ee93c1a7a0e8bd7c52c9f0949b31d791134424.pdf
TuhR4112Ii	3501	Comparing semantic and morphological analogy completion in word embeddings	['machine learning', 'computational linguistics', 'word embeddings', 'morphemes', 'semantic relationship', 'analogy completion']		Applications (eg, speech processing, computer vision, NLP)	anonymous|comparing_semantic_and_morphological_analogy_completion_in_word_embeddings	/pdf/277d57fd449c753d01c51b9906001315a057b322.pdf
ZTCxT2t2Ru	3503	DocPrompting: Generating Code by Retrieving the Docs	['code generation', 'retrieval-conditioned generation']	We propose to generalize the code generation models to unseen functions and usages through retrieving and reading code documentation	Applications (eg, speech processing, computer vision, NLP)	anonymous|docprompting_generating_code_by_retrieving_the_docs	/pdf/0cd380b448292457e8f1864ef3a80c0dd651818a.pdf
G_HSyfLk0m	3504	Graph Signal Sampling for Inductive One-Bit Matrix Completion: a Closed-form Solution	['inductive one-bit matrix completion', 'graph signal sampling']		General Machine Learning (ie none of the above)	anonymous|graph_signal_sampling_for_inductive_onebit_matrix_completion_a_closedform_solution	/pdf/626d201b45c026f5b7aee127ff1db2b97d3e1903.pdf
SCk8vEhwKo	3505	ATTRIBUTES RECONSTRUCTION IN HETEROGENEOUS NETWORKS VIA GRAPH AUGMENTATION	[]		Deep Learning and representational learning	anonymous|attributes_reconstruction_in_heterogeneous_networks_via_graph_augmentation	/pdf/bea6cc2ab4ff18cf64b20d1a0d61890d55ce39ca.pdf
-G1kjTFsSs	3506	Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment	['contextual bandit', 'kernelized method', 'asynchronous distributed learning', 'communication efficiency']	We propose and analyze a communication efficient asynchronous Kernel UCB algorithm with Nystrom approximation.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|learning_kernelized_contextual_bandits_in_a_distributed_and_asynchronous_environment	/pdf/1846c1f8e8c533be845b134638ca8c16b9ef3706.pdf
OfaJyiYonBk	3507	Iteratively Learning Novel Strategies with Diversity Measured in State Distances	['diverse behavior', 'multi-agent reinforcement learning', 'deep reinforcement learning']	We develop an iterative RL algorithm for discovering diverse high-reward strategies with provable convergence properties. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|iteratively_learning_novel_strategies_with_diversity_measured_in_state_distances	/pdf/fc89d579e1cb2f3fd05db5aafb8d9abed0c315b7.pdf
wQ-Tqt4eYQ	3508	ASGNN: Graph Neural Networks with Adaptive Structure	['Graph neural network', 'graph adversarial attacks and defenses', 'adaptive structure']	A novel graph neural network model with adaptive structure that has strong resilience to graph structural attacks	Deep Learning and representational learning	anonymous|asgnn_graph_neural_networks_with_adaptive_structure	/pdf/732697bbfae59cd3ae250165df11cd1138f7ed8d.pdf
tx-KRrFC2b	3509	Offline Equilibrium Finding	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_equilibrium_finding	/pdf/f40c7eef62d66a7620bcc03f3defca586f4a0448.pdf
5gDz_yTcst	3510	Towards Better Selective Classification	['Selective Classification', 'Semi-Supervised Learning']		Deep Learning and representational learning	anonymous|towards_better_selective_classification	/pdf/9643022f6fc5e728abca11713deeb113ed328daa.pdf
8oJHwb3Sgp	3511	Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|embed_to_control_partially_observed_systems_representation_learning_with_provable_sample_efficiency	/pdf/4345c509bc170f27b28d58167ca6a02fa9cc0807.pdf
vONX8wvmAP	3513	Online Min-max Optimization: Nonconvexity, Nonstationarity, and Dynamic Regret	['Online Optimization', 'Nonconvex', 'Minimax']	We study the online nonconvex-strongly-concave min-max optimization in the nonstationary environment and propose efficient algorithms with optimal theoretical guarantees under novel notion of regret	Optimization (eg, convex and non-convex optimization)	anonymous|online_minmax_optimization_nonconvexity_nonstationarity_and_dynamic_regret	/pdf/330753c949c0e75cb98c31fd783d863893c1c9f8.pdf
26aAV_wjoc	3514	VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment	['self-supervision', 'vision-language pre-training', 'transformer', 'patch-word alignment']	We introduce VoLTA, Vision-Language Transformer with weakly-supervised local-feature Alignment, a VLP paradigm trained with graph optimal transport (GOT) based image-text matching.	Unsupervised and Self-supervised learning	anonymous|volta_visionlanguage_transformer_with_weaklysupervised_localfeature_alignment	/pdf/ed9aba8cb255099bf7bbc2c85239d3ece05bed2a.pdf
ekTnbhhLHg	3515	Improving Inductive Link Prediction through Learning Generalizable Node Representations	['Link Prediction', 'Graph Machine Learning', 'Inductive Learning', 'Node Embedding', 'Representation Learning', 'Generalizability', 'Open Graph Benchmark']	We propose new methods for designing inductive tests on any graph dataset, accompanied by unsupervised pre-training of the node attributes for improved generalizability of the link prediction models.	Deep Learning and representational learning	anonymous|improving_inductive_link_prediction_through_learning_generalizable_node_representations	/pdf/74af3c3ac886ebac0357a2da7d2e4e94b85d73ab.pdf
yIxtevizEA	3516	Latent Bottlenecked Attentive Neural Processes	['Neural Processes', 'Meta-Learning', 'Uncertainty Estimation']	In this work, we propose Latent Bottlenecked Attentive Neural Processes (LBANPs), a new computationally efficient sub-quadratic NP variant, that has a querying computational complexity independent of the number of context datapoints.	Deep Learning and representational learning	anonymous|latent_bottlenecked_attentive_neural_processes	/pdf/9598ff13959753ebfd13bf2ffacf2efb1ff2c2d3.pdf
1EVPT82ttr	3517	Learning Unified Representations for Multi-Resolution Face Recognition	['multi-resolution face recognition', 'deep representation learning']	We propose Branch-to-Trunk Network to learn discriminative embeddings for multi-resolution face recognition while preserving representation compatibility.	Deep Learning and representational learning	anonymous|learning_unified_representations_for_multiresolution_face_recognition	/pdf/31868127f4589fcd6afd1015ba065963a23b79ec.pdf
Us5in-h2Dp	3518	MVP: Multi-task Supervised Pre-training for Natural Language Generation	['Natural language generation', 'pretrained language models', 'multi-task learning', 'prompt learning']	We pre-train a model MVP and task-specific prompts for natural language generation tasks with our collected labeled corpora MVPCorpus.	Applications (eg, speech processing, computer vision, NLP)	anonymous|mvp_multitask_supervised_pretraining_for_natural_language_generation	/pdf/46009fa8f3544ba68dfb0d9188a4ca71c3991e43.pdf
Q31C6XQOEvl	3520	NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual Question Answering	['Tabular-Textual Question Answering', 'Non-Autoregressive Program Generation', 'Natural Language Processing']	We present a non-autoregressive program generation model for the numerical reasoning of hybrid question answering to address the exposure bias issue of autoregressive generation and to boost the decoding speed.	Applications (eg, speech processing, computer vision, NLP)	anonymous|napg_nonautoregressive_program_generation_for_hybrid_tabulartextual_question_answering	/pdf/282bfaecb444cb5a251f1f14963f2ce08de70b2c.pdf
jPfDKW3nj5q	3521	Adaptive Kernel Selection for Convolutional Neural Network	['Adaptive', 'Kernel', 'CNN', 'Computer Vision']		Applications (eg, speech processing, computer vision, NLP)	anonymous|adaptive_kernel_selection_for_convolutional_neural_network	/pdf/7b970be18dcdffd9e350641bd955b134426225be.pdf
SaRj2ka1XZ3	3522	Language Models Can Teach Themselves to Program Better	['deep learning', 'natural language processing', 'program synthesis', 'large language models']	Language Models can be used to generate Programming Puzzles and Solutions, which can be filtered for correctness and used to finetune the LLM to improve its performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|language_models_can_teach_themselves_to_program_better	/pdf/585a06c716c50cf28fa45109a2c4d92e794517c1.pdf
ttfOGx6-_FT	3523	DROP: Conservative Model-based Optimization for Offline Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|drop_conservative_modelbased_optimization_for_offline_reinforcement_learning	/pdf/a67a7d42feb887f97532dec8546448e618cc825d.pdf
jBEXnEMdNOL	3524	Fairness and Accuracy under Domain Generalization	['fairness', 'accuracy', 'domain generalization', 'js-divergence', 'invariant representation', 'equalized odds', 'equal opportunity', 'regularization']	This paper presents (1) theoretical bounds for fairness and accuracy under domain generalization, and (2) a proposed model that can achieve good fairness and accuracy in an unseen target domain through invariant representation learning.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fairness_and_accuracy_under_domain_generalization	/pdf/f27b18a2866a253ae18173eab8378ec069b84345.pdf
P880C39xAvM	3525	Turning a Curse Into a Blessing: Enabling Data-Free Backdoor Unlearning via Stabilized Model Inversion	['Backdoor Defenses']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|turning_a_curse_into_a_blessing_enabling_datafree_backdoor_unlearning_via_stabilized_model_inversion	/pdf/1324ba3b9a0f28c0414ba3a49258c5b38ca5213b.pdf
Zd4hTGjpMNm	3526	A computational framework to unify representation similarity and function in biological and artificial neural networks	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|a_computational_framework_to_unify_representation_similarity_and_function_in_biological_and_artificial_neural_networks	/pdf/6b6d27c9e365afe4003dabec58b23d0717df7b3c.pdf
YSVbWFBDup	3528	How Weakly Supervised Information helps Contrastive Learning	[]		Unsupervised and Self-supervised learning	anonymous|how_weakly_supervised_information_helps_contrastive_learning	/pdf/ab52267a7c74cd5f9b981b51e5a4306bdfe8673b.pdf
X5BlM6YG7j	3530	OCIM : Object-centric Compositional Imagination for Visual Abstract Reasoning	['objects', 'imagination', 'visual reasoning', 'representation learning', 'inductive biases', 'compositional generalization']	Our model leveragse object-centric inductive biases to derive an imagination-based learning framework. We show that it leads to better compositional generalization in a visual abstact reasoning task.	Deep Learning and representational learning	anonymous|ocim_objectcentric_compositional_imagination_for_visual_abstract_reasoning	/pdf/a10b09f0df7ca74e9b45fd7c02becce32e2ec018.pdf
e-M4E3Jmnkq	3531	Detecting and Mitigating Indirect Stereotypes in Word Embeddings	['word embeddings', 'stereotypes', 'bias', 'bias mitigation', 'indirect bias']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|detecting_and_mitigating_indirect_stereotypes_in_word_embeddings	/pdf/8e4a36cc0d28d196af2a261b827b497b2ba9b6b1.pdf
ZamTdE_Q7hv	3532	When do Convolutional Neural Networks Stop Learning?	[]		Optimization (eg, convex and non-convex optimization)	anonymous|when_do_convolutional_neural_networks_stop_learning	/pdf/1b55065d077eb369937af7251a7bb0c05bfe27a3.pdf
xc5ajsvLzFO	3533	What do Vision Transformers Learn?  A Visual Exploration	['Vision Transformers', 'Visualization', 'Interpretability']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|what_do_vision_transformers_learn_a_visual_exploration	/pdf/047c9c68f7888741bab2951c62fc128854831fe9.pdf
Vk9RH9aL1Yv	3535	Continuous Goal Sampling: A Simple Technique to Accelerate Automatic Curriculum Learning	['reinforcement learning', 'curriculum learning', 'goal-conditioned reinforcement learning']	We present continuous goal sampling, an extension of goal-conditioned RL that accelerates a wide range of curriculum learning algorithms.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|continuous_goal_sampling_a_simple_technique_to_accelerate_automatic_curriculum_learning	/pdf/b3ab7a12541f4cd79bfdb3908d0728989f05c3bb.pdf
x5YkB3b_48o	3536	Stochastic Bridges as Effective Regularizers for Parameter-Efficient Tuning	['parameter-efficient tuning', 'pre-trained model', 'stochastic process']	We propose to use stochastic bridges in a latent space to regularize the intermediate states of pre-trained models, and show the effectiveness and generality of this regularization on different tasks, models, and parameter-efficient tuning methods.	Deep Learning and representational learning	anonymous|stochastic_bridges_as_effective_regularizers_for_parameterefficient_tuning	/pdf/944f5443fa71b649834e1c922fb66461609fee9f.pdf
5cio7DSIXLQ	3537	Adaptive Sparse Softmax: An Effective and Efficient Softmax Variant for Text Classification	[]		Deep Learning and representational learning	anonymous|adaptive_sparse_softmax_an_effective_and_efficient_softmax_variant_for_text_classification	/pdf/38e5dd3a151f2b30e6cb5286f00e5358ad1c738b.pdf
8TKFt2x3Sx	3540	Injecting Image Details into CLIP's Feature Space	['Text-Based Information Retrieval', 'Fine-Detail', 'CLIP', 'Single Feature', 'Detail Compression', 'Complete Cover', 'Feature Space Alignment', 'Self-Supervised']	We propose a framework, including a model-agnostic complete cover scheme to obtain image patches, a fusing model, the corresponding query proxy loss and a new text-image retrieval benchmark.	Deep Learning and representational learning	anonymous|injecting_image_details_into_clips_feature_space	/pdf/cb4b9d4d0968cd7f7afa384bdecb1d074282abf9.pdf
3HX__RcSFZj	3541	A Semantic Hierarchical Graph Neural Network for Text Classification	[]		Deep Learning and representational learning	anonymous|a_semantic_hierarchical_graph_neural_network_for_text_classification	/pdf/c42d9f949c1509a9f76ba972d773c6568d08ca15.pdf
fySLokohvj4	3544	Bandit Learning with General Function Classes: Heteroscedastic Noise and Variance-dependent Regret Bounds	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|bandit_learning_with_general_function_classes_heteroscedastic_noise_and_variancedependent_regret_bounds	/pdf/d871d948f4f2ab591fde48c244ab6859686a81ca.pdf
ZsvWb6mJnMv	3545	Augmented Lagrangian is Enough for Optimal Offline RL with General Function Approximation and Partial Coverage	['Offline RL', 'Pessimism', 'RL Theory']	We present practical and statistically optimal offline RL algorithms under general function approximation and single-policy concentrability.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|augmented_lagrangian_is_enough_for_optimal_offline_rl_with_general_function_approximation_and_partial_coverage	/pdf/f4cf9686bdcc53290e862acda92f625a478eae68.pdf
UifByHdLmmf	3546	Unlearning with Fisher Masking	['machine unlearning', 'Fisher Information']	We develop a new unlearning strategy based on Fisher Masking which shows strong unlearning performances across different datasets and deep neural network structures.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|unlearning_with_fisher_masking	/pdf/e3dd17b77fc69fb26de9bd736c34f991e6f41956.pdf
e9CKiV6pgBD	3547	Penalizing the High-likelihood: A Novel Sampling Method for Open-ended Neural Text Generation via Inverse Probability Weighting	['neural text generation', 'sampling algorithm', 'likelihood trap', 'diversity and novelty']	A novel sampling algorithm for neural text generation with improved diversity and novelty compared with top-p/k and temperature sampling.	Applications (eg, speech processing, computer vision, NLP)	anonymous|penalizing_the_highlikelihood_a_novel_sampling_method_for_openended_neural_text_generation_via_inverse_probability_weighting	/pdf/be9df49748c13d8d371d0f117b93886810d581a3.pdf
tFmjPd8J5o1	3548	A Note on Quantifying the Influence of Energy Regularization for Imbalanced Classification	['Influence Function', 'Energy based model', 'Imbalanced Dataset']		Deep Learning and representational learning	anonymous|a_note_on_quantifying_the_influence_of_energy_regularization_for_imbalanced_classification	/pdf/2aa2c2e5cfe9788c95fc458eaf6925186cf39557.pdf
lCzuxqRbThP	3549	FedMT: Federated Learning with Mixed-type Labels	['Federated Learning', 'Mixed-type Labels', 'Healthcare Application', 'Neural Tangent Kernel']		Deep Learning and representational learning	anonymous|fedmt_federated_learning_with_mixedtype_labels	/pdf/598655db93afa8c2bade90fa26ddf616f78a9d98.pdf
jl-zL6aETgQ	3551	Semi-Offline Reinforcement Learning for Portfolio Optimization	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|semioffline_reinforcement_learning_for_portfolio_optimization	/pdf/1dc1d31b95cc5d2122339f979c0b167c94ac6107.pdf
6Wl7-M2BC-	3552	An Adaptive Policy to Employ Sharpness-Aware Minimization	['Sharpness-aware minimization', 'model generalization', 'loss landscape']	We design an adaptive policy to employ SAM and propose two efficient algorithms to reduce the fraction of SAM updates.	Optimization (eg, convex and non-convex optimization)	anonymous|an_adaptive_policy_to_employ_sharpnessaware_minimization	/pdf/7a9c380c14fb65e2bd58dd45e6e797796d22ddc9.pdf
5G_SmGZlXQ	3553	Toxicity in Multilingual Machine Translation at Scale	['Toxicity', 'Holistic Bias', 'Input Attributions', 'Multilingual Machine Translation', 'Scale']	Quantification, analysis and mitigation recommendations of toxicity for 164 languages 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|toxicity_in_multilingual_machine_translation_at_scale	/pdf/b543059f768ca2c53d3f11f3b6da52a8ca5ca249.pdf
EqDnVOyiVX	3554	Learning to Optimize Quasi-Newton Methods	['meta-learning', 'learning to optimize', 'quasi-Newton', 'optimization', 'hypergradients']	We introduce a novel machine learning optimizer which combines learning to optimize with quasi-Newton methodology.	Optimization (eg, convex and non-convex optimization)	anonymous|learning_to_optimize_quasinewton_methods	/pdf/e991dd6c300f89f5902a704de1e1c7f6114050b4.pdf
CU8BwVAzLme	3556	Pathfinding Neural Cellular Automata	['pathfinding', 'neural cellular automata', 'graph neural networks', 'algorithmic alignment']	We show the algorithmic alignment of Neural Cellular Automata with pathfinding problems using hand-coded networks and learned models	Deep Learning and representational learning	anonymous|pathfinding_neural_cellular_automata	/pdf/0d8f075b5a3bb6f3755ef72215f3eade0d71aed2.pdf
G-uNfHKrj46	3557	Efficient Attention via Control Variates	['attention mechanism', 'transformers', 'random features', 'control variates', 'importance sampling']	We present a novel analysis of random feature attention based on control variates, which characterizes its gap to full softmax attention and induces a novel efficient variant that significantly improves the approximation while remaining efficient.	Deep Learning and representational learning	anonymous|efficient_attention_via_control_variates	/pdf/64a3765b2f3c055f819f329f6e38648ae4075bee.pdf
8yVy6LdhER4	3558	Approximating How Single Head Attention Learns	['NLP', 'training dynamics', 'attention']	Why do models often attend to salient words, and how does this evolve throughout training? We define a model property, Knowledge to Translate Individual Words, and claim that it drives the learning of the attention.	Deep Learning and representational learning	anonymous|approximating_how_single_head_attention_learns	/pdf/adcda390b02e60272ebbb8d482c30df9a28a4c8c.pdf
sy0PqUr2fq9	3559	Fairness-Aware Model-Based Multi-Agent Reinforcement Learning for Traffic Signal Control	['Traffic signal control', 'reinforcement learning', 'fairness']	A novel Fairness-aware Model-based Multi-agent Reinforcement Learning (FM2Light) method to improve the sample efficiency and fairness for multi-intersection control.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|fairnessaware_modelbased_multiagent_reinforcement_learning_for_traffic_signal_control	/pdf/92d08d43ffba321ac8b31e1965436b04652cefb7.pdf
z57WK5lGeHd	3560	On the Soft-Subnetwork for Few-Shot Class Incremental Learning	['Soft-subnetwork', 'Few-shot class incremental learning (FSCIL)']	SoftNet jointly learns the model weights and adaptive non-binary soft masks at a base training session in which each mask consists of the major and minor subnetwork.	Deep Learning and representational learning	anonymous|on_the_softsubnetwork_for_fewshot_class_incremental_learning	/pdf/27eff88d20c61f5d48cf446aa54fadc29f02205f.pdf
H-T3F0dMbyj	3561	CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled Videos	['universal sound separation', 'source separation', 'contrastive language-image pre-training', 'multi-modal learning', 'self-supervised learning']	A new method the leverages the pretrained CLIP model and noise invariant training for learning text-queried sound separation with only noisy unlabeled videos	Applications (eg, speech processing, computer vision, NLP)	anonymous|clipsep_learning_textqueried_sound_separation_with_noisy_unlabeled_videos	/pdf/efd3e4e43f464929b3a150569789466cc1081767.pdf
Oh0cnNTn5Di	3562	Lattice Convolutional Networks for Learning Ground States of Quantum Many-Body Systems	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|lattice_convolutional_networks_for_learning_ground_states_of_quantum_manybody_systems	/pdf/f9f8b2439d88e460274af3a4cde7a3ae85fc8e92.pdf
VLnODGVVAsL	3563	Anchor Sampling for Federated Learning with Partial Client Participation	['Federated Learning', 'Optimization']	To accelerate the training process and improve the model performance, FedAMD utilizes anchor sampling that disjoints the partial participants into anchor group (training with large batches) and miner group (training with small batches). 	Optimization (eg, convex and non-convex optimization)	anonymous|anchor_sampling_for_federated_learning_with_partial_client_participation	/pdf/b43dc89d9b23cce4968e080f3dcca4b55cb74716.pdf
RdudTla7eIM	3564	MoCa: Cognitive Scaffolding for Language Models in Causal and Moral Judgment Tasks	['cognitive science', 'causal reasoning', 'moral reasoning', 'dataset', 'chain-of-thought', 'step-by-step', 'language models']	We summarized the main findings of 24 cognitive science papers around human intuitions on causal and moral judgments, and collect a dataset to evaluate large language models.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|moca_cognitive_scaffolding_for_language_models_in_causal_and_moral_judgment_tasks	/pdf/65ddcff556f12357da83a104f89fe20cdec59193.pdf
aBH_DydEvoH	3565	Offline RL for Natural Language Generation with Implicit Language Q Learning	['offline reinforcement learning', 'natural language processing', 'dialogue', 'controlled generation']	We propose a novel offline RL method, implicit language Q-learning (ILQL), for use on language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|offline_rl_for_natural_language_generation_with_implicit_language_q_learning	/pdf/2ab7ee1befb6985f7cfdfe32f727b7a12cc93f32.pdf
z9fXRC5XdT	3567	Text and Patterns: For Effective Chain of Thought It Takes Two to Tango	['in-context learning', 'few-shot prompting', 'chain of thought prompting', 'large-language models']	Text and patterns play a complementary role in the success of few-shot prompting.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|text_and_patterns_for_effective_chain_of_thought_it_takes_two_to_tango	/pdf/9d892c13ad14f62564b397096dd516891bde702d.pdf
n9pes83qD1	3568	LA-BALD: An Information-Theoretic Image Labeling Task Sampler	['active learning', 'data annotation']	We propose LA-BALD, an information-theoretic image labeling task sampler, that actively selects image and worker pairs to improve labeling accuracy	Applications (eg, speech processing, computer vision, NLP)	anonymous|labald_an_informationtheoretic_image_labeling_task_sampler	/pdf/d495d0e7677ac2f9d68dca60607c3e091f1abab1.pdf
l9vM_PaUKz	3569	Soft Neighbors are Positive Supporters in Contrastive Visual Representation Learning	['contrastive learning', 'soft neighbors', 'visual correlation']	We leverage the soft neighbors to sufficiently explore the correlation information among samples in cotrastive learning.	Deep Learning and representational learning	anonymous|soft_neighbors_are_positive_supporters_in_contrastive_visual_representation_learning	/pdf/f36df944d51a03535c8f00c5a2f2ecfc46c21e1f.pdf
Dyzhru5NO3u	3570	On the Efficacy of Server-Aided Federated Learning against Partial Client Participation	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_efficacy_of_serveraided_federated_learning_against_partial_client_participation	/pdf/4d3c074f8275761076f7f9538a4b9882f99301aa.pdf
uh93gVo6Veu	3572	Imbalanced Lifelong Learning with AUC Maximization	['Imbalanced Lifelong Learning', 'AUC Maximization']	We propose a new approach to empower continual learning with imbalanced data: designing an algorithm to directly maximize one widely used metric in an imbalanced data setting: Area Under the ROC Curve (AUC). 	Deep Learning and representational learning	anonymous|imbalanced_lifelong_learning_with_auc_maximization	/pdf/eb4f328bab29a8d91ebf453629626310a8b3a4db.pdf
Cn6JkFnKgPX	3573	Analysis of differentially private synthetic data: a general measurement error approach	['Measurement Error Model', 'Differential Privacy', 'Regression', 'Statistical Inference']		General Machine Learning (ie none of the above)	anonymous|analysis_of_differentially_private_synthetic_data_a_general_measurement_error_approach	/pdf/b284fad4c803e970047f0da55be4dd1d6071e0db.pdf
4OS-U1a5kB-	3574	Safe Reinforcement Learning with Contrastive Risk Prediction	['safe reinforcement learning', 'contrastive risk prediction']	We propose a contrastive risk prediction method to train safe RL agents with risk preventive trajectory exploration and reward shaping.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|safe_reinforcement_learning_with_contrastive_risk_prediction	/pdf/5563be94c6fb3e4df04ea6173e4f1a162e2f4503.pdf
uUU05MP7Pv7	3576	Mitigating Demographic Bias of Federated Learning Models via Global Domain Smoothing	['Federated Learning', 'Demographic Fairness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|mitigating_demographic_bias_of_federated_learning_models_via_global_domain_smoothing	/pdf/3b1ccfb8cc01354808e35445cec97e464e02a0fe.pdf
ToNvGM_jXlA	3578	Self-supervised Learning for Cell Segmentation and Quantification in Digital Pathology Images	['Medical Segmentation', 'Self-supervised Learning', 'contrastive learning']	Identifying cell bodies in brain tissue digital pathology images	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|selfsupervised_learning_for_cell_segmentation_and_quantification_in_digital_pathology_images	/pdf/a8d073417bb04233c1080ecc02c0edbf8a367cc4.pdf
JFf-bPQu5RB	3579	Leveraged Asymmetric Loss with Disambiguation for Multi-label Recognition with One-Positive Annotations	[]		Deep Learning and representational learning	anonymous|leveraged_asymmetric_loss_with_disambiguation_for_multilabel_recognition_with_onepositive_annotations	/pdf/534343e4c94417710b506c9a90fe269c6b8ce469.pdf
17mPeO4rqGj	3580	Tackling Diverse Tasks via Cross-Modal Transfer Learning	['Cross-modal transfer learning', 'pretrained models', 'fine-tuning']	We study how to effectively transfer pretrained models to problems outside the pretraining modalities.	Deep Learning and representational learning	anonymous|tackling_diverse_tasks_via_crossmodal_transfer_learning	/pdf/c3d228e4513e948066ad2338fae73988cd204050.pdf
BR_ZhvcYbGJ	3582	Explaining Temporal Graph Models through an Explorer-Navigator Framework	['graph neural networks', 'gnn explainers', 'temporal graphs']	A MCTS-based explainer for temporal graph models.	Deep Learning and representational learning	anonymous|explaining_temporal_graph_models_through_an_explorernavigator_framework	/pdf/0282da51e75d7ac55f0c7364fecf14d49a127255.pdf
uH_RlkvQMUs	3583	Anatomical Structure-Aware Image Difference Graph Learning for Difference-Aware Medical Visual Question Answering	['Chest Xray', 'Difference Image VQA', 'medical dataset', 'Graph Neuron Networks']	Large scale image difference medical VQA dataset and expert knowledge-aware graph representation learning 	Applications (eg, speech processing, computer vision, NLP)	anonymous|anatomical_structureaware_image_difference_graph_learning_for_differenceaware_medical_visual_question_answering	/pdf/3349473af2334f9da1e52bf73c5c84f7dcfdeb8a.pdf
dnjZSPGmY5O	3587	Equivariant Descriptor Fields: SE(3)-Equivariant Energy-Based Models for End-to-End Visual Robotic Manipulation Learning	['Robotics', 'Manipulation', 'Robotic manipulation', 'Equivariance', 'SE(3)', 'SO(3)', 'Energy-based model', 'Lie group', 'Representation theory', 'Equivariant robotics', 'Roto-translation equivariance', 'End-to-end', 'Point clouds', 'Graph neural networks', 'Imitation learning', 'Learning from demonstration', 'Sample efficient', 'Few shot', 'Unseen object', 'Category-level manipulation', 'MCMC', 'Langevin dynamics']	We present SE(3)-equivariant energy based models that can learn robotic manipulation tasks end-to-end from only few demonstrations without any prior knowledge.	Applications (eg, speech processing, computer vision, NLP)	anonymous|equivariant_descriptor_fields_se3equivariant_energybased_models_for_endtoend_visual_robotic_manipulation_learning	/pdf/4c67b0de99b5d964c15b2be5958149db4415f702.pdf
NpsVSN6o4ul	3588	Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small	['Mechanistic Interpretability', 'Transformers', 'Language Models', 'Interpretability', 'Transparency', 'Science of ML']	We find a large circuit for a natural language task in GPT-2 small and provide quantitative evaluation of our human-understandable explanation.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|interpretability_in_the_wild_a_circuit_for_indirect_object_identification_in_gpt2_small	/pdf/e7c97e7ec25e55e199c5353df378bae28eef92dc.pdf
jpWa2RnZpIK	3591	MaskNeRF: Masked Neural Radiance Fields for Sparse View Synthesis	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|masknerf_masked_neural_radiance_fields_for_sparse_view_synthesis	/pdf/fdb87a875f608ca2809e358478fb5d49ed442994.pdf
39cMBLyo_ia	3592	Push and Pull:  Competing Feature-Prototype Interactions  Improve Semi-supervised Semantic Segmentation	['Semi-supervised', 'Segmentation', 'Competing Interactions', 'Classifier Prototype']		Applications (eg, speech processing, computer vision, NLP)	anonymous|push_and_pull_competing_featureprototype_interactions_improve_semisupervised_semantic_segmentation	/pdf/440867f96ba2fc2cb094daa323dfa53f9a9d3c61.pdf
1_ZHr9Ha_ZJ	3593	Multi-Reward Fusion:  Learning from Other Policies by Distilling 	['Energy-Based', 'Policy Distilling', 'Reinforcement Learning', 'Auto Reward Shaping']	Multi-Reward Fusion:  Learn from other policies by distilling 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multireward_fusion_learning_from_other_policies_by_distilling	/pdf/2834e2a60f9ced435bdfad54c758a1508f9ac07e.pdf
wsZsjOSytRA	3594	3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical Transformer for Medical Image Segmentation	['Depth-wise Convolution', 'Large Kernel Convolution', 'Convolutional Neural Network', 'Hierarchical Transformer', 'Volumetric Segmentation', 'Medical Image Segmentation']	We propose a lightweight network 3D UX-Net that simulates hierarchical transformer behavior with large kernel depthwise convolution and introduce pointwise depthwise scaling to scale features with less model parameters for volumetric segmentation.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|3d_uxnet_a_large_kernel_volumetric_convnet_modernizing_hierarchical_transformer_for_medical_image_segmentation	/pdf/6fbb9a2a61929a3a250f48de10a514ec1f7a4cc0.pdf
uLE3WF3-H_5	3595	Adversarial Diversity in Hanabi	['coordination', 'diversity', 'multi-agent reinforcement learning']	We produce meaningfully diverse and reasonable joint policies using off-belief learning and adversarial reward shaping.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adversarial_diversity_in_hanabi	/pdf/82758f316df892f3cd4f91ab262ef6d040744543.pdf
WUWJIV2Yxtp	3597	Re-calibrating Feature Attributions for Model Interpretation	['Feature Attribution', 'Explainable Artifical Intelligence']	We propose a re-calibration technique to calibrate existing integral-based attribution methods with valid references for a consistent explanation.	Deep Learning and representational learning	anonymous|recalibrating_feature_attributions_for_model_interpretation	/pdf/05a89ac20526cbcff4d46e95612413019422baca.pdf
-tYCaP0phY_	3598	FlexRound: Learnable Rounding by Element-wise Division for Post-Training Quantization	['Efficient Inference', 'Quantization', 'Post-Training Quantization']		Deep Learning and representational learning	anonymous|flexround_learnable_rounding_by_elementwise_division_for_posttraining_quantization	/pdf/b99eb1e8fa79fa6e05a7c3fd042c0e1d2c61c006.pdf
7GQfA9xAqxN	3599	Hypothetical Training for Robust Machine Reading Comprehension of Tabular Context	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|hypothetical_training_for_robust_machine_reading_comprehension_of_tabular_context	/pdf/531791952eabe5c4ea9018c713a50c015c68af23.pdf
_V-nKeWvs7p	3602	Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations	['molecular dynamics', 'machine learning force field', 'benchmark', 'simulation-based evaluation', 'ML for Sciences']	We benchmark machine learning force fields with novel datasets and metrics based on molecular simulations and reveal insights into how they should be evaluated and further improved.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|forces_are_not_enough_benchmark_and_critical_evaluation_for_machine_learning_force_fields_with_molecular_simulations	/pdf/010fcaff1ca14d26774fa6569714e3dcdc02acdf.pdf
BaWtp9o25zN	3603	Limitations of Piecewise Linearity for Efficient Robustness Certification	['robustness', 'certification', 'Lipschitz', 'limitations', 'adversarial examples']	We show that piecewise linearity imposes fundamental limitations for efficient robustness certification, e.g., Lipschitz-based certification; this imposes additional capacity requirements on networks that must be certified by such techniques.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|limitations_of_piecewise_linearity_for_efficient_robustness_certification	/pdf/a0fa4bbf46e6f7185626bf62d24fbf04057e2220.pdf
eExA3Mk0Dxp	3606	Robust Multi-Agent Reinforcement Learning against Adversaries on Observation	['multi-agent reinforcement learning', 'robust reinforcement learning', 'cooperative multi-agent systems', 'adversarial training']	We propose a training framework that progressively generates adversarial attacks on agents' observations to help agents learn a robust cooperative policy. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|robust_multiagent_reinforcement_learning_against_adversaries_on_observation	/pdf/0a82f38bab922a92e0d32ed7ef3897fae15382b7.pdf
xYlJRpzZtsY	3608	ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning	['step-by-step reasoning', 'evaluation']	We propose a new taxonomy for reasoning errors and suite of metrics to score step-by-step reasoning in language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|roscoe_a_suite_of_metrics_for_scoring_stepbystep_reasoning	/pdf/2bdff9cf9b3a6393173042555aefbd3f45914dbe.pdf
7d-d0BFz6Hf	3609	Mesh-Independent Operator Learning for PDEs using Set Representations	['partial differential equations', 'operator learning', 'set representations', 'attention-based model', 'implicit neural representation']	We propose an attention-based operator learning model for obtaining the continuous solution of PDEs, independent of the discretization formats.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|meshindependent_operator_learning_for_pdes_using_set_representations	/pdf/d67cb1e5b4044aa70c656b1c0ecee60858f5aeff.pdf
t7HIN3fUAUu	3610	ReG-NAS: Graph Neural Network Architecture Search using Regression Proxy Task	['Neural Architecture Search', 'GNN', 'Machine Learning']		Deep Learning and representational learning	anonymous|regnas_graph_neural_network_architecture_search_using_regression_proxy_task	/pdf/88ef1cfb9bb4cc5968403a8231f73c3ab233d413.pdf
s7oOe6cNRT8	3613	M-L2O: Towards Generalizable Learning-to-Optimize by Test-Time Fast Self-Adaptation	['L2O', 'Meta Learning', 'Generalization']		General Machine Learning (ie none of the above)	anonymous|ml2o_towards_generalizable_learningtooptimize_by_testtime_fast_selfadaptation	/pdf/a7043e0de124274d4489feba9f1ea71353dd7b33.pdf
ZLfD0cowleE	3614	VEHICLE-INFRASTRUCTURE COOPERATIVE 3D DETECTION VIA FEATURE FLOW PREDICTION	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|vehicleinfrastructure_cooperative_3d_detection_via_feature_flow_prediction	/pdf/bb803c893533994b02bed3d6c808196e8c6727f5.pdf
aCdREQkEMGk	3615	Synchronized Contrastive Pruning for Efficient Self-Supervised Learning	['Sparse Training', 'Self-supervised Learning', 'Neural Network Pruning']	Novel sparse training algorithm for self-supervised learning	Unsupervised and Self-supervised learning	anonymous|synchronized_contrastive_pruning_for_efficient_selfsupervised_learning	/pdf/7514dd5abba3941f68463d37616848194eb1c6bb.pdf
WePih5bXsNB	3616	Deep Contrastive Learning Approximates Ensembles of One-Class SVMs with Neural Tangent Kernels	['contrastive learning', 'one-class SVM', 'neural tangent kernel', 'sequential convex programming']		Deep Learning and representational learning	anonymous|deep_contrastive_learning_approximates_ensembles_of_oneclass_svms_with_neural_tangent_kernels	/pdf/8c5c8d430350dd936c081bfb468fc127b2a1f842.pdf
Db_WALIfbdC	3617	Bayesian Optimal Experimental Design for the Survey Bandit Setting	['Bayesian optimal experimental design', 'contextual bandit', 'survey']	We develop a Bayesian optimal experimental design procedure for the survey bandit setting.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|bayesian_optimal_experimental_design_for_the_survey_bandit_setting	/pdf/7404513cf6a65ffdebcd858cb1aa8056a9935f24.pdf
iaYcJKpY2B_	3618	CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis	['Program synthesis', 'multi-turn generation', 'code generation', 'large language models', 'generative models']	We open-source a large language models, CodeGen, for program synthesis and propose a multi-turn program synthesis benchmark for evaluation.	Deep Learning and representational learning	anonymous|codegen_an_open_large_language_model_for_code_with_multiturn_program_synthesis	/pdf/3657b674cbcd11a05a35777de33fcd140167a7a0.pdf
bGQw0awHUjQ	3619	Certified Robustness on Structural Graph Matching	['Structural graph matching (GM)', 'certified robustness', 'randomized smoothing', 'joint Gaussian distribution']	We are the first to define certified robustness on GM and design a new certification strategy using a joint smoothing distribution to maximize certified region.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|certified_robustness_on_structural_graph_matching	/pdf/ff8e5ccc7decef4084ec7b1aa612b1f9702f6aa7.pdf
xZxK8OG2igG	3620	Oracle-oriented Robustness: Robust Image Model Evaluation with Pretrained Models as Surrogate Oracle	['robustness', 'distribution shift', 'reliable machine learning']	We offer a dynamic evaluation protocol that evaluates vision models' robustness across generic i.i.d benchmarks, without requirement on the prior knowledge of the underlying causal structure depicted by the images and additional human efforts.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|oracleoriented_robustness_robust_image_model_evaluation_with_pretrained_models_as_surrogate_oracle	/pdf/410f8570cfaa357ae24eeafb959caede1f9ea654.pdf
s130rTE3U_X	3621	Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning	['contrastive learning', 'self-supervised learning', 'representation learning', 'nonlinearity', 'training dynamics', 'landscape']	We analyze the role played by the nonlinearity in the training dynamics nonlinear 2-layer network for contrastive learning. 	Unsupervised and Self-supervised learning	anonymous|understanding_the_role_of_nonlinearity_in_training_dynamics_of_contrastive_learning	/pdf/8ce37a9116f48d4ededb51c7b2c01edfa84709c0.pdf
l2FXO1RJ5Hs	3622	Precautionary Unfairness in Self-Supervised Contrastive Pre-training	['fairness', 'contrastive learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|precautionary_unfairness_in_selfsupervised_contrastive_pretraining	/pdf/d938cf6fdd405da06dc5d7ea7bf772cbd956bbaa.pdf
W7udwvFMnAd	3623	When Majorities Prevent Learning: Eliminating Bias to Improve Worst-group and Out-of-distribution Generalization	[]		Deep Learning and representational learning	anonymous|when_majorities_prevent_learning_eliminating_bias_to_improve_worstgroup_and_outofdistribution_generalization	/pdf/9ec48c81322e5176e1bb1881287cc08fde7c3571.pdf
zS9sRyaPFlJ	3626	PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm	['multi-objective reinforcement learning', 'MORL', 'DDQN', 'TD3', 'HER', 'continuous control', 'robotics application']	A novel approach that obtains a single policy network optimizing multiple objectives using multi-objective reinforcement learning on challenging continuous control tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pdmorl_preferencedriven_multiobjective_reinforcement_learning_algorithm	/pdf/f81c5bed8174d9c133c073946f6ecec7f3eebf7e.pdf
_1gu0EX0mM3	3627	Weakly-Supervised Domain Adaptation in Federated Learning	['federated learning', 'domain adaptation', 'healthcare']	We leverage auxiliary information and propose gradient projection (GP) to tackle federated domain adaptation problem under weak supervision. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|weaklysupervised_domain_adaptation_in_federated_learning	/pdf/0745020e021c3274f456accf062a119848a107bc.pdf
ZTPzwWtKW7o	3628	Evaluating Robustness of Generative Models with Adversarial Networks	['Adversarial examples', 'Generative models', 'Generative adversarial networks', 'Adversarial attacks']		Deep Learning and representational learning	anonymous|evaluating_robustness_of_generative_models_with_adversarial_networks	/pdf/0890b8772afabb75cb40ed51b4d70ec3c25cde80.pdf
qHbyR1MKG8K	3630	Wasserstein Barycenter-based Model Fusion and Linear Mode Connectivity of Neural Networks	['Linear mode connectivity', 'Neural network model fusion', 'Wasserstein barycenter', 'Federated learning']	We proposed a framework for model fusion through Wasserstein barycenter and Gromov-Wasserstein barycenter and connect it to the understanding of linear mode connectivity of neural networks.	Deep Learning and representational learning	anonymous|wasserstein_barycenterbased_model_fusion_and_linear_mode_connectivity_of_neural_networks	/pdf/c976bff8d9b1d7ea3be0705c506b38a888ed70c4.pdf
kAfl36VUr95	3632	A general differentially private learning framework for decentralized data	[]		Optimization (eg, convex and non-convex optimization)	anonymous|a_general_differentially_private_learning_framework_for_decentralized_data	/pdf/8041d84c2e6503a620947e94a6176b9885142b97.pdf
LcQ3aRCEuKK	3633	Holographic-(V)AE: an end-to-end SO(3)-Equivariant (Variational) Autoencoder in Fourier Space	[]		Unsupervised and Self-supervised learning	anonymous|holographicvae_an_endtoend_so3equivariant_variational_autoencoder_in_fourier_space	/pdf/dc51e36cee3884d0cef9217d4f4f2a0ec5179e4a.pdf
d_w12b7fb20	3635	Improving the Estimation of Instance-dependent Transition Matrix by using Self-supervised Learning	[]		Unsupervised and Self-supervised learning	anonymous|improving_the_estimation_of_instancedependent_transition_matrix_by_using_selfsupervised_learning	/pdf/0c664e829a7562f68a78c4369cbbac8f4f2bd870.pdf
JdTnc9gjVfJ	3636	MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations	['model-based reinforcement learning', 'visual reinforcement learning', 'learning from demonstrations']	We find that leveraging just a handful of demonstrations can dramatically improve the sample-efficiency of model-based RL, but requires three key ingredients: policy pretraining, targeted exploration, and oversampling of demonstration data.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|modem_accelerating_visual_modelbased_reinforcement_learning_with_demonstrations	/pdf/9399a1fe69a1c78ac70cd7c33b53ca7be0948336.pdf
27uBgHuoSQ	3637	Data Continuity Matters: Improving Sequence Modeling with Lipschitz Regularizer	['deep learning', 'data continuity', 'sequence modeling']		Deep Learning and representational learning	anonymous|data_continuity_matters_improving_sequence_modeling_with_lipschitz_regularizer	/pdf/7ecdfef1bb72e33a337a25d3ebf17b6168ae25da.pdf
-MQWXqNyoa	3638	Intrinsic Computational Complexity of Equivariant Neural Networks	['Equivariant Neural Networks', 'Learning Theory']	This paper theoretically studies the requried computational complexity for equivariant neural networks to achieve a desired expressivity.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|intrinsic_computational_complexity_of_equivariant_neural_networks	/pdf/a146e85a06c29f9ba099148580c4cc909213c8a5.pdf
nqoxB03tzi	3640	Understanding Pruning at Initialization: An Effective Node-Path Balancing Perspective	['Pruning Neural Network', 'Sparsity']	Our paper gives new perspectives on pruning at initialization from the configuration of subnetwork (particularly effective paths and nodes) to better design pruning algorithms.	Deep Learning and representational learning	anonymous|understanding_pruning_at_initialization_an_effective_nodepath_balancing_perspective	/pdf/4adb47a496201be9fae32fd266ed05621fcbae9b.pdf
Ha2MnQM9Ph	3641	Causal Estimation for Text Data with (Apparent) Overlap Violations	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|causal_estimation_for_text_data_with_apparent_overlap_violations	/pdf/c589af44facabc572211cb1d8c7bc077cb179e92.pdf
-Aw0rrrPUF	3642	GLM-130B: An Open Bilingual Pre-trained Model	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|glm130b_an_open_bilingual_pretrained_model	/pdf/967771078d75922c20390ee45e2b795c5fa67255.pdf
iPWiwWHc1V	3643	CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks	['Interpretability', 'Explainability', 'Network Dissection']	We propose an automated method for generating descriptions of the representation learned by hidden layer neurons, leveraging the multimodal CLIP-model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|clipdissect_automatic_description_of_neuron_representations_in_deep_vision_networks	/pdf/7c4e3e918b94eb0fa7720b9882b7d8f72972031c.pdf
XGagtiJ8XC	3644	Multi-level Protein Structure Pre-training via Prompt Learning	['protein representation learning', 'prompt learning', 'multi-task learning', 'multi-level structure']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|multilevel_protein_structure_pretraining_via_prompt_learning	/pdf/270b1f3e8bc292803bfd35d92547c0ae94e00ca7.pdf
Udho-Hry4RZ	3645	COMBAT: Alternated Training for Near-Perfect Clean-Label Backdoor Attacks	['backdoor', 'clean-label', 'alternated training']	We propose a novel mechanism to develop clean-label attacks with near-perfect attack performance, based on alternated training between a trigger generator and a surrogate classifier model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|combat_alternated_training_for_nearperfect_cleanlabel_backdoor_attacks	/pdf/053b8bff404ff0df81fd3b8b8caaebd7ba6f3965.pdf
FlCg47MNvBA	3646	Label-free Concept Bottleneck Models	['Interpretability', 'Explainability', 'Concept Bottleneck Models']	Scalable, automated and efficient way to create Concept Bottleneck Models without labeled concept data.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|labelfree_concept_bottleneck_models	/pdf/6ae7431af682a3729f5667b1f2a187a05a4f66aa.pdf
lid14UkLPd4	3647	Learning to Extrapolate: A Transductive Approach	[]		Deep Learning and representational learning	anonymous|learning_to_extrapolate_a_transductive_approach	/pdf/c03a0768429973ad3bd57269c8de04fea60a8ee3.pdf
Y2ShteTrnX2	3648	Meta-Learning General-Purpose Learning Algorithms with Transformers	['meta-learning', 'general-purpose', 'transformers', 'learning-to-learn', 'meta-optimization', 'large-models', 'black-box']	Transformers and other black-box models can exhibit learning-to-learn that generalizes to significantly different datasets while undergoing multiple phase transitions in terms of their learning behavior.	Deep Learning and representational learning	anonymous|metalearning_generalpurpose_learning_algorithms_with_transformers	/pdf/910485f3d74a6055f76ec86c81f542c952fc0acf.pdf
qV_M_rhYajc	3649	Spacetime Representation Learning	['pseudo-Riemannian geometry', 'spacetimes', 'Lorentz geometry', 'Lorentzian causality theory', 'Lorentzian pre-length spaces', 'directed graphs']	Representation of directed graphs by exploiting the causal structure of spacetimes via Lorentzian pre-length spaces	General Machine Learning (ie none of the above)	anonymous|spacetime_representation_learning	/pdf/fb123a0b56f3351e50197cc2d28b4ccab493a514.pdf
cJWxqmmDL2b	3650	Memorization-Dilation: Modeling Neural Collapse Under Noise	['Neural collapse', 'feature representation', 'label smoothing', 'cross entropy']		Deep Learning and representational learning	anonymous|memorizationdilation_modeling_neural_collapse_under_noise	/pdf/8a4461549e6527a01865cc535e0add6df207c067.pdf
kXiS0PpoSP6	3652	Excess risk analysis for epistemic uncertainty with application to variational inference	['Uncertainty', 'variational inference', 'Bayesian inference']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|excess_risk_analysis_for_epistemic_uncertainty_with_application_to_variational_inference	/pdf/76c9446d6e6935a2acee1b421dbc6e222c7e864a.pdf
wzlWiO_WY4	3653	Calibration Matters: Tackling Maximization Bias in Large-scale Advertising Recommendation Systems	['Maximization bias', 'calibration', 'distribution shifts', 'neural networks', 'recommendation system', 'computational advertisement']	We solve the maximization bias problem in Large-scale Advertising Recommendation Systems.	Applications (eg, speech processing, computer vision, NLP)	anonymous|calibration_matters_tackling_maximization_bias_in_largescale_advertising_recommendation_systems	/pdf/7eb348247a29bfbcbcc8642cea97ae3cd45e6b35.pdf
NiEtU7blzN	3654	Large Language Models Can Self-improve	['natural language processing', 'unsupervised learning', 'chain of thought']	Improving Reasoning Ability of Large Language Models in An Unsupervised Fashion	Applications (eg, speech processing, computer vision, NLP)	anonymous|large_language_models_can_selfimprove	/pdf/23db5ffb8bb32c1834004aa9cab879a808e1144c.pdf
xIr81Cft7s	3655	Generalization Mechanics in Deep Learning	['Deep Learning', 'Generalization', 'regularization']	Uncovers an implicit regularization in deep learning, and gives a new approach to obtain non-vacuous generalization bound	Deep Learning and representational learning	anonymous|generalization_mechanics_in_deep_learning	/pdf/8d21ace8beea577a5527211fbec19c1e28bde9d3.pdf
Us8pHYSEgO	3656	Demystifying black-box DNN training processes through Concept-Monitor	['interpretability', 'deep learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|demystifying_blackbox_dnn_training_processes_through_conceptmonitor	/pdf/b90cdbd22dd81e1365d980d37778f13424dd0e8e.pdf
OA4o8yKW3q	3657	Towards Robust Dataset Learning	['robust dataset learning']	We study the problem of learning a robust dataset such that any classifier naturally trained on the dataset is adversarially robust. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_robust_dataset_learning	/pdf/951cc5c100eb5e7a4a2cbf3e496f3d6996616013.pdf
CPg5IRu9PL	3658	Efficient Large-scale Transformer Training via Random and Layerwise Token Dropping	['Efficient Training', 'Large-scale Transformers', 'Token Dropping', 'GPT', 'BERT', 'ViT']	We present a novel random and layerwise token dropping method that can save up to 33.3% theoretical compute cost and 25.6% wall-clock time while achieving comparable accuracy as compared to the standard training procedure.	Deep Learning and representational learning	anonymous|efficient_largescale_transformer_training_via_random_and_layerwise_token_dropping	/pdf/a6de65e30a4f92db61abf0edf3d28244f2d18a6f.pdf
Azw-0kVtsX	3659	One-Vs-All AUC Maximization: an effective solution to the low-resource named entity recognition problem	['NLP', 'NER', 'Low-Resource', 'Imbalanced Distribution', 'AUC Maximization', 'One-Vs-All']		Deep Learning and representational learning	anonymous|onevsall_auc_maximization_an_effective_solution_to_the_lowresource_named_entity_recognition_problem	/pdf/370901538c75fce64416e4d976314d4c31c02535.pdf
PWWW73yQVp	3660	VARIATIONAL ADAPTIVE GRAPH TRANSFORMER FOR MULTIVARIATE TIME SERIES MODELING	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|variational_adaptive_graph_transformer_for_multivariate_time_series_modeling	/pdf/f415121ee11935102f6c9b1bacf57a352fb31634.pdf
44DHnx0Ya_j	3661	Coordinated Strategy Identification Multi-Agent Reinforcement Learning	['Multi-Agent Reinforcement Learning', 'Coordinated Strategy', 'Hierarchical Multi-Agent learning', 'Episodic Memory']	We present a framework which expedites and stabilizes learning of a hierarchical multi-agent reinforcement learning via episodic memory, while achieving coordinated behaviors among agents with a novel theoretic regularization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|coordinated_strategy_identification_multiagent_reinforcement_learning	/pdf/276a5e6f48cdaeb4cec5208198195869e63ee364.pdf
32w-1DCZuVS	3662	The Cost of Privacy in Fair Machine Learning	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|the_cost_of_privacy_in_fair_machine_learning	/pdf/43735400ef203b7a1c36f13a48efdcd39d21c6f2.pdf
i2e2wqt0nAI	3665	Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery	['symbolic regression for scientific discovery', 'physics', 'datasets', 'benchmarks']	We propose new datasets and evaluation metric to discuss the performance of symbolic regression for scientific discovery (SRSD).	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|rethinking_symbolic_regression_datasets_and_benchmarks_for_scientific_discovery	/pdf/8aed138140e9c5af4a96d9fc5176ab6d53061330.pdf
uVyD2VRZg_T	3666	The Emergence of Prototypicality: Unsupervised Feature Learning in Hyperbolic Space	['Unsupervised Learning', 'Prototypicality', 'Hyperbolic Space']	We propose a novel unsupervised learning method by leveraging the property of hyperbolic space for organizing images based on  prototypicality and semantics.	Deep Learning and representational learning	anonymous|the_emergence_of_prototypicality_unsupervised_feature_learning_in_hyperbolic_space	/pdf/2d4bd68acfd4e6d6ff50a647820ac91bb35d3d40.pdf
kugE_tCwsC	3668	Evaluating Robustness of Cooperative MARL: A Model-based Approach	['robust c-MARL', 'model-based adversarial attack']	A novel model-based adversarial attack framework for cooperative multi-agent reinforcement learning with novel victim agent selection strategy.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|evaluating_robustness_of_cooperative_marl_a_modelbased_approach	/pdf/85ffa906a22d4cf6ece151fbac2dc2f1d90df7d0.pdf
ugA1HX69sf	3670	Understanding Embodied Reference with Touch-Line Transformer	[]	People often refer to objects using both language expression and pointing gesture at the same time. Our model locate these objects (referents) more accurately using the virtual touch line. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|understanding_embodied_reference_with_touchline_transformer	/pdf/dce9892ba603c55b2f3de10c67b78d20762a8634.pdf
F61FwJTZhb	3671	Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning	[]	We train a bot that places first in a no-press Diplomacy tournament with humans by using human-data-regularized reinforcement learning and planning 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|mastering_the_game_of_nopress_diplomacy_via_humanregularized_reinforcement_learning_and_planning	/pdf/811340aa00ae9ca15e06a1379c00d156255fa2f6.pdf
LzPN-BHiJuc	3673	Linearly Constrained Bilevel Optimization: A Smoothed Implicit Gradient Approach	[]		Optimization (eg, convex and non-convex optimization)	anonymous|linearly_constrained_bilevel_optimization_a_smoothed_implicit_gradient_approach	/pdf/4454d5cb2b38d8817863eeec7931e40bcf0abe01.pdf
tVkrbkz42vc	3674	PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for Geometry-Agnostic System Identification	['System Identification', 'Neural Radiance Fields', 'Differentiable Physics', 'Material Point Method']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pacnerf_physics_augmented_continuum_neural_radiance_fields_for_geometryagnostic_system_identification	/pdf/2dff79095fe5e9ae94cfcb402e7919418b48c770.pdf
wUXcwhZ9yT	3675	Recommendation with User Active Disclosing Willingness	['recommender system', 'recommendation', 'collaborative filtering', 'user behavior modeling']		Applications (eg, speech processing, computer vision, NLP)	anonymous|recommendation_with_user_active_disclosing_willingness	/pdf/983a4646ac7bc7c4acaf1f5c3dc0d151f51716ac.pdf
JxpBP1JM15-	3676	Scaling Forward Gradient With Local Losses	[]		Deep Learning and representational learning	anonymous|scaling_forward_gradient_with_local_losses	/pdf/a1e0a1e038e9929ed5c081b47e1322ebd85a8bbb.pdf
a6NvoZ5DLoe	3677	DYNAMIC ENSEMBLE FOR PROBABILISTIC TIME- SERIES FORECASTING VIA DEEP REINFORCEMENT LEARNING	['Time series', 'ensemble', 'reinforcement learning']	We develop a general dynamic ensemble framework for probabilistic multi-horizon time series forecasting using deep reinforcement learning.	General Machine Learning (ie none of the above)	anonymous|dynamic_ensemble_for_probabilistic_time_series_forecasting_via_deep_reinforcement_learning	/pdf/805b2e57a74e0d4142dd9415f3adb9e5fba326d7.pdf
GPTjnA57h_3	3679	Free Lunch for Domain Adversarial Training: Environment Label Smoothing	['Out-of-Distribution Generalization', 'Domain adaptation/generalization', 'Domain adversarial training', 'environmnt label noise', 'non-asymptotic convergence']	We propose to smooth environment label for domain adversarial training methods, which is experimentally and theoretically shown able to improve training stability, local convergence, and robustness to noisy labels.	Deep Learning and representational learning	anonymous|free_lunch_for_domain_adversarial_training_environment_label_smoothing	/pdf/e7ca2965aa5c7fd0887790e9027cda6be4dd0f33.pdf
J0IhgZ8ziv-	3680	ENHANCING THE PRIVACY OF FEDERATED LEARNING THROUGH DATA SYNTHESIS	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|enhancing_the_privacy_of_federated_learning_through_data_synthesis	/pdf/f0d24abcc7c433cd7e1e2dd8cd45efdbdacdbefd.pdf
E1_fqDe3YIC	3681	Generative Gradual Domain Adaptation with Optimal Transport	['Domain Adaptation', 'Gradual Domain Adaptation', 'Distribution Shift']		General Machine Learning (ie none of the above)	anonymous|generative_gradual_domain_adaptation_with_optimal_transport	/pdf/2c41204f9ed862545debd48b76d156a719219b89.pdf
rJcLocAJpA6	3682	On Compositional Uncertainty Quantification for Seq2seq Graph Parsing	['Uncertainty Quantification', 'Seq2seq Graph Parsing']	In this paper, we aim to quantify and evaluate compositional uncertainty for seq2seq graph parsing by proposing a simple probabilistic framework and rigorous evaluation metrics.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|on_compositional_uncertainty_quantification_for_seq2seq_graph_parsing	/pdf/d3e0f384265903ee12b91f2b7f333544ded3f37c.pdf
jCpTofV7iY_	3683	Pre-trained Language Models can be Fully Zero-Shot Learners	['pre-trained language models', 'zero-shot learning', 'prompt']		Applications (eg, speech processing, computer vision, NLP)	anonymous|pretrained_language_models_can_be_fully_zeroshot_learners	/pdf/d101e66674ed8d6e4fb6df7b6ea270c3b3d7b673.pdf
QrdSiDAv5ek	3684	FACS: FAST ADAPTIVE CHANNEL SQUEEZING	['Fast Channel squeezing', 'Edge Devices', 'CNN']	Computationally Efficient Channel Squeezing in CNNs  with high representation power	Deep Learning and representational learning	anonymous|facs_fast_adaptive_channel_squeezing	/pdf/da005dfc1efb18f0e9086e568a6a4e835f9969db.pdf
N6iz-EQkuar	3685	Network Controllability Perspectives on Graph Representation	['Graph Representation', 'Network Controllability', 'Graph Classification']	We develop a novel graph representation method using network control properties and demonstrate its theoretical merits. 	Deep Learning and representational learning	anonymous|network_controllability_perspectives_on_graph_representation	/pdf/036d291ee71ee13c71a9d9f752aad73a7a8adf41.pdf
PArJcOptzg	3686	DeepGuiser: Learning to Disguise Neural Architectures for Impeding Adversarial Transfer Attacks	['Neural architecture extraction attack', 'neural architecture disguising', 'adversarial robustness', 'transferability predictor', 'policy learning']	DeepGuiser is an automatic, hardware-agnostic, and retrain-free neural architecture disguising method to disguise the neural architectures, to resist possible adversarial attacks rendered by the model extraction attacks. 	Deep Learning and representational learning	anonymous|deepguiser_learning_to_disguise_neural_architectures_for_impeding_adversarial_transfer_attacks	/pdf/23b0078eb8fbd1a4cfedc6824709e32331fcb574.pdf
FJdSi_seSg	3687	Do We Always Need to Penalize Variance of Losses for Learning with Label Noise?	[]		Unsupervised and Self-supervised learning	anonymous|do_we_always_need_to_penalize_variance_of_losses_for_learning_with_label_noise	/pdf/17e8db5a77780265d949c6819707d69c318681c9.pdf
0o_PPAJstY	3688	A Multi-objective Perspective towards Improving Meta-Generalization	['meta learning', 'multi-objective optimization']	We propose to improve meta-generalization from a multi-objective point of view. 	General Machine Learning (ie none of the above)	anonymous|a_multiobjective_perspective_towards_improving_metageneralization	/pdf/48a897589e5ee436a8f7144cab62279d604e2cab.pdf
Crw1sKsLDvl	3690	COMNET : CORTICAL MODULES ARE POWERFUL	['CNN Architecture', 'Multi-dimensional efficiencies', 'Cortical Modules', 'Columnar Structure', 'Real-Time Applications', 'Latency']	A novel CNN architecture leveraging biological structures in visual cortex to cater real-time applications with low latency, smaller depths	Deep Learning and representational learning	anonymous|comnet_cortical_modules_are_powerful	/pdf/7f8f5f709566d3f03c59c770650371c8b54bf921.pdf
rVM8wD2G7Dy	3691	Imbalanced Semi-supervised Learning with Bias Adaptive Classifier	['semi-supervised learning', 'weakly-supervised learning']	This work proposes a bi-level learning framework to learn a tailored classifier for imbalanced semi-supervised learning.	Deep Learning and representational learning	anonymous|imbalanced_semisupervised_learning_with_bias_adaptive_classifier	/pdf/cc9a393cb3759615bace55209a18db6f7f126fe8.pdf
rMkd7_6fB7	3694	The Eigenlearning Framework: A Conservation Law Perspective on Kernel Ridge Regression and Wide Neural Networks	['kernel regression', 'kernel ridge regression', 'wide neural networks', 'neural tangent kernel', 'ntk', 'generalization', 'conservation laws', 'learnability']	We identify a conserved quantity in kernel ridge regression and leverage it to develop a theory of generalization, concluding with various applications of our framework.	Deep Learning and representational learning	anonymous|the_eigenlearning_framework_a_conservation_law_perspective_on_kernel_ridge_regression_and_wide_neural_networks	/pdf/d861922b8f78d27d154b05583ec7cf71d8bac076.pdf
f8PIYPs-nB	3695	Leaves: Learning Views for Time-Series Data in Contrastive Learning	['Contrastive Learning', 'Data Augmentation', 'Learning Views', 'Time-Series Data', 'Adversarial Learning']	We propose a simple but effective method to automatrically learn views for time-series data in contrastive learning	Unsupervised and Self-supervised learning	anonymous|leaves_learning_views_for_timeseries_data_in_contrastive_learning	/pdf/bbfb043e9e7e517f2ca5901238e45aabf2a6da33.pdf
4MbGnp4iPQ	3697	Equivariant Shape-Conditioned Generation of 3D Molecules for Ligand-Based Drug Design	['molecules', 'equivariance', 'generation']	We develop a shape-conditioned 3D generative model for ligand-based drug design	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|equivariant_shapeconditioned_generation_of_3d_molecules_for_ligandbased_drug_design	/pdf/3b666dcd2c8ce0d9ceeb493aa88eebb639ce2cfd.pdf
vUC2qwPVvw	3698	Gradient-based Algorithms for Pessimistic Bilevel Optimization	['pessimistic bilevel optimization', 'convergence analysis', 'nonconvex', 'gradient-based method']	We propose the first gradient-based algorithm for pessimistic bilevel optimization, provide the first convergence result with nonlinear objective functions, and validate our design and analysis through experiments on several robust learning problems.	Optimization (eg, convex and non-convex optimization)	anonymous|gradientbased_algorithms_for_pessimistic_bilevel_optimization	/pdf/2cad44d5bcf253b3f9a116a2506ecc124883d674.pdf
U45w87vFQ3	3699	BinSGDM:  Extreme One-Bit Quantization for Communication Efficient Large-Scale Distributed Training 	['Distributed Learning', 'Optimizer', 'Communication Efficiency']	 Extreme One-Bit Quantization for Communication Efficient Large-Scale Distributed Training 	Deep Learning and representational learning	anonymous|binsgdm_extreme_onebit_quantization_for_communication_efficient_largescale_distributed_training	/pdf/80995230f7f7a030f5ecce05320e277dbb35ab3b.pdf
DD8ZJNdTPtO	3700	Stochastic Optimization under Strongly Convexity and Lipschitz Hessian: Minimax Sample Complexity	[]		Optimization (eg, convex and non-convex optimization)	anonymous|stochastic_optimization_under_strongly_convexity_and_lipschitz_hessian_minimax_sample_complexity	/pdf/2f062a0bd50b37bc1926f53a2dbe983fea87d072.pdf
lEkl0jdSb7B	3701	Any-scale Balanced Samplers for Discrete Space	['MCMC', 'Discrete Space Sampling', 'Locally Balanced Proposal']	We identify two key issues of existing gradient based locally balanced samplers, and provide improved proposals with adjusted weight function and 2nd order approximation.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|anyscale_balanced_samplers_for_discrete_space	/pdf/a917ad8223a89a460991271e7b5b3effc33a9548.pdf
iYZkvCji36L	3704	Hierarchical Multi-Resolution Graph Generation Networks	['Graph Generative models', 'GNN', 'Multinomial distribution']		Generative models	anonymous|hierarchical_multiresolution_graph_generation_networks	/pdf/7266d684fab5f0272f37e9b8d7339f3dac7f6258.pdf
cCjxF2QB-AT	3705	How Distinguishable Are Vocoder Models? Analyzing Vocoder Fingerprints for Fake Audio	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|how_distinguishable_are_vocoder_models_analyzing_vocoder_fingerprints_for_fake_audio	/pdf/f5ee54d7f1893337f3440c2b9ea5ad1e492f0b48.pdf
2YQrqe4RNv	3706	Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks	[]		Deep Learning and representational learning	anonymous|edgeformers_graphempowered_transformers_for_representation_learning_on_textualedge_networks	/pdf/ab9a22c7db8a026a19bd8e79ed286a1f20189c0d.pdf
cDVL245jZa	3707	GAPS: Few-Shot Incremental Semantic Segmentation via Guided Copy-Paste Synthesis	['continual learning', 'incremental learning', 'incremental segmentation', 'few-shot learning']	This paper proposes a guided copy-paste synthesis process for few-shot incremental semantic segmentation, which can be combined with existing methods to achieve dramatic performance increase.	Applications (eg, speech processing, computer vision, NLP)	anonymous|gaps_fewshot_incremental_semantic_segmentation_via_guided_copypaste_synthesis	/pdf/e18ee8ca5612ea42c5f443d8a1a4791f000a8431.pdf
O_m1c-A5w6w	3708	StepGCN: Step-oriented Graph Convolutional Networks in Representation Learning	[]		Deep Learning and representational learning	anonymous|stepgcn_steporiented_graph_convolutional_networks_in_representation_learning	/pdf/1f03ac243241c0a0911ea669da803351fa90e0bf.pdf
znLlSgN-4S0	3709	More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization	['Multi-Agent Reinforcement Learning']	We propose a novel multi-agent reinforcement learning algorithm where dependency among agents is explicitly considered	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|more_centralized_training_still_decentralized_execution_multiagent_conditional_policy_factorization	/pdf/e1efe882fec34c943d2dd502cf7ff684d4c7f31d.pdf
5FqeE2SojJi	3710	Proportional Amplitude Spectrum Training Augmentation for Synthetic-to-Real Domain Generalization	['Synthetic-to-Real Generalization', 'Fourier Space Augmentation', 'Single Domain Generalization']	We propose Proportional Amplitude Spectrum Training Augmentation (PASTA), an augmentation strategy for Synthetic-to-Real Generalization	Applications (eg, speech processing, computer vision, NLP)	anonymous|proportional_amplitude_spectrum_training_augmentation_for_synthetictoreal_domain_generalization	/pdf/52e39c1c12e7491b42128597a85886ca18d0d858.pdf
mqLowjofGBm	3711	Self-Supervised Logit Adjustment	['Long-tailed learning', 'self-supervised learning', 'logit adjustment', 'optimal transport']	We propose a novel algorithm for self-supervised long-tailed learning, which overcomes the intrinsic limitation of the conventional contrastive learning loss, i.e., sample-level uniformity, and progressively approaches the category-level uniformity.	Unsupervised and Self-supervised learning	anonymous|selfsupervised_logit_adjustment	/pdf/ff4c9cd0d1f1e200b5a4366d3d7cc80b6352770a.pdf
zA7hVj3rR19	3712	How hard are computer vision datasets? Calibrating dataset difficulty to viewing time	['deep learning', 'computer vision', 'cognitive science', 'datasets']	We develop a new dataset difficulty metric based on how long humans must view an image in order to classify a target object, finding that the distribution of current datasets is skewed towards easy images.	Applications (eg, speech processing, computer vision, NLP)	anonymous|how_hard_are_computer_vision_datasets_calibrating_dataset_difficulty_to_viewing_time	/pdf/4a6997b8721473954b4dad5139d7b6ba92161a7a.pdf
iNUtsk4h2q1	3714	Restoration based Generative Models	['Diffusion Generative Models', 'Image Restoration', 'Maximum a Posteriori']	A new framework on generative modeling in the perspective of restoration.	Generative models	anonymous|restoration_based_generative_models	/pdf/3374a9a0a5aa3ad672e180736347b8fcf7924e56.pdf
tsPXEkMzPjB	3716	Learning to Decouple Complex System for Sequential Data	['neural differential equation', 'sequential learning', 'decoupling complex system']	We propose to learn to decouple a complex system into simple but interacting latent sub-systems, which proved effective and powerful in sequential modeling.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_to_decouple_complex_system_for_sequential_data	/pdf/d30ab4773bb8118e17d3b951e3ed2ab5eb412c46.pdf
0Ij9_q567Ma	3717	Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives	['Automatic Machine learning', 'Hyperparameter tuning', 'Lexicographic preference']	Hyperparameter tuning under lexicographic preference	General Machine Learning (ie none of the above)	anonymous|targeted_hyperparameter_optimization_with_lexicographic_preferences_over_multiple_objectives	/pdf/447178a891c809b56249a885a5ca576ed569e7cd.pdf
UR_HvaCdgt6	3718	Graph-informed Neural Point Process With Monotonic Nets	['Point Process', 'Sequential Model', 'Graph Neural Network']	Graph-informed neural point process for sequential data modeling with conditional monotonic neural network.	Deep Learning and representational learning	anonymous|graphinformed_neural_point_process_with_monotonic_nets	/pdf/ada8c565c708c98d70b491a03c0e83f64793bfd8.pdf
PqvMRDCJT9t	3719	Flow Matching for Generative Modeling	['continuous normalizing flows', 'generative models']	We introduce a new simulation-free approach for training Continuous Normalizing Flows, generalizing the probability paths induced by simple diffusion processes. We obtain state-of-the-art on ImageNet in both NLL and FID among competing methods.	Generative models	anonymous|flow_matching_for_generative_modeling	/pdf/6aa08c71305fe00c8318d531018e95bcdea21aa4.pdf
Peot1SFDX0	3720	Preference Transformer: Modeling Human Preferences using Transformers for RL	['preference-based reinforcement learning', 'human-in-the-loop reinforcement learning', 'deep reinforcement learning']	We introduce a transformer-based architecture for preference-based RL considering non-Markovian rewards.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|preference_transformer_modeling_human_preferences_using_transformers_for_rl	/pdf/db57bb604334f4ced29fa3522ecb8ae1fa030eb9.pdf
elIEtsQdOYP	3721	Tensor Decompositions For Temporal Knowledge Graph Completion with Time Perspective	['Knowledge Graph', 'Temporal Knowledge Graph Completion']	Instead of focusing on facts and their evolution, we observe temporal knowledge graphs through time perspective, and improve the current tensor decomposition model based on the observed properties.	Deep Learning and representational learning	anonymous|tensor_decompositions_for_temporal_knowledge_graph_completion_with_time_perspective	/pdf/3a0f9c3ff9ef4edc00608c5cdf170f05866570eb.pdf
z92lBy1ehjI	3726	Winning Both the Accuracy of Floating Point Activation and the Simplicity of Integer Arithmetic	[]		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|winning_both_the_accuracy_of_floating_point_activation_and_the_simplicity_of_integer_arithmetic	/pdf/59c1d56b62be595c3c364dd4be9fc4505077355d.pdf
oCl1ggnIZ1_	3727	Analysis of Radio Localiser Networks under Distribution Shift	['RF localisation', 'RF positioning', 'robustness', 'benchmarking', 'domain shift', 'localisation', 'positioning']	Comparing and benchmarking SOTA RF localisation methods	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|analysis_of_radio_localiser_networks_under_distribution_shift	/pdf/3ef102162e0dd2ec9e9db853770de0adeb1f6433.pdf
t02FF6Fj5mH	3728	Best Possible Q-Learning	['multi-agent reinforcement learning']	A new Q-learning algorithm for multi-agent reinforcement learning	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|best_possible_qlearning	/pdf/2d4adcdac753bdb37dbe606e9691b82518b88e12.pdf
bn2J_zqfsEf	3729	Equivariant Disentangled Transformation for Domain Generalization under Combination Shift	['distribution shift', 'domain generalization', 'equivariance', 'invariance', 'disentanglement', 'algebraic theory', 'group theory', 'category theory']	Learning data augmentations based on the algebraic structures of labels is a promising approach for combination shift.	General Machine Learning (ie none of the above)	anonymous|equivariant_disentangled_transformation_for_domain_generalization_under_combination_shift	/pdf/b0b2f36cc31769688bcf0e0fa0a3e7591ad8a7fa.pdf
KDTaSChivXd	3730	Learning from student's mistakes: Improving mean teacher for end-to-end semi-supervised video action detection	['semi-supervised', 'activity detection', 'student-teacher', 'video understanding']		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_from_students_mistakes_improving_mean_teacher_for_endtoend_semisupervised_video_action_detection	/pdf/35b8da85cb04d5610bd45d601dfd6e61bf657cfb.pdf
QrnDe_9ZFd8	3731	Task Ambiguity in Humans and Language Models	['task ambiguity', 'safety', 'language models', 'few-shot learning', 'in-context learning']	We motivate the direction of studying task ambiguity in humans and language models, evaluating them on a new benchmark of ambiguously-specified tasks and develop methods for improving performance	Applications (eg, speech processing, computer vision, NLP)	anonymous|task_ambiguity_in_humans_and_language_models	/pdf/9040ac029b672b33b12a5d6473f116ce2c240999.pdf
sXfWoK4KvSW	3732	Long-Tailed Partial Label Learning via Dynamic Rebalancing	['long-tailed learning', 'partial label learning']	We propose a novel method RECORDS for long-tailed partial label learning, which overcomes the drawback of the straightforward combination between long-tailed learning and partial label learning, and significantly improves the performance.	Deep Learning and representational learning	anonymous|longtailed_partial_label_learning_via_dynamic_rebalancing	/pdf/41ac3bb64f02c549c205da6a7a10d77392adc7e3.pdf
L5pRidCQlRc	3733	The Final Ascent: When Bigger Models Generalize Worse on Noisy-Labeled Data	['supervised learning', 'generalization', 'overfitting', 'memorization']	When noise-to-sample-size ratio is sufficiently large, increasing the width or density of the model beyond a certain point only hurts the generalization performance.	Deep Learning and representational learning	anonymous|the_final_ascent_when_bigger_models_generalize_worse_on_noisylabeled_data	/pdf/ef74e872aa7034026e766808d2854cac2ae8ab3b.pdf
A2EeU2Jn3iX	3734	Game-Theoretic Understanding of Misclassification	[]		Deep Learning and representational learning	anonymous|gametheoretic_understanding_of_misclassification	/pdf/5faf31f7ae8da1dc54b3a2801eb83f27ea5f88e0.pdf
A4fSkNAs6E1	3735	Hierarchical Gaussian Mixture based Task Generative Model for Robust Meta-Learning	[]		Deep Learning and representational learning	anonymous|hierarchical_gaussian_mixture_based_task_generative_model_for_robust_metalearning	/pdf/928b1a4c0377951bcf298314fdd5b711e5d31ce5.pdf
Plr5l7r0jY6	3736	Language model with Plug-in Knowldge Memory	['pre-training', 'language model', 'memory']	we propose a pre-training framework to decouple the knowledge storage from PLM	Applications (eg, speech processing, computer vision, NLP)	anonymous|language_model_with_plugin_knowldge_memory	/pdf/81e32297d32bed3e2cfa27b3e25e930033611c3b.pdf
emwOOlciu9v	3737	The Dark Side of Invariance: Revisiting the Role of Augmentations in Contrastive Learning	['contrastive learning', 'self-supervised learning', 'feature suppression']	Contrastive learning can succeed even if the augmentations sometimes change the ground truth label—and there are cases where this can actually help rather than hurt learning	Unsupervised and Self-supervised learning	anonymous|the_dark_side_of_invariance_revisiting_the_role_of_augmentations_in_contrastive_learning	/pdf/4a657ca0e9728093bb72dffbf67b13d705b8fa67.pdf
5rX7M4wa2R_	3738	On Regularization for Explaining Graph Neural Networks: An Information Theory Perspective	['Explainability', 'Graph Neural Networks', 'Regularization']	We rethink the role of regularization in GNNs explainability from the perspective of information theory, and propose four intriguing propositions of regularization. 	Deep Learning and representational learning	anonymous|on_regularization_for_explaining_graph_neural_networks_an_information_theory_perspective	/pdf/9b73ae9ff16ad388109a3c9da443635dcd5559c1.pdf
jVDhQl8mPpx	3739	Route, Interpret, Repeat: Blurring the Line Between Posthoc Explainability and Interpretable Models 	['Explainable AI', 'Posthoc explanation', 'Computer Vision']	We seek to carve out the interpretable model from trained blackbox iteratively and explain the prediction in terms of human interpretable concepts using First order logic (FOL))	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|route_interpret_repeat_blurring_the_line_between_posthoc_explainability_and_interpretable_models	/pdf/08cea1e0029ea8f733bb89b8fdec4670a08e8b3f.pdf
Cp-io_BoFaE	3740	FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation	['Complex Fluid Manipulation', 'Differentiable Physics']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|fluidlab_a_differentiable_environment_for_benchmarking_complex_fluid_manipulation	/pdf/cf1b1e6a2b51d3cc31aff62c0eea98379e6b42fb.pdf
Bc_R_YyycnK	3741	Learning Multi-Object Positional Relationships via Emergent Communication	['emergence communication']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_multiobject_positional_relationships_via_emergent_communication	/pdf/06a261aea2ea099601ca2cc09f3d8a07442c982a.pdf
OA-gbD-ANFt	3742	Inverse Optimal Transport with Application to Contrastive Learning	['Contrastive Learning', 'Inverse Optimal Transoprt']		Deep Learning and representational learning	anonymous|inverse_optimal_transport_with_application_to_contrastive_learning	/pdf/aca0a3661ea30ff40ab09094022a136c392fe02c.pdf
JAezPMehaUu	3743	Mosaic Representation Learning for Self-supervised Visual Pre-training	['self-supervised learning', 'computer vision']	We propose a simple and effective mosaic representation learning framework consisting of a new data augmentation strategy, which aims to adequately learn discriminative feature representations.	Unsupervised and Self-supervised learning	anonymous|mosaic_representation_learning_for_selfsupervised_visual_pretraining	/pdf/b1203a3aceddf93913efe6c9282123f745828b4b.pdf
G29-Xa55dCXD	3746	Optical Flow Regularization of Implicit Neural Representations for Video Frame Interpolation	['Implicit Neural Representation', 'Video Representation', 'Video Frame Interpretation']	We show that constraining the derivatives of video INR to satisfy the optical flow constraint equation allows to reach state of the art VFI on limited motion ranges without relying on additional training data.	Deep Learning and representational learning	anonymous|optical_flow_regularization_of_implicit_neural_representations_for_video_frame_interpolation	/pdf/e730619231cd48bd690ddb86cdb84fc30426b2bc.pdf
NB69ih1tiA1	3747	Revisiting Over-smoothing in Graph Neural Networks	[]		Deep Learning and representational learning	anonymous|revisiting_oversmoothing_in_graph_neural_networks	/pdf/3a6b96056611c6b8f54d701c9aff85c3c2f71f79.pdf
04K3PMtMckp	3748	The hidden uniform cluster prior in self-supervised learning	['self-supervised learning', 'unsupervised learning', 'representation learning', 'transfer learning']	Many common self-supervised learning frameworks provably impose a hidden uniform prior, which is detrimental when pretraining with real-world class-imbalanced data.	Unsupervised and Self-supervised learning	anonymous|the_hidden_uniform_cluster_prior_in_selfsupervised_learning	/pdf/cfd8b0e4924c6eca83e802c37f61cc43c13faf44.pdf
sDCMrYnXNGY	3749	Which is Better for Learning with Noisy Labels: The Semi-supervised Method or Modeling Label Noise?	[]		Unsupervised and Self-supervised learning	anonymous|which_is_better_for_learning_with_noisy_labels_the_semisupervised_method_or_modeling_label_noise	/pdf/6f1373d67e72e77f6209e585c555a8cd563eef53.pdf
1Lr5QxntGcM	3750	NeuralEQ: Neural-Network-Based Equalizer for High-Speed Wireline Communication	['Forward-backward algorithm', 'Equalizer', 'Neural network', 'BER']		Applications (eg, speech processing, computer vision, NLP)	anonymous|neuraleq_neuralnetworkbased_equalizer_for_highspeed_wireline_communication	/pdf/f628ebaba66164bf96b6b891218d72d5bb916ce7.pdf
k5PEHHY4spM	3751	An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation	['dialogue systems', 'diverse text generation', 'EM algorithm']	We propose an efficient, effective, and theoretically understood EqHard-EM algorithm for diverse dialogue generation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|an_equalsize_hard_em_algorithm_for_diverse_dialogue_generation	/pdf/b78241ed36f63222f1aa140374e89b8037d86a56.pdf
p6wiThIOS5m	3752	Provably efficient multi-task Reinforcement Learning in large state spaces	['Reinforcement Learning', 'Multi-task Learning', 'Function Approximation', 'Sample Effficiency']	We develop sample efficient reinforcement learning algorithm with general function approximation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|provably_efficient_multitask_reinforcement_learning_in_large_state_spaces	/pdf/1a52f424033cba685a7806ab4335fc8be5fd12a5.pdf
G1STYDZDBeH	3753	Mitigating Out-of-Distribution Data Density Overestimation in Energy-Based Models	['Energy-Based Model']	We investigate why EBMs assign high density to OOD data and propose a method to mitigate this problem.	Generative models	anonymous|mitigating_outofdistribution_data_density_overestimation_in_energybased_models	/pdf/a9f3f5507d917f3ee0aace0965f760ff065e0f4a.pdf
SNwH0dDGl7_	3754	Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approximation	['Reinforcement Learning', 'Deployment efficiency', 'Reward free RL', 'Low adaptive RL']	We design algorithms for reward free RL under linear MDP with near-optimal deployment complexity and sample complexity.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|nearoptimal_deployment_efficiency_in_rewardfree_reinforcement_learning_with_linear_function_approximation	/pdf/fbfd71f3fbe06f05ee0d49dabba1813fc745e0ed.pdf
ydv0gtW4WLU	3755	CRISP: Curriculum inducing Primitive Informed Subgoal Prediction for Hierarchical Reinforcement Learning	['Hierarchical Reinforcement Learning', 'Inverse Reinforcement Learning', 'Imitation Learning', 'Curriculum Learning']	We effectively leverage expert demonstrations using our curriculum learning based approach to deal with non-stationarity in the context of hierarchical reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|crisp_curriculum_inducing_primitive_informed_subgoal_prediction_for_hierarchical_reinforcement_learning	/pdf/5d4efd1e632a72d9a90895ceb18fd6a77a3b956d.pdf
m_thN8e6qrF	3756	FedDebias: Reducing the Local Learning Bias Improves Federated Learning on Heterogeneous Data	['Federated Learning']	We propose a unified method to reduce the local feature and classifier bias in Federated Learning.	Deep Learning and representational learning	anonymous|feddebias_reducing_the_local_learning_bias_improves_federated_learning_on_heterogeneous_data	/pdf/9bbcde8d646628037592831b92782891772e2c5f.pdf
7wk9PqiiW2D	3757	ProsodyBERT: Self-Supervised Prosody Representation for Style-Controllable TTS	['prosody', 'self-supervised learning', 'text-to-speech', 'speech processing', 'emotion recognition', 'speech synthesis']	a self-supervised approach to learning prosody representations from raw audio	Applications (eg, speech processing, computer vision, NLP)	anonymous|prosodybert_selfsupervised_prosody_representation_for_stylecontrollable_tts	/pdf/0e205e308b7410258838d9f218902a5372bc4c98.pdf
-pAV454n6mS	3758	GRAPHSENSOR: A Graph Attention Network for Time-Series Sensor Data	[]		Deep Learning and representational learning	anonymous|graphsensor_a_graph_attention_network_for_timeseries_sensor_data	/pdf/2fffa6f7f4a72e3f941b2f4d92ff21632f73381d.pdf
oGVu9spZaJJ	3759	Asymptotic Instance-Optimal Algorithms for Interactive Decision Making	['reinforcement learning theory', 'instance optimality']	We design the first instance-optimal algorithm for general interactive decision making problems.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|asymptotic_instanceoptimal_algorithms_for_interactive_decision_making	/pdf/84ec46e854f6afc01d089ef15c25c2e663f1b5d0.pdf
9MDjKb9lGi	3760	The batch size can affect inference results	['Matrix operation', 'Floating-point', 'Batch size', 'GEMM']		Deep Learning and representational learning	anonymous|the_batch_size_can_affect_inference_results	/pdf/57b66dce7d9597251b44d2a33e727e01c48bd036.pdf
n-hKHMzBgy	3761	Max-Margin Works while Large Margin Fails: Generalization without Uniform Convergence	['generalization', 'uniform convergence', 'overparameterization', 'learning theory', 'max-margin', 'two-layer neural network']	We prove generalization for max-margin solutions on a 2 Layer NN problem in regimes where uniform convergence bounds provably fail.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|maxmargin_works_while_large_margin_fails_generalization_without_uniform_convergence	/pdf/73f505b146d4df73c996466ba8ce3d7f1e821665.pdf
d8VrVfNARSy	3763	On Nullspace of Vision Transformers and What Does it Tell Us?	['nullspace', 'vision transformers', 'robustness', 'watermarking', 'fooling interpretations', 'fooling models']	Our work highlights and discusses the concept of nullspace wrt vision transformers.	General Machine Learning (ie none of the above)	anonymous|on_nullspace_of_vision_transformers_and_what_does_it_tell_us	/pdf/3c6aa6b2fefade6e428d66639c3373724fed3800.pdf
0c2SbGJ3Lt	3764	Textless Phrase Structure Induction from Visually-Grounded Speech	['unsupervised speech processing', 'grammar induction', 'speech representation learning', 'visually-grounded representation learning']	The first study on grammar induction from audio-visual inputs, without relying on intermediate text or ASR. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|textless_phrase_structure_induction_from_visuallygrounded_speech	/pdf/ae2b94a0f611378d9b1664df60489a27d93c2f79.pdf
Hh0BdBf6Ls	3766	UNREAL: Unlabeled Nodes Retrieval and Labeling for Heavily-imbalanced Node Classification	['Node Classification', 'Heavily-imbalanced Representation Learning', 'Graph Neural Networks']	A method for retrieving unlabeled node information to handle heavily-imbalanced node classification	Deep Learning and representational learning	anonymous|unreal_unlabeled_nodes_retrieval_and_labeling_for_heavilyimbalanced_node_classification	/pdf/ac92a9abdeeab7d5b021f97214b95b7bcb2cbfe2.pdf
Sme6eesZqW	3770	PADDLES: Phase-Amplitude Spectrum Disentangled Early Stopping for Learning with Noisy Labels	['Learning with noisy labels', 'Frequency domain decomposition', 'Early Stopping Training']	We propose a new early stopping training method for learning with noisy labels by choosing different stopping points for the Phase and Amplitude spectrum in the frequency domain. 	Unsupervised and Self-supervised learning	anonymous|paddles_phaseamplitude_spectrum_disentangled_early_stopping_for_learning_with_noisy_labels	/pdf/5a2cbf43855cf17c47e0262c875abadcd2307a10.pdf
6FEULL9vSUt	3773	Learning to Predict Parameter for Unseen Data	['Parameter Prediction', 'Training paradigm']		Deep Learning and representational learning	anonymous|learning_to_predict_parameter_for_unseen_data	/pdf/7c5f57d300cddda9ac60506c24fc5828ea6fee38.pdf
csccDKhK7tw	3774	MDPose: Real-Time Multi-Person Pose Estimation via Mixture Density Model	['Instance-aware Pose Estimation', 'Density Estimation', 'Mixture Model']	We reformulate multi-person pose estimation task as a density estimation, enabling real-time instance-aware keypoint estimation without any additional instance identification process.	Applications (eg, speech processing, computer vision, NLP)	anonymous|mdpose_realtime_multiperson_pose_estimation_via_mixture_density_model	/pdf/f0f578450b05fc9b28c3248fc24c3bdcf0517a3d.pdf
MofT9KEF0kw	3775	Pushing the Accuracy-Fairness Tradeoff Frontier with Introspective Self-play	['Uncertainty Quantification', 'Spurious Correlation', 'Active Learning']	Principled training method to improve deep model's uncertainty and active learning performance under dataset bias.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|pushing_the_accuracyfairness_tradeoff_frontier_with_introspective_selfplay	/pdf/ec83f2b41c0523e5138700043e4a7145ca2fb268.pdf
2Fb-h04mt5I	3776	Robustify Transformers with Robust Kernel Density Estimation	['Transformers', 'Kernel Density Estimation', 'Robustness']	We propose a robust transformer that can that can alleviate the effect from contaminated data while improve the clean data performance.	Deep Learning and representational learning	anonymous|robustify_transformers_with_robust_kernel_density_estimation	/pdf/b393b52ae9c70e3e226ef50ad522e48a8a4927f1.pdf
xisxfxXJI21	3777	Open-domain Visual Entity Linking	['Open-domain Visual Entity Linking', 'Vision and Language']	We present a new task (with an associating dataset) that targets at linking visual contents to entities in a knowledge base	Applications (eg, speech processing, computer vision, NLP)	anonymous|opendomain_visual_entity_linking	/pdf/440d27c1a283a3f1be4089f778e407b1ed434a96.pdf
HwbEioBGLo3	3778	Rethinking Knowledge Distillation with Raw Features for Semantic Segmentation	['Knowledge Distillation', 'Semantic Segmentation', 'Raw Feature Learning']	In-depth analysis of the raw feature distillation and the design of an effective feature distillation method for semantic segmentation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|rethinking_knowledge_distillation_with_raw_features_for_semantic_segmentation	/pdf/189bc47015ca7b2b3733cef704ecd392f7158d2b.pdf
hf6JLVbAog	3779	Revisiting the Activation Function for Federated Image Classification	['Federated Learning', 'Activation Function']	We empirically observe that off-the-shelf activation functions used in centralized setting get a totally different order of accuracy in federated learning.	General Machine Learning (ie none of the above)	anonymous|revisiting_the_activation_function_for_federated_image_classification	/pdf/a03e838cb0f757a08d8b90d99e4c3cd1be280d02.pdf
1VQnc0wnIQ	3781	Understanding Graph Contrastive Learning From A Statistical Perspective	['graph contrastive learning', 'unsupervised', 'general principles']	From a statistical perspective, we propose two principles to guide graph contrastive learning.	Unsupervised and Self-supervised learning	anonymous|understanding_graph_contrastive_learning_from_a_statistical_perspective	/pdf/8012bb972d5784791b746bdd3042e5725cecddda.pdf
zAxuIJLb38	3782	Knowledge Unlearning for Mitigating Privacy Risks in Language Models	['privacy', 'large language models', 'knowledge unlearning', 'natural language processing']	We propose knowledge unlearning for efficiently providing empirical privacy guarantees for large language models as an alternative solution to existing methods.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|knowledge_unlearning_for_mitigating_privacy_risks_in_language_models	/pdf/329c5e122a3908e2c45965fd288c3a8213be14c6.pdf
Ms4S3XC3vtW	3783	Concealing Sensitive Samples for Enhanced Privacy in Federated Learning	['Privacy preserving', 'Model inversion attack', 'Federated Learning']	A method for improving privacy in federated learning by obfuscating sensitive data with adaptively synthesized concealed samples.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|concealing_sensitive_samples_for_enhanced_privacy_in_federated_learning	/pdf/cd65c84ca41c640abe50ef30b5c48c307b13e1d0.pdf
Z_tmYu060Kr	3784	Squeeze Training for Adversarial Robustness	['Adversarial Training', 'Adversarial Examples', 'Model Robustness']	We highlight that some collaborative examples, which show extremely lower prediction loss, can be utilized to enhance adversarial training. A novel method called squeeze training (ST) is thus proposed.	Deep Learning and representational learning	anonymous|squeeze_training_for_adversarial_robustness	/pdf/25713c14b1dd6204f0130965947b6f63e3625bb1.pdf
a18z-D9l763	3785	Poisoning Generative Models to Promote Catastrophic Forgetting	['poisoning attacks', 'backdoor attacks']	We develop a novel poisoning attack on generative models to promotes catastrophic forgetting.	General Machine Learning (ie none of the above)	anonymous|poisoning_generative_models_to_promote_catastrophic_forgetting	/pdf/287d22b552f6156440f73cd1083c6ed883bdb8c8.pdf
nNpv6IDLu5	3787	Clustering for directed graphs using parametrized random walk diffusion kernels	['clustering', 'diffusion geometry', 'parametrized random walks', 'directed graphs']	A novel clustering algorithm for directed graphs based on the diffusion geometry framework and parametrized random walk operators	General Machine Learning (ie none of the above)	anonymous|clustering_for_directed_graphs_using_parametrized_random_walk_diffusion_kernels	/pdf/dc7e045c31fc8ee2eb9b4a43d83a83662ff3e592.pdf
MpwWSMOlkc	3788	Local Distance Preserving Auto-encoders using Continuous k-Nearest Neighbours Graphs	['manifold learning', 'representational learning', 'generative models']		Deep Learning and representational learning	anonymous|local_distance_preserving_autoencoders_using_continuous_knearest_neighbours_graphs	/pdf/a92bfd1104557dde36cb8e76c175d280b76513fa.pdf
wF-QfZebInw	3789	Pose Transfer using a Single Spatial Transformation	[]		Generative models	anonymous|pose_transfer_using_a_single_spatial_transformation	/pdf/353ffb4a6d384c7df7b32b8edf82eedf00fdf22c.pdf
Yc9tld-ENbf	3790	Backdoor Mitigation by Correcting Activation Distribution Alteration	['backdoor', 'Trojan', 'adversarial learning', 'deep neural network']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|backdoor_mitigation_by_correcting_activation_distribution_alteration	/pdf/af27752e75f6e47d933407c498c301e9a5f0e5ec.pdf
1YE_zTFICdr	3791	Deep Attention Pooling Graph Neural Network for Text Classification	['GNN', 'Attention', 'Pooling', 'Adjacency matrix', 'Text Classification']	A fresh model based on GNN with dual adjacency matrix, and attention pooling for text classification.	Applications (eg, speech processing, computer vision, NLP)	anonymous|deep_attention_pooling_graph_neural_network_for_text_classification	/pdf/67ac5bf8250cd897cb914835539b95204d3815f6.pdf
ZEXh0XyO2hh	3792	Learning Binary Networks on Long-Tailed Distributions	['binary neural network', 'long-tailed recognition', 'distillation']	We propose the first method to learn binary networks on long-tailed distributions in the literature.	Deep Learning and representational learning	anonymous|learning_binary_networks_on_longtailed_distributions	/pdf/ad22d47e85eaeedbdf14ec3a9fe682eee7b3e40a.pdf
_kf9GU5c_sE	3793	Graph Neural Networks for Aerodynamic Flow Reconstruction from Sparse Sensing	['CFD', 'flow reconstruction', 'GNNs']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|graph_neural_networks_for_aerodynamic_flow_reconstruction_from_sparse_sensing	/pdf/880f2b832696557ae4b2897d62c044c3949bebd2.pdf
RqJZTlQMph	3794	Weakly Supervised Neuro-Symbolic Image Manipulation via Multi-Hop Complex Instructions	['Neuro-Symbolic Reasoning', 'Natural Language Guided Image Manipulation', 'Visual Question Answering', 'Weakly Supervised Learning']	We propose a weakly supervised neuro-symbolic approach for the problem of image manipulation using text instructions.	Deep Learning and representational learning	anonymous|weakly_supervised_neurosymbolic_image_manipulation_via_multihop_complex_instructions	/pdf/8c2c5e6f35a5f7820c9c88da2bac224ac1c0efc4.pdf
sE7-XhLxHA	3795	NewModel: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing	[]		Deep Learning and representational learning	anonymous|newmodel_improving_deberta_using_electrastyle_pretraining_with_gradientdisentangled_embedding_sharing	/pdf/9810b5199061bfcf7fe6af3444b8a0c6354f262d.pdf
1uPo_IrEp8	3796	Online Reinforcement Learning via Posterior Sampling of Policy	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|online_reinforcement_learning_via_posterior_sampling_of_policy	/pdf/4db1bc48d7b63ce7368403043d7cf521bb9e233f.pdf
mduJQSy7KE	3797	Meta-Weighted Language Model Tuning for Augmentation-Enhanced Few-Shot Learning	['Few-Shot Learning', 'Natural Language Understanding']	We study how to effectively tune language models to generate training samples for few-shot learning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|metaweighted_language_model_tuning_for_augmentationenhanced_fewshot_learning	/pdf/e0784246304caa122a4a29661bc48018f92097d6.pdf
jsZ8PDQOVU	3799	Task-Agnostic Online Meta-Learning in Non-stationary Environments	['online meta-learning', 'domain shift', 'dynamic regret', 'out of distribution detection']	We propose a novel algorithm for task-agnostic online meta-learning in non-stationary environments without knowledge of task boundaries. 	Deep Learning and representational learning	anonymous|taskagnostic_online_metalearning_in_nonstationary_environments	/pdf/78b993d002dc62f43fd5d5d195ac2581553aa9c7.pdf
m0X42gFenw	3800	Neural Semi-Counterfactual Risk Minimization	['semi-Counterfactual risk minimization', 'importance weighting upper bound', 'KL regularisation', 'Batch learning']	we study the semi-counterfactual risk minimization by considering access to both known reward and unknown reward logged datasets.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|neural_semicounterfactual_risk_minimization	/pdf/9af18fd8d4f7f9b4ef93525121c48f3a9e30305b.pdf
3gZop22KWP	3801	UNDERSTANDING PURE CLIP GUIDANCE FOR VOXEL GRID NERF MODELS	['Text to 3D Generation', 'CLIP', 'NeRF', 'Adversarial Examples', 'Augmentation']	We explore various mechanics that prevent adversarial generations from using CLIP as guidance for training a voxel grid NeRF model without any datasets.	Generative models	anonymous|understanding_pure_clip_guidance_for_voxel_grid_nerf_models	/pdf/6508f5874ccb152ccc034aeef316568ee0b55045.pdf
HcGb9QnNAew	3804	Global Nash Equilibrium in a Class of Nonconvex N-player Games	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|global_nash_equilibrium_in_a_class_of_nonconvex_nplayer_games	/pdf/ab8236534d482d61e2d62b71a9068433e07f7710.pdf
PRpO-cOCQoX	3805	Rethinking Missing Modality Learning: From a Decoding View	['multimodal', 'decoding', 'tensor decomposition']		Applications (eg, speech processing, computer vision, NLP)	anonymous|rethinking_missing_modality_learning_from_a_decoding_view	/pdf/65be97f9e0eee350e5b5f375ee5fb834f795dc3c.pdf
sn8w7P9TrYf	3806	Linear Convergence of Decentralized FedAvg for Non-Convex Objectives: The Interpolation Regime	['Polyak-Lojasiewicz (PL) inequality', 'Federated Averaging', 'Linear convergence']	Our work shows linear convergence for Federated Averaging algorithm in {\em Server} and {\em Decentralized} settings.	Optimization (eg, convex and non-convex optimization)	anonymous|linear_convergence_of_decentralized_fedavg_for_nonconvex_objectives_the_interpolation_regime	/pdf/ff2d78d975b7de5dcf90b8d8bbe5510437a3dd99.pdf
0DIkhwclYX3	3807	Efficient debiasing with contrastive weight pruning	['Debiasing', 'spurious correlation', 'pruning']		Deep Learning and representational learning	anonymous|efficient_debiasing_with_contrastive_weight_pruning	/pdf/32246884a84097dbde0928b46d9cdf2297db7f4e.pdf
OUV0Fh5Lgm2	3808	Robust Quantity-Aware Aggregation for Federated Learning	['Federated Learning', 'Robustness', 'Defense']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robust_quantityaware_aggregation_for_federated_learning	/pdf/76bc0a6212a6d25fe9a1c8137fd46db77b63684a.pdf
cRQwl-59CU8	3809	UTC-IE: A Unified Token-pair Classification Architecture for Information Extraction	['Information extraction', 'unified classification', 'Transformer', 'CNN']	Reformulate and unify three IE tasks as token-pair classifications and propose Plusformer to effectively model the interaction between token pairs.	Applications (eg, speech processing, computer vision, NLP)	anonymous|utcie_a_unified_tokenpair_classification_architecture_for_information_extraction	/pdf/fbfdcff665cb7477aa6d8833da3bf60d1c9b9975.pdf
qs2YCziX2o-	3810	On The Relative Error of Random Fourier Features for Preserving Kernel Distance	['random Fourier features', 'kernel methods', 'dimension reduction', 'clustering', 'Laplacian kernel']	We characterize for what kernels the random Fourier features method, proposed in a seminal paper by Rahimi and Recht, preserves the relative-error for the kernel distance.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_relative_error_of_random_fourier_features_for_preserving_kernel_distance	/pdf/82b0f7fc74bc4a96572e9c2f1cdd275d7f55847b.pdf
bQZ2wEYxRBL	3811	PartAfford: Part-level Affordance Discovery	[]	Discover 3D object part affordances by learning contrast in affordance compositions.	Deep Learning and representational learning	anonymous|partafford_partlevel_affordance_discovery	/pdf/d59721baf1604dcaad701e4140a8b28060c213ff.pdf
fB4V-2QvCEm	3814	Scaling Laws in Mean-Field Games	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|scaling_laws_in_meanfield_games	/pdf/893da14b5bd8cd168975bf4b3b10dfc6ea27650c.pdf
F7f4BYnDAIc	3815	Sampled Transformer for Point Sets	[]		Deep Learning and representational learning	anonymous|sampled_transformer_for_point_sets	/pdf/73c21d68be7e1c55ec7a8a5207cbe5e2eb059ace.pdf
2EFQ_QlcPs8	3816	Multi-Vector Retrieval as Sparse Alignment	['natural language processing', 'document retrieval', 'information retrieval']	We propose a novel multi-vector retrieval model with pairwise alignment and unary salience.	Applications (eg, speech processing, computer vision, NLP)	anonymous|multivector_retrieval_as_sparse_alignment	/pdf/68594e0449f8b0351de7967b32bdb96df12add29.pdf
o-Yxq5iicIp	3817	Adversarial Robustness based on Randomized Smoothing in Quantum Machine Learning 	['Quantum Computing', 'Adversarial Machine learning', 'Randomized Smoothing', 'Quantum Amplitude Estimation']	Algorithm, theoretical proof, circuits, and results for a certifiably robust Quantum Computing classifier based on Randomized Smoothing.	General Machine Learning (ie none of the above)	anonymous|adversarial_robustness_based_on_randomized_smoothing_in_quantum_machine_learning	/pdf/b1b4fef2db97310ac063e8ad0091a30b84b3227b.pdf
BGqYCl1k1fN	3818	Rank-1 Matrix Completion with Gradient Descent and Small Random Initialization	['Matrix Completion', 'Small Initialization', 'Gradient Descent']	Proves the convergence of gradient descent with small random initialization for rank-1 matrix completion.	Optimization (eg, convex and non-convex optimization)	anonymous|rank1_matrix_completion_with_gradient_descent_and_small_random_initialization	/pdf/f738fe02a0843bb2e06d26c6c2e11ccfcfb0dd7b.pdf
jNt9ql72mBg	3819	Confident Sinkhorn Allocation for Pseudo-Labeling	['pseudo-labeling', 'semi-supervised learning', 'tabular data']	a new pseudo-labeling method for semi-supervised learning without domain knowledge	General Machine Learning (ie none of the above)	anonymous|confident_sinkhorn_allocation_for_pseudolabeling	/pdf/8b9b4c4dca683c88ecf0ed8f2c5eb7bacf4dff7d.pdf
9NHWYzbKHLd	3820	Continuous Monte Carlo Graph Search	['online planning', 'sequential decision making', 'monte carlo tree search', 'MCTS', 'continuous control']	This paper proposes Continuous Monte Carlo Graph Search (CMCGS), a novel extension of MCTS to online planning in environments with continuous state and action spaces.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|continuous_monte_carlo_graph_search	/pdf/be53c777c0119594caa00a1c2190d398974e8a53.pdf
azCKuYyS74	3821	What Do Self-Supervised Vision Transformers Learn?	['contrastive learning', 'masked image modeling', 'vision transformer', 'representation learning', 'self-supervised learning', 'empirical analysis']	We show that (1) CL primarily captures global patterns compared with MIM, (2) CL is more shape-oriented whereas MIM is more texture-oriented, and (3) CL plays a key role in the later layers while MIM focuses on the early layers.	Unsupervised and Self-supervised learning	anonymous|what_do_selfsupervised_vision_transformers_learn	/pdf/e47557acc98532bab32817dafee473d3925038f8.pdf
7HgnhMmbIB	3822	Cross-Protein Wasserstein Transformer for Protein-Protein Interactions	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|crossprotein_wasserstein_transformer_for_proteinprotein_interactions	/pdf/02e52806becd7a5141a476559faa9aec1b67bdce.pdf
6bRKHpeZi7	3823	Visual Expertise and the Log-Polar Transform Explain Image Inversion Effects	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|visual_expertise_and_the_logpolar_transform_explain_image_inversion_effects	/pdf/6361999f66865dd6e498014fc5c482237be8d0e2.pdf
4rXMRuoJlai	3825	Mind's Eye: Grounded Language Model Reasoning through Simulation	['reasoning', 'alignment', 'simulation', 'physics', 'grounding']	We present a new reasoning paradigm that grounds language model reasoning on simulation results from the advanced physics engine MuJoCo.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|minds_eye_grounded_language_model_reasoning_through_simulation	/pdf/bb10cfccf75f115a390ffeadf76dddbc2c6815f6.pdf
cddqs4kvC20	3826	Deep Transformer Q-Networks for Partially Observable Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|deep_transformer_qnetworks_for_partially_observable_reinforcement_learning	/pdf/b1ade558cb439863db30d0006dab57bfad81b041.pdf
RHsOd1Aineq	3828	Learning to Boost Resilience of Complex Networks via Neural Edge Rewiring	['complex networks', 'network resilience', 'network robustness', 'graph neural networks']	We develop an inductive network resilience optimization method with the proposed topology-inspired FireGNN for learning inductive neural edge rewiring to boost resilience of complex networks without rich features.	Deep Learning and representational learning	anonymous|learning_to_boost_resilience_of_complex_networks_via_neural_edge_rewiring	/pdf/f5538f3bef892c0f11e9f2227337fd59997e6cf5.pdf
YurfS_kh5ib	3829	Partial Differential Equation-Regularized Neural Networks: An Application to Image Classification	['partial differential equations', 'image classification', 'physics-informed neural networks']	Learn a PDE (approximated by a neural network) from data for image classification	Deep Learning and representational learning	anonymous|partial_differential_equationregularized_neural_networks_an_application_to_image_classification	/pdf/e824394a910e7552d2be6d6a5a37ace006e4103a.pdf
Rywi6F_HVCO	3830	Augmentative Topology Agents For Open-Ended Learning	['Open-Ended Learning', 'NeuroEvolution']	This work brings generalization capabilities and ability to solve complex environments to Open Ended Learning framework by adding agents that augment their topologies over time.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|augmentative_topology_agents_for_openended_learning	/pdf/ca1673a9d3fe548d05748af6c46593a6c1d661c1.pdf
zPkbpQdAfFi	3832	DualMatch: Promoting Semi-Supervised Learning with Hierarchical Label and Contrastive Learning	['Semi-supervised Learning', 'Contrastive Learning', 'Hierarchical Label Matching']		Unsupervised and Self-supervised learning	anonymous|dualmatch_promoting_semisupervised_learning_with_hierarchical_label_and_contrastive_learning	/pdf/a22644f863d0685636b6126f2a3880eea315004a.pdf
0JD3EN75NJE	3833	Understanding and Mitigating Robust Overfitting through the Lens of Feature Dynamics	['Adversarial Training', 'Robust Overfitting', 'Generalization', 'Robustness', 'Adversarial Attack']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|understanding_and_mitigating_robust_overfitting_through_the_lens_of_feature_dynamics	/pdf/e620ae3b82934486773624c275bb46e8676cf536.pdf
a2jNdqE2102	3834	Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models	['Semi-parametric language model', 'text-to-text model', 'mixture-of-experts', 'natural language understanding']	We develop a novel knowledge-rich semi-parametric model, KiC, that is able to achieve superior zeros-hot performance on unseen task with a much smaller model size.	Applications (eg, speech processing, computer vision, NLP)	anonymous|knowledgeincontext_towards_knowledgeable_semiparametric_language_models	/pdf/07a4137415aec1f02145fc2968a14bd437f5282e.pdf
sVzBN-DlJRi	3835	Budgeted Training for Vision Transformer	[]		Deep Learning and representational learning	anonymous|budgeted_training_for_vision_transformer	/pdf/f60ad04349cded1a5bc374cb9eae9a770c6259a8.pdf
SZojABvWnkx	3836	Prompt Tuning for Graph Neural Networks	[]	We explore the prompt tuning method for pre-trained GNN models.	Deep Learning and representational learning	anonymous|prompt_tuning_for_graph_neural_networks	/pdf/1848acfe263dfd2ab7e435cdf5c7d9d6bf73e2a0.pdf
QIpfInYnAu2	3837	Neural Unbalanced Optimal Transport via Cycle-Consistent Semi-Couplings	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neural_unbalanced_optimal_transport_via_cycleconsistent_semicouplings	/pdf/ba617ffa27cf433c44e966445ea352ac67503485.pdf
SvcawuEiUVM	3838	Compositional Image Generation and Manipulation with Latent Diffusion Models	['Compositionality', 'Diffusion Models']		Generative models	anonymous|compositional_image_generation_and_manipulation_with_latent_diffusion_models	/pdf/5f4db348e95bce34f9b634c913f208a743192c6d.pdf
1UBSvnGHFxK	3839	Wasserstein Gradient Flows for Optimizing GMM-based Policies	['Optimal transport', 'policy optimization', 'gaussian mixture models', 'robot motion adaptation.']	Policy structure-aware Optimization via Wasserstein Gradient Flows for Robot Motion Adaptation	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|wasserstein_gradient_flows_for_optimizing_gmmbased_policies	/pdf/4f5d43ee8899e619e12f1a4fa5a32f11375d371e.pdf
PHpK5B2iGpq	3840	Self-supervised debiasing using low rank regularization	['Debiasing', 'spurious correlation', 'self-supervised learning']		Deep Learning and representational learning	anonymous|selfsupervised_debiasing_using_low_rank_regularization	/pdf/8cbc38ee967ed80c51e0ae7bf4a1c8bea5e92be6.pdf
lMO7TC7cuuh	3842	When Data Geometry Meets Deep Function: Generalizing Offline Reinforcement Learning	['offline reinforcement learning', 'deep Q functions generalization']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|when_data_geometry_meets_deep_function_generalizing_offline_reinforcement_learning	/pdf/2a519c2ef3efffc591d7631cee91615fa3abc542.pdf
_bFeNCnBAl7	3843	Curved Data Representations in Deep Learning	['representation learning', 'curvature analysis', 'deep neural networks']	A comprehensive analysis of curvature for data representations in deep neural networks	Deep Learning and representational learning	anonymous|curved_data_representations_in_deep_learning	/pdf/989b326b30f4978e0a812989e2a8852b33a8778c.pdf
XrgjF5-M3xi	3845	Incremental Learning of Structured Memory via Closed-Loop Transcription	['Generative Replay Incremental Learning', 'Closed Loop Transcription']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|incremental_learning_of_structured_memory_via_closedloop_transcription	/pdf/a6929560609ef09bab3849e4c2f41c2f4ecb996f.pdf
vuD2xEtxZcj	3846	Minimum Variance Unbiased N:M Sparsity for the Neural Gradients	['pruning', 'compression', 'structured sparsity', 'acceleration']	A method to use structured N:M sparsity on all training GEMM operations	Deep Learning and representational learning	anonymous|minimum_variance_unbiased_nm_sparsity_for_the_neural_gradients	/pdf/1c98b8e2ebd3055a4b739b36da3552611f1be4c8.pdf
k3VANp85b4S	3847	On the Robustness of Randomized Ensembles to Adversarial Perturbations	['adversarial robustness', 'efficient inference', 'randomized ensembles', 'boosting']	We derive fundamental results on the robustness of randomized ensemble classifiers to adversarial perturbations. Empirically, we propose a boosting algorithm for training robust randomized ensemble classifiers.	General Machine Learning (ie none of the above)	anonymous|on_the_robustness_of_randomized_ensembles_to_adversarial_perturbations	/pdf/b161a782b75dce88f9725f58eeff74dd4157859b.pdf
ZmYHoQm0SWH	3848	Managing Temporal Resolution in Continuous Value Estimation: A Fundamental Trade-off	['Temporal Discretization', 'Continuous Time', 'Langevin System', 'LQR', 'Policy Evaluation']	By analyzing Monte-Carlo value estimation for LQR systems we uncover a fundamental trade-off between approximation and statistical error in value estimation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|managing_temporal_resolution_in_continuous_value_estimation_a_fundamental_tradeoff	/pdf/cc32c3db6e33b9641239ffbe707677a08eefadb6.pdf
K96AogLDT2K	3849	Symmetric Pruning in Quantum Neural Networks	['quantum neural networks', 'symmetry', 'pruning', 'quantum neural tangent kernel', 'effective dimension']	We prove how the symmetry enhances the training performance of QNNs and then devise an efficient symmetric pruning scheme to distill a symmetric ansatz from an over-parameterized and asymmetric ansatz.	General Machine Learning (ie none of the above)	anonymous|symmetric_pruning_in_quantum_neural_networks	/pdf/64c8034cb868a7e4b1104c17830513800d568f2b.pdf
fsa9jrF73fo	3850	Learning Reduced Fluid Dynamics	['Fluid Dynamics', 'Model Reduction']	Learning optimal model-reduced fluid dynamics	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_reduced_fluid_dynamics	/pdf/14e69d77f11d6158f71fe69386b12670ad78c1a2.pdf
Oz0npxjLAsI	3851	MeGraph: Graph Representation Learning on Connected Multi-scale Graphs	['Hierachical Graph Learning', 'Multi-scale', 'Graph Pooling', 'Graph Neural Networks(GNNs)']	We present a novel graph network architechture learning on a mega graph derived by connecting multi-scale graphs. The architechture allows repeated information exchange across multiple scaled graphs.	Deep Learning and representational learning	anonymous|megraph_graph_representation_learning_on_connected_multiscale_graphs	/pdf/eccd08cb329fe7e59729f6b2b75495cf88aa3adf.pdf
RQY2AXFMRiu	3852	Solving Constrained Variational Inequalities via a First-order Interior Point-based Method	['constrained variational inequality', 'interior point', 'admm']	We derive a first-order method for solving constrained variational inequality problem when given general constraints, by combining interior-point methods and ADMM.	Optimization (eg, convex and non-convex optimization)	anonymous|solving_constrained_variational_inequalities_via_a_firstorder_interior_pointbased_method	/pdf/1d4304ca3eed06887e893d0658ab5844f69345d4.pdf
ygN9NbyVkyy	3853	Closed Boundary Learning for NLP Classification Tasks with the Universum Class	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|closed_boundary_learning_for_nlp_classification_tasks_with_the_universum_class	/pdf/58b5ec8f12e36633ea0eadd05495dd5e3ea181eb.pdf
cLcN6JY69aG	3854	DETRDistill: A Simple Knowledge Distillation Framework for DETR-Families	['Knowledge Distillation', 'DETR', 'Transformer', 'Model Compression']		Deep Learning and representational learning	anonymous|detrdistill_a_simple_knowledge_distillation_framework_for_detrfamilies	/pdf/17f343e828fc96df18e9766c0029375e05ca81db.pdf
jZdJd1dGF2A	3855	Unsupervised Learning of Structured Representations via Closed-Loop Transcription	['Unsupervised Conditional Image Generation', 'Self-supervised Generative Model', 'Closed-Loop Transcription']		Unsupervised and Self-supervised learning	anonymous|unsupervised_learning_of_structured_representations_via_closedloop_transcription	/pdf/e269d894a46a7f03bf57b7c33e36af6c5a93b7f7.pdf
Mf9fQ0OgMzo	3856	Preventing Mode Collapse When Imitating Latent Policies from Observations	['Imitation Learning', 'Imitation from Observations Only', 'Latent Policy Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|preventing_mode_collapse_when_imitating_latent_policies_from_observations	/pdf/fcab4a40a63e163a8934d5d5f90f6afb6b87b9db.pdf
vmFwJeiSx4X	3857	Multi-Layered 3D Garments Animation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|multilayered_3d_garments_animation	/pdf/01fa1fac8f954d023ad3fa214c4b8c399abd2476.pdf
walno7E1F8w	3859	A HIERARCHICAL FRAGMENT-BASED MODEL FOR 3D DRUG-LIKE MOLECULE GENERATION	['Drug Design', 'Molecule Generation', 'Deep Learning', 'Computational Biology']	This paper introduced a hierarchical generative model for fragment-based drug-like molecule generation.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_hierarchical_fragmentbased_model_for_3d_druglike_molecule_generation	/pdf/551479ff8178d770a75ff7722c55acbf90c5e3cb.pdf
8IN-qLkl215	3862	Visually-Augmented Language Modeling	['visually-grounded language modeling', 'visual commonsense reasoning', 'pre-trained visually-augmented language model']	We propose a novel pre-trained framework, to Visually-augment text tokens with retrieved relevant images for multimodal grounded Language Modeling.	Applications (eg, speech processing, computer vision, NLP)	anonymous|visuallyaugmented_language_modeling	/pdf/23b7e5ded1e0ddb258c00a32fb6b2e03ba969a04.pdf
mXPoBtnpMnuy	3864	Unsupervised 3d object learning through neuron activity aware plasticity	['Hebbian learning']		Unsupervised and Self-supervised learning	anonymous|unsupervised_3d_object_learning_through_neuron_activity_aware_plasticity	/pdf/a8c4b90e1a52ee81b05820909ad54b81a5bff139.pdf
LiWGbK8_iOB	3865	G-Censor: Graph Contrastive Learning with Task-Oriented Counterfactual Views	['graph contrastive learning', 'node property prediction', 'task-oriented counterfactual views']	Graph Contrastive learning with task-oriented counterfactual positive/negative views, a model-agnostic framework designed for node property prediction tasks.	Deep Learning and representational learning	anonymous|gcensor_graph_contrastive_learning_with_taskoriented_counterfactual_views	/pdf/3c8bd45f38e3a2f19a8278e960478bcae781c576.pdf
Pt1KTsjSfRG	3866	Image Segmentation using Transfer Learning with DeepLabv3 to Facilitate Photogrammetric Limb Scanning	['3D Scanning', 'Deep Learning', 'Image Segmentation', 'Photogrammetry', 'Telemedicine']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|image_segmentation_using_transfer_learning_with_deeplabv3_to_facilitate_photogrammetric_limb_scanning	/pdf/58fcd211906a7adcd7ef5949496ec5ff663da9d6.pdf
JZRBSoJv7lb	3867	Similarity of Neural Architectures Based on Input Gradient Transferability	['neural architecture similarity', 'model similarity', 'model diversity', 'model ensemble', 'knowledge distillation']	We propose a similarity score between neural networks. We provide analyses on 69 neural architectures using the proposed score.	Deep Learning and representational learning	anonymous|similarity_of_neural_architectures_based_on_input_gradient_transferability	/pdf/64f36b065a32da2cca0443a9e84af9043ee3858d.pdf
V9dXRjqvqcD	3868	Identification of the Adversary from a Single Adversarial Example	['Adversarial examples', 'Forensic investigation']	This paper proposes a forensic mechanism for the aftermath of adversarial attacks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|identification_of_the_adversary_from_a_single_adversarial_example	/pdf/1a374aff7de3e1aeead98c90aa71b476be6579c0.pdf
tyyNcEVrklJ	3869	Decentralized Policy Optimization	['multi-agent reinforcement learning']	A principled algorithm for fully decentralized policy optimization	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|decentralized_policy_optimization	/pdf/8df2d8b9b7259afe828930f441321009a6864326.pdf
ix3UDwIN5E	3871	Class-wise Visual Explanations for Deep Neural Networks	['Class-wise explanation', 'Backdoor attack detection', 'Global explanation']	We propose a method to visualize global explanation in the input space for every class learned in the training procedure.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|classwise_visual_explanations_for_deep_neural_networks	/pdf/c14c2c1a813b067760015531ed6b79febf98a7bc.pdf
__GGLJ79pV	3872	GuardHFL: Privacy Guardian for Heterogeneous Federated Learning	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|guardhfl_privacy_guardian_for_heterogeneous_federated_learning	/pdf/0758a79ab123a54dd9039e3c0bb4cc15357aad91.pdf
aR3hRo_O6cn	3874	SoTeacher: Toward Student-oriented Teacher Network Training for Knowledge Distillation	['Knowledge distillation', 'Teacher-student training', 'Empirical risk minimization']	We study the feasibility of training a teacher network towards the performance of the student with empirical risk minimization.	Deep Learning and representational learning	anonymous|soteacher_toward_studentoriented_teacher_network_training_for_knowledge_distillation	/pdf/ced82a843f2b6886da3d1a64f4946fbc58ff923c.pdf
pxnp5lBtXPr	3875	So-TVAE: Sentiment-oriented Transformer-based Variational Autoencoder Network for Live Video Commenting	['Automatic live video commenting', 'batch attention', 'cross-modal fusion']	This paper proposes a Sentiment-oriented Transformer-based Variational Autoencoder model which can achieve diverse video commenting with multiple sentiments and semantics for the automatic live video commenting task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sotvae_sentimentoriented_transformerbased_variational_autoencoder_network_for_live_video_commenting	/pdf/60949c232192eafbba3a76b21647d6a40a0bc531.pdf
X4DOJ-wL2I	3876	SDAC: Efficient Safe Reinforcement Learning with Low-Biased Distributional Actor-Critic	['Reinforcement learning', 'Safety', 'Distributional Critic']	We propose a safe reinforcement learning method based on the trust region method and distributional critics.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|sdac_efficient_safe_reinforcement_learning_with_lowbiased_distributional_actorcritic	/pdf/4e0094af0f006da70dcfd5e91ce9287b99407925.pdf
VezcnWFSd2d	3877	On Threshold Functions in Learning to Generate Feasible Solutions of Mixed Integer Programs	['Mixed Integer Programming', 'Neural Combinatorial Optimization']	We introduce a posthoc method and a learning approach to optimize the selection rate for partial discrete variables assignments in MIP to find feasible solutions efficiently.  	Deep Learning and representational learning	anonymous|on_threshold_functions_in_learning_to_generate_feasible_solutions_of_mixed_integer_programs	/pdf/74d8a69ec149029f38a4f703cab471424b81f0dc.pdf
rgp4_59eC0	3880	Representation Interference Suppression via Non-linear Value Factorization for Indecomposable Markov Games	['Multi-agent Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|representation_interference_suppression_via_nonlinear_value_factorization_for_indecomposable_markov_games	/pdf/c87a709549b094b57c4b4590d248a1f077c87864.pdf
THp4UABcMv	3881	Learning Asymmetric Visual Semantic Embedding for Image-Text Retrieval	['Cross-modal retrieval', 'image-text matching']	In this paper, we propose a novel method to calculate visual semantic similarity for image-text matching and achieve outperform recent state-of-the-art methods on two widely used datasets.	Deep Learning and representational learning	anonymous|learning_asymmetric_visual_semantic_embedding_for_imagetext_retrieval	/pdf/fd9dc73254640ae8bbe5ba72dc8931b06ca9cb71.pdf
TMYzh1hsHd	3882	MA2QL: A Minimalist Approach to Fully Decentralized Multi-Agent Reinforcement Learning	['multi-agent reinforcement learning']	A new algorithm for multi-agent reinforcement learning	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|ma2ql_a_minimalist_approach_to_fully_decentralized_multiagent_reinforcement_learning	/pdf/6a40af2ff394ac793988fc0040e41cdceb394643.pdf
KGV-GBh8fb	3883	Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization	['Zero-Shot Learning', 'Multi-Task Learning', 'Transfer Learning']		Deep Learning and representational learning	anonymous|not_all_tasks_are_born_equal_understanding_zeroshot_generalization	/pdf/1ab075a42bfa0602e685513269e8fa277282f887.pdf
FvqcQ_9u7Mo	3884	ECLAD: Extracting Concepts with Local Aggregated Descriptors	['explainable artificial intelligence', 'deep learning', 'interpretability', 'concept extraction']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|eclad_extracting_concepts_with_local_aggregated_descriptors	/pdf/d225646bfeb0a17507c3cb7d4d1dd0be6d692ab5.pdf
yf1icZHC-l9	3888	Complexity-Based Prompting for Multi-step Reasoning	['Chain-of-Thoughts', 'Multi-Step Reasoning', 'Large Language Models', 'Prompting']	We show using prompts with more reasoning steps can improve language models multi-step reasoning ability 	Applications (eg, speech processing, computer vision, NLP)	anonymous|complexitybased_prompting_for_multistep_reasoning	/pdf/762d9f4192bba245228e85950bfdd30bf012d086.pdf
ztkUF_MQj7J	3889	Test-Time AutoEval with Supporting Self-supervision	['Test-Time', 'AutoEval', 'Self-supervised Learning']	A new framework for unsupervised model evaluation without touching training sets	General Machine Learning (ie none of the above)	anonymous|testtime_autoeval_with_supporting_selfsupervision	/pdf/9352873ec2165474b12ef0e7697828569ea4e772.pdf
UKr0MwZM6fL	3890	Building a Subspace of Policies for Scalable Continual Learning	['continual learning', 'deep reinforcement learning']	We introduce a continual reinforcement learning method that incrementally builds a subspace of policies and adaptively prune it to preserve a good trade-off between model size and performance.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|building_a_subspace_of_policies_for_scalable_continual_learning	/pdf/a469879cd7b2b3366be229374808af7684f6cd21.pdf
kvAQEZZ_BI1	3891	Learning from conflicting data with hidden contexts	['Conflicting data', 'hidden contexts', 'subjective learning', 'multi-domain learning']	We formulate the problem of learning from conflicting data with hidden contexts and propose a subjective learning framework to tackle this problem.	Deep Learning and representational learning	anonymous|learning_from_conflicting_data_with_hidden_contexts	/pdf/c9ac617405e42c71272914476d23175899832a1e.pdf
TJPmwnQIMmw	3894	Adversarial Causal Augmentation for Graph Covariate Shift	['Graph Data Augmentation', 'Graph Neural Networks', 'Covariate Shift', 'OOD Generalization']	We propose a novel graph data augmentation method, Adversarial Causal Augmentation (AdvCA), to address the covariate shift issues.	Deep Learning and representational learning	anonymous|adversarial_causal_augmentation_for_graph_covariate_shift	/pdf/82f9431562f9810111da09df94d31402a544b781.pdf
Z-aIURmBbBk	3895	Multimodal Masked Autoencoders Learn Transferable Representations	['Multimodal', 'Self-supervised Learning', 'Pre-training', 'Masked Autoencoder', 'Representation Learning']	Multimodal Transformers for vision-language representation learning trained with masked token prediction.	Deep Learning and representational learning	anonymous|multimodal_masked_autoencoders_learn_transferable_representations	/pdf/ac45ad55cd88db4a5fe050d9428fbb2a59c9de77.pdf
lKOfilXucGB	3896	Decompositional Generation Process for Instance-Dependent Partial Label Learning	['partial label learning', 'weakly supervised learning', 'decompositional generation process']	 We consider instance-dependent PLL and assume that the generation process of the candidate labels could decompose into two sequential parts.	Deep Learning and representational learning	anonymous|decompositional_generation_process_for_instancedependent_partial_label_learning	/pdf/dcd778fc809d13c0501bf01b9595d7026a21ff3f.pdf
f0a_dWEYg-Td	3897	Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning	['data poisoning', 'contrastive learning']		General Machine Learning (ie none of the above)	anonymous|indiscriminate_poisoning_attacks_on_unsupervised_contrastive_learning	/pdf/511fa8f7ae10a3cb071484ab27796e875a687bc3.pdf
Tb3ZJBDF7aA	3898	Pre-training Protein Structure Encoder via Siamese Diffusion Trajectory Prediction	['Protein representation learning', 'diffusion models', 'self-supervised learning']	In this work, we propose a novel protein structure pre-training algorithm SiamDiff to effectively maximize mutual information between protein structure-sequence co-diffusion trajectories.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pretraining_protein_structure_encoder_via_siamese_diffusion_trajectory_prediction	/pdf/bdca69a2b0e465150813cbe59913d823805fe5a6.pdf
vdm4WnG5u-M	3899	Skill Graph for Real-world Quadrupedal Robot Reinforcement Learning	['Skill Graph', 'Quadrupedal Robot', 'Deep Reinforcement Learning.']	We propose a novel structured skill graph for accelerating the learning of robotic DRL policies and rapid adaptation to unseen real-world tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|skill_graph_for_realworld_quadrupedal_robot_reinforcement_learning	/pdf/feffb8ab83fd618d8920df94e94d892f6e582605.pdf
1_jFneF07YC	3900	Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations	['unsupervised semantic segmentation', 'object segmentation', 'object-centric learning']	Strong and simple baseline for unsupervised segmentation methods obtained by leveraging and combining object-centric priors.	Unsupervised and Self-supervised learning	anonymous|unsupervised_semantic_segmentation_with_selfsupervised_objectcentric_representations	/pdf/c8b8156fbf8db6a98fbbf17daffeecfb6d06c7bc.pdf
qihMOPw4Sf_	3902	Valid P-Value for Deep Learning-driven Salient Region	['Saliency Map', 'Attention', 'Selective Inference', 'Uncertainty Quantification', 'P-value', 'Statistical Hypothesis Testing']	We propose a novel method to quantify the reliability of neural network-driven saliency region in statistical hypothesis testing framework.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|valid_pvalue_for_deep_learningdriven_salient_region	/pdf/cb2ac5828324cbd07b1d0a85a44c602910b68006.pdf
fnDbEm6RxqH	3903	Unbiased Representation of Electronic Health Records for Patient Outcome Prediction	['Deep Learning', 'Electronic Health Records Representation Learning', 'Healthcare AI', 'Model Fairness']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|unbiased_representation_of_electronic_health_records_for_patient_outcome_prediction	/pdf/d3fba31d2ba1668a5385d75febaa2487fe29e0ef.pdf
OOWLRfAI_V_	3904	Quantized Compressed Sensing with Score-Based Generative Models	['generative models', 'compressed sensing', 'linear inverse problems', 'quantization']	Quantized Compressed Sensing with Score-Based Generative Models	Generative models	anonymous|quantized_compressed_sensing_with_scorebased_generative_models	/pdf/60fc926bfaf6fbf445522c6345af0bae4947f871.pdf
72lzvXrKqqd	3905	On the Importance of In-distribution Class Prior for Out-of-distribution Detection	[]		Deep Learning and representational learning	anonymous|on_the_importance_of_indistribution_class_prior_for_outofdistribution_detection	/pdf/a9dd25c1cfcd643655b57d8c8121d57ec56ece4f.pdf
TQZkycVeMIy	3907	Test-time Adaptation for Segmentation via Image Synthesis	['object-centric learning', 'test-time adaptation', 'unsupervised domain adaptation', 'test-time training', 'entity-centric models']	We propose a test-time adaptation framework that optimizes image synthesis loss to improve image segmentation.	Deep Learning and representational learning	anonymous|testtime_adaptation_for_segmentation_via_image_synthesis	/pdf/6d8ad6addfc4bc727a6090e038ecc3eeb3248d03.pdf
DvMDIEFtyjV	3908	CLUTR: Curriculum Learning via Unsupervised Task Representation Learning	['reinforcement learning', 'curriculum learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|clutr_curriculum_learning_via_unsupervised_task_representation_learning	/pdf/d6574c53d28f33397842c7a44fe3e0da3b2886fd.pdf
Nc1ZkRW8Vde	3911	Near-optimal Coresets for Robust Clustering	['clustering', 'outlier', 'robustness', 'coreset']	We obtain an \epsilon-coreset of near-optimal size for (k, z)-clustering (which includes k-median and k-means) with m outliers	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|nearoptimal_coresets_for_robust_clustering	/pdf/ae3af786a132ea7bc8a3614ca83b2b74989877f8.pdf
hpr8KTZzz4W	3912	PAVI: Plate-Amortized Variational Inference	['structured Variational Inference', 'Bayesian inference', 'Hierarchical Bayesian Models', 'Inference amortization', 'Neuroimaging']	We share a variational family's parameterization and learning across a model's plates to tackle efficiently very large plate cardinality regimes.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|pavi_plateamortized_variational_inference	/pdf/1317cdad9844154b1548ad355449ef6ca606d68f.pdf
tEyV6gwCECk	3913	Balancing MSE against Abrupt Changes for Time-Series Forecasting	['time-series forecasting', 'data imbalance', 'loss imbalance', 'noisy samples']		Deep Learning and representational learning	anonymous|balancing_mse_against_abrupt_changes_for_timeseries_forecasting	/pdf/d5635b8134c31f9037bee8b77c395dc066ddb161.pdf
rDm09u4Hws4	3914	Multi-Source Transfer Learning for Deep Model-Based Reinforcement Learning	['multi-source transfer learning', 'world models', 'model-based reinforcement learning', 'sample efficiency', 'cross-domain transfer learning']	Modular multi-source transfer learning techniques for model-based reinforcement learning that autonomously learn to extract information from a set of source tasks, regardless of differences between environments.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multisource_transfer_learning_for_deep_modelbased_reinforcement_learning	/pdf/b3fe7dab8aa465dc1e19f085f2c813772f458370.pdf
UG8bQcD3Emv	3915	CUTS: Neural Causal Discovery from Unstructured Time-Series Data	['Time series', 'Granger causality', 'Causal discovery', 'Neural networks', 'Graph neural networks']	Discovering causal relations from unstructured time-series data with a mutually boosting iterative method.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|cuts_neural_causal_discovery_from_unstructured_timeseries_data	/pdf/9655490a532e82edb9bd9ebd61b3b53d5de8b04b.pdf
DB3BH3arU2Y	3916	Revisiting Uncertainty Estimation for Node Classification: New Benchmark and Insights	['uncertainty estimation', 'distribution shift', 'graph', 'node classification', 'benchmark']	We analyze uncertainty estimation for node classification problems: we propose a benchmark covering distribution shifts of different types and perform a thorough analysis of various uncertainty estimation techniques.	Deep Learning and representational learning	anonymous|revisiting_uncertainty_estimation_for_node_classification_new_benchmark_and_insights	/pdf/8b4bffcea58947b3099bd22be3ac6176de4deb40.pdf
WH1yCa0TbB	3918	Learning Diffusion Bridges on Constrained Domains	[]		Generative models	anonymous|learning_diffusion_bridges_on_constrained_domains	/pdf/16521b81bfc7633c92880da3f1797b5fe97e8c5e.pdf
GCF6ZOA6Npk	3919	Learning Rotation-Equivariant Features for Visual Correspondence	['visual correspondence', 'equivariant representation learning', 'deep local feature extraction', 'self-supervised learning']	We introduce a self-supervised learning framework to yield discriminative rotation-invariant descriptors using local features extracted from group-equivariant CNNs for the task of visual correspondence.	Deep Learning and representational learning	anonymous|learning_rotationequivariant_features_for_visual_correspondence	/pdf/4259112c7f0f5733391acaf5020b44ccdc3d37bc.pdf
y4uc4NtTWaq	3920	Data augmentation alone can improve adversarial training	['deep learning', 'adversarial training', 'data augmentation', 'adversarial robustness']	data augmentation alone can significantly improve adversarial training regarding both accuracy and robustness	Deep Learning and representational learning	anonymous|data_augmentation_alone_can_improve_adversarial_training	/pdf/5e10c15785968d7086bb25f02586f5fdcea2e9a9.pdf
cEygmQNOeI	3921	Language Models are Realistic Tabular Data Generators	['tabular data', 'tabular data generation', 'large language models', 'transformers', 'probabilistic modeling', 'deep neural networks']	The GReaT approach utilizes the capabilities of large language models to synthesize realistic tabular data. A challenging set of experiments validates the proposed method’s efficiency.	Generative models	anonymous|language_models_are_realistic_tabular_data_generators	/pdf/fd8ffb56f79a819e8e268e43acdbdd43261dac90.pdf
t851DsVVtA	3922	A Mathematical Framework for Characterizing Dependency Structures of Multimodal Learning	['Multimodal learning', 'dependency structures', 'correlation anaylses', 'emotion recognition', 'classification']		General Machine Learning (ie none of the above)	anonymous|a_mathematical_framework_for_characterizing_dependency_structures_of_multimodal_learning	/pdf/6ce32c8dd50cca91d82d3104466debdd8b0c8553.pdf
cxul04S-aG	3923	CRISP: Curriculum based Sequential neural decoders for Polar code family	['information theory', 'coding theory', 'wireless communication', 'polar codes', 'PAC codes', 'machine learning', 'deep learning']	We introduce CRISP, a novel curriculum learning based neural decoder that attains near optimal reliability on the Polar code family in the short blocklength regime.	Applications (eg, speech processing, computer vision, NLP)	anonymous|crisp_curriculum_based_sequential_neural_decoders_for_polar_code_family	/pdf/87a8c70df966f38a803cf986036a760710497755.pdf
rOFKmzNTbC	3924	Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams.	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|tensorbased_sketching_method_for_the_lowrank_approximation_of_data_streams	/pdf/fe98c70856a2eec230dc260bdcb83698a266ae86.pdf
4t9q35BxGr	3925	Inequality phenomenon in $l_{\infty}$-adversarial training, and its unrealized threats	['Adversarial training', 'Adversarial robustness', 'Adversarial feature represenation']	We find an intriguing phenomena of $l_{\infty}$ adversarial training, and this phenomena brings unrealized threats to adversarially trained model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|inequality_phenomenon_in_l_\inftyadversarial_training_and_its_unrealized_threats	/pdf/26633acff0ff8230c8407ed08170cc25ae313e5f.pdf
XVjTT1nw5z	3926	Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow	[]		Generative models	anonymous|flow_straight_and_fast_learning_to_generate_and_transfer_data_with_rectified_flow	/pdf/0d73b88306e474e65d56e26a1bd43c72eee0be54.pdf
M0_sUuEyHs	3927	Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge Distillation	['Knowledge Distillation']	The proposed method dynamically introduces part of teacher's features to student as prior knowledge before applying knowledge distillation. 	Deep Learning and representational learning	anonymous|better_teacher_better_student_dynamic_prior_knowledge_for_knowledge_distillation	/pdf/9f6dd0b6cba16ceaed8a6a74fdb185a54ccdca13.pdf
hZRxiAZFJC	3928	FairGrad: Fairness Aware Gradient Descent	['Group Fairness', 'Optimization']	A method to enforce fairness based on a reweighting scheme that iteratively learns group specific weights based on whether they are advantaged or not.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fairgrad_fairness_aware_gradient_descent	/pdf/6089ba95914969da175dfa9223c1bdf887d0c557.pdf
Xk10fyKR8G	3929	Are Graph Attention Networks Attentive Enough? Rethinking Graph Attention by Capturing Homophily and Heterophily	['Graph ML', 'attention mechanism']	Propose a new attention mechanism for Graph ML	General Machine Learning (ie none of the above)	anonymous|are_graph_attention_networks_attentive_enough_rethinking_graph_attention_by_capturing_homophily_and_heterophily	/pdf/a08a2ae184294a48007a6c1a83dab96d446d157e.pdf
ms5edDXWcX	3930	Meta-learning with Auto-generated Tasks for Predicting Human Behaviour in Normal Form Games	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|metalearning_with_autogenerated_tasks_for_predicting_human_behaviour_in_normal_form_games	/pdf/0b8e28ba117411e772968c9869873ff7c14b9d63.pdf
_q7iqj1Ns8	3931	TransLog: A Unified Transformer-based Framework for Log Anomaly Detection	['System Security', 'Log data', 'Anomaly detection']		Applications (eg, speech processing, computer vision, NLP)	anonymous|translog_a_unified_transformerbased_framework_for_log_anomaly_detection	/pdf/49040e318938757d48c062cd5e867ca19d955503.pdf
ELmZduELxm	3932	UTS: When Monotonic Value Factorisation Meets Non-monotonic and Stochastic Targets	['Value Decomposition', 'Multi-Agent Reinforcement Learning']	We propose a novel value factorisation method to deal with non-monotonic and stochastic target joint action-values. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|uts_when_monotonic_value_factorisation_meets_nonmonotonic_and_stochastic_targets	/pdf/115b460f5dbb4e871ba5a6887064da280bc4c038.pdf
wOTLra5iXh	3933	Modeling the Uncertainty with Maximum Discrepant Students for Semi-supervised 2D Pose Estimation	['semi-supervised learning', 'pose estimation', 'uncertainty', 'convolutional neural networks']	Under the mean-teacher framework, the two maximum discrepant students (MDSs) are created to effectively model the uncertainty of pseudo-labels, so as to select the high quality pseudo-labels to improve the semi-supervised pose estimation performance.	Deep Learning and representational learning	anonymous|modeling_the_uncertainty_with_maximum_discrepant_students_for_semisupervised_2d_pose_estimation	/pdf/29b3234a0089d21317e416f79bfd3909cada0ab5.pdf
lcZTuVcAyW	3934	Uncertainty-oriented Order Learning for Facial Beauty Prediction	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|uncertaintyoriented_order_learning_for_facial_beauty_prediction	/pdf/7612a42aeef55da720ea3632d16372d9081ad779.pdf
819v9ONRbh	3935	AI BASED RESOURCE ALLOCATION SOLUTION FOR CLOUD GAMING	['resource allocation', 'deep reinforcement learning', 'cloud gaming', 'optimization']	Proposed a novel DRL based resource optimization algorithm to allocate gaming workloads efficiently on cloud platforms/physical resources.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|ai_based_resource_allocation_solution_for_cloud_gaming	/pdf/1558e3a0e2f6ed7944ec85911ef2087d3869e074.pdf
4VFNnqSinf	3938	PREDICTION OF TOURISM FLOW WITH SPARSE DATA INCORPORATING TOURIST GEOLOCATIONS	['GNN', 'RNN', 'Transformer', 'Tourism', 'Tourism flow prediction']	We apply state-of-the-art deep learning models such as GNNs, RNNs and Transformers to the problem of Tourism flow predictions	Applications (eg, speech processing, computer vision, NLP)	anonymous|prediction_of_tourism_flow_with_sparse_data_incorporating_tourist_geolocations	/pdf/f6ca61bd1897c2775d3df0ecb383f710a3911c55.pdf
bLmSMXbqXr	3939	Quality-Similar Diversity via Population Based Reinforcement Learning	['quality diversity', 'reinforcement learning', 'user-defined', 'population']	We formulate the Quality-Similar Diversity (QSD) problem and propose an efficient population-based RL algorithm to optimize the user-defined diversity at multiple quality levels throughout training.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|qualitysimilar_diversity_via_population_based_reinforcement_learning	/pdf/6cd2dc30506a9e190114ca034c9b26d38460ec00.pdf
lJdOlWg8td	3940	Efficient recurrent architectures through activity sparsity and sparse back-propagation through time	['RNN', 'GRU', 'recurrent network', 'language modeling', 'dvs', 'gesture recognition', 'activity sparsity', 'efficiency']	We add a activity sparsity mechanism to the GRU using a thresholding function, which makes both the forward and backward passes computationally sparse. This model achieves competitive performance on various benchmarks including language modeling.	Deep Learning and representational learning	anonymous|efficient_recurrent_architectures_through_activity_sparsity_and_sparse_backpropagation_through_time	/pdf/693d87455ad56c80e3774d0f2d90797c8f421efd.pdf
074e7Rojdj	3941	Unsupervised Performance Predictor for Architecture Search	['Neural Architecture Search', 'AutoML', 'Performance Predictor']	We propose a performance predictor which can utilize existing fully-trained architectures, thus reducing the high cost of annotating architectures in the background of NAS.	General Machine Learning (ie none of the above)	anonymous|unsupervised_performance_predictor_for_architecture_search	/pdf/afa5347d344801d7ca25d504b05198c62e7695b5.pdf
5s6NuOP9cW	3942	Merging Models Pre-Trained on Different Features with Consensus Graph	['Graph Neural Network', 'Probabilistic Methods']	Combining Pre-Trained Models with Different Feature Sets via Learning Consensus Graph	General Machine Learning (ie none of the above)	anonymous|merging_models_pretrained_on_different_features_with_consensus_graph	/pdf/35aa1cbc9fc92439c24ce86288d28e9657039a2f.pdf
p7xPXoKB0H	3943	Quantum Vision Transformers	['quantum computing', 'quantum machine learning', 'quantum deep learning', 'transformers', 'vision transformers']	We propose several quantum algorithms to mimic or enhance the transformer architecture, prove theoretical guarantees and provide experiments on real quantum hardware	Deep Learning and representational learning	anonymous|quantum_vision_transformers	/pdf/35b7e703f0792d336f35a614c88e4b7b28bd0e9c.pdf
xJz9LTHP0K	3944	On student-teacher deviations in distillation: does it pay to disobey?	['knowledge distillation', 'regularization', 'understanding', 'underfitting']	On the lack of fidelity in knowledge distillation	Deep Learning and representational learning	anonymous|on_studentteacher_deviations_in_distillation_does_it_pay_to_disobey	/pdf/cb3e91bc5282026313e614f5340b184cd80e508c.pdf
fC4pNRot_ys	3945	MATA*: Combining Learnable Node Matching with A* Algorithm for Approximate Graph Edit Distance Computation	['Graph Edit Distance', 'Machine Learning for Combinatorial Optimization', 'Graph Neural Networks', 'A* algorithm', 'Graph Similarity']	We present a data-driven hybrid approach MATA* based on Graph Neural Networks and A* algorithms, which leverages the learned candidate matching nodes to prune unpromising search directions of the A* algorithm.	Deep Learning and representational learning	anonymous|mata_combining_learnable_node_matching_with_a_algorithm_for_approximate_graph_edit_distance_computation	/pdf/7b49cda9f7accb6649bc4d67c8c03b68f3fbfeb7.pdf
53FyUAdP7d	3946	Discovering Generalizable Multi-agent Coordination Skills from Multi-task Offline Data	['multi-agent reinforcement learning', 'multi-task reinforcement learning', 'skill discovery', 'offline reinforcement learning']	We propose a novel multi-agent reinforcement learning algorithm to discover coordination skills from multi-task offline data and realize multi-task generalization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|discovering_generalizable_multiagent_coordination_skills_from_multitask_offline_data	/pdf/c2da47d2a901a647c60e53390850032088647662.pdf
u21cKsZAUAr	3947	Self-Supervised SVDE from Videos with Depth Variance to Shifted Positional Information	['Self-supervised', 'Depth Estimation', 'Monocular Depth']		Unsupervised and Self-supervised learning	anonymous|selfsupervised_svde_from_videos_with_depth_variance_to_shifted_positional_information	/pdf/fffa7f87b9d568543272b5f9fab040e796c08360.pdf
nYWqxUwFc3x	3948	Learning Vortex Dynamics for Fluid Inference and Prediction	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_vortex_dynamics_for_fluid_inference_and_prediction	/pdf/be08e548550ba496ad661d122658f74d2dc4b017.pdf
Ivkh2_UdL9O	3949	Efficient Hyperparameter Optimization Through Tensor Completion	['hyperparameter optimization', 'tensor completion']	An approach for hyperparameter optimization based on tensor completion methods.	General Machine Learning (ie none of the above)	anonymous|efficient_hyperparameter_optimization_through_tensor_completion	/pdf/9ca5f2c210bd4206d65b3d743ea64f83c57a2e24.pdf
OcHQVmfLn2c	3950	Prototypical Context-aware Dynamics Generalization for High-dimensional Model-based Reinforcement Learning	['model-based reinforcement learning', 'dynamics generalization', 'prototypical representation learning', 'latent world model']	We present a prototypical Context-aware Dynamics (ProtoCAD) model to capture the local dynamics by time consistent latent context.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|prototypical_contextaware_dynamics_generalization_for_highdimensional_modelbased_reinforcement_learning	/pdf/c36f6cd74b5ffb3acda5e5be71997edd0bb9052f.pdf
oztkQizr3kk	3952	$\Lambda$-DARTS: Mitigating Performance Collapse by Harmonizing Operation Selection among Cells	[]	We pinpoint the reason for performance collapse in DARTS and provide theoretical and empirical analysis on that as well as a solution to remedy the performance collapse via harmonizing the decisions of different cell.	Deep Learning and representational learning	anonymous|\lambdadarts_mitigating_performance_collapse_by_harmonizing_operation_selection_among_cells	/pdf/f889c257acdd6c4ed1753aa9993aba786bb25544.pdf
5RSq86IM6mE	3954	Shifts 2.0: Extending The Dataset of Real Distributional Shifts	['Distributional Shift', 'Uncertainty Estimation', 'Benchmark', 'MRI 3D segmentation', 'medical data', 'industrial tabular data']	We introduce two new datasets into the Shifts Benchmark for assessing robustness and uncertainty -  Multiple Sclerosis Lesion Segmentation in MRI images and Cargo Vessel Power Consumption Prediction	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|shifts_20_extending_the_dataset_of_real_distributional_shifts	/pdf/f7224b971ce19bd1d85d759b33f151463d307891.pdf
8JEpyIgQS0t	3955	Dynamical Signatures of Learning in Recurrent Networks	['RNNs', 'self-organization', 'criticality', 'spatio-temporal dynamics']	Self-organized learning of temporal sequences results in subcritical dynamics, which we propose is a signature of specialization. 	Unsupervised and Self-supervised learning	anonymous|dynamical_signatures_of_learning_in_recurrent_networks	/pdf/d06065f2cb4be64fe787f19fd4fa1fe5daabf8dd.pdf
TS_VsCpuWr	3956	Spectral Subgraph Localization	['subgraph isomorphism', 'subgraph localization']	We localize a subgraph Q in a graph G by manipulating their Laplacian spectra.	Unsupervised and Self-supervised learning	anonymous|spectral_subgraph_localization	/pdf/05a31758434a75aa9ca6b3a34d2d9e7fb6bb4788.pdf
kAx_rZtFbY	3957	Instance-Specific Augmentation: Capturing Local Invariances	['inductive bias', 'data augmentation', 'invariance']		Deep Learning and representational learning	anonymous|instancespecific_augmentation_capturing_local_invariances	/pdf/bda1719099ffa8e571a71b65e607e369913ee069.pdf
_izzMPiE1y	3958	Inverse Learning with Extremely Sparse Feedback for Recommendation	['Recommender System', 'Unlabeled Data', 'Denoising Training']	We propose inverse learning with inverse dual loss and inverse gradient to annotate the unlabeled data and achieve denoising augmentation from both positive and negative perspectives.	Applications (eg, speech processing, computer vision, NLP)	anonymous|inverse_learning_with_extremely_sparse_feedback_for_recommendation	/pdf/35a9df35f527372e6cea994ec623f70a70c47cd5.pdf
lVltX5KwODu	3959	Siamese-NAS: Using Trained Samples Efficiently to Find Lightweight Neural Architecture by Prior Knowledge	['predictor-based NAS', 'prior knowledge', 'sampling efficiency', 'lightweight CNN architecture.']	The proposed Siamese-Predictor to find lightweight neural architecture using a few trained samples by prior knowledge.	Deep Learning and representational learning	anonymous|siamesenas_using_trained_samples_efficiently_to_find_lightweight_neural_architecture_by_prior_knowledge	/pdf/b54e4843ed15fc9ca111edbab7f002e42c2639f0.pdf
NxnqA1iKeT	3960	From Distance to Dependency: A Paradigm Shift of Full-reference Image Quality Assessment	['Image quality assessment', 'brownian distance covariance', 'distance dependency']	Beyond distance measure, we propose the first Deep Image Dependency (DID) based full-reference image quality assessment model to capture transformation-invariant  texture perception.	Applications (eg, speech processing, computer vision, NLP)	anonymous|from_distance_to_dependency_a_paradigm_shift_of_fullreference_image_quality_assessment	/pdf/a79648db223c322f2f489f671c7a4e703147261e.pdf
wPVw218szF	3961	Near Optimal Private and Robust Linear Regression	['differential privacy', 'private estimation', 'linear regression', 'label corruption']	We provide a private gradient descent with adaptive clipping that achieves near optimal error rate and robustness against label noise.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|near_optimal_private_and_robust_linear_regression	/pdf/3cab907a5b0b78c5dca9394be388603e7e514db8.pdf
iYC5hOMqUg	3964	Bayesian Oracle for bounding information gain in neural encoding models	['information theory', 'evaluation metrics', 'Bayesian', 'Neuroscience', 'encoding models']	We provide a method to obtain upper bounds of information gain in order to evaluate neural encoding models.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|bayesian_oracle_for_bounding_information_gain_in_neural_encoding_models	/pdf/d03fd5143528bd1df3ea3226d7974aadb1de9e1c.pdf
8KYeilT3Ow	3965	NAGphormer: A Tokenized Graph Transformer for Node Classification in Large Graphs	['Graph Transformer', 'node classification', 'neighborhood aggregation', 'multi-hop neighborhood']	We propose a novel Graph Transformer that utilizes the neighborhood aggregation of multiple hops to build the input sequence of token vectors and thereby can handle large graphs efficiently.	Deep Learning and representational learning	anonymous|nagphormer_a_tokenized_graph_transformer_for_node_classification_in_large_graphs	/pdf/1587d4f9977db8a1b2e890e38a3dcca0348b739a.pdf
1ehuYMrigt	3966	Learning from Asymmetrically-corrupted Data in Regression for Sensor Magnitude	['regression', 'sensor data analytics', 'healthcare']	This paper addresses a regression problem for sensor magnitude in which a low value of labels can also mean incomplete observation. We derive an unbiased learning algorithm with a regression learned from data without incomplete observations.	General Machine Learning (ie none of the above)	anonymous|learning_from_asymmetricallycorrupted_data_in_regression_for_sensor_magnitude	/pdf/3b2970bb5ce373448549df514fadcc8e9a342e4d.pdf
Ki4ocDm364	3967	Pareto-Efficient Decision Agents for Offline Multi-Objective Reinforcement Learning	['Reinforcement Learning', 'Offline Reinforcement Learning', 'Multi-Objective Reinforcement Learning', 'Decision Transformer', 'Sequential Decision Making']	We introduce new dataset & benchmarks and propose new algorithms for offline Multi-Objective Reinforcement Learning (MORL)	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|paretoefficient_decision_agents_for_offline_multiobjective_reinforcement_learning	/pdf/c52f5c3855fcf633a69e2e1b509cb9797e2f0417.pdf
J9p5s5jwna	3968	Conditional Policy Similarity: An Overlooked Factor in Zero-Shot Coordination	['multi-agent reinforcement learning', 'zero-shot coordination', 'conditional policy similarity']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|conditional_policy_similarity_an_overlooked_factor_in_zeroshot_coordination	/pdf/c4f252cd83afe536402132a7ad1d5a69a85314fe.pdf
KkazG4lgKL	3969	Efficient Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy	['Out-of-Distribution detection', 'Hopfield Energy', 'Hyperparameter-Free']	We propose a novel out-of-distribution detection method motivated by  Modern Hopfield Energy, and futhur derive a simplified version that is effective, efficient and hyperparameter-free.	Deep Learning and representational learning	anonymous|efficient_outofdistribution_detection_based_on_indistribution_data_patterns_memorization_with_modern_hopfield_energy	/pdf/fa043559f80e457eceb7a9186836547a56cbb1d8.pdf
1yaLQb4mIl	3970	Can Fair Federated Learning reduce the need for personalization?	['Federated Learning', 'Fair Federated Learning', 'FL', 'Fair FL', 'Local Adaptation', 'Personalization', 'Machine Learning', 'ML', 'Deep Learning', 'DL', 'Distributed Machine Learning']	This work evaluates Q-Fair Federated Learning as an alternative to personalization, we find that it does not satisfactorily improve local federated model performance and propose an approach based on Knowledge Distillation offering favourable results.	Optimization (eg, convex and non-convex optimization)	anonymous|can_fair_federated_learning_reduce_the_need_for_personalization	/pdf/972c553d6ef725dfcee7e2ebf54007753cd4b562.pdf
SmufNDN90G	3971	Policy-Based Self-Competition for Planning Problems	['reinforcement learning', 'alphazero', 'self-competition', 'self-critical', 'gumbel', 'mcts']	Solving deterministic single-agent problems through self-competition by including a historical policy in the planning process of Gumbel AlphaZero.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|policybased_selfcompetition_for_planning_problems	/pdf/e1a1247806a6cf9d863fc372229cc04956b01a87.pdf
241s3NHjxc	3972	Extending graph transformers with quantum computed aggregation	['graph neural networks', 'graph representation learning', 'quantum computing', 'graph transformers']	A new Graph Neural Network architecture where the aggregation weights are computed with a quantum computer.	Deep Learning and representational learning	anonymous|extending_graph_transformers_with_quantum_computed_aggregation	/pdf/ac999837bc6f9e00c4e4b590ca03e2e3a649830c.pdf
N6NO4o_b5r	3973	Group-wise Verifiable Distributed Computing for Machine Learning under Adversarial Attacks	['Adversarial attack', 'Verifiable computing', 'Distributed Computing', 'Coded computing']	This paper tackles adversarial attack and straggler effect in distributed computing by proposing Group-wise Verifiable Coded Computing. 	General Machine Learning (ie none of the above)	anonymous|groupwise_verifiable_distributed_computing_for_machine_learning_under_adversarial_attacks	/pdf/ece03789eacf49df4f5648393051da731edd5a79.pdf
e8MaU4BNVA	3974	Revisiting Dense Retrieval with Unaswerable Counterfactuals	['Open-domain Question Answering', 'Text Retrieval']		Applications (eg, speech processing, computer vision, NLP)	anonymous|revisiting_dense_retrieval_with_unaswerable_counterfactuals	/pdf/ba235e7232ab5500c24f30c0998b3538ea430222.pdf
BVaytYu5Yj	3975	Improving Continual Learning by Accurate Gradient Reconstructions of the Past	[]	We propose a new, principled yet practical continual learning method that combines the complementary benefits of function-regularisation, weight-regularisation and experience replay.	General Machine Learning (ie none of the above)	anonymous|improving_continual_learning_by_accurate_gradient_reconstructions_of_the_past	/pdf/310e94227a197e850ef9c3fa42832275cda312ea.pdf
n-d5xFHrk4	3976	CCIL: Context-conditioned imitation learning for urban driving	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|ccil_contextconditioned_imitation_learning_for_urban_driving	/pdf/33960bae6e4a8592cf30896ed36fa5a7e61222b5.pdf
ORp91sAbzI	3977	Leveraging Unlabeled Data to Track Memorization	['memorization', 'label noise', 'generalization', 'unlabeled data', 'deep learning']	We propose a practical metric to track memorization for neural networks, which together with the overall training accuracy can distinguish models with low label noise memorization on the training set and high generalization to unseen data.	Deep Learning and representational learning	anonymous|leveraging_unlabeled_data_to_track_memorization	/pdf/eb92061c2a14b96e835f736a78d596339fe734a3.pdf
deit1AdsFU	3979	Learning To Invert: Simple Adaptive Attacks for Gradient Inversion in Federated Learning	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_to_invert_simple_adaptive_attacks_for_gradient_inversion_in_federated_learning	/pdf/64363982c84b5f6eb48debf9bb39680c33562378.pdf
GHOMWtsFhj	3980	Object Detection with OOD Generalizable Neural Architecture Search	['Out-of-Distribution', 'neural architecture search']		Applications (eg, speech processing, computer vision, NLP)	anonymous|object_detection_with_ood_generalizable_neural_architecture_search	/pdf/f9c65ab942c64fc57e5405acb8d8bdd48e3b5c47.pdf
0oDzoRjrbj	3981	Weak Supervision Variational Auto-Encoder	['Variational Auto-Encoders', 'Weak Supervision', 'Weak Labelling']	A VAE model with specifically designed components to perform weak supervision. Compared to existing weak supervision methods, it is considerably more robust to labelling functions design.	Deep Learning and representational learning	anonymous|weak_supervision_variational_autoencoder	/pdf/2346f673651e87506444f2397d2f51058b5fa2f7.pdf
h1SoBc6wLgp	3982	Graphics Capsule: Learning hierarchical 3D representations from 2D images and its application on human faces	[]		Unsupervised and Self-supervised learning	anonymous|graphics_capsule_learning_hierarchical_3d_representations_from_2d_images_and_its_application_on_human_faces	/pdf/75299c946fe58b85120c32e2e1aa076fe47087df.pdf
WhwtdGkbaDr	3983	Generalization Bounds with Arbitrary Complexity Measures	['Complexity Measure', 'Generalization Bounds', 'Disintegrated PAC-Bayes Bounds']	We provide novel probabilistic generalization bounds able to integrate arbitrary complexity measures be leveraging the framework of disintegrated PAC-Bayes bounds 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|generalization_bounds_with_arbitrary_complexity_measures	/pdf/8c8f880abfebc6a1d803477397318804aff0c5fe.pdf
7o6iMO1gkeJ	3984	DetectBench: An Object Detection Benchmark for OOD Generalization Algorithms	['Out-of-Distribution', 'object detection', 'benchmark']		Applications (eg, speech processing, computer vision, NLP)	anonymous|detectbench_an_object_detection_benchmark_for_ood_generalization_algorithms	/pdf/11ec8b5577ab2e79387e2ad6857d1a818a7d62e2.pdf
-SKvXtXPCaJ	3985	Learning Control by Iterative Inversion	['RL', 'IRL']	Inverting a dynamical system to give the actions which yield desired behavior, represented as an embedding of a trajectory.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_control_by_iterative_inversion	/pdf/dac83de44f4e9858598471c3518db217d7b629e0.pdf
wJkXkCzWFSx	3989	$\epsilon$-Invariant Hierarchical Reinforcement Learning for Building Generalizable Policy	['hierarchical reinforcement learning', 'generalizable policy', 'zero-shot generalization']	We propose a new HRL method, which can build generalizable policy with general subgoals, for solving complex high-dimensional controlling maze-navigation tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|\epsiloninvariant_hierarchical_reinforcement_learning_for_building_generalizable_policy	/pdf/e095ce305cf36c1fd18bf1e2f15b01e47dad9b23.pdf
oIkZyOytR3g	3990	Q-learning Decision Transformer: Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL	['offline reinforcement learning', 'reward conditional model', 'dynamic programming', 'decision transformer']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|qlearning_decision_transformer_leveraging_dynamic_programming_for_conditional_sequence_modelling_in_offline_rl	/pdf/b4ec62e324734b268902c0509c4e9339066e081a.pdf
7tJyBmu9iCj	3992	Neural-based classification rule learning for sequential data	['classification rule learning', 'binary neural network', 'interpretable AI', 'sequential data']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|neuralbased_classification_rule_learning_for_sequential_data	/pdf/40a73f09295c4a073eb4533ac003b30cbacfa97c.pdf
gu-SC0dpkvw	3993	Almost Linear Constant-Factor Sketching for $\ell_1$ and Logistic Regression	['regression', 'sketching', 'data streams', 'logistic regression']	We give the first constant factor approximate sketches for l1 and logistic regression in a turnstile stream with almost linear sketching dimension that result in an efficient optimization problem in the sketch space.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|almost_linear_constantfactor_sketching_for_\ell_1_and_logistic_regression	/pdf/dd5693baf14144671fe8beb0fed449a8e22bffa0.pdf
0Vv4H4Ch0la	3994	Capturing the Motion of Every Joint: 3D Human Pose and Shape Estimation with Independent Tokens	['3D human pose and shape estimation', '3d human reconstruction', 'transformer', 'independent tokens', 'temporal modeling', 'joint rotational motion']	We present a novel, effective and robust model with designed independent tokens to estimate 3D human pose and shape from monocular videos	Deep Learning and representational learning	anonymous|capturing_the_motion_of_every_joint_3d_human_pose_and_shape_estimation_with_independent_tokens	/pdf/f18d5d13ce391dfd10b98e4222fbe369771ae9b3.pdf
sKWlRDzPfd7	3995	MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning	['reinforcement learning', 'multi-agent learning', 'unsupervised environment design']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|maestro_openended_environment_design_for_multiagent_reinforcement_learning	/pdf/9f3a4f92e7e691e4440528a84435555e91c5c75d.pdf
gPxd1tTvoaC	3996	Combating noisy labels with stochastic noise-tolerated supervised contrastive learning	[]		Deep Learning and representational learning	anonymous|combating_noisy_labels_with_stochastic_noisetolerated_supervised_contrastive_learning	/pdf/8e34f0e779be8891887c2ead02dc396e55918c3d.pdf
oBbsPbMsY3	3997	Self-Supervised Extreme Compression of Gigapixel Images	['Self-supervision', 'gigapixel', 'pathology', 'cancer', 'data-augmentations', 'compression']	We adapted the self-supervised learning framework to learn gigapixels images embeddings and show their linear superiority on several downstream classification tasks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|selfsupervised_extreme_compression_of_gigapixel_images	/pdf/aa28e279e39da6d02c4c300cbc4126660f3d3d52.pdf
JpRExTbl1-	3998	Gradient Gating for Deep Multi-Rate Learning on Graphs	['GNNs', 'message-passing', 'oversmoothing', 'heterophilic graphs', 'multi-rate learning', 'gating', 'large graphs']		Deep Learning and representational learning	anonymous|gradient_gating_for_deep_multirate_learning_on_graphs	/pdf/8c0c3b6ed1a28722c08f194b84f7405a57038154.pdf
e3U6bGsfcA	4000	Two Birds, One Stone: An Equivalent Transformation for Hyper-relational Knowledge Graph Modeling	['Hyper-relational knowledge graph', 'hyperedge expansion', 'graph neural network']	We propose a simple yet effective transformation strategy for hyper-relational knowledge graph modeling with both semantic and structural information captured.	Deep Learning and representational learning	anonymous|two_birds_one_stone_an_equivalent_transformation_for_hyperrelational_knowledge_graph_modeling	/pdf/e09373dd7bda9f24cf9614b5cce587d792a68d1b.pdf
3v2DIO9oVl	4001	Generalization error bounds for Neural Networks with ReLU activation	['relu stability', 'sgd stability', 'non smooth neural network stability']	We show that generalization error of Neural Netowrks with ReLU activations approaches zero with proabbility 1 as we increase the training points	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|generalization_error_bounds_for_neural_networks_with_relu_activation	/pdf/d785b3353aa69771aab1933a1f35da863c9fb932.pdf
PAKkOriJBd	4002	Coordination Scheme Probing for Generalizable Multi-Agent Reinforcement Learning	['reinforcement learning', 'multi-agent reinforcement learning', 'agent modeling']	A few-shot MARL approach for improving coordination ability with diverse teammates	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|coordination_scheme_probing_for_generalizable_multiagent_reinforcement_learning	/pdf/4ff18e9857e0b62660a5a60bb230dd1c5aee5374.pdf
zZXztocaN9	4003	BO-Muse: A Human expert and AI teaming framework for accelerated experimental design 	['Experimental Design', 'Machine learning', 'Optimisation', 'Bayesian optimisation', 'Human-AI Teaming']	A Human-AI collaborative optimisation approach using sample-efficient Bayesian optimisation 	Optimization (eg, convex and non-convex optimization)	anonymous|bomuse_a_human_expert_and_ai_teaming_framework_for_accelerated_experimental_design	/pdf/1132e6bbd53b914e3538593d88fea40005f4ad8f.pdf
TmJtBnIWkB	4004	Pessimistic Policy Iteration for Offline Reinforcement Learning	['offline reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pessimistic_policy_iteration_for_offline_reinforcement_learning	/pdf/c2e3fcc8ab1cb6ad5b035ad6e82103023a11aeac.pdf
OTbRTIY4YS	4005	Global Explainability of GNNs via Logic Combination of Learned Concepts	['Explainability', 'Graph Neural Networks', 'Concept Learning']	We propose GLGExplainer, the first Global Explainer for GNNs capable of generating explanations as arbitrary Boolean combinations of graphical concepts.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|global_explainability_of_gnns_via_logic_combination_of_learned_concepts	/pdf/59a36229ea4867f6422d794b20601bc290adec20.pdf
UL3RnLLQ-jK	4007	Towards graph-level anomaly detection via deep evolutionary mapping	['Graph anomaly detection', 'anomaly detection', 'graph representation', 'deep learning', 'graph neural network']	We propose a novel graph-level anomaly detection framework by mapping graphs into a specially designed feature space in which anomalies and normal graphs are well-separated.	Deep Learning and representational learning	anonymous|towards_graphlevel_anomaly_detection_via_deep_evolutionary_mapping	/pdf/3f0c573f972864d6bc9a45007bc93324c3f532a4.pdf
ROHDcdx8g6n	4008	Efficient Controllable Generation with Guarantee	['controllable generation', 'variational autoencoder', 'identifiability']	We propose a general method with theoretical guarantee and integrate it with NVAE for controllable generation.	Generative models	anonymous|efficient_controllable_generation_with_guarantee	/pdf/3f7613c96e92aa765fc6167bff712d702ec98a36.pdf
JLLTtEdh1ZY	4010	Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees	['Reinforcement learning', 'Formal Verification', 'Representation Learning']	Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|wasserstein_autoencoded_mdps_formal_verification_of_efficiently_distilled_rl_policies_with_manysided_guarantees	/pdf/af1294b358f3ecec748d128070f831d88d1de036.pdf
8XQd91fDSf9	4011	Two-Dimensional Weisfeiler-Lehman Graph Neural Networks for Link Prediction	[]	We propose provably powerful 2-WL variants for link prediction and successfully implement them to get competitive results and speed advantage.	Deep Learning and representational learning	anonymous|twodimensional_weisfeilerlehman_graph_neural_networks_for_link_prediction	/pdf/c290eeabb5b9777fb32dbae531dc76c4c8716097.pdf
7pl0FRiS0Td	4012	Contextual Transformer for Offline Reinforcement Learning	['Offline Meta Reinforcement Learning', 'Prompt Tuning', 'Transformer']	This paper explores how prompts help sequence-modeling based offline-RL algorithms	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|contextual_transformer_for_offline_reinforcement_learning	/pdf/cff23618c8271baa4db98a6fb73e4abca72074b1.pdf
2mvALOAWaxY	4013	Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice Polytopes	['Rectified Linear Unit', 'Neural Network Expressivity', 'Neural Network Depth', 'Lattice Polytope', 'Normalized Volume']	We derive lower bounds on the depth of integral ReLU neural networks using volume arguments for lattice polytopes arising from connections to tropical geometry.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|lower_bounds_on_the_depth_of_integral_relu_neural_networks_via_lattice_polytopes	/pdf/0363b134323e34b6c65101cafee23e251e4373c7.pdf
yHIIM9BgOo	4014	Graph-based Deterministic Policy Gradient for Repetitive Combinatorial Optimization Problems	[]	A general learning framework is proposed to learn reusable node or edge representations that can reduce the optimality gap of fast heuristics for repetitive combinatorial optimization problems.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|graphbased_deterministic_policy_gradient_for_repetitive_combinatorial_optimization_problems	/pdf/220543410e3edc58866ce5856f42f6149ab66972.pdf
NM1Lt3ZBhal	4017	Pseudo-Edge: Semi-Supervised Link Prediction with Graph Neural Networks	['Graph Neural Networks', 'Link Prediction', 'Pseudo-labeling', 'Semi-supervised learning']		Deep Learning and representational learning	anonymous|pseudoedge_semisupervised_link_prediction_with_graph_neural_networks	/pdf/ae9387bb22708ccd53c3f8e4cd7f0fcdd8e0dca4.pdf
5KUPKjHYD-l	4018	MAST: Masked Augmentation Subspace Training for Generalizable Self-Supervised Priors	['Self-Supervised Learning (SSL)', 'Generalization', 'Computer vision']	Disentangled and uncertainty-aware learning of augmentation invariances during SSL improves generalization on downstream tasks	Unsupervised and Self-supervised learning	anonymous|mast_masked_augmentation_subspace_training_for_generalizable_selfsupervised_priors	/pdf/764609fd8399a64eaa350c54117b2ee3fb0ebe51.pdf
663Cl-KetJ	4019	Better with Less: Data-Active Pre-training of Graph Neural Networks	['Pre-training', 'Graph Neural Networks']		Deep Learning and representational learning	anonymous|better_with_less_dataactive_pretraining_of_graph_neural_networks	/pdf/9cd3e5b44de2e561ffc54b018e7b64e9577a87e0.pdf
u0aNcjqhEJ	4021	Consciousness-Aware Multi-Agent Reinforcement Learning	['multi-agent reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|consciousnessaware_multiagent_reinforcement_learning	/pdf/2fe17f30be38037dbd0879688559e2f0209d3645.pdf
si1JH05iUV	4022	Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts	['OOD Detection', 'Intent Detection', 'Multi-turn Dialogue Context']	A context-aware OOD intent detection framework (Caro) that aims to consider multi-turn contexts in OOD intent detection tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|outofdomain_intent_detection_considering_multiturn_dialogue_contexts	/pdf/543dcf9a952030ae88e922bab922bb3c47b20b94.pdf
xtbog7cfsr	4023	The Implicit Bias of Minima Stability in Multivariate Shallow ReLU Networks	['Implicit bias', 'implicit regularization', 'stability', 'Hessian', 'dynamical systems', 'depth separation', 'approximation']	A study of multivariate two layer ReLU nets via dynamical stability, showing bias to smooth functions, depth separation and stable approximation guarantees	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|the_implicit_bias_of_minima_stability_in_multivariate_shallow_relu_networks	/pdf/d25896109b68e0092c64e77879ee92e3e2b30dad.pdf
TBOFHtBariC	4024	On discrete symmetries of robotics systems: A group-theoretic and data-driven analysis	['Morphological Symmetries', 'Discrete Symmetries of Dynamical Systems', 'Equivariant Dynamics', 'Equivariant Function Approximators', 'Geometric Deep Learning']	We present a group-theoretic analysis of bilateral/radial symmetries of dynamical systems. Characterizing the symmetries of the system's dynamics, control, and proprioceptive/exteroceptive data. And elucidating how to exploit these symmetries in DL	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_discrete_symmetries_of_robotics_systems_a_grouptheoretic_and_datadriven_analysis	/pdf/a609928c7f24c130f82dd10241f46d331c8220dd.pdf
TpqJy1BmD6K	4025	Learning to solve the Hidden Clique Problem with Graph Neural Networks	['graph', 'graph neural network', 'GNN', 'hidden clique', 'supervised learning', 'deep learning']	Comparison of different graph neural networks on the hidden clique problem	Deep Learning and representational learning	anonymous|learning_to_solve_the_hidden_clique_problem_with_graph_neural_networks	/pdf/152d2dbfa268993085fab5c9b8ed595bd548c8b4.pdf
5spDgWmpY6x	4026	How Sharpness-Aware Minimization Minimizes Sharpness?	['implicit bias', 'implicit regularization', 'sharpness', 'sharpness aware minimization']	we prove the implicit bias of Sharpness-Aware Minimization (SAM) is minimizing the top eigenvalue of Hessian in the full-batch setting or minimizing the trace of Hessian when batch size is 1.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|how_sharpnessaware_minimization_minimizes_sharpness	/pdf/2d104d335aa40fb3bdce264ace705da0c26f3642.pdf
MnEjsw-vj-X	4027	Active Learning for Object Detection with Evidential Deep Learning and Hierarchical Uncertainty Aggregation	['Active Learning', 'Object Detection', 'Uncertainty Estimation', 'Bayesian Learning']	We propose an active learning method for object detection using evidential deep learning and novel uncertainty aggregation method.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|active_learning_for_object_detection_with_evidential_deep_learning_and_hierarchical_uncertainty_aggregation	/pdf/2abc183e0f08381117264c1240364ecffc689658.pdf
Rkk51I-BpMH	4028	Caption supervision enables robust learners: a controlled study of distributionally robust model training	['self-supervised learning', 'computer vision', 'effective robustness', 'vision language', 'CLIP', 'ImageNet', 'LAION', 'CC12M', 'YFCC']	We introduce CaptionNet, a fully captioned, fully supervised dataset with ImageNet-compliant labels, and through experiment,  show how the choice of loss function, data filtration and supervision strategy enable robust computer vision.	Unsupervised and Self-supervised learning	anonymous|caption_supervision_enables_robust_learners_a_controlled_study_of_distributionally_robust_model_training	/pdf/4b7a539c0be3142ce0a219506c7202dbebaee10e.pdf
mencEcrobES	4029	GAML: geometry-aware meta-learning via a fully adaptive preconditioner	['Meta-learning', 'few-shot learning']		Deep Learning and representational learning	anonymous|gaml_geometryaware_metalearning_via_a_fully_adaptive_preconditioner	/pdf/0c27c8bd51a41bcf506cb1b67eb1f534bb9d38aa.pdf
nchvKfvNeX0	4030	Learning ReLU networks to high uniform accuracy is intractable	['learning theory', 'ReLU networks', 'hardness results', 'sample complexity', 'teacher-student learning']	Learning target classes of ReLU networks to high uniform accuracy needs exponentially many samples.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|learning_relu_networks_to_high_uniform_accuracy_is_intractable	/pdf/725ea545fd4a5b9f10857806e9f514e485e837c4.pdf
4Jq0XWCZQel	4031	Neural Image Compression with a Diffusion-based Decoder	['neural', 'image', 'lossy', 'compression', 'diffusion', 'gan', 'perceptual']	Diffusion-based neural image codec allowing smooth and competitive rate-distortion-perception traversal at test time.	Generative models	anonymous|neural_image_compression_with_a_diffusionbased_decoder	/pdf/cf72b02378f0504ae839fb89b2d1d1487a296c1e.pdf
IXBC0sG3cN	4032	Tree-structure segmentation for logistic regression	['logistic regression', 'decision tree', 'credit scoring', 'segmentation']	"Practitioners, in particular in the banking industry, often perform clustering to obtain ""client segments"" on which they fit separate supervised models. We perform both by learning ""logistic regression trees""."	Applications (eg, speech processing, computer vision, NLP)	anonymous|treestructure_segmentation_for_logistic_regression	/pdf/dc7834e728370d4b6f0d8b75acf7188a7795fefa.pdf
a0e7x2EuFO	4033	Generative Spoken Language Model based on continuous word-sized audio tokens	['spoken language model', 'sentence generation', 'speech synthesis', 'k nearest neighbors', 'unsupervised learning', 'textless technology']	We introduced a generative spoken language model based on continuous word-sized acoustic tokens.	Generative models	anonymous|generative_spoken_language_model_based_on_continuous_wordsized_audio_tokens	/pdf/9fc0c73903aad9b17b29cbd60146d0a417035bec.pdf
EN8YE5dkOO	4034	Cold Rao-Blackwellized Straight-Through Gumbel-Softmax Gradient Estimator	['Gumbel-Softmax', 'categorical variables', 'Concrete distribution', 'gradient', 'straight-through', 'VAE', 'quantization']	Improved gradient estimator for categorical random variables by finding the zero temperature limit of the Rao-Blackwellized Straight-Through Gumbel-Softmax Gradient Estimator	Generative models	anonymous|cold_raoblackwellized_straightthrough_gumbelsoftmax_gradient_estimator	/pdf/85b560c17ddec961640b413f84a37883b7008bf7.pdf
Th4_9F0a6l	4036	The Effective coalitions of Shapley value For Integrated Gradients	['Explanation Shapley value']	The Effective coalitions of Shapley value For Integrated Gradients	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|the_effective_coalitions_of_shapley_value_for_integrated_gradients	/pdf/68e582f56cfad8e0f13264415b2e10c3340c88ca.pdf
HVVDVaegjaW	4037	MonoFlow: A Unified Generative Modeling Framework for GAN Variants	[]		Generative models	anonymous|monoflow_a_unified_generative_modeling_framework_for_gan_variants	/pdf/a7bd31e650f37974ae609fe963fa000d90f770e9.pdf
LeZ39Gkwbi0	4038	ProtoGNN: Prototype-Assisted Message Passing Framework for Non-Homophilous Graphs	['Graph Neural Networks', 'Graph representation learning', 'Non-homophilous Graph', 'Heterophily', 'Non-homophily', 'Node Classification']	Class prototype-assisted message passing framework for improving node representation learning on non-homophilous graphs	Deep Learning and representational learning	anonymous|protognn_prototypeassisted_message_passing_framework_for_nonhomophilous_graphs	/pdf/037869a1efff3871c6bdd02c0a6e81094b18112a.pdf
U3_J25hAoRQ	4042	Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed RL Environments	['long tail distribution', 'reinforcement learning', 'representation learning', 'contrastive learning', 'complementary learning system', 'hippocampus']	Improving learning in long-tailed RL environments using momentum boosted episodic memory.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|momentum_boosted_episodic_memory_for_improving_learning_in_longtailed_rl_environments	/pdf/e82c49153b1035add82c3f53f4f68e7691127f67.pdf
YAxV_Krcdjm	4043	ASIF: coupled data turns unimodal models to multimodal without training	['Representation learning', 'Multimodal models', 'Analogy', 'Sparsity', 'Relative representations']	How to build a CLIP-like model with two pretrained encoders and a limited amount of image-text pairs without tuning a neuron.	Deep Learning and representational learning	anonymous|asif_coupled_data_turns_unimodal_models_to_multimodal_without_training	/pdf/59fa76d833b31f4290f31f8cffd302285bdf080b.pdf
L64Bs1OSNjZ	4045	Learning DAGs from Fourier-Sparse Data	['directed acyclic graph', 'DAG learning', 'causal Fourier analysis', 'structural equation models', 'additive noise', 'Fourier-sparse']	We leverage recent causal Fourier analysis to pose the novel problem of learning DAGs from data with sparse spectrum and propose a solution that has better performance over existing DAG learning methods.	Unsupervised and Self-supervised learning	anonymous|learning_dags_from_fouriersparse_data	/pdf/2780779b54c17f838db3a0d26a5a240a1927edcf.pdf
YyTFUpG0WmN	4046	Improving the generalization ability of the chaotic time-series classification models by residual component extraction	['chaotic time-series classification', 'feature extraction', 'deep learning', 'clustering', 'chaotic time-series', 'time-series decomposition', 'generalization']	Novel approach to improve the generalization ability of the machine learning methods in the task of chaotic time-series classification.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|improving_the_generalization_ability_of_the_chaotic_timeseries_classification_models_by_residual_component_extraction	/pdf/0564472d90e77ff288937e1eec59b1ce80579032.pdf
xRMOW3kvsEv	4047	Invariance Makes a Difference: Disentangling the Role of Invariance and Equivariance in Representations	['representation learning', 'invariance', 'synthetic data']	We show that performance of representations critically depends on their invariances, via controlled experiments on synthetic data.	Deep Learning and representational learning	anonymous|invariance_makes_a_difference_disentangling_the_role_of_invariance_and_equivariance_in_representations	/pdf/8c559de8ad52160b28dd62894e08d82284ca84c0.pdf
X8-VWbONvr	4050	Lossy Image Compression with Conditional Diffusion Models	['neural image compression', 'denoising diffusion models']	We show that hybridizing compressive VAEs with denoising diffusion models leads to strong performance in perceptual image compression.. 	Generative models	anonymous|lossy_image_compression_with_conditional_diffusion_models	/pdf/207e991c6e4746ff55617908b06b56d4a3f0a9ef.pdf
0_TxFpAsEI	4051	A law of adversarial risk, interpolation, and label noise	['label noise', 'adversarial robustness', 'lower bound', 'robust machine learning']	Laws for how interpolating label noise increases adversarial risk, with stronger guarantees in presence of inductive bias and distributional assumptions.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_law_of_adversarial_risk_interpolation_and_label_noise	/pdf/bfc9b1f02d0a22662bb06105b98e8312de2a6bf5.pdf
c9lAOPvQHS	4052	Fisher-Legendre (FishLeg) optimization of deep neural networks	['Second-order optimization', 'Natural Gradient', 'Deep Learning', 'Meta-learning', 'Fisher information', 'Legendre-Fenchel duality']	We introduce a new approach to estimate the natural gradient via Legendre-Fenchel duality, provide a convergence proof, and show competitive performance on a number of benchmarks.	Deep Learning and representational learning	anonymous|fisherlegendre_fishleg_optimization_of_deep_neural_networks	/pdf/f8dbf067744644edab382f1781dab09baa599e5c.pdf
o_HqtIc-oF	4054	ACQL: An Adaptive Conservative Q-Learning Framework for Offline Reinforcement Learning	['Deep Reinforcement Learning', 'Offline Deep Reinforcement Learning']	We propose Adaptive Conservative Q-Learning (ACQL), a general framework that enables more flexible control over the conservative level of Q-function for offline RL.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|acql_an_adaptive_conservative_qlearning_framework_for_offline_reinforcement_learning	/pdf/7bd090baf00fc91e6d8d94cee843dec33cc80f83.pdf
iUYpN14qjTF	4057	Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization	['generalization', 'gradient descent', 'Neural tangent kernel', 'Adam', 'nonconvex optimization']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|understanding_the_generalization_of_adam_in_learning_neural_networks_with_proper_regularization	/pdf/f53e12a8dd9cafd711efcac49018afc60ef64661.pdf
lYZZl2hp1gp	4058	Robustness of Unsupervised Representation Learning without Labels	['robustness', 'representation learning']	We provide a framework for robustness evaluation and adversarial training of representation encoders without the need for labelled data.	Unsupervised and Self-supervised learning	anonymous|robustness_of_unsupervised_representation_learning_without_labels	/pdf/c3d9ef7c5270a3595b8cf082a74b9078b876ba0e.pdf
JunUr1y3Wa6	4062	Pruning by Active Attention Manipulation	[]		Deep Learning and representational learning	anonymous|pruning_by_active_attention_manipulation	/pdf/db0d1278cbfbc5064ce17fee7170cf6a59f4ba20.pdf
EBS4C77p_5S	4063	SLTUNET: A Simple Unified Model for Sign Language Translation	['Unified Modeling', 'Multi-task Learning', 'Sign Language Translation', 'Cross-modality Learning']	A simple unified model for sign language translation that achieves (near) state-of-the-art performance	Applications (eg, speech processing, computer vision, NLP)	anonymous|sltunet_a_simple_unified_model_for_sign_language_translation	/pdf/99ba56380bb1a018a79908c160e82c4657c13375.pdf
8CJrjp73sfk	4065	Few-bit Backward: Quantized Gradients of Activation Functions for Memory Footprint Reduction	[]		Deep Learning and representational learning	anonymous|fewbit_backward_quantized_gradients_of_activation_functions_for_memory_footprint_reduction	/pdf/82a12a2a1ce7184910f32570a6be3f2d22f96574.pdf
fwn2Mqpy4pS	4066	$\omega$GNNs: Deep Graph Neural Networks Enhanced by Multiple Propagation Operators	['Graph Neural Networks', 'Deep Learning', 'Graph Propagation Operators', 'Over-Smoothing']	We propose a modification to GNNs to prevent over-smoothing and enhance their expressiveness, followed by a theoretical analysis and experiments on 15 real-world datasets, reading similar or better accuracy than state-of-the-art methods.	Deep Learning and representational learning	anonymous|\omegagnns_deep_graph_neural_networks_enhanced_by_multiple_propagation_operators	/pdf/ef01dfd6be4a5a8a5e656b07ffa7a26422962773.pdf
GIZg_kOXqyG	4067	Private and Efficient Meta-Learning with Low Rank and Sparse decomposition	['Meta-learning', 'Low-rank', 'Sparse', 'Privacy']	Provable meta-learning via privacy preserving and optimal low-rank+sparse decomposition	Optimization (eg, convex and non-convex optimization)	anonymous|private_and_efficient_metalearning_with_low_rank_and_sparse_decomposition	/pdf/46eb4209e744fcad36cbafac15ac8ec7f238bd04.pdf
kV0cA81Vau	4068	Server Aggregation as Linear Regression: Reformulation for Federated Learning	['Federated Learning', 'Machine Learning']		General Machine Learning (ie none of the above)	anonymous|server_aggregation_as_linear_regression_reformulation_for_federated_learning	/pdf/a6575ae58ffb51f3cf3462ca442fbba9f0c5b4b3.pdf
rHqa5_nzaCA	4069	No-regret Learning in Repeated First-Price Auctions with Budget Constraints	['first-price auction', 'budget', 'no-regret learning']	We present a bidding strategy in first-price auctions with budget for buyers with sublinear regret.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|noregret_learning_in_repeated_firstprice_auctions_with_budget_constraints	/pdf/d432d985722b347060725f0f16c1bfe9539345ea.pdf
a4COps0uokg	4070	User-Interactive Offline Reinforcement Learning	['Offline RL', 'Reinforcement Learning', 'User', 'Model-based', 'Adaptive']	Offline RL policies need to be adaptvie after training so that a user can alter its behavior to its needs.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|userinteractive_offline_reinforcement_learning	/pdf/be523ab406f122ebdb2e0f9fabc28808df1efa32.pdf
N4K5ck-BTT	4072	Scaffolding a Student to Instill Knowledge	['knowledge distillation', 'tiny capacity student', 'large capacity teacher', 'budget constrained learning']	We develop a novel KD scheme where the teacher scaffolds the student's prediction on hard-to-learn examples.  It smoothens student's loss landscape so that the student encounters fewer local minima. As a result it has good generalization properties.	Deep Learning and representational learning	anonymous|scaffolding_a_student_to_instill_knowledge	/pdf/c740eb3180ac010d658b71f0b03c5f62bd7f7020.pdf
D3lPaQ7iqw	4073	Indoor Localisation for Detecting Medication Use in Parkinson's Disease	"['Transformer', 'Indoor Localisation', 'Medication State Classification', ""Parkinson's Disease""]"	A transformer-based network is proposed for indoor localisation utilising dual modalities where the derived in-home mobility features can be used to classify the medication state of a person with Parkinson's disease	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|indoor_localisation_for_detecting_medication_use_in_parkinsons_disease	/pdf/4f4e14b205b3d44d0b37f89549f1696a71d1e62a.pdf
WsUMeHPo-2	4074	Learnable Graph Convolutional Attention Networks	['GNN', 'GCN', 'GAT']	We propose a GNN which learns to use, in each layer, an interpolation of a GCN, GAT, and a GAT with convolved features. It outperforms existing methods, is more robust, and removes the need of cross-validating.	General Machine Learning (ie none of the above)	anonymous|learnable_graph_convolutional_attention_networks	/pdf/a6825c2f7619cbb55bf69490a3797569580b7110.pdf
rnRiiHw8Vy	4075	FastFill: Efficient Compatible Model Update	['Compatible Representation Learning', 'Image Retrieval', 'Model Regression']	We propose a new uncertainty based updating scheme for online model upgrades of image retrieval systems for compatible representation learning.	Deep Learning and representational learning	anonymous|fastfill_efficient_compatible_model_update	/pdf/f44676af1c11d649d1ab18f4af2dd61bffeb9916.pdf
D6lZTMvBo3	4076	I Speak, You Verify: Toward Trustworthy Neural Program Synthesis	['program synthesis', 'large language models']	Large language models over source code can be made more trustworthy when they jointly generate programs and specifications	Applications (eg, speech processing, computer vision, NLP)	anonymous|i_speak_you_verify_toward_trustworthy_neural_program_synthesis	/pdf/bf58fa05ca00e66312a04408d71db66417e2196d.pdf
10E_ZGfTBt	4077	Improving Adversarial Robustness via Frequency Regularization	[]	We show that AT-CNNs extract robust features from the low-frequency region to gain robustness and explain why the white-box attack is hard to defend from a spectral perspective, then propose a frequency regularization to improve the robustness.	Deep Learning and representational learning	anonymous|improving_adversarial_robustness_via_frequency_regularization	/pdf/f02febd463eac082373441dec52c1084795a17f4.pdf
ih3mo7J-vb	4078	Calibration for Decision Making via Empirical Risk Minimization	['Calibration', 'Risk', 'Bayesian decision making', 'score decomposition', 'temperature scaling', 'direct loss minimization', 'margin rescaling']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|calibration_for_decision_making_via_empirical_risk_minimization	/pdf/6ef47e2a5ee6db0a1c829f48ba911e5d26f253b1.pdf
YWVkyLV53X	4080	Visually-augmented pretrained language models for NLP Tasks without Images	['Visually-augmented pretrained language models for NLP tasks without images']		Applications (eg, speech processing, computer vision, NLP)	anonymous|visuallyaugmented_pretrained_language_models_for_nlp_tasks_without_images	/pdf/8872b847b0932f3251b94122e8ce8ccf1bed93af.pdf
WhbWzFg8cZ	4081	Keypoint Matching via Random Network Consensus	['Computer Vision', 'Keypoint Matching', 'Randomized Networks', 'Visual Descriptor', 'Detector']	A new approach that uses convolutional neural networks (CNNs) for keypoint description, detection, and matching, without requiring the deep networks to be trained.	Applications (eg, speech processing, computer vision, NLP)	anonymous|keypoint_matching_via_random_network_consensus	/pdf/9f3e1740d5d88ed0e6e91b376e29d6251a906434.pdf
IqN5SgOmxp	4082	Reinforcement Learning using a Molecular Fragment Based Approach for Reaction Discovery	['reinforcement learning', 'transfer learning', 'reaction discovery', 'deep generative model']	A multi-pronged deep learning approach using a fragment based method is applied to chemical reaction discovery	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|reinforcement_learning_using_a_molecular_fragment_based_approach_for_reaction_discovery	/pdf/b98fda30040e520dc7e9c26d6c9196d503cd3bad.pdf
5Egggz1q575	4083	Explaining RL Decisions with Trajectories	['Explainable RL', 'Explainable AI', 'Offline Reinforcement Learning', 'Trajectory Attribution', 'Decision-Aware AI']	This work focuses on idea of explaining actions of offline RL agent by attributing the actions to trajectories encountered during the training.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|explaining_rl_decisions_with_trajectories	/pdf/fe0642d7468e43a51a08dce0a29f50ed0335a125.pdf
U_T8-5hClV	4084	A Primal-Dual Framework for Transformers and Neural Networks	['attention', 'transformer', 'neural network', 'support vector regression', 'primal', 'dual']	We show that the self-attention corresponds to the support vector expansion derived from a support vector regression problem and provide a principled framework for constructing new attention mechanisms from popular neural network layers.	Deep Learning and representational learning	anonymous|a_primaldual_framework_for_transformers_and_neural_networks	/pdf/26469f624dfeccb03c6c48c736bc4ea6c590604e.pdf
u05JdX1Qz-b	4086	ChemAlgebra : Algebraic Reasoning on Chemical Reactions	['algebraic reasoning', 'datasets', 'benchmarks', 'learning-reasoning integration', 'chemical reactions']	In this paper we propose ChemAlgebra, a benchmark for measuring the reasoning capabilities of deep learning models through the prediction of stoichiometrically-balanced chemical reactions.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|chemalgebra_algebraic_reasoning_on_chemical_reactions	/pdf/51ae91a7ded8fdcaf0878c830b7819d432527de4.pdf
aySB6rDo0z	4089	Effective Offline Reinforcement Learning via Conservative State Value Estimation	['Offline Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|effective_offline_reinforcement_learning_via_conservative_state_value_estimation	/pdf/81fe454fae5bd2023f20b2b98ec2afac4d8f0b67.pdf
gfHLOC35Zh	4091	Modality Complementariness: Towards Understanding Multi-modal Robustness	['multimodal robustness theory']		General Machine Learning (ie none of the above)	anonymous|modality_complementariness_towards_understanding_multimodal_robustness	/pdf/e27b0ee4b2149bb27bc677ff54a3c94c61418862.pdf
47KG_AvNqeZ	4092	Online Low Rank Matrix Completion	['Matrix Completion', 'Online Learning', 'Recommendation System']	A novel algorithm for solving online low-rank matrix completion problem with optimal regret for rank-one case.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|online_low_rank_matrix_completion	/pdf/4c04939cf817c78569741489333cbe6c7fef64ae.pdf
qZ1yqKvQtE	4093	CLIP model is an Efficient Continual Learner	['Continual Learning', 'Vision-Language Models', 'Zero-shot Classifiers']	A simple baseline for future comparisons in the continual learning tasks using zero-shot CLIP.	Applications (eg, speech processing, computer vision, NLP)	anonymous|clip_model_is_an_efficient_continual_learner	/pdf/a7d2ab2dd53f8dbf48e3d8732baaa9e9a1da0e01.pdf
ZxhIjuo6p4	4094	Model-Based Decentralized Policy Optimization 	['Multi-Agent Reinforcement Learning']	A novel mode-based decentralized policy optimization algorithm	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|modelbased_decentralized_policy_optimization	/pdf/8409b6c626ebacc94d3b98282e02c13ff92bca07.pdf
xPkJYRsQGM	4095	Contrastive Learning for Unsupervised Domain Adaptation of Time Series	['unsupervised domain adaptation', 'time series', 'contrastive learning', 'deep learning']	We develop a novel framework for UDA of time series data, called CLUDA, through contrastive learning framework to learn domain-invariant contextual representations in multivariate time series.	Deep Learning and representational learning	anonymous|contrastive_learning_for_unsupervised_domain_adaptation_of_time_series	/pdf/f6f990914d30746235c7f54517c397e8d6dfd95b.pdf
J3Y7cgZOOS	4096	Anti-Symmetric DGN: a stable architecture for Deep Graph Networks	[]		Deep Learning and representational learning	anonymous|antisymmetric_dgn_a_stable_architecture_for_deep_graph_networks	/pdf/4f2dc9439af077898838b23223f091f3e68bd8ba.pdf
L8qKBr_bht	4097	Transformers with Multiresolution Attention Heads	['transformer', 'multiresolution analysis', 'attention heads']	We propose the Transformer with Multiresolution-head Attention (MrsFormer), a class of efficient transformers inspired by the multiresolution approximation (MRA) for approximating a signal f using wavelet bases	Deep Learning and representational learning	anonymous|transformers_with_multiresolution_attention_heads	/pdf/19b44cf3ace64634e3865b2f4b61ee9e753ecc26.pdf
33csNbhVnD	4098	Homotopy-based training of NeuralODEs for accurate dynamics discovery	['neural ordinary differential equation', 'synchronization', 'homotopy', 'dynamical systems', 'physics']	Building upon ideas from the chaos literature, we introduce a novel method of training neural ordinary differential equations with drastic improvements for long complex time series prediction.	Optimization (eg, convex and non-convex optimization)	anonymous|homotopybased_training_of_neuralodes_for_accurate_dynamics_discovery	/pdf/cff0f7a1456deb897c74f850843d402984e25dee.pdf
hxUwnEGxW87	4099	Statistical Theory of Differentially Private Marginal-based Data Synthesis Algorithms	['Synthetic data', 'differential privacy', 'marginal-based method', 'Bayesian network', 'learning theory']	We analyze the differentially private marginal-based data synthesis algorithms in a statistical framework and establish a theoretical guarantee for the accuracy and utility.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|statistical_theory_of_differentially_private_marginalbased_data_synthesis_algorithms	/pdf/c2952394229cefed04db09dd0adb65771dff043b.pdf
J_Cja7cpgW	4100	Consolidator: Mergable Adapter with Group Connections for Vision Transformer	['Efficient Transfer Learning', 'Groups Connections', 'Vision Transformer']	We propose a module named consolidator to achieve both parameter- and inference-efficient transfer learning for vision transformers	Applications (eg, speech processing, computer vision, NLP)	anonymous|consolidator_mergable_adapter_with_group_connections_for_vision_transformer	/pdf/54f4dbf30766e4a53eb5bb351e4b0a73681da8e3.pdf
iIfDQVyuFD	4102	Confidential-PROFITT: Confidential PROof of FaIr Training of Trees	['Fairness', 'Audit', 'Confidentiality', 'Zero-Knowledge Proof']	We introduce a method to provide a confidential proof of fair training.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|confidentialprofitt_confidential_proof_of_fair_training_of_trees	/pdf/1ebf11599295c2e93c9769d232b7d768a716707a.pdf
fQGjNpkGVf	4105	On the Shortcut Learning in Multilingual Neural Machine Translation	['Multilingual Neural Machine Translation', 'shortcut learning', 'generalization']	Single centric MNMT suffers from off-target issues due to overfitting of shortcut patterns of  language mappings. Multilingual pretraining aggregates such overfitting. We propose a simple training strategy to eliminate such shortcut patterns.	Applications (eg, speech processing, computer vision, NLP)	anonymous|on_the_shortcut_learning_in_multilingual_neural_machine_translation	/pdf/fc5ea57fa5e01c1968c9732353b766a38dfaedc1.pdf
7qyLeRm1e3	4106	Improving Generative Flow Networks with Path Regularization	['generative flow networks', 'path regularization', 'optimal transport']	We propose a novel path regularization method based on optimal transport theory that places  prior constraints on the underlying structure of the GFlowNets	Deep Learning and representational learning	anonymous|improving_generative_flow_networks_with_path_regularization	/pdf/c3c0714bdf407432cbb566b72fe07116b4a3d35c.pdf
7IG0wsTND7w	4108	Domain Generalisation via Domain Adaptation: An Adversarial Fourier Amplitude Approach	['Domain generalisation', 'Domain adaptation', 'Fourier analysis']	We tackle the domain generalisation problem by posing it as a domain adaptation task where we adversarially synthesise the worst-case target domain via Fourier amplitude generation.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|domain_generalisation_via_domain_adaptation_an_adversarial_fourier_amplitude_approach	/pdf/1a07bdc604017d9871d697cb42185d8595fbf652.pdf
Zp4EIt1yFID	4109	Toward Effective Deep Reinforcement Learning for 3D Robotic Manipulation: End-to-End Learning from Multimodal Raw Sensory Data	['deep reinforcement learning', 'robotic manipulation', 'end-to-end learning', 'multimodal representation learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|toward_effective_deep_reinforcement_learning_for_3d_robotic_manipulation_endtoend_learning_from_multimodal_raw_sensory_data	/pdf/a7c0d41379a2a855256837311d3406b5ec3f95e1.pdf
e9T1iIAbfKj	4110	UnifySpeech: A Unified Framework for Zero-shot Text-to-Speech and  Voice Conversion	['decoupling', 'zero-shot learning', 'text-to-speech', 'voice conversion', 'vector quantization']		Applications (eg, speech processing, computer vision, NLP)	anonymous|unifyspeech_a_unified_framework_for_zeroshot_texttospeech_and_voice_conversion	/pdf/19f9094e08a7425d88b3dce7c5b4b49667325116.pdf
I9J8gIyqRE	4111	Lmser-pix2seq: Learning Stable Sketch Representations For Sketch Healing	['sketch healing', 'Lmser', 'stable representations', 'bi-directional connections']		Deep Learning and representational learning	anonymous|lmserpix2seq_learning_stable_sketch_representations_for_sketch_healing	/pdf/db1b338a2dad0d7dcfcff52081659b1d1fbc72ea.pdf
hhvkdRdWt1F	4112	Dual Algorithmic Reasoning	['Algorithmic Reasoning', 'Deep Learning for Graphs']	A neural algorithmic reasoning approach exploiting the duality principle	Deep Learning and representational learning	anonymous|dual_algorithmic_reasoning	/pdf/d4e0f818497458f38ffafd6f899969b6fc5518df.pdf
fcA--b8ycdX	4113	Learning System Dynamics from Sensory Input under Optimal Control Principles	[]		Deep Learning and representational learning	anonymous|learning_system_dynamics_from_sensory_input_under_optimal_control_principles	/pdf/8563ba07ff5ebdd9dfad233e66489924b14cac45.pdf
Z7O43UCtGMO	4115	How to Keep Cool While Training	['neural network', 'calibration', 'network calibration', 'cooling', 'temperature scaling', 'classification']	The paper proposes a calibration method applied during neural network training, which removes the need for a learning rate schedule.	Deep Learning and representational learning	anonymous|how_to_keep_cool_while_training	/pdf/45243a2983c65a715fa0c29be1c2e5c314e904d2.pdf
fcg9phFVzjd	4116	Learning Discrete Representation with Optimal Transport Quantized Autoencoders	['VQ-VAE', 'Optimal Transport', '3D Motion Generation']	We propose a simple approach to train VQ-VAE, which can avoid the codebook collapse with the help of optimal transport.	Generative models	anonymous|learning_discrete_representation_with_optimal_transport_quantized_autoencoders	/pdf/a6395d2017057c1afe4d85aa70446eb96ce0170f.pdf
wTGORH_cHPX	4117	DeepGRAND: Deep Graph Neural Diffusion	['graph neural diffusion', 'graph neural networks', 'oversmoothing']	We propose the Deep Graph Neural Diffusion (DeepGRAND), a class of continuous-depth graph neural networks that leverages a data-dependent scaling term and a perturbation to the graph diffusivity to overcome the oversmoothing issue.	Deep Learning and representational learning	anonymous|deepgrand_deep_graph_neural_diffusion	/pdf/350cc3887f1d0161ebe5a91ba5d9572294efa56f.pdf
FGlL0dLjpn	4118	Learning Gradient-based Mixup towards Flatter Minima for Domain Generalization	['Domain Generalization', 'Mixup', 'Gradient-based Method', 'Flatness-aware Optimization']	 We propose a policy to generate the instance weights for mixup based on gradient similarity and optimize a learnable similarity function towards flatter minima for better generalization.	General Machine Learning (ie none of the above)	anonymous|learning_gradientbased_mixup_towards_flatter_minima_for_domain_generalization	/pdf/7cffe148ada85582f7e286f874a4463077fd6ee0.pdf
Oy-e1gcBzo	4119	Dynamic-Aware GANs: Time-Series Generation with Handy Self-Supervision	['Time-series modelling', 'Self-supervision', 'Deep Generative Models']	This paper presents Dynamic-Aware GANs as a data-efficient self-supervised paradigm for time-series data generation.	Unsupervised and Self-supervised learning	anonymous|dynamicaware_gans_timeseries_generation_with_handy_selfsupervision	/pdf/d844e8fec20f33ee2581639aa9745fc97f54a6f9.pdf
EIgLnNx_lC	4120	TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased Recommendations	['Recommender System', 'Bias', 'Debias', 'Doubly Robust']	This paper proposes a principled approach that can effectively reduce the bias and variance simultaneously compared to existing DR estimators for debiased recommendations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|tdrcl_targeted_doubly_robust_collaborative_learning_for_debiased_recommendations	/pdf/c0f8d33b054d819b61f760ae1390a33e66df4edd.pdf
7Kf5_7-b7q	4122	Comparing Auxiliary Tasks for Learning Representations for Reinforcement Learning	['Reinforcement learning', 'Representation learning', 'Auxiliary task', 'Comparison']	This paper empirically compares common auxiliary tasks used to learn representations for reinforcement learning (RL) across diverse continuous control environments and RL algorithms.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|comparing_auxiliary_tasks_for_learning_representations_for_reinforcement_learning	/pdf/f71f4dcebabb02500cbf88069faa5fa900a01bfc.pdf
CW6KmU5wPh	4123	DAVA: Disentangling Adversarial Variational Autoencoder	['Disentanglement learning', 'varational auto-encoder', 'curriculum learning', 'generative adversarial networks']	We propose an adversarial variational auto-encoder that alleviates the issue of hyperparameter selection for disentanglement learning and propose a new unsupervised disentanglement metric.	Unsupervised and Self-supervised learning	anonymous|dava_disentangling_adversarial_variational_autoencoder	/pdf/9856be5dca423bfaad4c6a13e0f08572c889c5d4.pdf
Jm-MaqTF6om	4124	End-to-end Invariance Learning with Relational Inductive Biases in Multi-Object Robotic Manipulation	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|endtoend_invariance_learning_with_relational_inductive_biases_in_multiobject_robotic_manipulation	/pdf/cd9d6156baf850c774cbe6a6242077fc969baf26.pdf
aPc-R01WvJV	4125	Prescribed Safety Performance Imitation Learning from A Single Expert Dataset	['safe imitation learning', 'inverse reinforcement learning']	We propose a method to conduct safe imitation learning with prescribed safety performance.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|prescribed_safety_performance_imitation_learning_from_a_single_expert_dataset	/pdf/d1ba2fcbe8bc211a73ec3f554f46bb0ce82d162d.pdf
fH4xGeqdgLb	4127	Does Structural Information have been Fully Exploited in Graph Data?	['Transformer', 'Discrete Ricci Curvature', 'Structural Information']	We propose a topology-aware graph-based architecture, termed as Curvphormer, by leveraging a geometric notion, i.e., discrete Ricci curvature.	Deep Learning and representational learning	anonymous|does_structural_information_have_been_fully_exploited_in_graph_data	/pdf/91b245a640b01f4e379b1a267af03da95d2f10cb.pdf
R3xfdth4Gyl	4128	Learning Task Agnostic Temporal Consistency Correction	['Video Processing', 'Temporal Consistency Correction', 'Video Restoration']	This work provides a general framework for task agnostic video temporal consistency correction capable of producing visually pleasing and temporally consistent videos without the requiring their unprocessed counterparts.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_task_agnostic_temporal_consistency_correction	/pdf/0c9dad3e4d1e579dc6df458a8f7be96c35a860c9.pdf
47B_ctC4pJ	4130	Learning Input-agnostic Manipulation Directions in StyleGAN with Text Guidance	['image manipulation', 'deep learning', 'generative adversarial network']		Generative models	anonymous|learning_inputagnostic_manipulation_directions_in_stylegan_with_text_guidance	/pdf/16dd0eed24a73183e79c974eefa873b8d1b423ec.pdf
5cAI0qXxyv	4131	A New Hierarchy of Expressivity for Graph Neural Networks	['Graph neural network', 'Weisfeiler-Lehman algorithm', 'k-WL hierarchy', 'graph classification']		Deep Learning and representational learning	anonymous|a_new_hierarchy_of_expressivity_for_graph_neural_networks	/pdf/2a50a1f18377eb48eddeb1e9bf0a04e52603baaf.pdf
KyxJ9Yfxo2	4132	Hidden Schema Networks	['Discrete representation learning', 'Unsupervised knowledge graph learning', 'Relational inductive biases', 'Semantic representation', 'Pretrained language models', 'Discrete VAE', 'Neuro-symbolic AI', 'Language modelling']	A neural language model that discovers networks of symbols (schemata) from text datasets via a VAE framework with pretrained BERT and GPT-2 as encoder and decoder, respectively.	Deep Learning and representational learning	anonymous|hidden_schema_networks	/pdf/00f7d54a6d02d3064e515cac4fafb9018653254a.pdf
MHXO5xRCSXh	4133	PET-NeuS: Positional Encoding Triplanes for Neural Surfaces	['Multi-view Surface Reconstruction', 'Neural Radiance Fields', 'Signed Distance Functions']	We improve NeuS by introducing Tri-planes, modulated positional encoding, and learned self-attention convolutions.	Deep Learning and representational learning	anonymous|petneus_positional_encoding_triplanes_for_neural_surfaces	/pdf/f37f96275e316d682023c6b1b5b2106909a62b27.pdf
Tuk3Pqaizx	4135	Sampling-free Inference for Ab-Initio Potential Energy Surface Networks	['Graph Neural Networks', 'Computational Physics', 'Self-Generative Learning', 'Machine Learning for Science', 'Online Learning', 'Self-Supervised Learning', 'Molecules']	We improve neural wave function methods by avoid numerical integration at inference time and introducing restricted neural wave functions.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|samplingfree_inference_for_abinitio_potential_energy_surface_networks	/pdf/24f7f10830717ab535c3e60c8366f96bf1f72739.pdf
UBSPGUwjNV	4136	RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding	[]		Deep Learning and representational learning	anonymous|rule_neuralsymbolic_knowledge_graph_reasoning_with_rule_embedding	/pdf/ba630ee24a5c62c490344ccc767d138287c3353e.pdf
L97ftsVhiUi	4139	CAKE: CAusal and collaborative proxy-tasKs lEarning for Semi-Supervised Domain Adaptation	[]		Deep Learning and representational learning	anonymous|cake_causal_and_collaborative_proxytasks_learning_for_semisupervised_domain_adaptation	/pdf/7bc1065462507b89a8675a91e5aac6dcf13a7ca6.pdf
UYcIheNY9Pf	4140	Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning	['Offline Reinforcement Learning', 'Model Based Reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|value_memory_graph_a_graphstructured_world_model_for_offline_reinforcement_learning	/pdf/c009b483aece2452bbb3644f0b4e29014462bb05.pdf
Vf6WcUDnY7c	4141	Optimizing Spca-based Continual Learning: A Theoretical Approach	['continual learning', 'high dimensional statistics', 'machine learning theory']	This paper proposes a theoretical analysis of a simple but efficient continual learning algorithm	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|optimizing_spcabased_continual_learning_a_theoretical_approach	/pdf/10e2f7e915ee3b8965e437d49d4d01d1decfb9d0.pdf
ytuGu-E4cIl	4142	Scalable Multi-Modal Continual Meta-Learning	['Continual meta-learning', 'Indian Buffet Process', 'Evidential Sparcification']		Deep Learning and representational learning	anonymous|scalable_multimodal_continual_metalearning	/pdf/7abb6d8952ac20e2fd9c439832f2b8cb907762aa.pdf
LPcxnvN9vLw	4144	Memory Learning of Multivariate Asynchronous Time Series	['Multivariate Asynchronous Time Series', 'Gated Recurrent Unit', 'Sequential Models']	Modeling Multivariate Asynchronous Time Series	Applications (eg, speech processing, computer vision, NLP)	anonymous|memory_learning_of_multivariate_asynchronous_time_series	/pdf/1f13c6be27e58353eed5b3b0c2ad9c0b5e7072eb.pdf
tXc-riXhmx	4145	Revisit Finetuning strategy for Few-Shot Learning to Strengthen the Equivariance of Emdeddings	['Few-Shot Learning', 'Finetuning', 'Equivariance']	We design a novel finetuning strategy to finetune the feature extractor with unbiased estimation in Few-Shot Learning.	Deep Learning and representational learning	anonymous|revisit_finetuning_strategy_for_fewshot_learning_to_strengthen_the_equivariance_of_emdeddings	/pdf/a980498cf6c460799f764dd3fd80157e694c4475.pdf
rB6TpjAuSRy	4148	CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers	['pretraining', 'text-to-video generation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|cogvideo_largescale_pretraining_for_texttovideo_generation_via_transformers	/pdf/42197d3f51dfeaeea80907d343bcf47209c9da08.pdf
M3GzgrA7U4	4149	Graph Neural Networks as Gradient Flows: understanding graph convolutions via energy	['Graph Neural Networks', 'Gradient flows', 'Energy functionals', 'Spectral theory']	We apply the gradient flow formalism to GNNs to both develop new frameworks and provide a better theoretical understanding of existing ones.	Deep Learning and representational learning	anonymous|graph_neural_networks_as_gradient_flows_understanding_graph_convolutions_via_energy	/pdf/4ff68fae318fa74d47a2ffbc944a140c30a979f4.pdf
IB5Njg_ztYB	4150	GraphVF: Controllable Protein-Specific 3D Molecule Generation with Variational Flow	['Controllable Molecular Generation', 'Pocket-based Drug Design', 'Variational Flow']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|graphvf_controllable_proteinspecific_3d_molecule_generation_with_variational_flow	/pdf/d80bee5d50f293d96a64bd17c23f2e7eaa9a7bb5.pdf
42zs3qa2kpy	4151	Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling	['offline reinforcement learning', 'generative models', 'diffusion models', 'behavior modeling']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_reinforcement_learning_via_highfidelity_generative_behavior_modeling	/pdf/43eb70bd49c28d3b2d2199998ec2821ac170409b.pdf
4orJ47he7WV	4152	Emergent collective intelligence from massive-agent cooperation and competition	['Reinforcement Learning', 'Multi-agent System', 'Emergent Behavior']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|emergent_collective_intelligence_from_massiveagent_cooperation_and_competition	/pdf/0cc5c07016740d0bfe076ec008a727027d42aa11.pdf
FoRC6dIfO8u	4155	Cyclophobic Reinforcement Learning	['Reinforcement learning', 'intrinsic rewards', 'exploration', 'transfer learning', 'objects']	Cyclophobic Reinforcement Learning systematically and efficiently explores the state space by penalizing cycles, achieving excellent results in sparse reward environements.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|cyclophobic_reinforcement_learning	/pdf/c7c75f8bb45195927968268dbea99d47bd895b76.pdf
_hHYaKu0jcj	4156	Robust Explanation Constraints for Neural Networks	['Explainability', 'Adversarial Robustness', 'Neural Networks', 'Robustness Certification']	We present a method for guaranteeing adversarial robustness of explanations that are based on the input gradient of a neural network.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robust_explanation_constraints_for_neural_networks	/pdf/03aec9d9fd40c4ec814a7f94541a8a8b2b1fb4b0.pdf
aLgoMwjNDsi	4157	CCT: Cross-consistency training for Clone Detection and Code Search Tasks	['pre-training', 'language model']	We present a novel approach for pre-training the language models for better code and text representation improving results in code search and clone detection.	Applications (eg, speech processing, computer vision, NLP)	anonymous|cct_crossconsistency_training_for_clone_detection_and_code_search_tasks	/pdf/35daa149486da82ba74fc724e0b9ef2037a0e092.pdf
kTqYrmqnUm1	4158	FedHPO-Bench: A Benchmark Suite for Federated Hyperparameter Optimization	['federated learning', 'hyperparameter optimization']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|fedhpobench_a_benchmark_suite_for_federated_hyperparameter_optimization	/pdf/612c79b9c5336730ea5f4506d89b9f43c9525ffc.pdf
DUIjRKNFFbG	4160	LEXA: Language-agnostic Cross-consistency Training for Question Answering Tasks	['pre-training', 'language model', 'natural language processing']	We developed a novel pre-training method to improve cross-lingual consistency in a language model. We demonstrate the achieved ability on several question answering datasets.	Applications (eg, speech processing, computer vision, NLP)	anonymous|lexa_languageagnostic_crossconsistency_training_for_question_answering_tasks	/pdf/bd92acbb58a9d9df323d3777e7c43c26e31a37a5.pdf
u4quDwcd9S3	4162	A Decomposition Based Dual Projection Model for Multivariate Time Series Forecasting and Anomaly Detection	['Multivariate Time Series', 'Decomposition', 'Projection', 'Forecasting', 'Anomaly Detection']	A seasonal-trend decomposition based model with the channel-wise and sequence-wise dual projection is developed for efficient and accurate multivariate time series forecasting and anomaly detection.	Unsupervised and Self-supervised learning	anonymous|a_decomposition_based_dual_projection_model_for_multivariate_time_series_forecasting_and_anomaly_detection	/pdf/593cfd0bbd8065fb6d9e82f1634833d568b5553d.pdf
k2CRIF8tJ7Y	4165	Local KL Convergence Rate for Stein Variational Gradient Descent with Reweighted Kernel	['SVGD', 'asymptotic analysis']		Optimization (eg, convex and non-convex optimization)	anonymous|local_kl_convergence_rate_for_stein_variational_gradient_descent_with_reweighted_kernel	/pdf/370bfc5d90b87e245321cdc5b8de94cae8b099da.pdf
RMnJxnLwGak	4166	VQ-TR: Vector Quantized Attention for Time Series Forecasting	['deep learning', 'time series forecasting', 'latent variable models', 'transformer']	A linear transformer using a vector quantized cross attention block for time series forecasting.	Deep Learning and representational learning	anonymous|vqtr_vector_quantized_attention_for_time_series_forecasting	/pdf/99968a4da056de2d146685aeef3239e93b9ff59e.pdf
2qM88ymKO6r	4167	DeNF: Unsupervised Scene-Decompositional Normalizing Flows	[]		Unsupervised and Self-supervised learning	anonymous|denf_unsupervised_scenedecompositional_normalizing_flows	/pdf/3fae455f952ef0a484a6ad8a8169e4aac5cbfa69.pdf
KzkLAE49H9b	4168	Training language models for deeper understanding improves brain alignment	['language', 'nlp', 'neuroscience', 'fMRI', 'interpretability']	We show that training language models for deeper narrative understanding (characters, emotions, relationships) results in richer representations that have improved alignment to human brain activity.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|training_language_models_for_deeper_understanding_improves_brain_alignment	/pdf/d5feb33047bc47fcda91f885f524e07e47999037.pdf
ar_09k_Gsos	4169	Learning 3D Point Cloud Embeddings using Optimal Transport	['Optimal Transport', '3D Point Cloud', 'Wasserstein Space', 'Contrastive Learning']	We introduce a novel method to learn Wasserstein embeddings for 3D point clouds endowed by contrastive learning setup.	Deep Learning and representational learning	anonymous|learning_3d_point_cloud_embeddings_using_optimal_transport	/pdf/dd3667b1a822a08512ef11527ebda847e874d359.pdf
HwcEuhLtCJr	4171	Cold Posteriors through PAC-Bayes	['cold posteriors', 'Bayesian', 'Bayesian Neural Networks', 'PAC-Bayes', 'Laplace approximation']	PAC-Bayes objectives naturally contain a temperature parameter, we investigate it's relation to the cold posterior effect.	Deep Learning and representational learning	anonymous|cold_posteriors_through_pacbayes	/pdf/dc829928c5d2b51175f422a84264dfad50b4f06b.pdf
Jifob4dSh99	4172	Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|theoretical_characterization_of_the_generalization_performance_of_overfitted_metalearning	/pdf/755db517c12a60d818eb9577c54bbe0e20960c5f.pdf
eCcG7QlFWeJ	4173	Gated Inference Network: Inferencing and Learning State-Space Models	['Time Series', 'Recurrent Networks', 'Gaussian Process']	A structure, using Bayesian properties and non-linearity in its design, is introduced that can learn complex state-spaces.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|gated_inference_network_inferencing_and_learning_statespace_models	/pdf/8987b8f9ce81397bdd2024c37dfd8c86b2d41207.pdf
Q6AMSS-9HIz	4175	Look Beneath the Surface: Dynamics enhanced Offline Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|look_beneath_the_surface_dynamics_enhanced_offline_reinforcement_learning	/pdf/2fefa97644058f07b6f6bfbef86bbb43504a4ab6.pdf
7uIycrR-KOa	4176	Test-Time Adaptation for Real-World Denoising Networks via Noise-Aware Image Generation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|testtime_adaptation_for_realworld_denoising_networks_via_noiseaware_image_generation	/pdf/609ce7237a0da745fa2195b5105f7d5e5530c80a.pdf
JrVIWD81Z0u	4177	FedProp: Cross-client Label Propagation for Federated Semi-supervised Learning	['federated learning', 'semi-supervised learning', 'label propagation', 'cryptographically secure computation']		Unsupervised and Self-supervised learning	anonymous|fedprop_crossclient_label_propagation_for_federated_semisupervised_learning	/pdf/005f065de84da7b9dd094ddafbe66a1839e50794.pdf
iJ_E0ZCy8fi	4178	Text-Guided Diffusion Image Style Transfer with Contrastive Loss Fine-tuning	['Diffusion models', 'Style transfer']		Generative models	anonymous|textguided_diffusion_image_style_transfer_with_contrastive_loss_finetuning	/pdf/ce3058718d763bf444a25da92cb371dae5a0675e.pdf
5-Df3tljit7	4179	Defending against Adversarial Audio  via Diffusion Model	['Adversarial attack and defense', 'AI security', 'speech recognition', 'diffusion models']	We propose a defense method based based on diffusion models for acoustic systems against diverse audio adversarial examples.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|defending_against_adversarial_audio_via_diffusion_model	/pdf/7b318422896c241b3c18ce5cac6a86bc1d3e3959.pdf
aoDyX6vSqsd	4180	Sampling-based inference for large linear models, with application to linearised Laplace	['Laplace', 'linearised Laplace', 'Bayesian neural network', 'Bayesian linear regression', 'uncertainty estimation', 'Bayesian deep learning', 'EM', 'large scale regression', 'sample then optimise', 'evidence framework']	We scale the linearised Laplace method for uncertainty estimation to large neural networks and datasets using an efficient method for posterior sampling	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|samplingbased_inference_for_large_linear_models_with_application_to_linearised_laplace	/pdf/706191be3e55b3027a4a299eb09cbcd9bc00c9f9.pdf
BR1qoDGxjWp	4182	Feed-Forward Latent Domain Adaptation	['latent domain adaptation', 'source-free', 'cross-attention', 'meta-learning']	Cross-attention based meta-learning approach for fast latent domain adaptation	Deep Learning and representational learning	anonymous|feedforward_latent_domain_adaptation	/pdf/42721c424d37eb22918379115a4c446b322ef104.pdf
8xZogWcm73f	4185	Automatic Dictionary Generation: Could Brothers Grimm Create a Dictionary with BERT?	['dictionary generation', 'natural language processing', 'transformers']		Applications (eg, speech processing, computer vision, NLP)	anonymous|automatic_dictionary_generation_could_brothers_grimm_create_a_dictionary_with_bert	/pdf/f005cdb131b9dcce298f1e84b3985a750620fd86.pdf
5c9imxdLlCW	4186	Rewiring with Positional Encodings for GNNs	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|rewiring_with_positional_encodings_for_gnns	/pdf/99242f6c6db4b3b73e6770d1ef07ed660ced4330.pdf
FbC2VeNlth5	4187	Differentiable Logic Programming for Probabilistic Reasoning	['Inductive Logic Programming', 'Differentiable Programming', 'Logic Rules']	Learn Logic Rules for Reasoning	General Machine Learning (ie none of the above)	anonymous|differentiable_logic_programming_for_probabilistic_reasoning	/pdf/7dc58d6cdd90d79d3de92a6c5edf781bb4b89b72.pdf
hF1WEiIYPNb	4188	Query The Agent: Improving Sample Efficiency Through Epistemic Uncertainty Estimation	['goal-conditioned reinforcement learning', 'reinforcement learning', 'goal-conditioned', 'goal', 'model-free', 'sample efficiency', 'deep reinforcement learning']	Designing more sample efficient reinforcement learning curricula by measuring and exploiting agents' epistemic uncertainty. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|query_the_agent_improving_sample_efficiency_through_epistemic_uncertainty_estimation	/pdf/bc691e68c2328c093a66a9df67d7f41932321395.pdf
a1ttBXvNCLO	4189	Variational Causal Dynamics: Discovering Modular World Models from Interventions	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|variational_causal_dynamics_discovering_modular_world_models_from_interventions	/pdf/50ba96a28f696a2ff277a72325c401ba54f4d8d6.pdf
2NQ8wlmU9a_	4190	Hybrid-Regressive Neural Machine Translation	['autoregressive translation', 'non-autoregressive translation', 'inference acceleration']		Applications (eg, speech processing, computer vision, NLP)	anonymous|hybridregressive_neural_machine_translation	/pdf/ce71076b117e1cf0bce51e99c7c97446e5524e70.pdf
3VO1y5N7K1H	4191	StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random	['Recommender System', 'Bias', 'Debias', 'Doubly Robust']	This paper proposes a theoretically guaranteed stabilized doubly robust learning approach that overcomes the shortcomings due to the presence of extremely small propensities in debiased recommendations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|stabledr_stabilized_doubly_robust_learning_for_recommendation_on_data_missing_not_at_random	/pdf/898134b246b85057e80eec375b16bb154c956559.pdf
OlgXPQX9uQE	4192	Probabilistic Attention-to-Influence Neural Models for Event Sequences	['deep probabilistic model', 'event sequence', 'graphical model', 'transformer']	We provide a novel neural probabilistic attention-to-influence model which not only captures complex dynamics of event sequences without meaningful timestamps, but also learns a set of influencers for a given event of interest.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|probabilistic_attentiontoinfluence_neural_models_for_event_sequences	/pdf/44b3f1f28fdae27a02a34d451e4216c0c939dd5d.pdf
_apb5VI2_0o	4193	Diversity of Generated Unlabeled Data Matters for Few-shot Hypothesis Adaptation	['Hypothesis Adaptation']		Deep Learning and representational learning	anonymous|diversity_of_generated_unlabeled_data_matters_for_fewshot_hypothesis_adaptation	/pdf/88b49cd453074812008ba70830dc99108ffcc5e8.pdf
m0fEJ2bvwpw	4194	Thinking fourth dimensionally: Treating Time as a Random Variable in EBMs	['energy-based models', 'markov chain mote carlo', 'contrastive divergence']	We generalize the common practice of utilizing a series of auxiliary distributions in EBM training, and utilize this approach to improve the performance of existing methods.	Generative models	anonymous|thinking_fourth_dimensionally_treating_time_as_a_random_variable_in_ebms	/pdf/e2d29a11a0a8bc750e847ed1be28e788f2643612.pdf
syfgJE6nFRW	4196	PASHA: Efficient HPO and NAS with Progressive Resource Allocation	['Neural architecture search', 'Hyperparameter optimization', 'Large datasets', 'Computational efficiency', 'Cost']	Efficient multi-fidelity method with progressive resource allocation for HPO and NAS.	General Machine Learning (ie none of the above)	anonymous|pasha_efficient_hpo_and_nas_with_progressive_resource_allocation	/pdf/59ade1e6f8facdd888f5857f0331b6e3d70356fc.pdf
sAJDi9lD06L	4197	Holistic Adversarially Robust Pruning	['adversarial robustness', 'model pruning']	We propose HARP that realizes the adversarially robust pruning in a holistic way and yields an outstanding capability at aggressive compression.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|holistic_adversarially_robust_pruning	/pdf/c84f0ce577fb5c63318fab72778139e3f3987d00.pdf
_Esnr5KvO6-	4198	Prompt Injection: Parameterization of Fixed Inputs	['Prompt', 'Injection', 'Parameterization', 'Language Model', 'Inference Efficiency', 'Distillation']	We formulate a new problem called Prompt Injection (PI) that focuses on injecting the prompt into the parameters of an LM to be an efficient alternative to attaching fixed prompts to the input.	Applications (eg, speech processing, computer vision, NLP)	anonymous|prompt_injection_parameterization_of_fixed_inputs	/pdf/0280f76c04f30a989d55a72bebac8ec103d2bd4d.pdf
wZ2SVhOTzBX	4199	That Label's got Style: Handling Label Style Bias for Uncertain Image Segmentation	['Uncertainty Quantification', 'Segmentation']	We present a method to reduce bias caused by differing label style for uncertain image segmentation.	Deep Learning and representational learning	anonymous|that_labels_got_style_handling_label_style_bias_for_uncertain_image_segmentation	/pdf/f69f1dc4b8aa283534c77829fc9d67c6be7c2dd0.pdf
wqu7hutzn3K	4200	Unbiased Decisions Reduce Regret: Adversarial Optimism for the Bank Loan Problem	['adversarial domain adaptation', 'online learning', 'adversarial de-biasing', 'neural optimism']	We use adversarial domain adaptation to combat accumulating bias for a class of online learning problems.	Deep Learning and representational learning	anonymous|unbiased_decisions_reduce_regret_adversarial_optimism_for_the_bank_loan_problem	/pdf/515f5eab91c5d139bbd42ac4a2fbe46e41f08da7.pdf
LofRPZeXNNk	4201	Preserving Semantics in Textual Adversarial Attacks	['NLP', 'Adversarial Attacks', 'Sentence Encoders', 'Semantics Similarity']	We propose a novel sentence encoder that improves the quality of textual adversarial attacks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|preserving_semantics_in_textual_adversarial_attacks	/pdf/c055c7fe3e74b1b44c1100f79d5c8238c9d6047a.pdf
UqVDq19iVx	4202	Biological Factor Regulatory Neural Network	['biological factor', 'gene regulatory network']	We propose BFReg-NN to simulate the complex biological processes in a cell system, understand the functions of genes or proteins, and ultimately give insights into the mechanism of larger living systems	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|biological_factor_regulatory_neural_network	/pdf/58aa314357419514d3e49221407237acefce7beb.pdf
jD2jOzx1aef	4203	Heterogeneous Loss Function with Aggressive Rejection for Contaminated data in anomaly detection	['Anomaly detection', 'contaminated data', 'Unsupervised learning']	This paper proposes heterogeneous loss with aggressive rejection for contaminated data in anomaly detection. 	Unsupervised and Self-supervised learning	anonymous|heterogeneous_loss_function_with_aggressive_rejection_for_contaminated_data_in_anomaly_detection	/pdf/26dd2ab5ecbf386c67ea6a2fc6dc5f3c12c6ade3.pdf
Lt8bMlhiwx2	4204	DECAP: Decoding CLIP Latents for Zero-shot Captioning	['Zero-shot captioning', 'Decoder training', 'Multi-modal learning']	We propose a simple framework with a lightweight visual-aware language decoder for zero-shot captioning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|decap_decoding_clip_latents_for_zeroshot_captioning	/pdf/16533b00c520e05fe5570e2d3ceb8977e18fea98.pdf
Cx1xYn6vVm2	4205	A Mutual Information Duality Algorithm for Multi-Agent Specialization	['Multi-agent', 'Reinforcement Learning', 'Mutual Information', 'Duality', 'Policy Gradient', 'Social Graph']	The social behavioral change in population learning is impacted by the dual properties of mutual information.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_mutual_information_duality_algorithm_for_multiagent_specialization	/pdf/08ccab9b8f49b48dd752585606cc981e3636ca3a.pdf
0vG8GbuPOH3	4206	Semantic Prior for Weakly Supervised Class-Incremental Segmentation	['class-incremental learning', 'weakly supervised semantic segmentation']	Leveraging semantic similarities between old and new classes to improve weakly supervised class-incremental semantic segmentation	Deep Learning and representational learning	anonymous|semantic_prior_for_weakly_supervised_classincremental_segmentation	/pdf/459918ca7b674303d6cd6c346640af5bbdd8e103.pdf
3urtgEaXCA9	4208	A Weight Variation-Aware Training Method for Hardware Neuromorphic Chips	['edge computing systems', 'neuro-inspired computing', 'hardware implementation', 'synaptic device', 'hardware-oriented neural network']		General Machine Learning (ie none of the above)	anonymous|a_weight_variationaware_training_method_for_hardware_neuromorphic_chips	/pdf/ecc094fbd17cbd35dfd8a38fe4836299744b5133.pdf
hrRNkyyGGgx	4209	Multi-Head State Space Model for Sequence Modeling	['multi-head', 'state space', 'transformer', 'stateformer', 'sequence model', 'rnn']	We develop a novel multi-head state space model as a replacement and/or complement to attention, achieving state-of-the-art performance in speech recognition and masked language modeling.	Applications (eg, speech processing, computer vision, NLP)	anonymous|multihead_state_space_model_for_sequence_modeling	/pdf/5d872ff377f95d869115748134751da1ad929b65.pdf
_BoPed4tYww	4210	Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints	['dynamic programming', 'impulse control', 'optimal stopping', 'reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|timing_is_everything_learning_to_act_selectively_with_costly_actions_and_budgetary_constraints	/pdf/4cabbd2371969c0c8a2c7af7fb9d59f77f656eba.pdf
r3B62g_nL0l	4211	Delve into the Layer Choice of BP-based Attribution Explanations	['XAI', 'attribution methods', 'layer choice', 'TIF']	We quantified the influence of the layer choice on BP-based attributions. Based on the experimental results, we show how to fuse different layer attributions to obtain complete, fine-grained and reliable attribution results.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|delve_into_the_layer_choice_of_bpbased_attribution_explanations	/pdf/ede9e7279b3b7b6aa5fadfc6eb9089af295e9d09.pdf
fBoNN1Y6PjG	4212	Probabilistic Imputation for Time-series Classification with Missing Data	['Missing Data Imputation', 'Multivariate Time Series', 'Classification', 'Generative Model', 'Variational Autoencoder', 'Dropout']		Generative models	anonymous|probabilistic_imputation_for_timeseries_classification_with_missing_data	/pdf/61d5ee22343bf47bec10d391d431e8f09099b3f2.pdf
FtOxgKe_Zg2	4213	Guess the Instruction! Making Language Models Stronger Zero-Shot Learners	['natural language processing', 'zeroshot language models', 'large language models']	We introduce Flipped Learning, a meta-training method that computes the likelihood of the task instruction given input instance and label.	Applications (eg, speech processing, computer vision, NLP)	anonymous|guess_the_instruction_making_language_models_stronger_zeroshot_learners	/pdf/8febee02112b003cd209c0834c25a0bc119531fe.pdf
Y5SEe3dfniJ	4215	Compressing multidimensional weather and climate data into neural networks	['Weather and climate data', 'Compression']	We compress weather and climate data into neural network weights.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|compressing_multidimensional_weather_and_climate_data_into_neural_networks	/pdf/2651dd999064a8f0a42f806758fb96d66f3f591d.pdf
QsgeAdRwILD	4217	Accuracy Boosters: Epoch-Driven Mixed-Mantissa Block Floating-Point for DNN Training	['DNN training', 'low-precision training', 'mixed-precision training', 'efficient training', 'number formats', 'numerical encodings', 'block floating-point', 'DNN accelerators']	We propose an epoch-driven mixed-mantissa Hybrid Block Floating-Point training method converting 99.7% of arithmetic operations in training to 4-bit mantissas and using 6-bit mantissas in the last epoch, while preserving/outperforming FP32 accuracy.	General Machine Learning (ie none of the above)	anonymous|accuracy_boosters_epochdriven_mixedmantissa_block_floatingpoint_for_dnn_training	/pdf/284c99c0a60f12f35586b4e71191e43f819c7c31.pdf
E2y2TrpJhYN	4218	Perturbation Defocusing for Adversarial Defense	['text adversarial defense', 'perturbation defocusing']	propose a new perspective to defend against text adversarial attack	Applications (eg, speech processing, computer vision, NLP)	anonymous|perturbation_defocusing_for_adversarial_defense	/pdf/1f00c1eb87379c79cde2f191fd0cee646ec6eadc.pdf
q-PbpHD3EOk	4220	Learning Fast and Slow for Time Series Forecasting	['online time series forecasting', 'continual learning']	A novel time series forecasting framework based on continual learning and the Complementary Learning System theory	Deep Learning and representational learning	anonymous|learning_fast_and_slow_for_time_series_forecasting	/pdf/f7c9a5620a0bbb707147d8836cec222d5c8b511a.pdf
1UCaQYUdE_o	4222	Understanding Neural Coding on Latent Manifolds by Sharing Features and Dividing Ensembles	['neuroscience', 'neural activity', 'tuning curves', 'neural ensemble detection', 'grid cells', 'latent variable models']	We propose neural latent variable models with feature sharing and ensemble detection.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|understanding_neural_coding_on_latent_manifolds_by_sharing_features_and_dividing_ensembles	/pdf/5258d13f31743c30daab20177dc976e07ce67e95.pdf
O_lFCPaF48t	4223	Structure by Architecture: Structured Representations without Regularization	['Autoencoder', 'Structure', 'Generative', 'Architecture', 'Disentanglement', 'Regularization', 'Hybridization']	A novel autoencoder architecture to structure the learned representation without regularizing the objective and improve sampling for generative modeling.	Deep Learning and representational learning	anonymous|structure_by_architecture_structured_representations_without_regularization	/pdf/ff9fda0639c2e77fbd5ad731c7b9624a0b310caf.pdf
IN499pgOOEl	4224	Dimensionless instance segmentation by learning graph representations of point clouds	['instance segmentation', 'graph representation', 'point cloud segmentation']	Novel method for learning point cloud graph representation for instance segmentation	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|dimensionless_instance_segmentation_by_learning_graph_representations_of_point_clouds	/pdf/89af0cb0ef19bb3d261ce5633fa384a39ae28ee2.pdf
ujibH3ervr	4225	Flareon: Stealthy Backdoor Injection via Poisoned Augmentation	[]	A simple, stealthy, lightweight, and effective backdoor injection mechanism that targets the data augmentation pipeline with motion-based triggers.	Deep Learning and representational learning	anonymous|flareon_stealthy_backdoor_injection_via_poisoned_augmentation	/pdf/1323dc61eef605956d0d588fb64d3220c8759e6b.pdf
piIsx-G3Gux	4226	On Explaining Neural Network Robustness with Activation Path	['Randomized Smoothing', 'Robustness', 'Neural Network']		Deep Learning and representational learning	anonymous|on_explaining_neural_network_robustness_with_activation_path	/pdf/38776e5374357b9eb56b71f1fcf4ca75ad45bbb9.pdf
p4RvNzlJX7W	4227	Parameter Averaging for SGD Stabilizes the Implicit Bias towards Flat Regions	['stochastic gradient descent', 'large step size', 'parameter averaging', 'implicit bias', 'flat minima']	This paper shows that averaged SGD with a large step-size efficiently converges to flat regions.	Optimization (eg, convex and non-convex optimization)	anonymous|parameter_averaging_for_sgd_stabilizes_the_implicit_bias_towards_flat_regions	/pdf/a84a3d58d778039fb1ccfa2291672b31109d183b.pdf
pHMpgT5xWaE	4228	A GNN-Guided Predict-and-Search Framework for Mixed-Integer Linear Programming	[]		Optimization (eg, convex and non-convex optimization)	anonymous|a_gnnguided_predictandsearch_framework_for_mixedinteger_linear_programming	/pdf/ca79a517b0ad4d556ac3d62dd398956fa6f81512.pdf
PfpEtB3-csK	4229	LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval	['Self-Supervised Learning', 'Lexicon Representation', 'Large-Scale Retrieval']	A new pre-training framework, dubbed lexicon-bottlenecked masked autoencoder, is proposed to learn importance-aware lexicon representations in line with the lexicon-weighting paradigm for large-scale retrieval. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|lexmae_lexiconbottlenecked_pretraining_for_largescale_retrieval	/pdf/ae14af9487a5ca2e7fc281b75e909d7786773596.pdf
K7YxdCYmd6w	4230	End-to-End Speech Synthesis Based on Deep Conditional Schrödinger Bridges	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|endtoend_speech_synthesis_based_on_deep_conditional_schrödinger_bridges	/pdf/c2178942e077b23917313de2481349543ef7f69e.pdf
4DU_HCijfJp	4231	Short-Term Memory Convolutions	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|shortterm_memory_convolutions	/pdf/fdad7b09d6d67f0011100f8704cb29d133351166.pdf
vFK6PhTxKHR7	4233	FedMEKT: Split Multimodal Embedding Knowledge Transfer in Federated Learning	['Semi-supervised learning', 'Multimodal Learning', 'Federated Learning', 'Knowledge Transfer']	The paper designs the split embedding knowledge transfer mechanism for multimodal federated learning under semi-supervised learning setting	General Machine Learning (ie none of the above)	anonymous|fedmekt_split_multimodal_embedding_knowledge_transfer_in_federated_learning	/pdf/05fa7c256c80b5291242ef8bd81f01c7666691bc.pdf
04OL67rm6ok	4234	QUIC-FL: : Quick Unbiased Compression for Federated Learning	['Distirubted', 'Mean Estimation', 'Federate Learning', 'Quantization', 'Unbiased', 'Communication Efficient', 'Bandwidth Reduction', 'Compression']	A distributed mean estimation compression scheme with accuracy on-par with the state of the art while asymptotically improving the decoding time.	General Machine Learning (ie none of the above)	anonymous|quicfl_quick_unbiased_compression_for_federated_learning	/pdf/0a1d74a2869a508a120fb5bbbcfdb6c83ec5a2df.pdf
t9myAV_dpCB	4235	Score Matching via Differentiable Physics	['diffusion models', 'physics simulations', 'stochastic partial differential equations']	We propose to learn score fields with a differentiable physics operator for natural non-deterministic physical processes like diffusion in order to solve inverse problems and obtain their posterior distribution.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|score_matching_via_differentiable_physics	/pdf/856f6e309b87e9ac5524fc9e9217b39995c36f46.pdf
WlbG820mRH-	4236	Fundamental Limits in Formal Verification of Message-Passing Neural Networks	['formal verification', 'graph neural networks']	We prove that certain safety properties of MPNN can not be verified formally.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fundamental_limits_in_formal_verification_of_messagepassing_neural_networks	/pdf/e546976e24aec92f369c970527c96462f03166a7.pdf
35PLkGkJOQ4	4237	Energy Consumption-Aware Tabular Benchmarks for Neural Architecture Search	['NAS', 'tabular benchmarks', 'energy consumption', 'carbon footprint', 'deep learning', 'multi-objective optimisation', 'automl']	Energy consumption-aware tabular benchmarks for NAS can be used to access sub-space of architectures that are inherently efficient.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|energy_consumptionaware_tabular_benchmarks_for_neural_architecture_search	/pdf/0e53432311750541e386b8f931386480708848de.pdf
7tmlbL5JQyt	4238	Optimizing Connectivity through Network Gradients for the Restricted Machine	['Neural Networks', 'Restricted Boltzmann Machine', 'Neural Architecture Search', 'Network Pruning', 'Network Optimization', 'AutoML']	This paper proposes a novel methodology that optimizes the network connectivity of an RBM using the idea of connection gradients jointly with other model parameters. 	Deep Learning and representational learning	anonymous|optimizing_connectivity_through_network_gradients_for_the_restricted_machine	/pdf/9bd0ab0f6e863a8ec733a7ac1e6666a9a94e994f.pdf
kDSmxOspsXQ	4240	Boosting the Cycle Counting Power of Graph Neural Networks with I$^2$-GNNs	['Graph neural networks']		Deep Learning and representational learning	anonymous|boosting_the_cycle_counting_power_of_graph_neural_networks_with_i^2gnns	/pdf/05c1a75f465d1cea6393a34f0c6ad29d2d74eb51.pdf
GrpU6dxFmMN	4241	Improving the imputation of missing data with Markov Blanket discovery	['Feature selection', 'Imputation', 'Markov Blanket discovery']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|improving_the_imputation_of_missing_data_with_markov_blanket_discovery	/pdf/c4481785e141eb178c2ef4032cb200c45aa06ee6.pdf
q4qocCgE3uM	4242	MARLlib: Extending RLlib for Multi-agent Reinforcement Learning	['MARL']	We introduce MARLlib, the MARL extension of RLlib	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|marllib_extending_rllib_for_multiagent_reinforcement_learning	/pdf/3ac64ef2d41cb6f22bf2e2febc3bb2e046da0b08.pdf
udNhDCr2KQe	4243	Learning to Solve Constraint Satisfaction Problems with Recurrent Transformers	['transformer', 'constraint reasoning', 'semi-supervised learning']	We show how Recurrent Transformer can be trained to perform logical reasoning on constraint satisfaction problems in an end-to-end manner and how to inject discrete constraints into its training	Deep Learning and representational learning	anonymous|learning_to_solve_constraint_satisfaction_problems_with_recurrent_transformers	/pdf/c43e625ab9428ba47be7e58aec22e83e70cf97e8.pdf
4CQ9os3s4h3	4244	Random Matrix Analysis to Balance between Supervised and Unsupervised Learning under the Low Density Separation Assumption	['Random Matrix Theory', 'semi-supervised learning', 'high dimensional statistics']	We introduce a semi-supervised learning algorithm based on the low density assumption and propose a theoretical analysis of the latter.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|random_matrix_analysis_to_balance_between_supervised_and_unsupervised_learning_under_the_low_density_separation_assumption	/pdf/cc1701f4593a1e450e8ed8391e08e185287aa431.pdf
Rb3RN0maB7F	4245	QuAFL: Federated Averaging Made Asynchronous and Communication-Efficient	['Federated Learning', 'Distributed optimization', 'Load Balancing']		Optimization (eg, convex and non-convex optimization)	anonymous|quafl_federated_averaging_made_asynchronous_and_communicationefficient	/pdf/a26aae20c514379eb22cdbac20cc75f7c13eb99e.pdf
4vYWYGd13cZ	4246	Targeted Attacks on Timeseries Forecasting	['timeseries', 'forecasting', 'targeted attacks', 'adversarial ml', 'ai security', 'apgd']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|targeted_attacks_on_timeseries_forecasting	/pdf/b572ce9cd05394d27298ad03b61296d34d693929.pdf
Vk-34OQ7rFo	4247	Model-based Causal Bayesian Optimization	['causal inference', 'bayesian optimization']	A principled algorithm for causal bayesian optimization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|modelbased_causal_bayesian_optimization	/pdf/a3994b1377175da0d7c444c0446848554854c916.pdf
ukea-WPOL4Dw	4250	Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems	['numerical reasoning', 'language model']	"leverage simple numbers as ""anchors"" to probe the implicitly inferred arithmetic relationship from language models and then explicitly apply the relationship on complex numbers"	Applications (eg, speech processing, computer vision, NLP)	anonymous|inversely_eliciting_numerical_reasoning_in_language_models_via_solving_linear_systems	/pdf/79aef6867415e0c61e7f389ffd7f7d55e6cf4599.pdf
Y3wBqgTbxyw	4251	SPC-Net: A New Scalable Point Cloud Compression Framework for Both Machine and Human Vision Tasks	['point cloud', 'compression', 'scalable coding']		Applications (eg, speech processing, computer vision, NLP)	anonymous|spcnet_a_new_scalable_point_cloud_compression_framework_for_both_machine_and_human_vision_tasks	/pdf/90ebb2637b1f3eda61d56933fe8e20f3435c548c.pdf
Nae2_YHH-24	4252	Improving Translation Capabilities of Pre-Trained Multilingual Sequence-to-Sequence Models for Low-Resource Languages	['Pre-Trained Multilingual Sequence-to-Sequence Model', 'Machine Translation', 'Low Resource Languages', 'Empirical Experiments']	Empirical experiments on data and techniques for leveraging Pre-Trained Multilingual Sequence-to-Sequence Models for Low-Resource language translation	Applications (eg, speech processing, computer vision, NLP)	anonymous|improving_translation_capabilities_of_pretrained_multilingual_sequencetosequence_models_for_lowresource_languages	/pdf/5c1b6b9d82582f5e7d02dfc3d40bfe7be6392151.pdf
x01dnxUEDRv	4253	How does Uncertainty-aware Sample-selection Help Decision against Action Noise?	['Imitation Learning', 'State-Dependent Action Noise', 'Uncertainty-Aware', 'Negative Learning']	To learn a robust imitation learning policy against action noise, this work proposes a novel paradigm called USN, which bridges Uncertainty-aware Sample-selection with Negative learning.  	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|how_does_uncertaintyaware_sampleselection_help_decision_against_action_noise	/pdf/e71079e4a5383662bf4d6dbff6a3f5065f190c9b.pdf
n6H86gW8u0d	4254	TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization	['Deep Learning', 'Tabular Data', 'Regularization']	We introduce TANGOS, a regularization method that orthogonalizes the gradient attribution of neurons to improve the generalization of deep neural networks on tabular data.	Deep Learning and representational learning	anonymous|tangos_regularizing_tabular_neural_networks_through_gradient_orthogonalization_and_specialization	/pdf/886c4d4f347720d9138094b39f6790ee0c295b4e.pdf
7oPAgqxNb20	4255	DynaMS: Dyanmic Margin Selection for Efficient Deep Learning	['efficient training', 'data selection']	A general dynamic data selection framework for efficient deep neural network training that enjoy both theoretical and practical advantages.	Deep Learning and representational learning	anonymous|dynams_dyanmic_margin_selection_for_efficient_deep_learning	/pdf/22d1db86ae0bf30cefa00c2c1898f34fe815dc20.pdf
Ll21hhIJ_oG	4256	KeyCLD: Learning Constrained Lagrangian Dynamics in Keypoint Coordinates from Images	['Lagrangian', 'dynamics', 'keypoints', 'images', 'unsupervised']	We learn unsupervised keypoint representations as state, jointly with constrained Lagrangian dynamics, based on videos of dynamical systems.	Deep Learning and representational learning	anonymous|keycld_learning_constrained_lagrangian_dynamics_in_keypoint_coordinates_from_images	/pdf/a6ebdd465c76141cb41c6d5d3a32253650aafc7c.pdf
1TxMUE7cF6_	4257	Modeling Temporal Data as Continuous Functions with Process Diffusion	['time series', 'stochastic process', 'diffusion', 'probabilistic forecasting', 'score-based matching']	We modify the diffusion framework to model continuous functions and apply the learned generative model on different time series tasks.	Generative models	anonymous|modeling_temporal_data_as_continuous_functions_with_process_diffusion	/pdf/f76faf362a714934786abdf75f1cb71620091f2a.pdf
nG9RF9z1yy3	4258	DiffusER: Diffusion via Edit-based Reconstruction	['text generation', 'editing', 'denoising autoencoders']	We propose a generally applicable text generative model which takes inspiration from diffusion models and parameterises generation steps as text editing steps without compromising performance and adding flexibility.	Applications (eg, speech processing, computer vision, NLP)	anonymous|diffuser_diffusion_via_editbased_reconstruction	/pdf/73f3b621f6648aeb39445346304b87a64b1b25f2.pdf
IWoHx6bY4Zm	4259	Lightweight Equivariant Graph Representation Learning for Protein Engineering	['graph neural networks']	We design a lightweight pre-training model for multi-task protein representation learning from its 3D structure and sequence. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|lightweight_equivariant_graph_representation_learning_for_protein_engineering	/pdf/20673f1027ade9ada9fff73ddd05e182cfbe8974.pdf
QlK8nHnY8zc	4260	NGswin: N-Gram Swin Transformer for Efficient Single Image Super-Resolution	['N-Gram', 'Single Image Super-Resolution', 'Swin Transformer', 'Efficiency', 'Deep Learning']	In our efficient NGswin, N-Gram context is proposed for deep learning in single image super-resolution for the first in history.	Applications (eg, speech processing, computer vision, NLP)	anonymous|ngswin_ngram_swin_transformer_for_efficient_single_image_superresolution	/pdf/a956ce18c7117d75697cea5c7901396c7dab8dbd.pdf
eHrqmewX1B-	4261	Can Wikipedia Help Offline Reinforcement Learning?	['offline rl', 'language models', 'transfer learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|can_wikipedia_help_offline_reinforcement_learning	/pdf/4eff060bd0c353d27a8c60aebeec6c629330cc47.pdf
rpVxn-rX2Wh	4262	Fine-grained Few-shot Recognition by Deep Object Parsing	['Few-shot learning', 'Representation learning']	A method for fine-grained few-shot recognition that relies on representing objects as a collection of parts, where each part is identified by a location and a set of active templates.	Deep Learning and representational learning	anonymous|finegrained_fewshot_recognition_by_deep_object_parsing	/pdf/4b1ec7477a914e385bd50f1400f65793efeaf350.pdf
9X3UZJSGIg9	4263	Adversarial Text to Continuous Image Generation	['gan', 'generative modelling', 'text-to-image', 'text2image', 'hypernetworks']	Receiving text input, hypernetworks generate weights for INR-GAN to synthesize image.	Generative models	anonymous|adversarial_text_to_continuous_image_generation	/pdf/0d09ff8be38d161c19658c1648da368192bb1b02.pdf
KPyHNVpear1	4264	Conditional Execution Of Cascaded Models Improves The Accuracy-Efficiency Trade-Off	['inference', 'efficiency', 'cascades', 'pretrained']	We show how to combine pairs of pretrained models to improve the entire ImageNet accuracy-compute Pareto front.	Deep Learning and representational learning	anonymous|conditional_execution_of_cascaded_models_improves_the_accuracyefficiency_tradeoff	/pdf/9c1f2b3c3b7cf2416205c50d5c25822888a226e5.pdf
fSa5IjNMmmi	4265	Multi-objective optimization via equivariant deep hypervolume approximation	['Multi-objective optimization', 'Hypervolume approximation', 'Geometric deep learning', 'Bayesian optimization', 'Evolutionary algorithms']	Hypervolume approximation using permutation invariant, scaling equivariant neural network	Optimization (eg, convex and non-convex optimization)	anonymous|multiobjective_optimization_via_equivariant_deep_hypervolume_approximation	/pdf/4058d36b8508114978d6118d7c79b6bfe4224231.pdf
mE91GkXYipg	4266	Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video Relation Detection	['Prompt Tuning', 'Video Relation Detection']		Applications (eg, speech processing, computer vision, NLP)	anonymous|compositional_prompt_tuning_with_motion_cues_for_openvocabulary_video_relation_detection	/pdf/fecdedbdfa67c5287c270fc7e6b2521faa928f25.pdf
nnrdKoTNDV6	4267	Physics Model-based Autoencoding for Magnetic Resonance Fingerprinting	['Magnetic Resonance Fingerprinting (MRF)', 'Physics based representation learning', 'Medical imaging', 'Anti-causal representation learning', 'Quantitative Magnetic Resonance Imaging (QMRI)']	For Magnetic Resonance Fingerprinting (MRF), we propose a physics-based auto-encoder framework where a fast and differentiable MRI physics model guides the encoder to learn generalizable representations.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|physics_modelbased_autoencoding_for_magnetic_resonance_fingerprinting	/pdf/aa0aa280e70dcada65dfdb7e0dc3827b0bcd6eb4.pdf
5ZSBBhiAapV	4269	On Feature Diversity in Energy-based Models	['energy-based models', 'redundancy reduction', 'feature diversity']	We derive generalization bounds for energy-based models showing that reducing the redundancy of the feature can lead to better generalization	General Machine Learning (ie none of the above)	anonymous|on_feature_diversity_in_energybased_models	/pdf/3b70101cc2c8ed8792f7dcccd6d38a20acb13060.pdf
ocyru3h_WIi	4270	Learning to Register Unbalanced Point Pairs	['Point Cloud Registration']	We propose a new point cloud registration approach that can handle unbalanced point pairs where one point is significantly larger than others in terms of number of points and size.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_to_register_unbalanced_point_pairs	/pdf/f58c5d27f1468d3eb7547919b677d7a98ffdd23d.pdf
uw9hk67tDEE	4271	Multivariate Gaussian Representation of Previous Tasks for Continual Learning	['Continual Learning', 'Memory Replay', 'Sample Generation', 'Multivariate Gaussian Distribution', 'Expectation-Maximization', 'Local Adaptation']	we propose a method for storing and reproducing distributed representations of data for each class in memory	Deep Learning and representational learning	anonymous|multivariate_gaussian_representation_of_previous_tasks_for_continual_learning	/pdf/f59b5758490fbe9207aac373e98c8cdd01c11c50.pdf
N4k3klHNzQj	4272	Graph MLP-Mixer	[]		Deep Learning and representational learning	anonymous|graph_mlpmixer	/pdf/927f036dfc5219ada646337823ebeff91c13874b.pdf
2aSj08z30A1	4274	ReaKE: Contrastive Molecular Representation Learning with Chemical Synthetic Knowledge Graph	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|reake_contrastive_molecular_representation_learning_with_chemical_synthetic_knowledge_graph	/pdf/1789a0a3eb4547bc77a0b85b267a7b2da531f3d0.pdf
Ph5cJSfD2XN	4276	Unbiased Supervised Contrastive Learning	['contrastive learning', 'debiasing', 'supervised learning', 'representation learning', 'deep learning', 'neural networks']	We introduce FairKL, a debiasing regularization technique along with a metric learning theoretical framework and a novel formulation of the supervised contrastive loss, ϵ-SupInfoNCE	Deep Learning and representational learning	anonymous|unbiased_supervised_contrastive_learning	/pdf/d2da42818eefdc64b3499e28c1d850c4d935fa76.pdf
UOYMeUkFmoN	4277	Locally Consistent to Realize State Augmentation Reinforcement Learning	['State Augmentation', 'Local Consistant']		Deep Learning and representational learning	anonymous|locally_consistent_to_realize_state_augmentation_reinforcement_learning	/pdf/337e4570701645d990188f9f26ff62a76d4536b2.pdf
3lJ3pMuAwDT	4278	AGREE: A Simple Aggregator of Detectors’ Decisions	['AI Safety', 'Algorithms Evaluation', 'Deep Learning', 'Adversarial Examples']	We propose a simple yet effective method to aggregate the decisions based on the soft-probability outputs of multiple trained detectors, possibly provided by a third party.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|agree_a_simple_aggregator_of_detectors_decisions	/pdf/781dccddfe678ee6aab21be992e51c59f513b68e.pdf
2L-nspTvNVC	4279	Deep Class Conditional Gaussians for Continual Learning	['Contiual Learning', 'Lifelong Learning', 'Bayesian', 'Emprical Bayes', 'Probabilistic Machine Learning']	We present an empirical Bayesian method to solve the problem in continual learning of how to use simple metric-based probabilistic models when the embedding function must be learnt online.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|deep_class_conditional_gaussians_for_continual_learning	/pdf/f29839f1a0f8dff8509c694c21fad0935dfabf82.pdf
ceOdspvoaEA	4281	A Connection between One-Step Regularization and Critic Regularization in Reinforcement Learning	['reinforcement learning', 'regularization', 'one-step RL', 'theory']	We discuss some connections between one-step RL and critic regularization methods	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_connection_between_onestep_regularization_and_critic_regularization_in_reinforcement_learning	/pdf/3b82417d3f2c662c317dd22ab89c44b4170b5d2f.pdf
4C8ChYvMYBn	4283	The Curious Case of Benign Memorization	[]		Deep Learning and representational learning	anonymous|the_curious_case_of_benign_memorization	/pdf/089d7a7afd4a540253830650a630a849491c588b.pdf
tMfuHn80HtH	4287	Zero-Label Prompt Selection	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|zerolabel_prompt_selection	/pdf/df55da2e989573994cb4ae1f0980edf76c5eda64.pdf
cXMHQD-xQas	4288	Learning Probabilistic Topological Representations Using Discrete Morse Theory	['Topological Representation', 'Discrete Morse Theory', 'Persistent Homology']	We use discrete Morse theory and persistent homology to construct an one-parameter family of structures as the topological/structural representation space to perform inference tasks.	Deep Learning and representational learning	anonymous|learning_probabilistic_topological_representations_using_discrete_morse_theory	/pdf/152478752eb895dc3a4a94fc8c10ebb9b5486a8f.pdf
hgHEUpY3TB6	4289	A Simple Framework for Low-Resolution Detection with High-resolution Knowledge	['object detection', 'low-resolution', 'knowledge distillation']	We propose a simple distillation-based framework to improve detection on low-resolution images.	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_simple_framework_for_lowresolution_detection_with_highresolution_knowledge	/pdf/9758351a6f54cf39ba19284947c5db27a422b401.pdf
OIcMPYZXFPL	4291	Mastering Spatial Graph Prediction of Road Networks	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|mastering_spatial_graph_prediction_of_road_networks	/pdf/772a3ccc593943b1d9d3076884dd313016921533.pdf
i1Z_VysEgu8	4293	Time-Myopic Go-Explore: Learning A State Representation for the Go-Explore Paradigm	['Exploration', 'Self-Supervised Learning', 'Go-Explore']	To add flexibility to and possibly improve Go-Explore we study how its representation heuristic can be replaced by a time-predicting neural network.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|timemyopic_goexplore_learning_a_state_representation_for_the_goexplore_paradigm	/pdf/ace3ade2a1d9c673a0d05627887d240ac19155e8.pdf
QVSoh6VM4nG	4294	Vector Quantization and Shifting: Exploiting Latent Properties to Optimize Neural Codecs	['Neural Image Compression', 'Uniform Vector Quantization', 'Gradient of Entropy']	We improve the performance of any neural codecs by uniform vector quantization and gradient of the entropy.	Deep Learning and representational learning	anonymous|vector_quantization_and_shifting_exploiting_latent_properties_to_optimize_neural_codecs	/pdf/1a049ee533fdd0ce8af671aad7799a8070b02481.pdf
5d_yTyTj646	4296	Escaping saddle points in zeroth-order optimization:  two function evaluations suffice	['zeroth-order optimization', 'nonconvex optimization', 'escape saddle points']	We provide the first result showing that zeroth-order optimization with constant number of function evaluations per iteration can escape saddle points efficiently.	Optimization (eg, convex and non-convex optimization)	anonymous|escaping_saddle_points_in_zerothorder_optimization_two_function_evaluations_suffice	/pdf/6fe6610a163fd0d5feef7f5a5f18187609270f73.pdf
CCF5eG4UPNS	4297	Interpreting Class Conditional GANs with Channel Awareness	['class-conditional GANs', 'representations', 'interpretation']	This work discovered that some channels are primarily responsible for a particular class, and some channels are shared by all classes. This finding further facilitates multiple novel applications.	Generative models	anonymous|interpreting_class_conditional_gans_with_channel_awareness	/pdf/2e53d42bd2cb584c4f61ac6abd2fbd2815395553.pdf
10BQ_HZKWXn	4298	robust positive-unlabeled learning via noise negative sample self-correction	['PU Learning', 'Curriculum Learning']		Deep Learning and representational learning	anonymous|robust_positiveunlabeled_learning_via_noise_negative_sample_selfcorrection	/pdf/e611c07f6073580130c38526f1671ba12bf2eba7.pdf
lIu-ixf-Tzf	4299	Learning topology-preserving data representations	['representation learning', 'dimensionality reduction', 'topological data analysis']	We propose a method for learning topology-preserving data representations.	Deep Learning and representational learning	anonymous|learning_topologypreserving_data_representations	/pdf/6045af3cd8fc4ace9fafcb7d8a5e60031e954774.pdf
TLx9diIRJVj	4300	SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data	[]		Deep Learning and representational learning	anonymous|synbench_taskagnostic_benchmarking_of_pretrained_representations_using_synthetic_data	/pdf/148de6536f32949b067911f71dd5b689051bc865.pdf
O5PXo5Y0csVi	4301	Relaxed Attention for Transformer Models	['transformer', 'attention', 'regularization', 'internal language model', 'relaxed attention']	A simple smoothing in the attention function of transformer models contributes to improved regularization and internal language model suppression.	Applications (eg, speech processing, computer vision, NLP)	anonymous|relaxed_attention_for_transformer_models	/pdf/c4a0b1535503ebb863205244077d57385482f20c.pdf
o8HjiLULWq5	4302	Reducing Communication Entropy in Multi-Agent Reinforcement Learning	['multi-agent reinforcement learning', 'multi-agent communication', 'low entropy']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|reducing_communication_entropy_in_multiagent_reinforcement_learning	/pdf/c8c1cf7fdee73fc0fd88d440cb819c82c1fa0696.pdf
dMMPUvNSYJr	4303	Sequential Learning of Neural Networks for Prequential MDL	['mdl', 'continual-learning', 'deep-learning']	Techniques for obtaining short MDL descriptions lengths for image datasets with modern NN architectures and continual learning.	Deep Learning and representational learning	anonymous|sequential_learning_of_neural_networks_for_prequential_mdl	/pdf/eefdf3e1b70beafb73f4f3ae6dd5e7899fa2a4c6.pdf
zuQQ7GrDFfH	4304	Irregularity Reflection Neural Network for Time Series Forecasting	['DNN', 'CNN', 'time series', 'fourier series', 'irregularity representation learning']	This research devises the Irregularity Representation Block that extracts and trains the irregularity from the time series data using CNN architecture.	Deep Learning and representational learning	anonymous|irregularity_reflection_neural_network_for_time_series_forecasting	/pdf/dc169736612da844ac5bf78c85a8d3af00d713eb.pdf
bvxY6ThxGzB	4305	MILAN: Masked Image Pretraining on Language Assisted Representation	[]		Deep Learning and representational learning	anonymous|milan_masked_image_pretraining_on_language_assisted_representation	/pdf/ecb0722a838b45e67e153e6618c254cc39efb4a5.pdf
dO4aZ9-CsTn	4306	Hierarchical Prototypes for  Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning	['Unsupervised Dynamics Generalization', 'Model-Based Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|hierarchical_prototypes_for_unsupervised_dynamics_generalization_in_modelbased_reinforcement_learning	/pdf/20e881856fbf47168891abe80e2abf024ecf7b50.pdf
xjb563TH-GH	4310	Representational Dissimilarity Metric Spaces for Stochastic Neural Networks	['stochastic neural networks', 'noise', 'representational geometry', 'dissimilarity metrics']	Representational dissimilarity metrics that account for noise geometry in biological and artificial neural responses. 	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|representational_dissimilarity_metric_spaces_for_stochastic_neural_networks	/pdf/380f8e2150e0a034b67f80a55f7311a74cbe2daa.pdf
XkYe7K_AQ8I	4311	Learning Interpretable Neural Discrete Representation for Time Series Classification	['Time series classification', 'discrete neural representation', 'interpretability', 'deep learning']	We propose a model for time series classification based on a convolutional model which learn in an unsupervised manner a small dictionary of patterns.	Deep Learning and representational learning	anonymous|learning_interpretable_neural_discrete_representation_for_time_series_classification	/pdf/1ef92735ab0080fe24fc773fc4f1332306cd569a.pdf
ZfILgclY4J-	4312	Spatial Entropy as an Inductive Bias for Vision Transformers	['Vision Transformers', 'Self-Supervised Learning', 'Attention', 'Regularization.']	We propose a self-supervised pretext task to include an object-based inductive bias in Vision Transformers.	Unsupervised and Self-supervised learning	anonymous|spatial_entropy_as_an_inductive_bias_for_vision_transformers	/pdf/16388513b7405f3da1bb15da9dc1ddc59919c6bf.pdf
K1KJ0NbFu1h	4313	Learning Dictionaries over Datasets through Wasserstein Barycenters	['Dictionary Learning', 'Optimal Transport', 'Domain Adaptation', 'Manifold Learning']	We apply Wasserstein Dictionary Learning to datasets understood as empirical distributions.	Unsupervised and Self-supervised learning	anonymous|learning_dictionaries_over_datasets_through_wasserstein_barycenters	/pdf/1f68eba34ae07c62a79e4644a051c3c18a7ad454.pdf
-k7Lvk0GpBl	4314	Localized Randomized Smoothing for Collective Robustness Certification	['Robustness', 'Certification', 'Verification', 'Trustworthiness', 'Graph neural networks']	We propose a novel collective robustness certificate based on randomized smoothing that uses different anisotropic smoothign distribution for the different outputs of a multi-output model.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|localized_randomized_smoothing_for_collective_robustness_certification	/pdf/d48c943f74ed756c5ae31f9203f0a30e7581af3a.pdf
bG0TaFFa1c9	4315	SeKron: A Decomposition Method Supporting Many Factorization Structures	['model compression', 'tensor decomposition', 'factorization structure']		Deep Learning and representational learning	anonymous|sekron_a_decomposition_method_supporting_many_factorization_structures	/pdf/acc16f9af999d9e67eadf7f9d81227a671d35ed6.pdf
bp6Lr0TmmUS	4317	Harnessing Client Drift with Decoupled Gradient Dissimilarity	['Federated Learning', 'Deep Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|harnessing_client_drift_with_decoupled_gradient_dissimilarity	/pdf/e9e1e36028f3091f28ffef2203e3bb8c7eb50c24.pdf
IERSU0La-Nt	4318	FedPD: Defying data heterogeneity through privacy distillation	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fedpd_defying_data_heterogeneity_through_privacy_distillation	/pdf/db1af6a6011c61b90c4771e11078337b597bc4b0.pdf
AXP2Sf6qqSZ	4320	Counterfactual Explanation via Search in Gaussian Mixture Distributed Latent Space	['XAI', 'Counterfactual Explanation', 'Autoencoder', 'Guassian-Mixture Distribution', 'Disentanglement']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|counterfactual_explanation_via_search_in_gaussian_mixture_distributed_latent_space	/pdf/0d5dc86800d7d18a9b0e84609646bba67e1e406d.pdf
xkev3_np08z	4321	ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion	['knowledge graph embedding', 'knowledge graph completion', 'composition', 'hierarchy', 'geometric interpretation']	ExpressivE: A fully expressive KGC model that captures a rich set of patterns with an intuitive geometric interpretation and state-of-the-art performance.	Deep Learning and representational learning	anonymous|expressive_a_spatiofunctional_embedding_for_knowledge_graph_completion	/pdf/6363c7be618c8caf7ddcd10cfa3e66badcbefecf.pdf
-CA8yFkPc7O	4322	Why adversarial training can hurt robust accuracy	['Adversarial training', 'Learning Theory', 'Robust generalisation']	Adversarial training can hurt robust generalization for perceptible perturbations when the sample size is small	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|why_adversarial_training_can_hurt_robust_accuracy	/pdf/fcb3c62eb1d0a30cd1f237ffc42bdb2c2ae70884.pdf
vKHuq9WeHMU	4323	Association Rules in QUBO Samples and Where to Find Them	['Association rule', 'Annealing', 'QUBO']	Find valuable association rules from QUBO samples to simplify QUBO problem and improve optimisation results	General Machine Learning (ie none of the above)	anonymous|association_rules_in_qubo_samples_and_where_to_find_them	/pdf/da672b73026ddc8928c2f27f4ddd9c1c41aa1f33.pdf
HLQyRgRnoXo	4324	Distributed Inference and Fine-tuning of Large Language Models Over The Internet	['volunteer computing', 'distributed deep learning', 'distributed inference', 'efficient inference', 'large language models', 'gpt-3']	We propose a practical algorithm for running large language models by pooling together weak geographically distributed devices. Our system can inference BLOOM-176B over the Internet more than 10x faster compared to RAM offloading.	Applications (eg, speech processing, computer vision, NLP)	anonymous|distributed_inference_and_finetuning_of_large_language_models_over_the_internet	/pdf/82160e667668fb24b4f8084a1b7a3732e3a44b49.pdf
Z-CqSH6J_VK	4326	Differentiable and transportable structure learning	['graph learning']	We introduce an architecture and loss to encourage transportability in gradient-based graph learning methods. Before our method, gradient-based approaches were not transportable.	General Machine Learning (ie none of the above)	anonymous|differentiable_and_transportable_structure_learning	/pdf/e281d0d439ac1b01538e65648c7093e1a211e995.pdf
bW-gfNJatfXX	4327	Adversarial Driving Policy Learning by Misunderstanding the Traffic Flow	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adversarial_driving_policy_learning_by_misunderstanding_the_traffic_flow	/pdf/f260762137c1d3dc374865b764c418b4faec605d.pdf
6uv5W_DXvRr	4329	Linearised Implicit Variational Inference	['Implicit models', 'Variational Inference', 'Bayesian Deep Learning']	A novel bound for training implicit variational approximations for Bayesian Neural Networks	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|linearised_implicit_variational_inference	/pdf/85d2869dd409577f5c1b8df9144f3758c0efa3d8.pdf
vHgL7XYBiTd	4330	Finding Generalization Measures by Contrasting Signal and Noise	['generalization measure', 'signal and noise']	A new generalization measure	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|finding_generalization_measures_by_contrasting_signal_and_noise	/pdf/3c2d0cff14d51e5ea027408d6244ba96313cd412.pdf
iI8zWfCyCIQ	4331	Graph Backup: Data Efficient Backup Exploiting Markovian Transitions	['reinforcement learning', 'graph structure', 'neuro-symbolic methods', 'data efficient reinforcement learning']	In this paper, we treat the transition data of the MDP as a graph, and define a novel backup operator, Graph Backup, which exploits this graph structure for better value estimation. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|graph_backup_data_efficient_backup_exploiting_markovian_transitions	/pdf/f45aef61d3fcfcae4c7f7b9f0af9267e62a68e6e.pdf
CROlOA9Nd8C	4333	Copy is All You Need	['neural text genertion']		Applications (eg, speech processing, computer vision, NLP)	anonymous|copy_is_all_you_need	/pdf/80b224661ddfb2fd551a48e8155fb4d39b8e4aa7.pdf
O2cW5Q3bH_M	4334	Gradient flow in the gaussian covariate model: exact solution of learning curves and multiple descent structures	['Gaussian Covariate Model', 'Gradient Flow', 'Gradient Descent', 'Double Descent', 'Epoch-wise Double Descent', 'Random Matrix', 'Linear Pencil', 'Cauchy Integrals', 'High-dimensional Limits', 'Stieltjes Transform', 'Random Feature Model']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|gradient_flow_in_the_gaussian_covariate_model_exact_solution_of_learning_curves_and_multiple_descent_structures	/pdf/757c93bc82756545a73ae811403eec2c59264c3e.pdf
PExjmUwEAAH	4335	Interactive Sequential Generative Models	['Generative Models and Autoencoders', 'Graph Neural Networks', 'Recurrent Networks', 'Sequential Models', 'Multi-Agent']	We propose a  novel framework for multiagent trajectories that augments sequential generative models with latent social structures.	Generative models	anonymous|interactive_sequential_generative_models	/pdf/0fe72cd49683f9d7f8c105faddd67457367085b3.pdf
9Nj_gNdvqYf	4336	Leveraging Importance Weights in Subset Selection	['data subset selection', 'importance weighted sampling']		General Machine Learning (ie none of the above)	anonymous|leveraging_importance_weights_in_subset_selection	/pdf/0c593d7355a93ab1b74d622180f365eac498e578.pdf
RnH_0iL4xao	4337	Towards Conditionally Dependent Masked Language Models	['Markov random fields', 'masked language models', 'compatibility']	We study the limitations of MRFs defined from MLMs' unary conditionals, and propose alternatives that are either better (from a probabilistic modeling standpoint) or faster to run	Applications (eg, speech processing, computer vision, NLP)	anonymous|towards_conditionally_dependent_masked_language_models	/pdf/99d0a40ad04eea7c6ca71e79d9cbb41ac6fe95b2.pdf
fUX3bszZSOw	4338	Do You Remember? Overcoming Catastrophic Forgetting for Fake Audio Detection	['fake audio detection', 'regularized adaptive weight modification', 'catastrophic forgetting', 'continual learning']	We propose a regularized adaptive weight modification algorithm to overcome catastrophic forgetting for fake audio detection.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|do_you_remember_overcoming_catastrophic_forgetting_for_fake_audio_detection	/pdf/b1e4a22e3f5201f40c8501c351e3547ee9e563c4.pdf
eLgK35G3A5d	4340	Annealed Fisher Implicit Sampler	['Implicit Generative Models', 'Score Matching', 'Learning to Sample', 'Sampling']	Train an implicit sampler by minimizing Fisher Divergence with a novel S2D loss.	Generative models	anonymous|annealed_fisher_implicit_sampler	/pdf/8ea11059a8bc1f85b9c15dee59d6325f688cfc1d.pdf
mAWJpM7S21-	4341	Simplicity bias leads to amplified performance disparities	['fairness', 'model bias', 'dataset bias', 'bias amplification', 'simplicity bias']	We introduce difficulty disparity and difficulty amplification, where a model's bias towards simplicity results in disparate performance between groups.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|simplicity_bias_leads_to_amplified_performance_disparities	/pdf/c80b08f1ad4f998b54fcadc939a0426cf503eb41.pdf
8JsaP7j1cL0	4342	Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation	['Biologically Plausible Neural Networks', 'Blind Correlated Source Separation', 'Correlative Information Maximization']	This paper proposes biologically plausible neural networks for blind separation of correlated sources exploiting prior domain assumptions via an information maximization criterion.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|correlative_information_maximization_based_biologically_plausible_neural_networks_for_correlated_source_separation	/pdf/d0af93a71de255fc7efa2c2d9599f0c6c65eb60e.pdf
eWvjcZIZrWu	4343	Improved Stein Variational Gradient Descent with Importance Weights	"['SVGD', 'Importance Sampling', 'Importance Weights', 'Sampling', ""R\\'enyi Divergence"", 'KL-divergence']"	theoretical paper to show the power of importance weights in SVGD	General Machine Learning (ie none of the above)	anonymous|improved_stein_variational_gradient_descent_with_importance_weights	/pdf/02e474db582dabb8035ed3b2279cdfdad46dca9f.pdf
cA77NrVEuqn	4344	Efficient Planning in a Compact Latent Action Space	['Model-based RL', 'Planning', 'Sequence Modelling RL', 'Generative Model', 'Offline Reinforcement Learning']	We propose Trajectory Autoencoding Planner (TAP) a model-based RL method that learns a compact discrete latent action space for efficient planning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|efficient_planning_in_a_compact_latent_action_space	/pdf/7615e765aae5cac2a92429e16ce9279c9fd89f93.pdf
ATLEl_izD87	4345	Enhancing the Inductive Biases of Graph Neural ODE for Modeling Dynamical Systems	['Neural ODE', 'Graph neural network', 'physical systems', 'Graph Neural ODE']	Inferring the dynamics of physical systems can be significantly enhanced by Graph neural ODEs with appropriate inductive biases	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|enhancing_the_inductive_biases_of_graph_neural_ode_for_modeling_dynamical_systems	/pdf/9d95cc680b5f94cb2a3adfc0de8d4a798b5a3586.pdf
nlda8uNdwuJ	4347	Analyzing Transformers in Embedding Space	['transformers', 'interpretability', 'embedding space', 'explainability']		Deep Learning and representational learning	anonymous|analyzing_transformers_in_embedding_space	/pdf/55c34a0e02f99ef5f39b6eb67ddc7a6358b69bd0.pdf
6iVJOtr2zL2	4348	Contrastive Meta-Learning for Partially Observable Few-Shot Learning	['Contrastive Learning', 'Meta-Learning', 'Few-Shot Learning', 'Partial Observability']	An approach for meta-learning contrastive representations under partial observability.	Deep Learning and representational learning	anonymous|contrastive_metalearning_for_partially_observable_fewshot_learning	/pdf/72c5f5c50401977c4076a0d716a480f4cee556d7.pdf
nMZhFqYsiad	4349	Guided Safe Shooting: model based reinforcement learning with safety constraints	['Model-based Reinforcement learning', 'Safe-RL', 'Evolutionary method', 'Planning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|guided_safe_shooting_model_based_reinforcement_learning_with_safety_constraints	/pdf/4958d1f7cb2ac5c23fbe0fc8104eacf95f3360bb.pdf
3Pf3Wg6o-A4	4350	Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning	['System 2', 'Logical reasoning', 'Language Models', 'Large Language Models', 'Reasoning', 'Neuro-symbolic', 'Neural Symbolic', 'Interpretability']	Using language models to produce a human interpretable chain of logical reasoning to answer questions.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|selectioninference_exploiting_large_language_models_for_interpretable_logical_reasoning	/pdf/3fc749226db4329c635440641f054411cd832f65.pdf
xgQO2_F-w8b	4353	Representation Balancing with Decomposed Patterns for Treatment Effect Estimation	['Treatment Effect Estimation', 'Counterfactual Estimation', 'Representation Balancing', 'Selection Bias', 'Covariate Shift']	We derive the bound for individual propensity confusion and decompose representation balancing into patterns of (i) individual propensity confusion and group distance minimization and (ii) pre-balancing and balancing, for treatment effect estimation.	General Machine Learning (ie none of the above)	anonymous|representation_balancing_with_decomposed_patterns_for_treatment_effect_estimation	/pdf/e6e31139f12193bcb3fc40621e4ed9fffdb0272c.pdf
4ojYamKgnQc	4354	MetaPhysiCa: Causality-aware Robustness to OOD Initial Conditions in Physics-informed Machine Learning	['physics-informed machine learning', 'out-of-distribution', 'robustness', 'causality']	This work proposes combining causal structural discovery, invariant risk minimization, and meta-learning in order to make Physics-informed Machine Learning robust to OOD tasks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|metaphysica_causalityaware_robustness_to_ood_initial_conditions_in_physicsinformed_machine_learning	/pdf/14017eba2226242555946a9ecd22994c67c771e5.pdf
wHt8UumYfGT	4356	Prompt-Based Metric Learning for Few-Shot NER	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|promptbased_metric_learning_for_fewshot_ner	/pdf/3ce32c288e929b2c4e68b8bf7dc9c1e98cb711c5.pdf
SYsmAZ8PHez	4358	InteriorSim: A Photorealistic Simulator for Embodied AI	['simulation environment', 'embodied AI']	InteriorSim is a photorealistic simulator for embodied AI in the home.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|interiorsim_a_photorealistic_simulator_for_embodied_ai	/pdf/c53d5fbe18b34ee6333a81d792f548e61a7bba2e.pdf
cRzIAw8Rem2	4359	Learning Privacy-Preserving Graph Embeddings Against Sensitive Attributes Inference	['Inference privacy', 'differential privacy', 'graph representation']	Preserving the inference privacy of certain sensitive attributes associated with graph nodes for graph representation learning.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_privacypreserving_graph_embeddings_against_sensitive_attributes_inference	/pdf/cc582db48bd4e4f61e213f4509950dc78a0d1bc1.pdf
Pv1GPQzRrC8	4360	Imitating Human Behaviour with Diffusion Models	['imitation learning', 'behavioral cloning', 'behavioral cloning', 'diffusion models', 'generative models']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|imitating_human_behaviour_with_diffusion_models	/pdf/12db0e5165e8ac822b51660da9e4e78ad9681e59.pdf
Hrj3MhDO_a	4362	A Simple Nadaraya-Watson Head for Explainable and Calibrated Classification	['Image Classification', 'Nonparametric', 'Interpretability', 'Explainability', 'Calibration']	We present a simple, nonparametric replacement to the fully-connected head in the image classification setting based on the Nadaraya-Watson (NW) estimator, which can be shown to be interpretable and well-calibrated.	Deep Learning and representational learning	anonymous|a_simple_nadarayawatson_head_for_explainable_and_calibrated_classification	/pdf/b6a20ad69d2bfcec452e467b8bb240dc0e9ce1e4.pdf
lXMlDL78Alx	4363	Causal Attention to Exploit Transient Emergence of Causal Effect	['causal attention mechanism', 'coupling-drive', 'sparse causal effect', 'neural dynamics', 'causal network reconstruction']	We propose the causal attention mechanism for a class of causal network reconstruction tasks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|causal_attention_to_exploit_transient_emergence_of_causal_effect	/pdf/bc2f508bdce73933b2c7d3e515120a1b536b4319.pdf
v-rx235RlfI	4364	Model Stealing Attacks Against Vision-Language Models	['Vision-Language Model', 'Model Stealing Attack']	We propose the first model stealing attack against the vision-language models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|model_stealing_attacks_against_visionlanguage_models	/pdf/2faede1ef7c7f0aaa5bee6573f9309985c254c8a.pdf
FDiO2xfKnkj	4365	Affinity-VAE for clustering and classification of objects in multidimensional image data	['representation learning', 'VAE', '$\\beta$-VAE', 'affinity', 'cryo-ET', 'cryo-electron tommography', 'structural biology', 'visual proteomics']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|affinityvae_for_clustering_and_classification_of_objects_in_multidimensional_image_data	/pdf/1392562039752c1e0037e22fe0155058f61a13fc.pdf
ul7HSEpkEHX	4366	Learning Robust Kernel Ensembles with Kernel Average Pooling	['convolutional neural networks', 'topographical neural networks', 'adversarial robustness', 'ensemble models']	Using Kernel Average Pools for learning robust kernel ensembles in neural networks	Deep Learning and representational learning	anonymous|learning_robust_kernel_ensembles_with_kernel_average_pooling	/pdf/4c245b841f588f6794e2ac1da406acf1360bbef4.pdf
ztgT8Iok130	4367	Sample-efficient multi-objective molecular optimization with GFlowNets	['multi-objective molecular optimization', 'Bayesian optimization', 'generative flow networks']	A GFlowNet-based Bayesian optimization algorithm for sample-efficient multi-objective molecular optimization	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|sampleefficient_multiobjective_molecular_optimization_with_gflownets	/pdf/e3070a0eb9d316fd6ae518e9b417e539580fdbda.pdf
uBKBoix9NXa	4368	Understanding weight-magnitude hyperparameters in training  binary networks	['Binary Neural Networks', 'Optimization', 'Digital Signal Processing', 'Inifnite Impulse Response Filter']	We analysed the effects of hyperparameters in BNN optimization and propose an optimizer that is based upon Infinite Impulse Response Filters	Deep Learning and representational learning	anonymous|understanding_weightmagnitude_hyperparameters_in_training_binary_networks	/pdf/b23d9669a760e579ccfee8ecab7381f1b454a290.pdf
QYiN3R9nVUG	4369	SEQuence-rPPG: A Fast BVP Signal Extraction Method From Frame Sequences	['rPPG', 'Remote vital sensing', 'Signal processing']	A new rPPG method is proposed, which is very simple, fast and accurate.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|sequencerppg_a_fast_bvp_signal_extraction_method_from_frame_sequences	/pdf/cd0a22163b63828d2fc7f7374412fc21f472b2fc.pdf
lh-HRYxuoRr	4370	This Looks Like It Rather Than That: ProtoKNN For Similarity-Based Classifiers	['XAI', 'Inherently Interpretable Model', 'This Looks Like That Framework', 'Fine-grained Image Classification', 'Deep Learning']		Deep Learning and representational learning	anonymous|this_looks_like_it_rather_than_that_protoknn_for_similaritybased_classifiers	/pdf/900bbbe68d83f682883a97650b757ea4943f3f88.pdf
3i_Bzt7Hmcm	4372	DP-InstaHide: Data Augmentations Provably Enhance Guarantees Against Dataset Manipulations	[]		Deep Learning and representational learning	anonymous|dpinstahide_data_augmentations_provably_enhance_guarantees_against_dataset_manipulations	/pdf/eab859351425b5d5bc29e562ccfc1e05bc1eed0b.pdf
wysXxmukfCA	4373	Towards Robust Model Watermark via Reducing Parametric Vulnerability	['Model Watermarking', 'Backdoor Watermark', 'Ownership Verification', 'Deep IP Protection']	Based on the observation of the watermarked model in parametric space, we propose a minimax approach to improve the robustness of watermarked models against state-of-the-art removal attacks.	Deep Learning and representational learning	anonymous|towards_robust_model_watermark_via_reducing_parametric_vulnerability	/pdf/e852efe0da8a2bf0f7a57c5a1d2085c516c974f9.pdf
S4PGxCIbznF	4374	Client-agnostic Learning and Zero-shot Adaptation for Federated Domain Generalization	['Federated learning', 'Domain generalization', 'Zero-shot adaptation']	Propose client-agnostic learning and zero-shot adaptation for federated domain generalization	Deep Learning and representational learning	anonymous|clientagnostic_learning_and_zeroshot_adaptation_for_federated_domain_generalization	/pdf/2ed2b833046094f7cb17bb015f15410e9dab98dd.pdf
tNAYMjSd296	4375	On the Robustness of Dataset Inference	['ownership verification', 'model extraction', 'model stealing', 'fingerprinting']	Dataset Inference, a model fingerprinting technique published at ICLR 2021, suffers from false positives and false negatives.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_robustness_of_dataset_inference	/pdf/238c3a41fee3a56ad5676392700e18afc07a7ce5.pdf
rByagyHWlpb	4376	DBA: Efficient Transformer with Dynamic Bilinear Low-Rank Attention	['Efficient Transformer']		Applications (eg, speech processing, computer vision, NLP)	anonymous|dba_efficient_transformer_with_dynamic_bilinear_lowrank_attention	/pdf/8c231cfd25c8ada7e54cc60e88522263de1d31c0.pdf
Mj7K4lglGyj	4378	UNICORN: A Unified Backdoor Trigger Inversion Framework	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|unicorn_a_unified_backdoor_trigger_inversion_framework	/pdf/e33c887e4cc606c6071a894a1ed707b7848a5be1.pdf
JLR_B7n_Wqr	4381	Latent Graph Inference using Product Manifolds	['Latent Graph Inference', 'Product Manifolds', 'Graph Neural Networks']		Deep Learning and representational learning	anonymous|latent_graph_inference_using_product_manifolds	/pdf/029da6bd9a375a728046edb44e52f04079051a5a.pdf
dZrQR7OR11	4382	Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach	['federated learning', 'variational inference', 'expectation propagation']	This work introduces a probabilistic message-passing algorithm for federated learning based on expectation propagation (FedEP) and studies algorithmic considerations to scale up classic expectation propagation to modern federated learning settings.	General Machine Learning (ie none of the above)	anonymous|federated_learning_as_variational_inference_a_scalable_expectation_propagation_approach	/pdf/0c186f0c7abaee223ccc209325d60f3c785add41.pdf
DZ4FS-Evau7	4384	Task-Agnostic Unsupervised Robust Representation Learning	['unsupervised robustness', 'transferable adversarial robustness']	We propose a method to learn robust representations without any labels or adversarial fine-tuning in downstream tasks, based on a theoretically grounded unsupervised robustness regularizer.	Unsupervised and Self-supervised learning	anonymous|taskagnostic_unsupervised_robust_representation_learning	/pdf/0636f0712ab88ec2af361a51a23815d1401b669e.pdf
U_2kuqoTcB	4387	Identifiability Results for Multimodal Contrastive Learning	['multimodal learning', 'multi-view learning', 'contrastive learning', 'causal representation learning', 'nonlinear ica', 'identifiability']	We show that multimodal contrastive learning can block-identify latent factors shared between heterogenous modalities (e.g., images and captions), even in the presence of nontrivial statistical and causal dependencies.	Unsupervised and Self-supervised learning	anonymous|identifiability_results_for_multimodal_contrastive_learning	/pdf/2d4c368c8d02b03d1b577ade73df1c33e7367f87.pdf
mMaInr0r0c	4388	A View From Somewhere: Human-Centric Face Representations	['similarity', 'faces', 'annotator bias', 'computer vision', 'cognitive', 'mental representations', 'diversity']	Implicit discovery of face-varying dimensions and annotator bias by learning on a novel face similarity dataset	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_view_from_somewhere_humancentric_face_representations	/pdf/1f4df80ca5ca6ce3e1b86dc01664bf88b09d7004.pdf
Or8rcTLo7U	4389	Maximal Correlation-Based Post-Nonlinear Learning for Bivariate Causal Discovery	[]		Deep Learning and representational learning	anonymous|maximal_correlationbased_postnonlinear_learning_for_bivariate_causal_discovery	/pdf/ebe6518f0f507d282f6cfb6154b2da0a99cb5c6b.pdf
ciZrud3kf3	4391	Wasserstein Generalization Bound for Few-Shot Learning	['Few shot learning', 'Generalization']	We use properties of wassertein distance to give a tight bound for few shot learning, specifically prototypical networks.	Deep Learning and representational learning	anonymous|wasserstein_generalization_bound_for_fewshot_learning	/pdf/6a8c20ea52a1e71f3567514cd1c5241508550c73.pdf
qg2XdQ773R	4392	Multivariate Time Series Forecasting By Graph Attention Networks With Theoretical Guarantees	['Multivariate Time Series Forecasting', 'Graph Attention Networks', 'Generalization Error Bound', 'Rademacher Complexity']		Applications (eg, speech processing, computer vision, NLP)	anonymous|multivariate_time_series_forecasting_by_graph_attention_networks_with_theoretical_guarantees	/pdf/70d4cc5e03c577901e65b332c16983b03f70e56f.pdf
Kf7Yyf4O0u	4394	CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning	['Federated Learning', 'Differential Privacy', 'Empirical Privacy', 'Model Auditing', 'Membership Inference Attack']	Crafting canaries to measure empirical privacy of DP-FL training under a realistic threat model	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|canife_crafting_canaries_for_empirical_privacy_measurement_in_federated_learning	/pdf/e36514b1d4200283133d2692e199d5aebe8ba37f.pdf
1mjOVFZ3C-	4395	Global-Scale Species Mapping From Crowdsourced Data	['species distribution modeling', 'coordinate networks', 'deep learning']	A new model for jointly estimating the spatial range of thousands of different species from sparse partially observed data. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|globalscale_species_mapping_from_crowdsourced_data	/pdf/cc6eb3eab0caf25b8b9a1c7e2aff1c1e97254cd2.pdf
RZHdb7FnqlY	4396	Towards the Detection of Diffusion Model Deepfakes	['Diffusion Model', 'Generative Adversarial Network', 'GAN', 'Deepfakes', 'Detection', 'Frequency Artifact', 'Frequency Analysis', 'Spectrum Discrepancies', 'Synthetic Images', 'Disinformation', 'Social Media']	We take a first look at the detection of images generated by diffusion models by evaluating state-of-the-art detectors and analyzing DM-generated images in the frequency domain.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_the_detection_of_diffusion_model_deepfakes	/pdf/b54799845ee36442c918e5741a7a13cc9be79135.pdf
2bJ6Cqrd-a	4399	Few-shot Lifelong Reinforcement Learning with Generalization Guarantees: An Empirical PAC-Bayes Approach	['Few-shot Learning', 'Lifelong Meta RL', 'Multi-Task RL', 'PAC-Bayes Bound', 'Generalization Error Bound']		General Machine Learning (ie none of the above)	anonymous|fewshot_lifelong_reinforcement_learning_with_generalization_guarantees_an_empirical_pacbayes_approach	/pdf/9766bbf3e7eecfcef313435809403d316f38cfbb.pdf
p9zz7hLzH-4	4400	Affinity-Aware Graph Networks	['Graph neural networks', 'message passing networks', 'effective resistance']	We show how to use affinity measures arising from random walks (e.g., effective resistance) to design message passing networks that are shown to outperform various benchmarks with fewer message passing steps.	Deep Learning and representational learning	anonymous|affinityaware_graph_networks	/pdf/411c0722ded46fd217eedf30628421ea9ce9f523.pdf
tgAI50giBbg	4401	Enforcing Delayed-Impact Fairness Guarantees	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|enforcing_delayedimpact_fairness_guarantees	/pdf/15c3ba2e8d93b0f564409d605b0c09de23854938.pdf
MWGDhOQkr3	4402	Towards Reliable Link Prediction with Robust Graph Information Bottleneck	['Robust link prediction', 'Inherent edge noise', 'Graph representation learning']	We provide an information-theory-guided principle and its two instantiations for robust link prediction under inherent edge noise.	Deep Learning and representational learning	anonymous|towards_reliable_link_prediction_with_robust_graph_information_bottleneck	/pdf/f3d8b4eb13befa313bc95cf0946e7d8b11e1e9cc.pdf
qcJmsP3oE9	4403	Edge Guided GANs with Contrastive Learning for Semantic Image Synthesis	['Semantic image synthesis', 'contrastive learning', 'GANs', 'edge']	A novel contrastive learning based edge guided GAN for semantic image synthesis.	Applications (eg, speech processing, computer vision, NLP)	anonymous|edge_guided_gans_with_contrastive_learning_for_semantic_image_synthesis	/pdf/1c0270eca126f9d879320d3fe988aa4b40cd03e2.pdf
bGRqRRVA8C	4405	CLAS: Central Latent Action Spaces for Coordinated Multi-Robot Manipulation	['Latent Action Spaces', 'Multi-Robot Manipulation', 'Cooperative Control', 'Reinforcement Learning']	We propose a method for coordinating multi-robot manipulation by learning a latent action space that is task specific and acts on the manipulated object.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|clas_central_latent_action_spaces_for_coordinated_multirobot_manipulation	/pdf/dfb90a1f5c136b86e82c7510a38950613cf73511.pdf
OAw6V3ZAhSd	4406	HyperDeepONet: learning operator with complex target function space using the limited resources via hypernetwork	['Hypernetwork', 'Operator learning', 'Deep operator network', 'DeepONet']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|hyperdeeponet_learning_operator_with_complex_target_function_space_using_the_limited_resources_via_hypernetwork	/pdf/ec406b90863266b50c1bc2d572c66b29853365bd.pdf
QP4nkeQ1BpT	4407	Hidden Markov Mixture of Gaussian Process Functional Regression: Utilizing Multi-Scale Structure for Time-Series Forecasting	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|hidden_markov_mixture_of_gaussian_process_functional_regression_utilizing_multiscale_structure_for_timeseries_forecasting	/pdf/34620195310692040767da9bbd2e7fb62e4db040.pdf
Uzgfy7_v7BH	4408	Causal Mean Field Multi-Agent Reinforcement Learning	['multi-agent reinforcement mearning', 'causal inference']	This paper aims at the scalability problem in large-scale multi-agent system. We use causal inference to imporve the robustness of mean field Q-learning. Experiments verify that our method achieve superior scalability performance.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|causal_mean_field_multiagent_reinforcement_learning	/pdf/9a606f475706e8c2cc5704dda4df3dcc2e8f057e.pdf
TKcVjKZ0BxE	4409	A NEW PARADIGM FOR CROSS-MODALITY PERSON RE-IDENTIFICATION	['People Re-identification，Cross-modality']		Applications (eg, speech processing, computer vision, NLP)	anonymous|a_new_paradigm_for_crossmodality_person_reidentification	/pdf/722c840b4d0394a95ca5934a2c103884bdf1c07f.pdf
Ajk3Bfo9AUW	4410	Using Planning to Improve Semantic Parsing of Instructional Texts	['nlp', 'semantic parsing', 'planning']	Integrating symbolic planning information as a decoding constraint improves few-shot semantic parsing of instructional texts	Applications (eg, speech processing, computer vision, NLP)	anonymous|using_planning_to_improve_semantic_parsing_of_instructional_texts	/pdf/c29b88878b512bf163c049a300bc6a20acefb620.pdf
kRCRcDayfk6	4412	Robust and accelerated single-spike spiking neural network training with applicability to challenging temporal tasks	['Spiking neural networks', 'single-spike', 'accelerated training', 'dead neuron problem']	We propose a new model for robust and accelerated training of single-spike SNNs with competitive performance across various image and neuromorphic datasets and demonstrate a broader computational role for single-spike SNNs than previously believed.	General Machine Learning (ie none of the above)	anonymous|robust_and_accelerated_singlespike_spiking_neural_network_training_with_applicability_to_challenging_temporal_tasks	/pdf/779c3ee2a1c835a7b499e153cd2feb6c6a4026cf.pdf
im5YMG981ST	4413	Going Beyond Approximation: Encoding  Constraints for Explainable Multi-hop Inference via Differentiable Combinatorial Solvers	['Explainable AI', 'Constrained Optimization', 'Integer Linear Programming', 'Question Answering']	The paper presents a novel neuro-symbolic framework that integrates Integer Linear Programming with pre-trained transformers to perform end-to-end explainable multi-hop inference	Applications (eg, speech processing, computer vision, NLP)	anonymous|going_beyond_approximation_encoding_constraints_for_explainable_multihop_inference_via_differentiable_combinatorial_solvers	/pdf/e8fbe52028ffe4478399186b14b7eab005967095.pdf
s5NL0rQ31zJ	4414	Adaptive Smoothing Gradient Learning for Spiking Neural Networks	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|adaptive_smoothing_gradient_learning_for_spiking_neural_networks	/pdf/511dc809cbb2a53b9737537c4c49e271802bc649.pdf
eXkhH12DTD9	4415	Pseudo-label Training and Model Inertia in Neural Machine Translation	['knowledge distillation', 'semi-supervised learning', 'self-training', 'forward translation', 'stability', 'robustness', 'machine translation']	pseudo-label training improves model stablity to updates and input perturbations	Generative models	anonymous|pseudolabel_training_and_model_inertia_in_neural_machine_translation	/pdf/20e352e3951dc14e8e331d3e1588208747d730ca.pdf
WpGqKAEwMn	4417	Analyzing diffusion as serial reproduction	['diffusion models', 'cognitive science', 'serial reproduction', 'generative models']	We identify a correspondence between diffusion models and a cognitive paradigm known as serial reproduction and use that to explain key features of diffusion models.	Generative models	anonymous|analyzing_diffusion_as_serial_reproduction	/pdf/0f132035068fc2ae88a4203b51caafc5ba1f0b51.pdf
ykOpK9O5qYv	4418	Multi-Behavior Dynamic Contrastive Learning for Recommendation	['Multi-Behavior Recommendation', 'Dynamic Contrastive Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|multibehavior_dynamic_contrastive_learning_for_recommendation	/pdf/d071b3537a6f8a2d9fad89964da90d7141ab6744.pdf
r0JMLPgGXS_	4421	Autoregressive Generative Modeling with Noise Conditional Maximum Likelihood Estimation	['density estimation', 'autoregressive models', 'generative modeling', 'score-based models', 'diffusion models']	We propose a noise-robust modification for maximum likelihood estimation. Under this framework, we improve density estimation and significantly enhance the sample quality of images generated by autoregressive models.	Generative models	anonymous|autoregressive_generative_modeling_with_noise_conditional_maximum_likelihood_estimation	/pdf/c032bf2df8194f791d3c6e4c36ce61b88cf12009.pdf
LiXDW7CF94J	4423	How robust is unsupervised representation learning to distribution shift?	['distribution shift', 'OOD generalisation', 'spurious correlation', 'simplicity bias', 'SSL', 'unsupervised learning', 'auto-encoder']	Representations learned from self-supervised learning and auto-encoder based algorithms are surprisingly robust to distribution shift.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|how_robust_is_unsupervised_representation_learning_to_distribution_shift	/pdf/5e73f168dfa316fa62efa2e2f6c9f6e88f50f7d3.pdf
sC-PmTsiTB	4424	Probabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse	['Counterfactual explanations', 'algorithmic recourse', 'explainability']	We propose a novel framework to generate probabilistically robust algorithmic recourse	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|probabilistically_robust_recourse_navigating_the_tradeoffs_between_costs_and_robustness_in_algorithmic_recourse	/pdf/294cc882cb81aa4689f31ed0db95de60e7f3bd87.pdf
xveTeHVlF7j	4425	A Self-Attention Ansatz for Ab-initio Quantum Chemistry	['Machine learning for science', 'attention', 'Transformers', 'Monte Carlo', 'MCMC', 'self-generative learning', 'quantum physics', 'chemistry', 'machine learning for physics', 'machine learning for molecules', 'machine learning for chemistry']	We use a novel self-attention neural network to make quantum chemistry calculations from first principles much more accurate.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_selfattention_ansatz_for_abinitio_quantum_chemistry	/pdf/de4c5bdbddafa58acf619bb1d928f4aa22297e0e.pdf
VqrEwH4WwI-	4428	Learning a Domain-Agnostic Policy through Adversarial Representation Matching for Cross-Domain Policy Transfer	['imitation learning', 'domain transfer', 'zero-shot transfer']	We obtain a domain-invariant feature space by behavioral cloning and adversarial training using unpaired trajectories of proxy tasks, and use it for zero-shot cross-domain transfer.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_a_domainagnostic_policy_through_adversarial_representation_matching_for_crossdomain_policy_transfer	/pdf/79a99f17459913ac54c768eb5beeff531b5fb2ce.pdf
9OmCr1q54Z	4429	AE-FLOW: Autoencoders with Normalizing Flows  for  Medical Images Anomaly Detection 	['Anomaly Detection', 'Normalizing Flow', 'Auto-encoder.']	We propose a normalizing flow based autoencoder for medical anomaly detection and it outperformed the other approaches by a large margin.	Applications (eg, speech processing, computer vision, NLP)	anonymous|aeflow_autoencoders_with_normalizing_flows_for_medical_images_anomaly_detection	/pdf/06fb6bb99f79055af8602e2f81228eddc34bf1c9.pdf
Ch4e4wk7Ew	4431	Continuously Parameterized Mixture Models	['mixture models', 'normalizing flows', 'ordinary differential equations', 'clustering', 'interpretable learning']	We parameterize mixtures of factor analyzers by a neural ordinary differential equation and train with a smooth curriculum to learn an interpretable likelihood model superior to standard mixture results.	Generative models	anonymous|continuously_parameterized_mixture_models	/pdf/6cf1a75688e9f7cee2b02b57a2fd51e89eef109e.pdf
VBQZkYu22G	4432	SmilesFormer: Language Model for Molecular Design	['De novo drug design', 'Language model', 'Molecule Optimization']	We developed a transformer-based language model for SMILES strings, able to generate and efficiently optimize molecules for drug discovery.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|smilesformer_language_model_for_molecular_design	/pdf/c96ac2a50422693c817492c02ff0f00490334e30.pdf
PocqkbIelt	4433	CounterNet: End-to-End Training of Prediction Aware Counterfactual Explanations	['Counterfactual Explanation', 'Algorithmic Recourse', 'Explainable AI', 'Interpretability']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|counternet_endtoend_training_of_prediction_aware_counterfactual_explanations	/pdf/74867f5560ce656956db7a06d58c2e5eec72e081.pdf
OMwyBv1UBh	4434	Towards Federated Learning of Deep Graph Neural Networks	['federated learning', 'graph representation learning', 'deep graph neural networks']	We study the problem of graph representation learning under a federated setting and propose a novel framework for federated learning of deep graph neural networks via reconstructing neighborhood information of nodes.	General Machine Learning (ie none of the above)	anonymous|towards_federated_learning_of_deep_graph_neural_networks	/pdf/9e9386029b3a3aea3b4260265b3469359315492d.pdf
gwcQajoXNF	4435	Computing all Optimal Partial Transports	['Optimal Transport', 'Combinatorial Optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|computing_all_optimal_partial_transports	/pdf/fa9c67f50b27f58cd1e5c6963b55088c6b9c0f98.pdf
Lrxaf7IPVT	4436	On the Importance of Diversity in Data-free Model Stealing	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_importance_of_diversity_in_datafree_model_stealing	/pdf/65ec29628bbaba097178823d7e92dc9c7a827162.pdf
oXHHj0_NN9	4437	BiasPAD: A Bias-Progressive Auto-Debiasing Framework	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|biaspad_a_biasprogressive_autodebiasing_framework	/pdf/8c62ee2a2fcd44edc716217e6c259eb8f513ad44.pdf
hy0a5MMPUv	4438	In-context Reinforcement Learning with Algorithm Distillation	['Reinforcement Learning', 'Transformers', 'Learning to Learn', 'Large Language Models']	We present Algorithm Distillation, a method that outputs an in-context RL algorithm by treating learning to reinforcement learn as a sequential prediction problem.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|incontext_reinforcement_learning_with_algorithm_distillation	/pdf/d992dcdf1e33bb2740207db3fd6e472e5f11039b.pdf
DP_u25iQWg	4441	Enhanced Spatio-Temporal Image Encoding for Online Human Activity Recognition	['3D Skeleton Data', 'Spatio-temporal Image Encoding', 'Motion Energy', 'Online Action Recognition', 'Human Activity Recognition', 'Deep learning']	In this work, we propose to improve the spatio-temporal image encoding of 3D skeletons data, by studying the concept of motion energy which focuses mainly on the joints that are the most solicited for an action.	Applications (eg, speech processing, computer vision, NLP)	anonymous|enhanced_spatiotemporal_image_encoding_for_online_human_activity_recognition	/pdf/ae485a63736eae99187777cf298e96830093a88a.pdf
PzbYN5d76a	4442	Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention	['Unsupervised representation learning', 'Morphology induction', 'Deep learning']	We propose an unsupervised method to learn the abstract meaning-bearing units in a sequence of characters with Dynamic Capacity Slot Attention. 	Deep Learning and representational learning	anonymous|inducing_meaningful_units_from_character_sequences_with_dynamic_capacity_slot_attention	/pdf/bcaee1b1e5ac52b4d306dd83251e42117372b006.pdf
zufPou5foW	4444	RoCourseNet: Distributionally Robust Training of a Prediction Aware Recourse Model	['Counterfactual Explanation', 'Algorithmic Recourse', 'Adversarial ML', 'Robustness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|rocoursenet_distributionally_robust_training_of_a_prediction_aware_recourse_model	/pdf/c306ab4b5b0c09613eb02e025a4549502dda6f6c.pdf
CN223OXgyb5	4445	BALTO: efficient tensor program optimization with diversity-based active learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|balto_efficient_tensor_program_optimization_with_diversitybased_active_learning	/pdf/3a77ca21e780934355c2358b7f19fd407856b54f.pdf
NeDc-Ak-H_	4448	Learning What and Where - Unsupervised Disentangling Location and Identity Tracking	['object permanence', 'CATER', 'unsupervised learning', 'binding problem']	Loci: an unsupervised disentangled LOCation and Identity tracking system, which excels on the CATER and related object tracking challenges featuring emergent object permanence and stable entity disentanglement via fully unsupervised learning.	Unsupervised and Self-supervised learning	anonymous|learning_what_and_where_unsupervised_disentangling_location_and_identity_tracking	/pdf/65c7131e137f12134036b0ef0505f5f6d395d69f.pdf
7hYCGFacpz	4449	Renamer: A Transformer Architecture In-variant to Variable Renaming	[]		Deep Learning and representational learning	anonymous|renamer_a_transformer_architecture_invariant_to_variable_renaming	/pdf/13fe9b31e7a371ad67c669edf6c81cb796e96457.pdf
MZFDUB40NJ	4450	Uncertainty-aware off policy learning	['off-policy learning', 'uncertainty']	We consider the estimation uncertainty of logging policy, and proposed a new estimator for improved off-policy learning by controlling the effect of inaccurate estimation of logging policy.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|uncertaintyaware_off_policy_learning	/pdf/9eb9a9450a8e4722b0b03d95b5c0b46f3102879d.pdf
RKMbC8Tslx	4451	A GENERAL SCENARIO-AGNOSTIC REINFORCEMENT LEARNING FOR TRAFFIC SIGNAL CONTROL	['reinforcement learning', 'model generalizability', 'traffic signal control', 'smart mobility']		Applications (eg, speech processing, computer vision, NLP)	anonymous|a_general_scenarioagnostic_reinforcement_learning_for_traffic_signal_control	/pdf/bc5b8ab3f50fa2a8deb2a4f4b95a4d6d302d747d.pdf
LemVOgJ4yP	4452	Learning to Cooperate and Communicate Over Imperfect Channels	['multi-agent systems', 'deep reinforcement learning', 'emergent communication', 'imperfect communication channels']	We investigate communication in multi-agent reinforcement learning and propose an adaptive message size selection that enables agents to use an imperfect communication channel more efficiently.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_to_cooperate_and_communicate_over_imperfect_channels	/pdf/9c87def43eb30ece1b203d3f5b482016008eaebf.pdf
HWt4BBZjVW	4455	On the Trade-Off between Actionable Explanations and the Right to be Forgotten	['Counterfactual Explanations', 'Algorihtmic Recourse', 'Explainability', 'Interpretability', 'Transparency']	We analyze the tradeoff between actionable explanations and the right to be forgotten, and provide algorithms to find a critical subset of training data points, which, when removed would lead to a maximum invalidation of recourses.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_tradeoff_between_actionable_explanations_and_the_right_to_be_forgotten	/pdf/935ba6514244a91d6d30ccdfc8d73127e4182979.pdf
i8L9qoeZOS	4456	A Theory of Dynamic Benchmarks	['Dynamic Benchmarks', 'Adversarial Data Collection']	We propose a formal model of dynamic benchmarks illuminating their benefits and limitations.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_theory_of_dynamic_benchmarks	/pdf/6b5a5570614ed797c2303cfd835d0bb02246ae1d.pdf
h_Ma6BSi9Q	4457	Marginal Probability Explanation: A Saliency Map with Closed-loop Validation	['MPE', 'saliency map', 'closed-loop validation', 'typical sample']	We propose a saliency map using marginal probability for each input dimension whose meaningfulness can be closed-loop validated.	Deep Learning and representational learning	anonymous|marginal_probability_explanation_a_saliency_map_with_closedloop_validation	/pdf/359ea38b4c3e282866aacd59d15b7572d9fe41e8.pdf
QL85H5Mkip	4458	Uncovering Directions of Instability via Quadratic Approximation of Deep Neural Loss in Reinforcement Learning	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|uncovering_directions_of_instability_via_quadratic_approximation_of_deep_neural_loss_in_reinforcement_learning	/pdf/1a2d9d065100c176b6b4d8afa34a5b09b8755901.pdf
xkSlKCYyV_	4459	Memory-Efficient Reinforcement Learning with Priority based on Surprise and On-policyness	['replay buffer', 'reinforcement learning', 'memory efficiency']	We propose a method to prune experiences in the replay buffer using a metric based on surprise and on-policyness of the experience and use it to save memory consumption in off-policy reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|memoryefficient_reinforcement_learning_with_priority_based_on_surprise_and_onpolicyness	/pdf/41480ab40f475f45c9dc9537b3e4566f323994da.pdf
ytZIYmztET	4460	EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data	['Non-convex optimization', 'federated learning', 'heterogeneous data', 'gradient clipping', 'relaxed smoothness']	We introduce EPISODE, an algorithm for federated learning with heterogeneous data under the relaxed smoothness setting for training deep neural networks, and provide state-of-the-art computational and communication complexity guarantees.	Optimization (eg, convex and non-convex optimization)	anonymous|episode_episodic_gradient_clipping_with_periodic_resampled_corrections_for_federated_learning_with_heterogeneous_data	/pdf/f5700ac7b65df9be17e46d06ee3d5e1165c02863.pdf
MND1kmmNy0O	4461	Solving Math Word Problems with Process-based and Outcome-based Feedback	['language models', 'reasoning', 'reward models']	Both process- and outcome-based feedback with all the tricks achieve similar final-answer error rates and SOTA results, but generating accurate reasoning steps requires either process-based supervision, or a reward model that emulates it.	Deep Learning and representational learning	anonymous|solving_math_word_problems_with_processbased_and_outcomebased_feedback	/pdf/39076185a88bf528272173644c6d055488fea121.pdf
qqcIHdvjyJr	4462	Human-AI Coordination via Human-Regularized Search and Learning	['human-ai collaboration', 'multi-agent', 'search', 'deep reinforcement learning']	a new method for human-AI collaboration based on human regularized search, imitation learning and RL, tested with large scale human experiments.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|humanai_coordination_via_humanregularized_search_and_learning	/pdf/16b1d73300d4ca21645cbc243d648ff0da39a669.pdf
HPdxC1THU8T	4463	Revisiting adapters with adversarial training	['adapters', 'adversarial', 'robustness', 'soup']		Deep Learning and representational learning	anonymous|revisiting_adapters_with_adversarial_training	/pdf/8cd1ba480389c5707ac9be5dc7eb92ade2cab58c.pdf
wCFB37bzud4	4464	Bidirectional Language Models Are Also Few-shot Learners	['prompting', 'prompt-based learning', 'mt5', 't5', 'machine translation', 'llm', 'large language models']	We present Sequential Autoregressive Prompting, a technique that enables prompting of bidirectional models demonstrating prompt-based learning is an emergent property of a broader class of language models, rather than of only unidirectional models.	Unsupervised and Self-supervised learning	anonymous|bidirectional_language_models_are_also_fewshot_learners	/pdf/c7528f481a67c257b8de94d2fa1da946f5fd672a.pdf
jgUqPzuMiJQ	4465	Representation Power of Graph Convolutions : Neural Tangent Kernel Analysis	['Graph Neural Networks', 'Neural Tangent Kernels', 'Node classification', 'Stochastic Block Model']	Graph NTK shows that row normalized graph convolution preserves the underlying class structure, and skip connections retain the class structure at infinite depth.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|representation_power_of_graph_convolutions_neural_tangent_kernel_analysis	/pdf/8144bd6b3a20131da2f141ca7ba7128ba3a6357e.pdf
3dnrKbeVatv	4466	Energy-Based Test Sample Adaptation for Domain Generalization	['domain generalization', 'energy-based model', 'test-time sample adaptation', 'variational inference']	We propose a discriminative energy-based model to adapt target samples to the source domain distributions for domain generalization.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|energybased_test_sample_adaptation_for_domain_generalization	/pdf/89ba9bf6dced3f25d64e4b637aca6719cd96a2f9.pdf
aMXD8gqsIiC	4467	A Higher Precision Algorithm for Computing the $1$-Wasserstein Distance	['Wasserstein Distance', 'Earth Movers Distance', 'Bipartite Matching']		Optimization (eg, convex and non-convex optimization)	anonymous|a_higher_precision_algorithm_for_computing_the_1wasserstein_distance	/pdf/4d8263d7a17e89f761a534df6015ed544f904c80.pdf
HjOo2k8lhFl	4468	Efficient Learning of Rationalizable Equilibria in General-Sum Games	['Game Theory', 'Online Learning', 'Rationalizability']	We develop provably efficient algorithms for finding approximate CE and CCE that are also rationalizable.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|efficient_learning_of_rationalizable_equilibria_in_generalsum_games	/pdf/77238f4a6f084e87e69017d964d28659af8f27b1.pdf
gy1YvA9mh6q	4469	HiT-DVAE: Human Motion Generation via Hierarchical Transformer Dynamical VAE	['generative models', 'human motion generation']		Generative models	anonymous|hitdvae_human_motion_generation_via_hierarchical_transformer_dynamical_vae	/pdf/f1d2702e953e8659c56e1adb260e9ac6d563506c.pdf
kUf4BcWXGJr	4471	HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization	['Uniformed Large-Scale Retrieval', 'Multi-Task hyper-prompted training', 'Retrieval Generalization']	A multitask hyper-prompted training mechanism that enables a neural retriever to dynamically process different types of queries with different hyper-prompts and transfer learned knowledge across different domains and tasks. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|hyper_multitask_hyperprompted_training_enables_largescale_retrieval_generalization	/pdf/15ae1e95120137cd8bdaf9ee4c84f60cf0e74570.pdf
qco4ekz2Epm	4473	Online Boundary-Free Continual Learning by Scheduled Data Prior	['Continual learning', 'data prior', 'boundary-free']	We propose a new continual learning setup without explicit task boundary and a method to address it.	Deep Learning and representational learning	anonymous|online_boundaryfree_continual_learning_by_scheduled_data_prior	/pdf/cac6141c32af8c4450747d9a382ea7dea87aa1d2.pdf
QTXKTXJKIh	4474	Achieve Near-Optimal Individual Regret & Low Communications in Multi-Agent Bandits	['Multi-agent multi-armed bandits', 'individual regret', 'communication']	A near-optimal algorithm for both individual and group regrets and only requiring O(\log (\log T)) communication times	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|achieve_nearoptimal_individual_regret_low_communications_in_multiagent_bandits	/pdf/36ec718baeabca5c7740e0f5f5bb7e95b68581d1.pdf
-H7FPruqEX	4476	CASA: Bridging the Gap between Policy Improvement and Policy Evaluation with Conflict Averse Policy Iteration	['reinforcement learning', 'policy iteration']	This paper proposes a method to eliminate gradient conflicts between policy improvement and policy evaluation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|casa_bridging_the_gap_between_policy_improvement_and_policy_evaluation_with_conflict_averse_policy_iteration	/pdf/c29ac418867e076667859c50b95830d5727d2379.pdf
74A-FDAyiL	4477	Sublinear Algorithms for Kernel Matrices via Kernel Density Estimation	['kernel density estimation', 'sublinear time algorithms']	We give a framework for using recently developed tools for kernel density estimation to solve downstream kernel problems in sub-quadratic time.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|sublinear_algorithms_for_kernel_matrices_via_kernel_density_estimation	/pdf/89e2a4f42fb34aebb84704e375e7b4553bfed2cd.pdf
AHvFDPi-FA	4478	Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning	['offline RL', 'diffusion models', 'behavior cloning', 'policy regularization', 'Q-learning']	Diffusion models serve as expressive policies to boost offline RL performance. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|diffusion_policies_as_an_expressive_policy_class_for_offline_reinforcement_learning	/pdf/76ea7b75617fe1705c94a262360050854dedf0a4.pdf
-qjmJkacGv	4480	Tackling Imbalanced Class in Federated Learning via Class Distribution Estimation	['Federated Learning', 'class imbalance', 'class distribution estimation']		General Machine Learning (ie none of the above)	anonymous|tackling_imbalanced_class_in_federated_learning_via_class_distribution_estimation	/pdf/bc92f5ab40152678ac3abe14e6e6293f97b76071.pdf
rM6CpkZLPB	4481	Personalized federated composite learning with forward-backward envelopes	['Federated composite optimization', 'personalization', 'forward-backward envelopes']		Optimization (eg, convex and non-convex optimization)	anonymous|personalized_federated_composite_learning_with_forwardbackward_envelopes	/pdf/86569a230beb28b21dae73d1bde832eaa55acfda.pdf
QFm186CbBp	4482	Attention Based Models for Cell Type Classification on Single-Cell RNA-Seq Data	['Single-cell RNA-seq data cell type classification', 'attention mechanism', 'learning representations']	We propose two novel models through representation and attention learning for cell type classification task on single-cell RNA-seq data.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|attention_based_models_for_cell_type_classification_on_singlecell_rnaseq_data	/pdf/8cecb37d69bdea542e9731d65508588964621dd2.pdf
hp_RwhKDJ5	4484	Learning to Induce Causal Structure 	['causality', 'deep learning']		Deep Learning and representational learning	anonymous|learning_to_induce_causal_structure	/pdf/488f65093d7108fad515f5f57fef129264119cc9.pdf
zNVpWmE6JM	4485	Learning Stackelberg Equilibria and Applications to Economic Design Games	['Multi-agent Systems', 'Reinforcement Learning', 'Economic Design']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_stackelberg_equilibria_and_applications_to_economic_design_games	/pdf/988910c78ab1507e94f710f0c128a5f042834ea9.pdf
LKXAKOxu-T	4486	Multi-stationary point losses for robust model	['Robustness', 'MS loss', 'Cross-entropy loss', 'Multi-stationary point losses', 'Adversarial attack']	We propose a familiy of Multi-stationary point losses, which improved robustness. 	Deep Learning and representational learning	anonymous|multistationary_point_losses_for_robust_model	/pdf/793593250a8cb94612fa226ee504fe13be70e571.pdf
rYgeBuEHlh	4487	Adversarial Cheap Talk	['Meta-Learning', 'Reinforcement Learning', 'Meta-Reinforcement Learning']	We can cause an RL agent to fail, succeed, or be manipulatable by deterministically perturbing irrelevant features in its observation during training.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adversarial_cheap_talk	/pdf/8b85ec35207f1e0e543d40a5762ae43520b4a622.pdf
QHevLM-OnA	4488	Generalized Belief Transport	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|generalized_belief_transport	/pdf/73bedf9cc2887d4a118987508bee07cc0e22ff1c.pdf
Ey2ePmtABj	4489	No-Regret Learning in Strongly Monotone Games Converges to a Nash Equilibrium	['Online game', 'no-regret learning', 'Nash equilibrium convergence', 'monotone game']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|noregret_learning_in_strongly_monotone_games_converges_to_a_nash_equilibrium	/pdf/7ec1eaa6e3ee3f8856d3fa53758b615653ba804a.pdf
iOag71mvHI	4491	Variational Pseudo Labels for Meta Test-time Adaptation	['Test-time adaptation', 'probabilistic framework', 'variational pseudo label', 'meta learning']	We address test-time adaptation in a probabilistic formulation by introducing variational pseudo labels with meta adaptation. 	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|variational_pseudo_labels_for_meta_testtime_adaptation	/pdf/8641a965ef00a627e464bb0c64b90257b3919a26.pdf
_-eJYVfSYH	4492	Would decentralization hurt generalization?	['decentralized SGD', 'flat minima', 'generalization', 'implicit regularization', 'large batch training']	D-SGD introduces an implicit regularization that penalizes the learned minima’s sharpness.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|would_decentralization_hurt_generalization	/pdf/b2f8bcbb814c852b84fe224be89c9f0a16cd7dfe.pdf
JKuBOuzntQ	4493	Removing Backdoors in Pre-trained Models by Regularized Continual Pre-training	[]		Deep Learning and representational learning	anonymous|removing_backdoors_in_pretrained_models_by_regularized_continual_pretraining	/pdf/2261085e2927f52a0af72e82656b3acbf4fae8a5.pdf
9kBCMNb5mc	4494	Optimistic Exploration with Learned Features Provably Solves Markov Decision Processes with Neural Dynamics	['Reinforcement Learning', 'Neural Network', 'Representation Learning.']	We identify a class of Markov decision processes with neural network parameterization and propose an oracle-efficient algorithm whose sample complexity does not depend on the Eluder dimension of the NN class.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|optimistic_exploration_with_learned_features_provably_solves_markov_decision_processes_with_neural_dynamics	/pdf/c76ed3ebf0db70bf98061ce70e16de941c283797.pdf
Gzmyu-Baq0	4495	Self-Guided Diffusion Models	['diffusion model', 'self-supervised learning', 'unsupervised learning']		Generative models	anonymous|selfguided_diffusion_models	/pdf/8e4750e145cbc0597eea47b24df7502e08f3bdf1.pdf
hT1S68yza7	4496	Brain2GAN; Reconstructing perceived faces from the primate brain via StyleGAN3	['Face reconstruction', 'generative adversarial networks', 'neural decoding']	Reconstruction of perceived faces by neural decoding of cortical responses from the primate brain	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|brain2gan_reconstructing_perceived_faces_from_the_primate_brain_via_stylegan3	/pdf/7007c11aa13554782fa08f50aab8cca7b95f6408.pdf
JDuEddUsSb	4497	Efficient Discovery of Dynamical Laws in Symbolic Form	['Symbolic', 'ODE', 'Transformer']	Given a time series that is governed by an ordinary differential equation (ODE), our model infers the mathematical expression of the ODE.	Deep Learning and representational learning	anonymous|efficient_discovery_of_dynamical_laws_in_symbolic_form	/pdf/56a406d6754e62091574887e1c797e9cdebcfb1e.pdf
CtS2Rs_aYk	4498	Stay Moral and Explore: Learn to Behave Morally in Text-based Games	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|stay_moral_and_explore_learn_to_behave_morally_in_textbased_games	/pdf/647f2514d9c14b32d80c49528fb82391d41c9dd7.pdf
fFDM6aIZhN	4499	Weighted Regularization for Efficient Neural Network Compression	['Weighted Regularization', 'Neural Network Compression']	A weighted regularization method for network compression is proposed and theoretical analysis is given.	Deep Learning and representational learning	anonymous|weighted_regularization_for_efficient_neural_network_compression	/pdf/23eaa7f8e05ddb90053dc7f4e74bd19133107fd4.pdf
cIbjyd2Vcy	4500	Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism	[]		Unsupervised and Self-supervised learning	anonymous|towards_a_unified_theoretical_understanding_of_noncontrastive_learning_via_rank_differential_mechanism	/pdf/fa67359102caf61ad0768be4db5377d7b752dc64.pdf
b9tUk-f_aG	4501	Bridging the Gap to Real-World Object-Centric Learning	['object discovery', 'object-centric learning', 'vision transformer', 'self-supervised learning', 'unsupervised learning']	Our method uses slot attention with self-supervised DINO features to discover objects on real-world data.	Deep Learning and representational learning	anonymous|bridging_the_gap_to_realworld_objectcentric_learning	/pdf/5c3a7c5a21a233287da71d541783915c1bce1910.pdf
TqCHPi7xlV	4502	Language Modeling Using Tensor Trains	['Tensor network', 'RNNs', 'Language modeling']		Deep Learning and representational learning	anonymous|language_modeling_using_tensor_trains	/pdf/8b72e905fb10af4a6c13fc8d7843ede0d8435318.pdf
YJ7o2wetJ2	4503	Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training	['Pre-Training for Control', 'Offline RL', 'Goal-Conditioned RL', 'Deep RL', 'Robot Learning', 'Self-Supervised Learning', 'Visuomotor Control']	A method for pre-training a goal-conditioned value function on human videos that can be effectively used as zero-shot visual reward and representation for unseen robotics tasks in simulation and real-world.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_universal_visual_reward_and_representation_via_valueimplicit_pretraining	/pdf/18e5e5d846657100c43485aab6201e9bc229463e.pdf
hFCUPkSSRE	4504	Internet-augmented language models through few-shot prompting for open-domain question answering	['language models', 'few-shot prompting', 'retrieval-augmented', 'question answering']	We use few-shot prompting to condition pre-trained LMs on Google retrieved evidence for improving open-domain question answering 	Applications (eg, speech processing, computer vision, NLP)	anonymous|internetaugmented_language_models_through_fewshot_prompting_for_opendomain_question_answering	/pdf/99a02b1a5acd9c25f276e4a112e1a06bea22d460.pdf
eYm_Q5KLQr	4505	Automatic Curriculum Generation for Reinforcement Learning in Zero-Sum Games	['multi-agent reinforcement learning', 'curriculum learning', 'zero-sum games']	In this work, we present the first theoretical framework of automatic curriculum learning in the setting of zero-sum game and derive a surprisingly simple indicator of training progress, i.e., the policy variance	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|automatic_curriculum_generation_for_reinforcement_learning_in_zerosum_games	/pdf/ae2b05c02df4479aaaea763e30eb7649516527ad.pdf
yUY15QBERj	4506	Temporal Dynamics Aware Adversarial Attacks On Discrete-Time Graph Models	['Graph Neural Networks', 'Dynamic Graphs', 'Adversarial Attacks', 'Evolution-preserving']	Introduces a novel constraint to attack dynamic graph models while preserving the original graph evolution and presents an effective approach to find such attacks	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|temporal_dynamics_aware_adversarial_attacks_on_discretetime_graph_models	/pdf/91096a820b8935823afafcfbffc36e8490309870.pdf
QubsmJT_A0	4507	Neuromechanical Autoencoders: Learning to Couple Elastic and Neural Network Nonlinearity	['morphological computation', 'mechanical metamaterials', 'computational mechanics', 'mechanical co-design', 'automatic differentiation', 'differentiable simulation']	We introduce Neuromechanical Autoencoders, a framework for co-design of neural network and mechanical metamaterials for performing morphological computation.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neuromechanical_autoencoders_learning_to_couple_elastic_and_neural_network_nonlinearity	/pdf/032c775880081821297db5fd9e0f0b15b5a570fb.pdf
Tjp51oUrk3	4508	AN OPERATOR NORM BASED PASSIVE FILTER PRUNING METHOD FOR EFFICIENT CNNS	['Convolutional neural network', 'filter pruning', 'VGGish', 'DCASE', 'MNIST']	A passive filter pruning framework is proposed by incorporating significance of filters in producing output to eliminate unimportant CNN filters for reducing computational complexity and paramters in CNNs.	Deep Learning and representational learning	anonymous|an_operator_norm_based_passive_filter_pruning_method_for_efficient_cnns	/pdf/275818e78b958395c44e91a0668eda1012a3902c.pdf
JFtHy-Ve7e	4509	Batch Normalization Explained	['batch normalization', 'continuous piecewise linear networks', 'unsupervised learning']	Batch normalization adapts the geometry of the deep network to the data manifold and serves as a smart initialization and a margin maximization method	Deep Learning and representational learning	anonymous|batch_normalization_explained	/pdf/0890bb9493fee30c7d731072a58156476e54b43a.pdf
RN4iVt9ndGa	4510	Active Learning based Structural Inference	['Structural Inference', 'Active Learning', 'Mutual Information', 'Deep Learning']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|active_learning_based_structural_inference	/pdf/be39f7e3e38843c567647bc5193db07424068622.pdf
7i6OZa7oij	4512	Strong inductive biases provably prevent harmless interpolation	['high-dimensional statistics', 'non-parametric regression', 'deep learning theory', 'generalization bounds', 'benign overfitting']	We show that the strength of a model’s inductive bias determines whether interpolation of noisy data is harmless or harmful.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|strong_inductive_biases_provably_prevent_harmless_interpolation	/pdf/0b3c11cc01ba8cda1371f5f13563502005e1029a.pdf
8uu6JStuYm	4513	Self-supervised learning with rotation-invariant kernels	['Self-supervised learning', 'maximum mean discrepancy', 'rotation-invariant kernel', 'hypersphere']	A regularization loss based on kernel mean embeddings with rotation-invariant kernels on the hypersphere for self-supervised learning of image representations	Unsupervised and Self-supervised learning	anonymous|selfsupervised_learning_with_rotationinvariant_kernels	/pdf/636342c10a0d0e97c4d80144bf6f29d46f60b8da.pdf
253DOGs6EF	4514	Mesh-free Eulerian Physics-Informed Neural Networks	['Physics-informed Neural Network', 'PINN', 'SIREN', 'fluid dynamics', 'implicit neural representations', 'PDEs']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|meshfree_eulerian_physicsinformed_neural_networks	/pdf/2761f71c27720ca53b4fccc5a60cbd2fafe94247.pdf
g-kR7WU4Iw-	4515	 Continual Zero-shot Learning through Semantically Guided Generative Random Walks	['Continual Learning', 'Zero-shot Learning', 'Random Walk']		Deep Learning and representational learning	anonymous|continual_zeroshot_learning_through_semantically_guided_generative_random_walks	/pdf/560de6e2f65d840b6a9e93e3457c8a01e6a73975.pdf
oze0clVGPeX	4516	Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping	['differential privacy', 'per-layer clipping', 'efficiency', 'DP-SGD']	Explore the limit of the efficiency of DP-SGD with group-wise clipping	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|exploring_the_limits_of_differentially_private_deep_learning_with_groupwise_clipping	/pdf/5de562f3a17ba0e48fc8ce998590eb16019a3667.pdf
T-camDtiuUg	4517	Trimsformer: Trimming Transformer via Searching for Low-Rank Structure	['Vision Transformer', 'Model Compression', 'Low-Rank Approximation', 'Neural Architecture Search']	Constructing the efficient low-rank vision transformer structure based on neural architecture search.	Applications (eg, speech processing, computer vision, NLP)	anonymous|trimsformer_trimming_transformer_via_searching_for_lowrank_structure	/pdf/f3a8d61565ed95c2a4d60b58dc37376db5d753e6.pdf
stgewiZP0OH	4518	Latent Hierarchical Imitation Learning for Stochastic Environments	['hierarchical imitation learning', 'learning from demonstrations', 'autonomous driving', 'causal confusion']	We formalize and alleviate challenges in imitation learning when hierachical policies are used to prevent mode collapse. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|latent_hierarchical_imitation_learning_for_stochastic_environments	/pdf/05b4f2c4d657544669e94271774f1039a505e3b4.pdf
uTshHIKOtan	4519	MC-SSL: Towards Multi-Concept Self-Supervised Learning	['Self-supervised Learning', 'Group Masked Model Learning', 'Masked Autoencoders', 'Vision Transformers', 'Knowledge Distillation']		Unsupervised and Self-supervised learning	anonymous|mcssl_towards_multiconcept_selfsupervised_learning	/pdf/17d5c96173166ff083a1403f15a5efe17ec64d86.pdf
aG_B1SZ92t	4521	Revealing Dominant Eigendirections via Spectral Non-Robustness Analysis in the Deep Reinforcement Learning Policy Manifold	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revealing_dominant_eigendirections_via_spectral_nonrobustness_analysis_in_the_deep_reinforcement_learning_policy_manifold	/pdf/b5ee4dbd14e55fc5d64f82451c7c273712059c4a.pdf
22h1XSEiN0	4522	Deep Probabilistic Time Series Forecasting over Long Horizons	['time series', 'neural networks', 'probabilistic forecasting']	We demonstrate that with simple adaptations high performing deterministic models can be made into state of the art probabilistic forecasters.	Deep Learning and representational learning	anonymous|deep_probabilistic_time_series_forecasting_over_long_horizons	/pdf/d1bf346ee83619922c22f81718a779c355ae0f3f.pdf
JhsVJoK13u	4523	Active Learning at the ImageNet Scale	['active learning', 'large-scale active learning']	We identify sampling-imbalance as a major failure mode in large-scale active learning, and we propose Balanced Selection, a simple, scalable AL algorithm to remedy it.	Deep Learning and representational learning	anonymous|active_learning_at_the_imagenet_scale	/pdf/612d97e13e467e336eea3e0dd4eb3880c1964451.pdf
16BDzjpOwe	4524	Learning Debiased Representations via Conditional Attribute Interpolation	['debiased representation', 'conditional attribute interpolation', 'image classification']	This paper proposes a novel method to learn debiased representation via conditional attribute interpolation.	Deep Learning and representational learning	anonymous|learning_debiased_representations_via_conditional_attribute_interpolation	/pdf/7cb4950b313fc585e46c708c3e0975db62410444.pdf
WOquZTLCBO1	4525	Provably Efficient Neural Offline Reinforcement Learning via Perturbed Rewards	['Offline Reinforcement Learning', 'Neural Networks']	A provably and computationally efficient algorithm for offline RL with deep neural networks 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|provably_efficient_neural_offline_reinforcement_learning_via_perturbed_rewards	/pdf/d2eef236d99de22def9b495541d544f4b0963154.pdf
t00nS5YLjSc	4526	Distilling Pre-trained Knowledge in Chemical Reactions for Molecular Property Prediction	['Molecular property prediction', 'Chemical reactions', 'Pre-training for molecular representations', 'Knowledge distillation', 'AI for drug discovery']	We propose a novel method to incorporate chemical domain knowledge for molecular property prediction.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|distilling_pretrained_knowledge_in_chemical_reactions_for_molecular_property_prediction	/pdf/a8773f178bdce3c60833edda5648a524f1fef0de.pdf
sPgP6aISLTD	4527	Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning	['Reinforcement Learning', 'Representation Learning', 'Disentanglement']	We introduce Temporal Disentanglement (TED) to learn disentangled representations for Reinforcement Learning, improving generalisation to unseen environment variables.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|temporal_disentanglement_of_representations_for_improved_generalisation_in_reinforcement_learning	/pdf/1ec44bc44bc2c9121e9414eb5b4b68c460ce4a3a.pdf
7Cb7Faxa1OB	4528	Understanding The Robustness of Self-supervised Learning Through Topic Modeling	['deep learning theory', 'self-supervised learning']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|understanding_the_robustness_of_selfsupervised_learning_through_topic_modeling	/pdf/f8c442968e4f7e1a1ed79cace0e426963564c7c4.pdf
vDY5Y8HMNxO	4529	GMML is All you Need	['Self-supervised Learning', 'Group Masked Model Learning', 'Masked Autoencoders', 'Vision Transformers.']		Unsupervised and Self-supervised learning	anonymous|gmml_is_all_you_need	/pdf/379e5b604e414a7c1631c5a2c50d091e6ecc7dd2.pdf
zVrw4OH1Lch	4530	Obtaining More Generalizable Fair Classifiers on Imbalanced Datasets	['Fairness', 'Generalization']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|obtaining_more_generalizable_fair_classifiers_on_imbalanced_datasets	/pdf/2ef3812c6a2cb33b0e3c178411fec1d226e18016.pdf
EO-NrUPaFLz	4531	On the Forward Invariance of Neural ODEs	['Neural ODE', 'Forward Invariance', 'Specification Guarantees']	This paper proposes to achieve specification guarantees in the output space of neural ODEs with invariance set propagation.	Deep Learning and representational learning	anonymous|on_the_forward_invariance_of_neural_odes	/pdf/7d0a9055927a1290944ad35b2f480668eeafbfd3.pdf
DyFvlCAj8j_	4533	Highly Parallel Deep Ensemble Learning	[]		Deep Learning and representational learning	anonymous|highly_parallel_deep_ensemble_learning	/pdf/92917b9bc3ef80e63d26fd3f329d7198b42d911c.pdf
U09miyCFe6T	4534	Conceptual Behavior and Human-Likeness in Vision-and-Language Models	['mutlimodal deep learning', 'vision-and-language', 'semantic knowledge', 'conceptual knowledge', 'representational analysis', 'human-likeness']		Deep Learning and representational learning	anonymous|conceptual_behavior_and_humanlikeness_in_visionandlanguage_models	/pdf/d613b704aa3a9f28e038469b22baf205f7eee06b.pdf
UpyXmNMdQEn	4535	Quantization-aware Policy Distillation (QPD)	['DRL', 'Quantization', 'Distillation', 'Model Compression', 'Low-Power', 'Actor-Critic']	We introduce a method based on quantization and policy distillation that can effectively compress a network down to 0.5% of its original size, without any loss in performance.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|quantizationaware_policy_distillation_qpd	/pdf/199ea3f810e66576a33be2b53be4983de0b3d18e.pdf
-yqNb_CxRr	4537	REST: REtrieve & Self-Train for generative action recognition	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|rest_retrieve_selftrain_for_generative_action_recognition	/pdf/56fab1df3fc95846af4abe5f9ac38bc07ae48f57.pdf
pNnXjO3q82	4538	Islands of Confidence: Robust Neural Network Classification with Uncertainty Quantification	['uncertainty quantification', 'neural collapse', 'deep learning']	We address the overconfidence of neural networks and related issues with a new centroidal-based confidence measure.	Deep Learning and representational learning	anonymous|islands_of_confidence_robust_neural_network_classification_with_uncertainty_quantification	/pdf/69b865656bbbee673b043f8a792581cfb6808dc0.pdf
mumZwT6OrEV	4541	ULF: UNSUPERVISED LABELING FUNCTION CORRECTION USING CROSS-VALIDATION FOR WEAK SUPERVISION	['nlp', 'weak supervision', 'text classification', 'sentiment analysis']	We introduce a new algorithm ULF for denoising weakly annotated data based on the principle of k-fold cross-validation. ULF uses models trained on all but some LFs to detect and correct biases specific to the held-out LFs.	Applications (eg, speech processing, computer vision, NLP)	anonymous|ulf_unsupervised_labeling_function_correction_using_crossvalidation_for_weak_supervision	/pdf/8ac9c8a6ec5b89f24d3fb54ef648b8daae415683.pdf
-itAMjwvDJC	4542	Efficient neural representation in the cognitive neuroscience domain: Manifold Capacity in One-vs-rest Recognition Limit	['computational neuroscience', 'statistical physics of learning', 'representation geometry', 'perceptual manifolds', 'object recognition']	Our Sparse Replica Manifold Analysis enables a separability and geometric analysis of neural data by extending the scope of the theory to a realistic number of neurons and tasks more relevant to cognitive neuroscience.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|efficient_neural_representation_in_the_cognitive_neuroscience_domain_manifold_capacity_in_onevsrest_recognition_limit	/pdf/06d935a63c552f8ae6f6cb171c509727eab6ca64.pdf
De4FYqjFueZ	4543	Transformers Learn Shortcuts to Automata	['Transformer', 'self-attention', 'group theory', 'semigroup theory', 'algebraic automata theory', 'shortcut learning', 'theory of deep learning']	Shallow, non-recurrent Transformers can simulate the recurrent dynamics of finite-state automata, via counterintuitive shortcuts.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|transformers_learn_shortcuts_to_automata	/pdf/ac0599706365afab4529dc8d18354b6e82a96443.pdf
NE5P2sEK4Z5	4545	Closed-loop Transcription via Convolutional Sparse Coding	['Convolutional Sparse Coding', 'Inverse Models', 'Rate Reduction']	This paper combines the recent closed-loop transcription framework with convolutional sparse coding layers and demonstrates superior generative autoencoding performance.	General Machine Learning (ie none of the above)	anonymous|closedloop_transcription_via_convolutional_sparse_coding	/pdf/b8bceb3b2d4a875a3e766c3f7de5c1cadd9a1f8d.pdf
fe2S7736sNS	4546	$k$NN Prompting: Learning Beyond the Context with Nearest Neighbor Inference	['Large Language Models', 'In-Context Learning', 'K Nearest Neighbors']	We enable data scaling under the gradient-free paradigm of large language models using kNN inference, and bring substantial improvements over standard In-Context Learning.	Deep Learning and representational learning	anonymous|knn_prompting_learning_beyond_the_context_with_nearest_neighbor_inference	/pdf/0eacf61441d283a6f6e58f135fb0b42a88fd70f2.pdf
QutyHwpIKVw	4547	MultiQuan RDP: Rate-Distortion-Perception Coding via Offset Quantizers	['information theory', 'quantization', 'rate-distortion-perception', 'compression']	We propose the MultiQuan quantizers interpolating between single quantizer and dithered quantization for rate-distortion-perception coding.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|multiquan_rdp_ratedistortionperception_coding_via_offset_quantizers	/pdf/6067428c4773001d75cd41c44ac2c00905212bbb.pdf
4Ox_yJWZP56	4549	Exploring Methods for Parsing Movie Scripts - Feature Extraction for Further Social Injustice Analysis	['Movie Parsing', 'Script Parsing', 'Parsers', 'IMSDB', 'Deep Neural Networks', 'Discussion Tree', 'BERT Parser']	An exploration of methods to parse movie scripts 	Applications (eg, speech processing, computer vision, NLP)	anonymous|exploring_methods_for_parsing_movie_scripts_feature_extraction_for_further_social_injustice_analysis	/pdf/2047eb7964710e90cdef05af2aa859e54ded6325.pdf
OAsXFPBfTBh	4550	Autoregressive Conditional Neural Processes	[]		General Machine Learning (ie none of the above)	anonymous|autoregressive_conditional_neural_processes	/pdf/ed070c0a03b572320f7281159008c10085482b2f.pdf
C9uEwyfklBE	4551	Pareto Manifold Learning: Tackling multiple tasks via ensembles of single-task models	['Multi-Task Learning', 'multitask learning', 'mode connectivity', 'loss landscape', 'pareto optimal', 'pareto frontier']		Deep Learning and representational learning	anonymous|pareto_manifold_learning_tackling_multiple_tasks_via_ensembles_of_singletask_models	/pdf/d9cc43f9a2d8490c97d5c5cb84e4ca8b6b00b369.pdf
ZBUthI6wK9h	4552	Robust Scheduling with GFlowNets	['Scheduling', 'GFlowNets', 'Combinatorial Optimization']	We use GFlowNets for robust scheduling.	Applications (eg, speech processing, computer vision, NLP)	anonymous|robust_scheduling_with_gflownets	/pdf/0ffa97d4e77ebfed18235739a17ccb523d6037a1.pdf
rfvuuHmqHOQ	4555	Graph Contrastive Learning with Model Perturbation	['Graph Contrastive Learning', 'Model Perturbation', 'Graph Augmentation']		Unsupervised and Self-supervised learning	anonymous|graph_contrastive_learning_with_model_perturbation	/pdf/bd259014ce9590847a3ab0d0d27204c7bc8dddb6.pdf
bn0GZZdDfI1	4556	Decentralized Optimistic Hyperpolicy Mirror Descent: Provably No-Regret Learning in Markov Games	['Reinforcement learning theory (statistical learning theory)']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|decentralized_optimistic_hyperpolicy_mirror_descent_provably_noregret_learning_in_markov_games	/pdf/de1e7bd42ea7254ea6842da822ee94c9235c8736.pdf
OVbY-QCCjAh	4557	SAGE: Semantic-Aware Global Explanations for Named Entity Recognition	['Explainable AI', 'Named Entity Recognition', 'Language Models', 'Natural Language Processing']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|sage_semanticaware_global_explanations_for_named_entity_recognition	/pdf/891799d4abebd6a5329ab9ecb16ca5c20ae54060.pdf
XYDSqLaHFVq	4558	Distributed Graph Neural Network Training with Periodic Stale Representation Synchronization	['GNN', 'Distributed training']	A novel distributed GNN training framework that achieves vast training speedup without compromising performance.	Deep Learning and representational learning	anonymous|distributed_graph_neural_network_training_with_periodic_stale_representation_synchronization	/pdf/a493dd996c904d15acdd0ef4dde918fd10733aac.pdf
40Mw2GJnlZ	4560	Fourier PINNs: From Strong Boundary Conditions to Adaptive Fourier Bases	['Physics Informed Machine Learning', 'Fourier Analysis', 'Scientific Machine Learning', 'Partial Differential Equations']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|fourier_pinns_from_strong_boundary_conditions_to_adaptive_fourier_bases	/pdf/ecb38bf2b64f87d8177397a048ae8ea9011b5beb.pdf
XnF9OtkASy	4561	Stein Variational Goal Generation for adaptive Exploration in Multi-Goal Reinforcement Learning	['Exploration', 'Goal-conditioned Policies', 'Automatic curriculum', 'Stein Variational Gradient Descent']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|stein_variational_goal_generation_for_adaptive_exploration_in_multigoal_reinforcement_learning	/pdf/68fe38354540fd4dddf04cbcde41fcc30723a76d.pdf
yNRfzsGELb	4562	Removing Structured Noise with Diffusion Models	['inverse problems', 'diffusion models', 'score-based', 'generative models', 'structured noise']	We propose a novel posterior sampling method to efficiently remove structured noise in various inverse problems using diffusion models.	Generative models	anonymous|removing_structured_noise_with_diffusion_models	/pdf/d9a66def1631b32687541df91694a058259dfa8e.pdf
6aKcyoDJBaX	4565	Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization	['federated learning', 'bilevel optimization', 'distributed optimization', 'generalization performance']	We propose a federated learning method with adaptively weighted nodes and analyze its generalization performance.	General Machine Learning (ie none of the above)	anonymous|federated_learning_on_adaptively_weighted_nodes_by_bilevel_optimization	/pdf/e51cc45c287e6e626aef9bf1b16db599733a19bc.pdf
FVW7Mi2ph6C	4566	PAC Reinforcement Learning for Predictive State Representations	['Reinforcement learning theory (statistical learning theory)']	PAC learning for PSRs.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pac_reinforcement_learning_for_predictive_state_representations	/pdf/03e14559ae8f38f174054e1486e0dc8827253333.pdf
Uk40pC45YJG	4567	Towards Multi-spatiotemporal-scale Generalized PDE Modeling	['PDE modeling', 'multi-spatiotemporal-scale', 'PDE generalization', 'Fourier vs U-Net', 'fluid mechanics']	We present a comprehensive study of Fourier and U-Net inspired architectural choices towards generalization of multi-spatiotemporal-scale problems.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|towards_multispatiotemporalscale_generalized_pde_modeling	/pdf/50751bea1fe005fae0c3ffc86778653ed4ba3a29.pdf
QwqxO8URJzn	4568	$\sigma$Reparam: Stable Transformer Training with Spectral Reparametrization	['Transformers', 'self-attention', 'optimization', 'stability', 'spectral normalization', 'self-supervised learning', 'vision', 'speech', 'language', 'contrastive learning']	We introduce a weight reparameterization method which stabilizes transformer training across a variety of domains and setups, enabling simpler training recipes and robustness to hyperparameters without performance tradeoffs.	Optimization (eg, convex and non-convex optimization)	anonymous|\sigmareparam_stable_transformer_training_with_spectral_reparametrization	/pdf/402f11d6708e8ecb5895b67fab479e481ed4ec0f.pdf
quCOIL8JQnp	4569	Improving Adversarial Robustness by Contrastive Guided Diffusion Process	[]		Generative models	anonymous|improving_adversarial_robustness_by_contrastive_guided_diffusion_process	/pdf/698c8e0204d951ec8d5353ccae1c86820f1efac8.pdf
k_iNqflnekU	4570	An ensemble view on mixup	['mixup', 'ensembles', 'generalization', 'calibration', 'ood', 'detection']	mixup brings about all the benefits of an expensive ensemble; you can improve things by evaluating multiple mixed up examples at test time	Deep Learning and representational learning	anonymous|an_ensemble_view_on_mixup	/pdf/decd4329115c6bf7ab18a99cb1b1ee2ec3af73f9.pdf
DjzBCrMBJ_p	4573	Spectral Augmentation for Self-Supervised Learning on Graphs	['graph self-supervised learning', 'graph spectral theory', 'graph augmentation']	We propose a novel spectral augmentation method which uses graph spectrum to capture structural properties and guide topology augmentations for graph self-supervised learning.	Unsupervised and Self-supervised learning	anonymous|spectral_augmentation_for_selfsupervised_learning_on_graphs	/pdf/d896c1ae0f5fc715b85421f5d87bb5b9ba7d0bd9.pdf
Z4lOwCEJQ8Z	4574	Training Normalizing Flows from Dependent Data	['Normalizing Flows']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|training_normalizing_flows_from_dependent_data	/pdf/2745dfd97b4b2ae87609fe0a60ce441313099f31.pdf
CDlHZ78-Xzi	4575	MACTA: A Multi-agent Reinforcement Learning Approach for Cache Timing Attacks and Detection	['multi-agent reinforcement learning', 'security', 'game theory']		Applications (eg, speech processing, computer vision, NLP)	anonymous|macta_a_multiagent_reinforcement_learning_approach_for_cache_timing_attacks_and_detection	/pdf/8a467a56c657f6d9cd31821ac4658fc4dda3d77d.pdf
5cFfz6yMVPU	4576	$\mathcal{O}$-GNN: incorporating ring priors into molecular modeling	['Graph Neural Network', 'Ring', 'Molecular Modeling']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|\mathcalognn_incorporating_ring_priors_into_molecular_modeling	/pdf/ddb69dff50590b7dce1842c585251ef8fbb9e668.pdf
moIlFZfj_1b	4577	Latent Neural ODEs with Sparse Bayesian Multiple Shooting	[]		Generative models	anonymous|latent_neural_odes_with_sparse_bayesian_multiple_shooting	/pdf/e7e01a7decb0d22a3d18a1a3d310401c9c060679.pdf
lTt4KjHSsyl	4579	Emergence of Maps in the Memories of Blind Navigation Agents	['embodied AI', 'navigation', 'characterizing representations']	‘Blind’ AI navigation agents (with only egomotion sensing) can learn to navigate new environments and build map-like representations (supporting the ability to take shortcuts, follow walls, and predict free-space and collisions) of their environment.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|emergence_of_maps_in_the_memories_of_blind_navigation_agents	/pdf/cefe03dc71151e442167faff00270ee42ab32121.pdf
UmHG2bD7X3w	4581	Dynamic Scheduled Sampling with Imitation Loss for Neural Text Generation	['exposure bias', 'text generation']	We proposed a new training objective that alleviates exposure bias problem in text generation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dynamic_scheduled_sampling_with_imitation_loss_for_neural_text_generation	/pdf/4ecb4b1af8506d810070ea338e3da8a35ef92b9f.pdf
6jqSG88Mf_D	4582	3D Neural Embedding Likelihood for Robust Sim-to-Real Transfer in Inverse Graphics	['3D inverse graphics', 'probabilistic inference', 'likelihood', 'RGB-D', 'neural embedding', 'object pose estimation']	We propose 3D Neural Embedding Likelihoods (3DNEL), a 3D likelihood that models both shape information from depth and appearance information from RGB via neural embeddings and bridges the sim-to-real gap in 3D inverse graphics.	Applications (eg, speech processing, computer vision, NLP)	anonymous|3d_neural_embedding_likelihood_for_robust_simtoreal_transfer_in_inverse_graphics	/pdf/e5127f2bea90719af9227085615ef35f47ebc543.pdf
L9RXJBTQaDf	4583	A new photoreceptor-inspired CNN layer enables deep learning models of retina to generalize across lighting conditions	['retina model', 'photoreceptor model', 'bio-inspired artificial vision', 'retina predictor', 'dynamic environments']	A new bio-inspired deep learning model that enables generalization in dynamic lighting conditions	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|a_new_photoreceptorinspired_cnn_layer_enables_deep_learning_models_of_retina_to_generalize_across_lighting_conditions	/pdf/7930617683b3ae48a125f87f27607a339e06b6ee.pdf
iaCzfh6vtwQ	4586	FUN: Filter-based Unlearnable Datasets	['unlearnable examples', 'data protection', 'privacy', 'adversarial machine learning']	We propose a novel, model-free convolutional filter-based unlearnable dataset (FUN) generation technique that protects data from empirical risk minimization and adversarial training with various budgets.	Applications (eg, speech processing, computer vision, NLP)	anonymous|fun_filterbased_unlearnable_datasets	/pdf/14744d41a6e82972888d781fed640d8a48bf457a.pdf
1_OGWcP1s9w	4588	Learning Fair Graph Representations via Automated Data Augmentations	[]	We propose an automated graph data augmentation method to learn fair graph representations.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|learning_fair_graph_representations_via_automated_data_augmentations	/pdf/eec9b2e54d193c08419996db198789613e4a58ae.pdf
sKc6fgce1zs	4590	Learning About Progress From Experts	['learning from demonstrations', 'reinforcement learning', 'exploration', 'nethack']	We learn a model of long-term progress using expert demonstrations, and show that it can be used to form an exploration reward that allows reinforcement learning agents to solve very challenging sparse tasks in NetHack.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_about_progress_from_experts	/pdf/33a7018f1562777ef89eaba299efb9fa6ea5cf7f.pdf
cnutOGKrz7f	4591	Soft Sampling for Efficient Training of Deep Neural Networks on Massive Data	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|soft_sampling_for_efficient_training_of_deep_neural_networks_on_massive_data	/pdf/ab33c354c6a514c3e67ca3e52365bd96533ff6aa.pdf
6PIrhAx1j4i	4592	Understanding DDPM Latent Codes Through Optimal Transport	['diffusion models', 'ddpm', 'optimal transport', 'theory']	ddim encoder is almost equal to optimal transport	Generative models	anonymous|understanding_ddpm_latent_codes_through_optimal_transport	/pdf/5b308ea48a784b20f670296cee300822a7dfd0cb.pdf
VXyzRA_Zaj1	4593	Burstormer: Burst Image Restoration and Enhancement Transformer	['Burst super-resolution', 'multi-frame processing', 'feature alignment']		Applications (eg, speech processing, computer vision, NLP)	anonymous|burstormer_burst_image_restoration_and_enhancement_transformer	/pdf/6adfb1c5706c3cc0ce6dcc935caaafcb4f9a12f6.pdf
3mlITJRYYbs	4595	Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation	['Interneurons', 'recurrent neural networks', 'gradient flows', 'implicit acceleration', 'statistical whitening']	We show that adding interneurons to a recurrent neural network for statistical whitening accelerates the learning dynamics	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|interneurons_accelerate_learning_dynamics_in_recurrent_neural_networks_for_statistical_adaptation	/pdf/1f75a1be4e2a16cef4272427557e311544dc6e01.pdf
HgJ3HYIP3pY	4596	DCT-DiffStride: Differentiable Strides with Real-Valued Data	['strides', 'decimation', 'deep learning', 'discrete cosine transform']	We propose DCT-DiffStride, a differentiable method to learn strides leveraging the energy compaction properties of the discrete cosine transform.	Deep Learning and representational learning	anonymous|dctdiffstride_differentiable_strides_with_realvalued_data	/pdf/bbf0e66e7256a947b31a87ea0f41381b2ac55743.pdf
t2qu5Hotedi	4597	Variational Prompt Tuning Improves Generalization of Vision-Language Models	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|variational_prompt_tuning_improves_generalization_of_visionlanguage_models	/pdf/fad39090b8f60eed13ad84051e72067f957e2ef6.pdf
-rHOeHtdWP	4598	Wide Attention is the Way Forward for Transformers	['transformer', 'attention', 'wide', 'deep', 'accuracy', 'latency', 'interpretability', 'xformer', 'size']	Widening the attention layer in a Transformer and only using a single layer is surprisingly effective, with a number of advantages.	Deep Learning and representational learning	anonymous|wide_attention_is_the_way_forward_for_transformers	/pdf/762e180d31af635f7e68c266bbda520d2b927893.pdf
a40XE0dgOdL	4599	Neural Network Differential Equation Solvers allow unsupervised error estimation and correction	['Deep learning', 'Numerical Methods', 'Differential Equations']	A blueprint for deep learning solution models for differential equation	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neural_network_differential_equation_solvers_allow_unsupervised_error_estimation_and_correction	/pdf/72f2a7b95c35fb25035a26a3dc9173e1e6eba795.pdf
oja19FZn5Y	4601	CLUSTERBERT: MULTI-STAGE FINE-TUNING OF TRANSFORMERS FOR DEEP TEXT CLUSTERING	['Text Clustering', 'Deep Clustering', 'Transformer', 'Sentence Embedding']		Deep Learning and representational learning	anonymous|clusterbert_multistage_finetuning_of_transformers_for_deep_text_clustering	/pdf/262999fcab563964ab251e73c13ab6d8ea4ddc6b.pdf
QmH1_mn6SI	4602	FP_AINet: Fusion Prototype with Adaptive Induction Network for Few-Shot Learning	[]		Deep Learning and representational learning	anonymous|fp_ainet_fusion_prototype_with_adaptive_induction_network_for_fewshot_learning	/pdf/c51e506d557480230aee4c9b4dd83d49aa2f35ae.pdf
3rGLfR0dqp	4603	Predicting Out-of-Domain Generalization with Local Manifold Smoothness	['complexity measure', 'out of domain generalization', 'smoothness']	Local manifold smoothness is a novel complexity measure that can be used to predict generalization even on out-of-domain test sets without labels.	Deep Learning and representational learning	anonymous|predicting_outofdomain_generalization_with_local_manifold_smoothness	/pdf/02158d15d9e938f1950f84ca4dc1c835963fc9d1.pdf
MtGmCCPJD-	4604	Repository-Level Prompt Generation for Large Language Models of Code	['prompt generation', 'codex', 'large language models of code', 'code-autocompletion', 'source code', 'LLM', 'retrieval']		Applications (eg, speech processing, computer vision, NLP)	anonymous|repositorylevel_prompt_generation_for_large_language_models_of_code	/pdf/6d0f27ca3135642048a123c4405e33b7b148bcf7.pdf
z8mVbZIMOjx	4606	Learning to Unlearn: Instance-wise Unlearning for Pre-trained Classifiers	['Machine Unlearning', 'Adversarial Examples', 'Weight Importance']	We propose an instance-wise unlearning framework with two regularization approaches to reduce forgetting on remaining data.	Deep Learning and representational learning	anonymous|learning_to_unlearn_instancewise_unlearning_for_pretrained_classifiers	/pdf/bf3794104a8ab2499bd07e56c282f659738473cc.pdf
dyRVv79XBAB	4608	COC curve: operating neural networks at high accuracy and low manual effort	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|coc_curve_operating_neural_networks_at_high_accuracy_and_low_manual_effort	/pdf/86e9a7906fc16b05b21cf7a9c20c07757fa449bb.pdf
e964ppNfoIJ	4609	Bringing robotics taxonomies to continuous domains via GPLVM on hyperbolic manifolds	['GPLVM', 'hyperbolic geometry', 'robotic taxonomies']	A GPLVM with hyperbolic latent space augmented with graph-based priors for representing robotic taxonomies.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|bringing_robotics_taxonomies_to_continuous_domains_via_gplvm_on_hyperbolic_manifolds	/pdf/d4fdd0d8f3469eccedcf69ee38fd7827941f6a90.pdf
hH36JeQZDaO	4610	Generating Sequences by Learning to Self-Correct	['Language models', 'text generation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|generating_sequences_by_learning_to_selfcorrect	/pdf/5ac1aff431c529c7361f15bbcd914a533134fd77.pdf
_DYi95e8CAe	4611	Multi-Task Structural Learning using Local Task Similarity induced Neuron Creation and Removal	['Multi-task Learning', 'Structural Learning', 'Brain-inspired Neural Network', 'Neuron Creation', 'Neuron Removal']	We propose a multi-task learning method inspired by structural learning in the brain that simultaneously learns the architecture and its parameters.	Deep Learning and representational learning	anonymous|multitask_structural_learning_using_local_task_similarity_induced_neuron_creation_and_removal	/pdf/8a99fb50981f43f242d6ea51afeaf032f8aa3f7a.pdf
LUql3ZOFwFD	4612	Differentially Private Conditional Text Generation For Synthetic Data Production	['differential privacy', 'conditional text generation', 'NLP']	synthesis of private text classification datasets via conditional text generation through GPT-2 fine-tuned with DP-SGD	Applications (eg, speech processing, computer vision, NLP)	anonymous|differentially_private_conditional_text_generation_for_synthetic_data_production	/pdf/da80055e8a1f2af09d27a65feb9e5b15654769cf.pdf
oN7tNztrYa3	4613	On the optimization and generalization of overparameterized implicit neural networks	['Gradient descent', 'generalization', 'implicit neural networks']	This paper analyzes the training and generalization for a implicit neural network with random initialization.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_optimization_and_generalization_of_overparameterized_implicit_neural_networks	/pdf/0a9b15677b60fd7beb804e90dc8ad928a07f206f.pdf
UiNhIyGi1MT	4616	TimeSeAD: Benchmarking Deep Time-Series Anomaly Detection	['anomaly detection', 'multivariate time series', 'deep learning', 'benchmark', 'evaluation metrics']	We analyze multivariate time-series datasets, introduce an evaluation metric for time series, and evaluate numerous deep anomaly detection methods.	Unsupervised and Self-supervised learning	anonymous|timesead_benchmarking_deep_timeseries_anomaly_detection	/pdf/43adeab2614009f3e52dd90b42071e9f43ea8007.pdf
OKcJhpQiGiX	4621	Disentanglement of Correlated Factors via Hausdorff Factorized Support	['disentanglement', 'representation learning', 'generalization']	We develop a method that allows for disentangled representation learning not only under the assumption of independent factors of variation but instead fundamentally allows for much more realistic correlations during training.	Deep Learning and representational learning	anonymous|disentanglement_of_correlated_factors_via_hausdorff_factorized_support	/pdf/d865850a6ae27c0b608b8bdc3b03231c61c60b5e.pdf
PhkWyijGi5b	4622	Choreographer: Learning and Adapting Skills in Imagination	['unsupervised reinforcement learning', 'skill learning', 'world models']	Choreographer: a model-based agent that discovers and learns unsupervised skills in latent imagination, and it's able to efficiently coordinate and adapt the skills to solve downstream tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|choreographer_learning_and_adapting_skills_in_imagination	/pdf/fdfaef4b29c373240297815c844d6ce8b3bc3dbb.pdf
EQfeudmWLQ	4623	TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation	['Test time adaptation', 'Domain adaptation', 'Batch Normalization']	We propose a test-time batch normalization method, which interpolates source and current batch statistics considering each layer's domain-shift sensitivity level that shows robust performance over various realistic evaluation scenarios..	Deep Learning and representational learning	anonymous|ttn_a_domainshift_aware_batch_normalization_in_testtime_adaptation	/pdf/962b651da3ab013929c0491a03dca3d51837c7cb.pdf
-lGvSmht7a	4624	Sequential Gradient Coding For Straggler Mitigation	['gradient coding', 'straggler mitigation', 'distributed computation', 'coded computing']	We propose to improve gradient coding by exploiting the temporal dimension while training deep learning models in distributed cloud systems.	General Machine Learning (ie none of the above)	anonymous|sequential_gradient_coding_for_straggler_mitigation	/pdf/92ec2c0927a15d211734621b28668826781e2938.pdf
xmXsZBRTzrI	4625	Semantic Transformation-based Data Augmentation for Few-Shot Learning	['few-shot learning', 'data augmentation', 'semantic feature transformation', 'sample bias']	We propose a semantic transformation based data augmentation approach by transferring samples from base dataset to the novel tasks in an encoder-decoder paradigm to alleviate the data scarce problem.	Deep Learning and representational learning	anonymous|semantic_transformationbased_data_augmentation_for_fewshot_learning	/pdf/db4af98e08452df62c02f3f2b50afbbe3dad265e.pdf
GpW327gxLTF	4629	Univariate vs Multivariate Time Series Forecasting with Transformers	['forecasting', 'time series', 'transformers', 'univariate', 'multivariate']	We achieve SOTA results via a simple method of producing multivariate forecasts in a univariate manner which points to flaws in current architectures.	Deep Learning and representational learning	anonymous|univariate_vs_multivariate_time_series_forecasting_with_transformers	/pdf/feee69c0b04e2a1829a60652018c9c463192f1ee.pdf
n-UHRIdPju	4630	Revisiting Populations in multi-agent Communication	['emergent communication']		Applications (eg, speech processing, computer vision, NLP)	anonymous|revisiting_populations_in_multiagent_communication	/pdf/d2e5671fdede8ea49cc70e1da98993c2d77269ec.pdf
hzG72qB0XQ	4631	Certifiably Robust Transformers with 1-Lipschitz Self-Attention	['Certified robustness', 'Transformers']	We propose a 1-Lipschitz Transformer which allows us to achieve superior certified robustness than existing transformer architectures.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|certifiably_robust_transformers_with_1lipschitz_selfattention	/pdf/c12d20546a0ff02f2e715c5d3db1bf8d1a1b4d04.pdf
jHA-yCyBGb	4632	DIFFUSION GENERATIVE MODELS ON SO(3)	['Deep Generative Models', 'Manifold Learning', 'SO(3)', 'Denoising Diffusion', 'Score-based models']	In this work, we establish a framework for score-based denoising diffusion generative models on the SO(3) manifold.	Generative models	anonymous|diffusion_generative_models_on_so3	/pdf/791804d589f52e6532f622c96996c04ab61157f2.pdf
fkmO7EFaNT	4634	Direct-Effect Risk Minimization	['Domain Generalization', 'Causal Inference', 'Direct and Indirect Effects']	We develop a novel domain generalization algorithm for correlation shift based on direct causal effects, which achieves good results in our experiments on 5 correlation-shifted datasets and the DomainBed benchmark.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|directeffect_risk_minimization	/pdf/eb9ef79497e9540aea2df6ec284b3569ba93add2.pdf
nXOhmfFu5n	4635	Amortised Invariance Learning for Contrastive Self-Supervision	[]		Unsupervised and Self-supervised learning	anonymous|amortised_invariance_learning_for_contrastive_selfsupervision	/pdf/8e6d65f8c1de404a8d7df1e9f00429c128563dd5.pdf
CMPIBjmhpo	4636	Neural Implicit Shape Editing using Boundary Sensitivity	[]		Generative models	anonymous|neural_implicit_shape_editing_using_boundary_sensitivity	/pdf/c5998d898af14db8ad4c15e6ca5b2090bdedf5a5.pdf
cTdzZI83Iud	4638	A Subspace Correction Method for ReLU Neural Networks for Solving PDEs	['ReLU neural network', 'Subspace correction method', 'Training algorithm', 'Function approximation', 'Partial differential equation']	We propose a novel algorithm called Neuron-wise Parallel Subspace Correction Method for training ReLU neural networks for solving partial differential equations.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_subspace_correction_method_for_relu_neural_networks_for_solving_pdes	/pdf/30c55e301759446b24ce9f143be91e82f3620899.pdf
dCSFiAl_VO3	4639	Improved Learning-augmented Algorithms for k-means and k-medians Clustering	['clustering', 'learning-augmented algorithms']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|improved_learningaugmented_algorithms_for_kmeans_and_kmedians_clustering	/pdf/ad7ceae6fc2cd39109b789413947d82519a7a96b.pdf
7MthJsb-nm	4640	Fast Bayesian Updates for Deep Learning with a Use Case in Active Learning	['Bayesian Neural Networks', 'Deep Learning', 'Active Learning']		General Machine Learning (ie none of the above)	anonymous|fast_bayesian_updates_for_deep_learning_with_a_use_case_in_active_learning	/pdf/5d21e02f8730f1040e262c2f291c612ead6d00b7.pdf
bjCAHZLoKy	4641	Semi-parametric Prompt-Generation for Model Editing	['Model Editing', 'Prefix Tuning', 'Fine-tuning']	An efficient prefix generation method to efficiently update knowledge of large language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|semiparametric_promptgeneration_for_model_editing	/pdf/f3158fdb51be20be6a5bc26c5f1618cfb034048d.pdf
DwOaHJJKy9	4643	Using semantic distance for diverse and sample efficient genetic programming	['genetic programming', 'meta learning']	We show the importance of diversity in semantic (phenotypic) space when mutating genetic programs, and apply it to learning ML components.	General Machine Learning (ie none of the above)	anonymous|using_semantic_distance_for_diverse_and_sample_efficient_genetic_programming	/pdf/804aca5c841c06d946baeae9f2e09e91989f9147.pdf
M8rwWdaGa6x	4644	Optimal Scalarizations for Provable Multiobjective Optimization	['multiobjective optimization', 'scalarization', 'linear bandits']	Don't linearly combine your objectives: Hypervolume scalarizations provide provable and more optimal multiobjective optimization.	Optimization (eg, convex and non-convex optimization)	anonymous|optimal_scalarizations_for_provable_multiobjective_optimization	/pdf/c46a6bc36b66c6930c33ea564250b7a0c6bdda7b.pdf
axFCgjTKP45	4645	Reprogramming Large Pretrained Language Models for Antibody Sequence Infilling	['Antibody', 'Protein', 'CDR', 'Infilling']	We use large pretrained language models and reprogram them for the new task of protein infilling	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|reprogramming_large_pretrained_language_models_for_antibody_sequence_infilling	/pdf/405d604b0f1df86fde74512c4d2533bf3c102467.pdf
UbH1jxLIPhb	4646	Maximum Entropy Information Bottleneck for Confidence-aware Stochastic Embedding	['Deep learning', 'Computer vision', 'Stochastic embedding']	We use the maximum entropy objective to better learn stochastic embedding.	Deep Learning and representational learning	anonymous|maximum_entropy_information_bottleneck_for_confidenceaware_stochastic_embedding	/pdf/b88824f8ffcdc097821a188dbf275f33d9905581.pdf
b7SBTEBFnC	4647	Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|canary_in_a_coalmine_better_membership_inference_with_ensembled_adversarial_queries	/pdf/183114970496ae20da98b46fc970502e69d1aea9.pdf
NnHz2rU0Hjp	4648	Masked Siamese ConvNets: Towards an Effective Masking Strategy for General-purpose Siamese Networks 	['self-supervised learning', 'siamese networks', 'masking', 'convNets']	We propose a masking strategy for siamese networks with ConvNets.	Unsupervised and Self-supervised learning	anonymous|masked_siamese_convnets_towards_an_effective_masking_strategy_for_generalpurpose_siamese_networks	/pdf/32d20b5151cde4d92402bc4e7b10f55e1d465aaa.pdf
xdVNc95sY1l	4649	SYNC: Efficient Neural Code Search Through Structurally Guided Hard Negative Curricula	['Neural Code Search', 'Curriculum Learning', 'Hard Negative Mining', 'Abstract Syntax Tree', 'Structure-aware Embeddings']	This paper proposes an AST-guided hard negative sampling method for training efficient neural code search models using curriculum learning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sync_efficient_neural_code_search_through_structurally_guided_hard_negative_curricula	/pdf/9670b20ce75db997613c7bef65e9872ccb634cd9.pdf
QvIyd7l718	4651	Beyond Link Prediction: On Pre-Training Knowledge Graph Embeddings	[]		Deep Learning and representational learning	anonymous|beyond_link_prediction_on_pretraining_knowledge_graph_embeddings	/pdf/66f1659081a7f4e225e76ede077840e06c1ef395.pdf
vDybC2brXKh	4652	The Adversarial Regulation of the Temporal Difference Loss Costs More Than Expected	[]		General Machine Learning (ie none of the above)	anonymous|the_adversarial_regulation_of_the_temporal_difference_loss_costs_more_than_expected	/pdf/48d63216315bbb1fdfb9fe67c4210790f965ab9c.pdf
iy_syzfX6I	4653	A Scalable Finite Difference Method for Deep Reinforcement Learning	['Deep Reinforcement Learning', 'Reinforcement Learning', 'Finite Differences', 'Distributed Systems', 'Policy Optimization']	An efficient & scalable method for policy optimization using finite differences and a modification of SGD.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_scalable_finite_difference_method_for_deep_reinforcement_learning	/pdf/0d707d1618d737df0c6c91cd35e3d9942be609f2.pdf
4daKS8wEze5	4655	ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|resgrad_residual_denoising_diffusion_probabilistic_models_for_text_to_speech	/pdf/2d65b8c77aa847a85c9b2c52cdc40da5cb29f7f3.pdf
6s8XPvu7bI8	4656	Fine-grain Inference on Out-of-Distribution Data with Hierarchical Classification	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|finegrain_inference_on_outofdistribution_data_with_hierarchical_classification	/pdf/341431878c91a942ffa1429554493d763a10b549.pdf
IM4Iwo58T4M	4657	TOWARDS AN OBJECTIVE EVALUATION OF THE TRUSTWORTHINESS OF CLASSIFIERS	['Model trustworthiness', 'Explainable AI']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_an_objective_evaluation_of_the_trustworthiness_of_classifiers	/pdf/fd5dfb8cbd00377b327e5062aff1ab09145f2d5f.pdf
wYZeJ3BsXl6	4658	PMI-guided Masking Strategy to Enable Few-shot Learning for Genomic Applications	['gene sequence modeling', 'few-shot', 'MLM masking']	PMI-masking in MLMs helps to achieve better few-shot classification performance in gene sequence modeling applications.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pmiguided_masking_strategy_to_enable_fewshot_learning_for_genomic_applications	/pdf/6f82850f7738d344ad341addfb5526b9837218b1.pdf
sRsceSk_5l0	4661	Self-Supervised Learning of Maximum Manifold Capacity Representations	['self-supervised learning', 'representation geometry', 'neural manifolds', 'statistical physics of learning', 'theoretical neuroscience']	We present a novel self-supervised framework that maximimizes the number of linearly separable augmentation manifolds.	Unsupervised and Self-supervised learning	anonymous|selfsupervised_learning_of_maximum_manifold_capacity_representations	/pdf/2d81df8a64b71f1843992c015ea6c5bd3aaec4a7.pdf
c2l1XbSRnpZ	4662	Smooth Mathematical Functions from Compact Neural Networks	['regression', 'function approximation', 'mathmatical function', 'compact model']	Smooth mathematical functions are obtained from neural networks comprised few weight parameters using a new activation function and the new batch method.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|smooth_mathematical_functions_from_compact_neural_networks	/pdf/11c903fb0ae7779e4ea56f48250d4d3d5f2d0682.pdf
Xyme9p1rpZw	4664	SoftZoo: A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments	['soft robot', 'co-design', 'differentiable physics']	We introduce a new virtual environment for soft robot co-design.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|softzoo_a_soft_robot_codesign_benchmark_for_locomotion_in_diverse_environments	/pdf/a538cbe131cb6e3f13c9232322c0cbe5fa7fd528.pdf
xFiI7VmVB4H	4665	Hardware-aware compression with Random Operation Access Specific Tile (ROAST) hashing	['model compression', 'hardware aware']	efficient model compression using parameter sharing tuned to underlying hardware and algorithm implementations.	General Machine Learning (ie none of the above)	anonymous|hardwareaware_compression_with_random_operation_access_specific_tile_roast_hashing	/pdf/8dcef9b3c97c211810ada3123fa0e76119c2e860.pdf
HXz7Vcm3VgM	4666	ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations	[]	we annotate ImageNet images with factor labels to explain model mistakes	Deep Learning and representational learning	anonymous|imagenetx_understanding_model_mistakes_with_factor_of_variation_annotations	/pdf/f9491b57d6302587ca24b47b1e748835c85c0d50.pdf
lCYrsdHb5SQ	4667	Non-Gaussian Process Regression	['Non-parametric regression', 'Bayesian methods', 'Approximate Inference', 'Levy processes']	We extend the Gaussian process regression model to allow for locally adaptive behaviour through time-changed GPs and learn latent probabilistic representations of inputs.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|nongaussian_process_regression	/pdf/919643bcc69293d00b131da05256a2e454fc8f04.pdf
sWUlKZOM8kfs	4668	Shuffled Transformers for Blind Training	['Data privacy', 'split learning', 'Transformer', 'privacy-preserving']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|shuffled_transformers_for_blind_training	/pdf/961332e66f2c9f7d9ad66be596bcc1b629a12973.pdf
wPLEzBcSC7p	4669	A Cognitive-inspired Multi-Module Architecture for Continual Learning	['Continual Learning', 'Catastrophic Forgetting', 'Experience Replay', 'Lifelong Learning', 'Cognitive Learning', 'Inductive Bias']	Cognitive Continual Learner (CCL), a novel cognitive-inspired method that employs multiple modules, implicit and explicit knowledge representation dichotomy, inductive bias, and a multi-memory system. 	Deep Learning and representational learning	anonymous|a_cognitiveinspired_multimodule_architecture_for_continual_learning	/pdf/a3ffe56eb626bdb8f9d603d77614d2f0170a38e8.pdf
XGXPeOXbiT-	4670	Unsupervised Model-based Pre-training for Data-efficient Control from Pixels	['unsupervised reinforcement learning', 'world models', 'planning']	We combine the findings of a large-scale study on the Unsupervised RL Benchmark and propose a new hybrid planner, to establish an end-to-end approach that can be efficiently fine-tuned after unsupervised pre-training.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|unsupervised_modelbased_pretraining_for_dataefficient_control_from_pixels	/pdf/c8008d9493b2196c695e8be1ae4d598844257c5f.pdf
PJVZCd4Dn2w	4671	Convexifying Transformers: Improving optimization and understanding of transformer networks	['Convex optimization', 'transformers', 'attention', 'self-attention', 'group sparsity']	We first propose a convex alternative to the self-attention mechanism and then develop a convex analytic framework to train attention/transformer networks. 	Optimization (eg, convex and non-convex optimization)	anonymous|convexifying_transformers_improving_optimization_and_understanding_of_transformer_networks	/pdf/1d01b7ebfe71af19b3249b2d985545032e5ba4ca.pdf
brk7Ct4Tb1M	4672	AlphaFold Distillation for Improved Inverse Protein Folding	['Inverse Protein Folding Design', 'Protein Design', 'Model Distillation', 'AlphaFold', 'Protein Folding']	We distilled AlphaFold to generate structural confidence scores (pTM, pLDDT) for any protein sequence and applied it to inverse folding design and antibody infilling 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|alphafold_distillation_for_improved_inverse_protein_folding	/pdf/70991b4227297d2958446f59de7ca62e2dba33eb.pdf
33daZzvuzY6	4673	DLP: Data-Driven Label-Poisoning Backdoor Attack	['Backdoor learning', 'End-to-end learning', 'Clean-sample attack']	We introduce a new type of end-to-end clean-sample backdoor attack, allowing attackers to backdoor effectively, as measured by test performances, for an arbitrary backdoor sample size. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|dlp_datadriven_labelpoisoning_backdoor_attack	/pdf/185eab633f4819f7b1cac2547817535e4e9fd684.pdf
3oWo92cQyxL	4675	Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning	['multimodal', 'few-shot learning', 'meta-learning', 'transformers', 'vision and language models']	We introduce a novel multimodal few-shot meta-learner, by learning how to bridge large-scale frozen vision and language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|meta_learning_to_bridge_vision_and_language_models_for_multimodal_fewshot_learning	/pdf/4a54483308783c6b31b615ee0a60176d5d3c365c.pdf
tVrRejrC-RZ	4676	Robust Exploration via Clustering-based Online Density Estimation	['exploration', 'representation learning', 'density estimation', 'reinforcement learning']	We derive a theoretically sound and effective exploration bonus for deep RL using online clustering to estimate visitation densities in a learned latent representation space 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|robust_exploration_via_clusteringbased_online_density_estimation	/pdf/3bad51927be8ec15aee41f50e4fddf2df22d9b49.pdf
op-ceGueqc4	4677	Scaling Laws For Deep Learning Based Image Reconstruction	['scaling laws', 'number of training examples', 'inverse problems', 'deep learning', 'denoising', 'magnetic resonance imaging', 'super-resolution']	The performance improvement of deep learning based image reconstruction methods as a function of the training set size slows already at moderate training set sizes, indicating that only marginal gains are expected beyond a few thousand examples.	Deep Learning and representational learning	anonymous|scaling_laws_for_deep_learning_based_image_reconstruction	/pdf/ccfcbdc733a49a22ab762ff8d16f847dbeadaa79.pdf
BW2A403ema	4678	The Robustness Limits of SoTA Vision Models to Natural Variation	['robustness', 'computer vision', 'generalization', 'deep learning']	Even today's best vision models are not robust and struggle to generalize changes in factors such as pose, size, and position.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|the_robustness_limits_of_sota_vision_models_to_natural_variation	/pdf/ba9dcc910a316877dbdc710a8f347cc96603f8b1.pdf
X6MIKw1XuxF	4679	Bridging between Pool- and Stream-Based Active Learning with Temporal Data Coherence	[]	New Steam based active learning approach using properties of temporal stream data 	Applications (eg, speech processing, computer vision, NLP)	anonymous|bridging_between_pool_and_streambased_active_learning_with_temporal_data_coherence	/pdf/d1afbdc1fa54128cea06d50bf2b8c93a78c436e6.pdf
Hyan74saltV	4680	SkillS: Adaptive Skill Sequencing for Efficient Temporally-Extended Exploration	['Reinforcement Learning', 'Control', 'Skills', 'Priors', 'Hierarchical Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|skills_adaptive_skill_sequencing_for_efficient_temporallyextended_exploration	/pdf/e79b484f3d42a657b32717cb9783ab04b3b2ebd3.pdf
gm0VZ-h-hPy	4681	Proposal-Contrastive Pretraining for Object Detection from Fewer Data	['Object Detection', 'Unsupervised', 'Pretraining', 'Contrastive Learning']	We present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach for Object Detection that leverages the large number of object proposals generated by transformer-based detectors using an improved contrastive loss.	Unsupervised and Self-supervised learning	anonymous|proposalcontrastive_pretraining_for_object_detection_from_fewer_data	/pdf/09d83f2246516b815cd8b597423faada57b330ed.pdf
hFUlfiyf1oQ	4682	Rethinking Uniformity in Self-Supervised Representation Learning	['Collapse Analysis', 'Wasserstein Distance', 'Self-Supervised Representation Learning']		Unsupervised and Self-supervised learning	anonymous|rethinking_uniformity_in_selfsupervised_representation_learning	/pdf/1ae4e61e542ed3097d2ffaaec4e6f62ab12088fd.pdf
T2Ncx_PN2K	4684	In-Situ Text-Only Adaptation of Speech Models with Low-Overhead Speech Imputations	['Text-Only Adaptation', 'End-to-end Speech Recognition']	A lightweight text-only adaptation technique for end-to-end speech recognition that is both fast and accurate.	Applications (eg, speech processing, computer vision, NLP)	anonymous|insitu_textonly_adaptation_of_speech_models_with_lowoverhead_speech_imputations	/pdf/8e4262937d2e05f61f93ac4257982868fa19bc1b.pdf
4gwZXPNhBt	4685	Topological Data Analysis-Deep Learning Framework for Predicting Cancer Phenotypes	['Topological data analysis', 'Deep learning', 'Gene expression', 'Cancer Phenotype prediction']	The use of topological data analysis to predict cancer-type phenotypes. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|topological_data_analysisdeep_learning_framework_for_predicting_cancer_phenotypes	/pdf/95ce8dcc95c2bce671064a94d5ae68a0623b82ba.pdf
klOPHkfx0ic	4686	CLMIU: Commonsense Learning in Multimodal Image Understanding.	['Vision and language pretraining', 'Image captioning', 'Commonsense knowledge', 'Transformers', 'Graph attention networks', 'Group masked model learning']	Incorporating external commonsense knowledge into multimodal image understanding tasks, e.g., image captioning. The proposed method achieves state of the art results without needing a pretrained object detector.	Applications (eg, speech processing, computer vision, NLP)	anonymous|clmiu_commonsense_learning_in_multimodal_image_understanding	/pdf/d97814892aa908d6e3987c93060db1e8a2165710.pdf
Qi4oCA89CmO	4687	Why Did This Model Forecast This Future? Information-Theoretic Temporal Saliency for Counterfactual Explanations of Probabilistic Forecasts	['probabilistic forecasting', 'saliency', 'explainability']	We propose an information-theoretic saliency-based framework for counterfactual reasoning in probabilistic forecasting. For common distributions, we obtain a closed-form expression for the saliency of observed timesteps towards a model's forecasts. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|why_did_this_model_forecast_this_future_informationtheoretic_temporal_saliency_for_counterfactual_explanations_of_probabilistic_forecasts	/pdf/4e0b143e591dc0584b2892ff5e98a8f6b0bf5beb.pdf
_3Lk3cUWSI	4688	Off Policy Average Reward Actor Critic with Deterministic Policy Search	['reinforcement learning', 'actor critic algorithm', 'deterministic policy', 'off-policy', 'target network', 'average reward', 'finite time analysis', 'convergence', 'three time scale stochastic approximation', 'DeepMind control suite']	This paper proposes actor critic algorithm with deterministic policy for the average reward criterion	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|off_policy_average_reward_actor_critic_with_deterministic_policy_search	/pdf/db62016e73261b1e2fbc397a0d96925d948291b7.pdf
qLKammDlpF	4689	Fusion over the Grassmann Manifold for Incomplete-Data Clustering	['high-rank matrix completion', 'subspace clustering', 'manifold learning']	We introduce a novel paradigm that optimizes on the Grassmannian to complete and cluster incomplete data in a union of subspaces.	Unsupervised and Self-supervised learning	anonymous|fusion_over_the_grassmann_manifold_for_incompletedata_clustering	/pdf/a28d111c6105a697526f00c3998f742028eed05d.pdf
Rkxj1GXn9_	4690	On the Expressive Power of Geometric Graph Neural Networks	['Graph Neural Networks', 'Geometric Deep Learning', 'Equivariance', 'Expressive Power', 'Graph Isomorphism']	We propose a geometric version of the Weisfeler-Leman graph isomorphism test to characterise the expressive power of GNNs for geometric graphs.	Deep Learning and representational learning	anonymous|on_the_expressive_power_of_geometric_graph_neural_networks	/pdf/932cf34e063c4bd869d02d1ca90d8db766293de0.pdf
2lrx543-MbS	4691	Improving Generalization of Motor-Imagery Brainwave Decoding via Dynamic Convolutions	['Brain-Computer Interfaces', 'Dynamic Convolution', 'Causality']	Tackling inter-subject variability using dynamic convolutions and causal reasoning	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|improving_generalization_of_motorimagery_brainwave_decoding_via_dynamic_convolutions	/pdf/5a5cc7e406234dfebd34a2efa6b7a650332aa6d4.pdf
SMYdcXjJh1q	4692	Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness	['Computer Vision', 'Primate Vision', 'Adversarial Robustness', 'Behavioral Alignment', 'Inferior Temporal Cortex']	Aligning late stage model representations with neural recordings from macaque IT broadly improves adversarial robustness and alignment on human behavior.	Deep Learning and representational learning	anonymous|aligning_model_and_macaque_inferior_temporal_cortex_representations_improves_modeltohuman_behavioral_alignment_and_adversarial_robustness	/pdf/1a59679965432ffceda8e71e62c857e8d60dee93.pdf
73U_NlKaNx	4694	Time Series Subsequence Anomaly Detection via Graph Neural Networks	[]	A graph neural network-based time series subsequence anomaly detection method consdering multiple effective heuristics. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|time_series_subsequence_anomaly_detection_via_graph_neural_networks	/pdf/343010151ed9fac35ccacb9af20a1a02dff80be2.pdf
Jp7NLnL3n_1	4695	Spurious Features in Continual Learning	['Spurious Features', 'Continual Learning', 'Plasticity']	This paper show that catastrophic forgetting is partially due to spurious features.	Deep Learning and representational learning	anonymous|spurious_features_in_continual_learning	/pdf/6ba13d0994c08d5a897cad7bd959733b7a9fd8e9.pdf
xYmlvET9jNU	4696	Triplet learning of task representations in latent space for continual learning	['Continual Learning', 'Triplet Learning', 'Image Generation']		Deep Learning and representational learning	anonymous|triplet_learning_of_task_representations_in_latent_space_for_continual_learning	/pdf/9a7af28be053c87a522c6e4a0ce8d9643ba943cd.pdf
7WgLZCURXxT	4698	Multi-instance Interactive Segmentation with Self-Supervised Transformer	['Vision Transformer', 'Self-supervised learning', 'Interactive Image Segmentation', 'Semi-supervised learning']	Multi-instance interactive segmentation using Label Propagation and self-supervised representations from Vision Transformer.	Unsupervised and Self-supervised learning	anonymous|multiinstance_interactive_segmentation_with_selfsupervised_transformer	/pdf/40bb671118e928c5f9615b4895aef31c3caa1a18.pdf
fadoo8Xs6pH	4699	Towards Antisymmetric Neural Ansatz Separation	['antisymmetric', 'Slater', 'Jastrow', 'quantum chemistry', 'separation']	We show an exponential separation between the Slater Ansatz and Jastrow Ansatz used in quantum chemistry.	Deep Learning and representational learning	anonymous|towards_antisymmetric_neural_ansatz_separation	/pdf/39b70565ff141769f249426a9afffe186cddf18a.pdf
VkPuKTKH2Gx	4701	Re-Benchmarking Out-of-Distribution Detection in Deep Neural Networks	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|rebenchmarking_outofdistribution_detection_in_deep_neural_networks	/pdf/3106b6a8e1ace98a5ba1a27ccec669d8a2d3e63b.pdf
vV1aVdCD2WW	4703	$\ell$Gym: Natural Language Visual Reasoning with Reinforcement Learning	['reinforcement learning', 'natural language', 'visual reasoning', 'benchmark']	A new benchmark for language-conditioned reinforcement learning in visual environments with highly compositional human-written language.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|\ellgym_natural_language_visual_reasoning_with_reinforcement_learning	/pdf/872a3fb776edbf26a94c8aaf9a9926f2fbd8a47c.pdf
Jpctg2jSnMA	4704	A Scalable Training Strategy for Blind Multi-Distribution Noise Removal	['denoising', 'image restoration', 'curriculum learning']	A Scalable Training Strategy for Blind Multi-Distribution Noise Removal	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_scalable_training_strategy_for_blind_multidistribution_noise_removal	/pdf/83b64bbb7b0624d81276f637e72a671c624efd13.pdf
h1kEyC8CFI	4706	Single SMPC Invocation DPHelmet: Differentially Private Distributed Learning on a Large Scale	['differential privacy', 'distributed learning', 'privacy-preserving machine learning', 'privacy', 'federated learning']	Our differentially private distributed learning algorithm for image recognition tasks (e.g., CIFAR-10) scales better than prior work while improving the utility-privacy tradeoff on data-starved parties (50 data points per party).	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|single_smpc_invocation_dphelmet_differentially_private_distributed_learning_on_a_large_scale	/pdf/b6670d126db5974bc64b49b1df5df5d682d32598.pdf
PvLnIaJbt9	4707	Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics	['Metadata archaeology', 'Learning curves', 'Loss trajectory', 'Data auditing']	Our work provides a unified and efficient framework for Metadata Archaeology -- uncovering and inferring metadata of examples in a dataset	General Machine Learning (ie none of the above)	anonymous|metadata_archaeology_unearthing_data_subsets_by_leveraging_training_dynamics	/pdf/6aedfcf4db1a2ed2537117533896b2395a890267.pdf
0Hfv9xPBSPQ	4708	Do We Really Need Labels for Backdoor Defense?	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|do_we_really_need_labels_for_backdoor_defense	/pdf/f1f5ea3bf90d7629f67adc37b8daa60631dc809d.pdf
TBaS6AqX_F_	4710	MyoDex: Generalizable Representations for Dexterous Physiological Manipulation	['Musculoskeletal', 'Machine Learning', 'human dexterity', 'muscle synergies']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|myodex_generalizable_representations_for_dexterous_physiological_manipulation	/pdf/14e03ff9e48d6e321bd0a1a0f23f1259a1c40e9c.pdf
T5ADm9PHGeJ	4711	Tiered Pruning for Efficient Differentialble Inference-Aware Neural Architecture Search	['nas', 'dnas', 'neural architecture search', 'differentiable neural architecture search', 'state-of-the-art', 'imagenet', 'classification', 'gpunet', 'efficientnet', 'pruning', 'inference-aware', 'computer vision', 'object detection']		Deep Learning and representational learning	anonymous|tiered_pruning_for_efficient_differentialble_inferenceaware_neural_architecture_search	/pdf/0468ddc07077adb80748fded4b5046c62e72c571.pdf
8NLta1E_BPR	4712	Meta-Learning via Classifier(-free) Guidance	['deep leaning', 'meta learning', 'hypernetworks', 'generative models', 'classifier guidance', 'contrastive learning', 'clip', 'classifier-free guidance', 'latent diffusion', 'diffusion models']	We develop a meta-learning method that uses classifier(-free) guidance from the generative modeling literature to generate zero-shot adapted network weights.	Generative models	anonymous|metalearning_via_classifierfree_guidance	/pdf/5305a2dc46e193c43411c9ff6ff536cda4a256f1.pdf
ZqvoLWz05jT	4713	Mask-tuning: Towards  Improving  Pre-trained Language Models' Generalization	['NLP', 'Pre-trained langugae model', 'out-of-distribution learning', 'robust generalization', 'fine-tuning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|masktuning_towards_improving_pretrained_language_models_generalization	/pdf/64bcb54556c76459e1e3247928827378fc69287e.pdf
SdXv2C2-tnj	4714	Density Sketches for Sampling and Estimation	['density estimation', 'sampling', 'machine learning']	online summary of data for density estimation and sampling new data.	General Machine Learning (ie none of the above)	anonymous|density_sketches_for_sampling_and_estimation	/pdf/a2a043c6134998ced719f3314110d3fae585578b.pdf
4Fi-5Jiyy5w	4715	Applying Second Order Optimization to Deep Transformers with Parameter-Efficient Tuning	['Pre-trained Models', 'NLP', 'Model Adaptation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|applying_second_order_optimization_to_deep_transformers_with_parameterefficient_tuning	/pdf/e43f2f4ec96948126890feac75b5a14a59132c7f.pdf
kt-dcBQcSA	4716	A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation	['neuroscience', 'dimensionality reduction', 'probabilistic methods', 'inter-area interactions']	New probabilistic estimator partitions multi-area neural variability into shared and private sources, aligned to meaningful task axes.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|a_probabilistic_framework_for_taskaligned_intra_and_interarea_neural_manifold_estimation	/pdf/887419ff66c4a348b6cdc8a04b0cfc20468a2767.pdf
QCcrFi7q3u	4718	Forget to Learn (F2L): Rethinking Replay Loss in Unsupervised Continuous Domain Adaptation	['Domain Adaptation', 'Lifelong Learning', 'Replay Loss', 'Knowledge Distillation', 'Stability Plasticity Dilemma']		Deep Learning and representational learning	anonymous|forget_to_learn_f2l_rethinking_replay_loss_in_unsupervised_continuous_domain_adaptation	/pdf/29f91489703770e7388768cc0bea0734a756a18f.pdf
sdQGxouELX	4719	MMVAE+: Enhancing the Generative Quality of Multimodal VAEs without Compromises	['Multimodal Variational Autoencoder', 'Variational Autoencoder', 'Multimodal Generative Learning']		Generative models	anonymous|mmvae_enhancing_the_generative_quality_of_multimodal_vaes_without_compromises	/pdf/26d292889d4ed3cb20030830ce29d2eb22925b53.pdf
QIRtAqoXwj	4721	Heterogeneous Neuronal and Synaptic Dynamics for Spike-Efficient Unsupervised Learning: Theory and Design Principles	['theory', 'spiking neural network', 'LIF', 'STDP', 'heterogeneity', 'memory capacity', 'spike efficiency', 'bayesian optimization']	We prove that heterogeneity in neuronal dynamics improves the memory capacity while heterogeneity in the STDP synaptic dynamics improves the spike efficiency	Unsupervised and Self-supervised learning	anonymous|heterogeneous_neuronal_and_synaptic_dynamics_for_spikeefficient_unsupervised_learning_theory_and_design_principles	/pdf/f1c611aea15b101c4a27cda258e2c7df5f71c714.pdf
JyD-NobfNL_	4722	Distinguishing Feature Model for Ranking From Pairwise Comparisons	[]		Deep Learning and representational learning	anonymous|distinguishing_feature_model_for_ranking_from_pairwise_comparisons	/pdf/3b1c7aeb2c2e960ec25f4bc8d3bf87beb6f61897.pdf
dJruFeSRym1	4723	Efficient Conditionally Invariant Representation Learning	['conditional independence', 'kernel methods']	Batch-efficient conditional independence regularization	Deep Learning and representational learning	anonymous|efficient_conditionally_invariant_representation_learning	/pdf/fffadbd74976872997a22e566bce32d10e0b072d.pdf
EmABrt4zzz3	4725	PES: Probabilistic Exponential Smoothing for Time Series Forecasting	['time series forecast', 'demand forecast', 'probabilistic forecast', 'recurrent neural network', 'exponential smoothing', 'automatic differentiation']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|pes_probabilistic_exponential_smoothing_for_time_series_forecasting	/pdf/20c86be99aa4e5f03e077164d293ec61be341a13.pdf
r8PDECVumsJ	4729	Image Emotion Recognition using Cognitive Contextual Summarization Framework	['Emotion Recognition', 'Valence-Arousal', 'Image Captioning', 'BERT', 'human cognition', 'Sentiment Analysis']	We propose a novel framework for emotion prediction in continuous space (Valence-Arousal) and provide a new benchmark for the community to explore and enhance the human emotion perception.	Applications (eg, speech processing, computer vision, NLP)	anonymous|image_emotion_recognition_using_cognitive_contextual_summarization_framework	/pdf/bf8fe3424dccb5fab50b5c74d9745bdf2eccdc5e.pdf
eHkWu_OXBGt	4730	Gaussian-Bernoulli RBMs Without Tears	['Gaussian-Bernoulli Restricted Boltzmann Machines', 'Restricted Boltzmann Machines', 'Langevin Monte Carlo Sampling', 'Contrastive Divergence']		Generative models	anonymous|gaussianbernoulli_rbms_without_tears	/pdf/c7fad9b494963b41f382b96e84e8950e5b8dc728.pdf
GG0sigkMnxF	4731	URVoice: An Akl-Toussaint/ Graham- Sklansky Approach towards Convex Hull Computation for Sign Language Interpretation	['Communication disorder', 'computational geometry', 'convex hull', 'sign language', 'URVoice', 'vocalizer', 'computer vision', 'deep learning']	 We present URVoice, a vocalizer for the communication impaired, based on the Indian Sign Language Notations and a real time translation of gesture to text/voice using convex hull as the computational geometry.	Optimization (eg, convex and non-convex optimization)	anonymous|urvoice_an_akltoussaint_graham_sklansky_approach_towards_convex_hull_computation_for_sign_language_interpretation	/pdf/ae97bb974f5c7a82e282d54bfe1ab9cc1157aafb.pdf
JLg5aHHv7j	4733	(Certified!!) Adversarial Robustness for Free!	[]	Using an off-the-shelf diffusion model as a denoiser gives state-of-the-art certified adversarial robustness.	Deep Learning and representational learning	anonymous|certified_adversarial_robustness_for_free	/pdf/dc00d30875b740c946d12110573f000b7f599519.pdf
j3AyKG-H3uM	4736	Improved Group Robustness via Classifier Retraining on Independent Splits	['spurious correlations', 'group shifts', 'overfitting', 'distributionally robust optimization']	We propose a simple method to improve group robustness by fine-tuning only the classification layer on independent splits of the data, with minimal parameter tuning.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|improved_group_robustness_via_classifier_retraining_on_independent_splits	/pdf/41a2e73700723a1694942fa8f4c41e8e1cff8fe0.pdf
VuuDXDgujAc	4737	HiT-MDP: Learning the SMDP option framework on MDPs with Hidden Temporal Variables	['Hiearchical Reinforcement Learning', 'Reinforcement Learning', 'Markov Decision Process']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|hitmdp_learning_the_smdp_option_framework_on_mdps_with_hidden_temporal_variables	/pdf/316d38b1c4d88ec68c86096a42b9b65897a02372.pdf
TTcpISh-_oI	4738	ResFed: Communication Efficient Federated Learning by Transmitting Deep Compressed Residuals	['Federated Learning', 'Communication Efficiency', 'Deep Compression']	We introduce ResFed federated learning framework to achieve more efficient communication by leveraging deep compressed residuals rather than weights or gradients.	Deep Learning and representational learning	anonymous|resfed_communication_efficient_federated_learning_by_transmitting_deep_compressed_residuals	/pdf/da974c8d2e992fd7eab841408c2463f174130b89.pdf
5-X1XzdAWcC	4739	Efficient Exploration using Model-Based Quality-Diversity with Gradients	['Quality-Diversity', 'Exploration', 'Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|efficient_exploration_using_modelbased_qualitydiversity_with_gradients	/pdf/8ec03a2b506da8624df3a90d1b70c1b3858cf508.pdf
IfxsiXMZoNX	4740	 Debiasing the Pre-trained Language Model  Through Fine-tuning the Downstream Tasks	['NLP', 'Debiasing pre-trained langugae model', 'Social biases', 'Robustness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|debiasing_the_pretrained_language_model_through_finetuning_the_downstream_tasks	/pdf/dea3d7cdbe49507c6ebdd6a424be26683a2ccdc6.pdf
s5GClg38TU	4742	Is end-to-end learning enough for fitness activity recognition?	['end-to-end learning', 'action recognition', '3D convolution', 'video', 'fitness']	With appropriately labeled data end-to-end learning on raw pixels can compete with pose estimation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|is_endtoend_learning_enough_for_fitness_activity_recognition	/pdf/1db5b6bc76f7aeb4bc36d1509dae0aabd19cb491.pdf
fgaiMgCpZV	4744	Data dependent frequency sensitivity of convolutional neural networks	['deep learning', 'convolutional neural networks', 'sparsity', 'matrix factorization', 'robustness']	We show with theory and experiments that the observed sensitivity of convolutional neural networks (CNNs) to low frequency perturbations of input images is a consequence of the frequency distribution of natural images.	Deep Learning and representational learning	anonymous|data_dependent_frequency_sensitivity_of_convolutional_neural_networks	/pdf/b378cc0e1c42f223827e40b2866fc33dbfb9610e.pdf
WgbcOQMNXB	4745	Large language models are not zero-shot communicators	['large language models', 'pragmatics', 'natural language processing', 'communication', 'conversation', 'implicature']	Large language models are significantly worse than humans in interpreting language in context, which is a crucial aspect of communication.	Applications (eg, speech processing, computer vision, NLP)	anonymous|large_language_models_are_not_zeroshot_communicators	/pdf/6d8b5c52e58dadec83ac5e2ee2a41a524253b8af.pdf
r8Mu7idxyF	4746	Making Better Decision by Directly Planning in Continuous Control	['Model-based Reinforcement Learning', 'Reinforcement Learning', 'Planning', 'Policy Optimization']	Directly using the environment model to do the planning might be an efficient way when making decision. We propose a novel POMP algorithm with a D3P planner module to achieve the efficient planning in the continuous action space control problem.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|making_better_decision_by_directly_planning_in_continuous_control	/pdf/b0dd06cac3a4a97915d65619da5d96a9e9e8dca4.pdf
3z1Ws6GEYV4	4749	Multi-Objective GFlowNets	['generative flow networks', 'multi-objective optimization', 'drug discovery', 'material design']	We generate diverse Pareto-optimal candidates for high-dimensional multi-objective optimization problems with GFlowNets. 	Generative models	anonymous|multiobjective_gflownets	/pdf/1b6dccaf05fa37890c8dbc3d12f7cf11b925ff85.pdf
5mqFra2ZSuf	4750	SP2 : A Second Order Stochastic Polyak Method	[]		Optimization (eg, convex and non-convex optimization)	anonymous|sp2_a_second_order_stochastic_polyak_method	/pdf/58795d2df69b7dc8c84a0dd7d6fcdaa74e7e5f35.pdf
4WjVKtMUOP	4751	Bounded Attacks and Robustness in Image Transform Domains	['Adversarial example', 'white-box attack', 'neural networks', 'discrete linear transforms', 'DCT', 'JPEG', 'wavelet']	A novel set of attacks operating in the well-known DCT DWTs domains that do not abolish the usual $L^\infty$ threat model, leading to adversarial examples with higher visual similarity and better adversarial learning transferability.	Deep Learning and representational learning	anonymous|bounded_attacks_and_robustness_in_image_transform_domains	/pdf/dccffe609fab1a56277f776d9ae6aa7694fab871.pdf
ULnHxczCBaE	4752	On the Convergence of AdaGrad on $\mathbb{R}^d$: Beyond Convexity, Non-Asymptotic Rate and Acceleration	['Convex Optimization', 'Adaptive Algorithms']	New techniques to prove the convergence rate of AdaGrad and new accelerated adaptive algorithms without bounded domain assumption beyond standard convex and smooth functions	Optimization (eg, convex and non-convex optimization)	anonymous|on_the_convergence_of_adagrad_on_\mathbbr^d_beyond_convexity_nonasymptotic_rate_and_acceleration	/pdf/e5dc7a6147390a9c09df4ed02149b46080578682.pdf
MT2l4ziaxeE	4753	Know Your Boundaries: The Advantage of Explicit Behavior Cloning in Offline RL	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|know_your_boundaries_the_advantage_of_explicit_behavior_cloning_in_offline_rl	/pdf/d1c57b9d088020d137c10635667f91d4dfc2d752.pdf
woOQ5Hb1oOF	4754	Brain Signal Generation and Data Augmentation with a Single-Step Diffusion Probabilistic Model	['diffusion probabilistic model', 'generative model', 'electroencephalograpghy', 'eeg', 'erp', 'motor imagery', 'synthesis', 'augmentation']	We show on multiple brain signal datasets that distilled diffusion probability models can synthesize EEG signals with high accuracy and diversity, which can be used for data augmentation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|brain_signal_generation_and_data_augmentation_with_a_singlestep_diffusion_probabilistic_model	/pdf/7f791a78a8c779a82018ddd5cc77f196864a226f.pdf
5eCi6tAPc7	4756	Learning implicit hidden Markov models using neural likelihood-free inference	['likelihood-free', 'Bayesian inference', 'simulation based inference', 'ABC-SMC', 'HMM', 'simulator', 'implicit models']	We propose a novel method, using an autoregressive-flow, for carrying out likelihood-free Bayesian inference of a hidden Markov model	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|learning_implicit_hidden_markov_models_using_neural_likelihoodfree_inference	/pdf/95f21fa64b82b8cf1a5586a955b8c21d80228425.pdf
3IXDfzaJ2LF	4758	Flatter, Faster: Scaling Momentum for Optimal Speedup of SGD	['SGD', 'momentum', 'acceleration', 'generalization', 'scaling limit', 'deep learning', 'implicit bias', 'implicit regularization']	We find the implicit bias induced by noise in SGD with momentum; this leads us to identify a scaling limit of the momentum hyperparameter in the learning rate that maximally accelerates training, without depleting generalization.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|flatter_faster_scaling_momentum_for_optimal_speedup_of_sgd	/pdf/1972b4cbc024612382a82ceb9e5026e63b031360.pdf
ubqLbhIzbk	4759	Reducing the Capacity Gap via Spherical Knowledge Distillation	['Knowledge Distillation', 'Model Compression']	This work proposes an efficient knowledge distillation method to train competitive students distilled by oversized teachers.	Deep Learning and representational learning	anonymous|reducing_the_capacity_gap_via_spherical_knowledge_distillation	/pdf/81b404e9ad34bf1a05f5ef0e9934397bb9c41d5b.pdf
ZAgV_f00Mm	4760	Revisiting Structured Dropout	[]		General Machine Learning (ie none of the above)	anonymous|revisiting_structured_dropout	/pdf/b59913f4a2a92b79befd965859f471e60bf864ee.pdf
GUfVNbxIYv	4761	$\Phi$-DVAE: Learning Physically Interpretable Representations with Nonlinear Filtering	['variational autoencoder', 'nonlinear filter', 'physics-informed', 'parameter estimation', 'variational inference', 'Bayesian inverse problems']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|\phidvae_learning_physically_interpretable_representations_with_nonlinear_filtering	/pdf/f404f06ca716ff76daeda157c1d9342b70cb8718.pdf
yXk83o735o	4763	Conformal Prediction is Robust to Label Noise	[]		General Machine Learning (ie none of the above)	anonymous|conformal_prediction_is_robust_to_label_noise	/pdf/d2773c901f8f6e01d2aaf1db48b4353b7bd19693.pdf
2W6ExpOzWGV	4764	AQuaMaM: An Autoregressive, Quaternion Manifold Model for Rapidly Estimating Complex SO(3) Distributions	[]		Deep Learning and representational learning	anonymous|aquamam_an_autoregressive_quaternion_manifold_model_for_rapidly_estimating_complex_so3_distributions	/pdf/049d296e21d7a45832e4e1ed6bee4882fe2392d3.pdf
Q-neeWNVv1	4765	Order Matters: Agent-by-agent Policy Optimization	['Multi-agent Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|order_matters_agentbyagent_policy_optimization	/pdf/d725fa05cdb67e068551368fcad6c9006c9cdef8.pdf
Zo9MZCOn0u	4766	Learning to Abstain from Uninformative Data	['PAC Learning', 'Sample Complexity', 'Selective Learning', 'Uninformative Data']	Learning with data contain majority uninformative data with selective loss	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|learning_to_abstain_from_uninformative_data	/pdf/36a6cb741d97a08cfdbd8f4b75723d33d1683ff6.pdf
N3FlFslv_J	4767	Multi-Hypothesis 3D human pose estimation metrics favor miscalibrated distributions	['Pose estimation', 'calibration', 'metrics', 'graph neural networks']	Pose estimation metrics favor overconfident models; we propose cGNF, a model capable of maximizing likelihood and thus estimating accurate and well-calibrated distributions of 3D poses.	Applications (eg, speech processing, computer vision, NLP)	anonymous|multihypothesis_3d_human_pose_estimation_metrics_favor_miscalibrated_distributions	/pdf/8a8644ea0032e79ebfd79a6255fa889966830df9.pdf
yVcLmMW5ySI	4768	PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for Generalized Category Discovery	['Novel class discovery', 'General category discovery', 'Self-supervised learning', 'Label propagation']	Our approach seeks to discover known and unknown classes in the unlabelled datasets using affinity relationships between samples via auxiliary prompts.	Deep Learning and representational learning	anonymous|promptcal_contrastive_affinity_learning_via_auxiliary_prompts_for_generalized_category_discovery	/pdf/7c6bff92682f59384e35b39dd53ae9e3bad8cd03.pdf
FbRY1XVfwK	4769	Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|accelerating_hamiltonian_monte_carlo_via_chebyshev_integration_time	/pdf/d436e9c077b7f3178bc5fb6ec54879472fa6002f.pdf
3LUxNRrhK1	4770	Robust Graph Representation Learning via Predictive Coding	['Predictive coding', 'deep geometric learning', 'deep learning', 'machine learning', 'bio-inspired learning', 'neuroscience']	For the first time, we use predictive coding in deep geometric learning and demonstrate that we can enhance the robustness of learning representation through energy minimization.	Deep Learning and representational learning	anonymous|robust_graph_representation_learning_via_predictive_coding	/pdf/c868a60fe0b1513c81dce3c74cf6cca9e8c88bef.pdf
fKemamaw9M	4771	Robustifying Language Models via Adversarial Training with Masked Gradient	['NLP', 'language model', 'robustness', 'classification']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robustifying_language_models_via_adversarial_training_with_masked_gradient	/pdf/8a4c15e0762a8fc2e6215d0e6812df9d12907935.pdf
_5sMa2sdU4	4772	FedAvg Converges to Zero Training Loss Linearly: The Power of Overparameterized Multi-Layer Neural Networks	['Overparameterized Neural Network', 'FedAvg']		Optimization (eg, convex and non-convex optimization)	anonymous|fedavg_converges_to_zero_training_loss_linearly_the_power_of_overparameterized_multilayer_neural_networks	/pdf/777098bb8c5ea4ff245a22b69d61cc5a629ad109.pdf
adN-ccNeW4d	4774	Synaptic Dynamics Realize First-order Adaptive Learning and Weight Symmetry	['synapses', 'optimizer', 'biologically plausible', 'weight transport', 'Adam']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|synaptic_dynamics_realize_firstorder_adaptive_learning_and_weight_symmetry	/pdf/c28c586264811cc04bc0632923c902677b32fdf6.pdf
JgwnZxlxA46	4775	On Gradient Descent Convergence beyond the Edge of Stability	['gradient descent', 'edge of stability']	We prove convergence results of Gradient Descent beyond Edge of Stability in several nonlinear and high-dimensional problems.	Optimization (eg, convex and non-convex optimization)	anonymous|on_gradient_descent_convergence_beyond_the_edge_of_stability	/pdf/26d97ee0374fd0d13f0d0f3736cf270642331363.pdf
BW9KtL-bott	4776	SPIDER: Searching Personalized Neural Architecture for Federated Learning	['Personalized Neural Architecture Search', 'Data Heterogeneity', 'Personalized Federated Learning']	SPIDER searches and trains heterogeneous architectures in a federated learning setting to achieve the objective of personalization.	Deep Learning and representational learning	anonymous|spider_searching_personalized_neural_architecture_for_federated_learning	/pdf/fd9d8127d2f54ea86148accca727411f861588d9.pdf
xzqyoU4PsUj	4777	Unsupervised Non-Parametric Signal Separation Using Bayesian Neural Networks	['bayesian neural networks', 'probabilistic graphical models', 'signal disaggregation']	Authors propose using BNNs as building blocks of graphical models and apply it to the spectral/spatial additive mixture example (signal/background).	Unsupervised and Self-supervised learning	anonymous|unsupervised_nonparametric_signal_separation_using_bayesian_neural_networks	/pdf/d1b29127ce9df5424af583b126393b9f656792c6.pdf
a6rCdfABJXg	4778	Architectural optimization over subgroups of equivariant neural networks	['equivariance', 'neural architecture search', 'geometric deep learning']	Towards architectural optimization over subgroups of equivariant neural networks, we present two mechanisms for approximate equivariance over subgroups and two equivariance-aware neural architecture search algorithms that utilize them.	Deep Learning and representational learning	anonymous|architectural_optimization_over_subgroups_of_equivariant_neural_networks	/pdf/1db5fad920b054a01e08c506e5c7b0323287f3ef.pdf
YzOEjv-7nP	4780	PALM: Preference-based Adversarial Manipulation against Deep Reinforcement Learning	['adversarial attack', 'deep reinforcement learning', 'preference-based reinforcement learning', 'bi-level optimization']	A preference-based adversarial attack method that manipulates the victim policy to perform human desired behaviors.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|palm_preferencebased_adversarial_manipulation_against_deep_reinforcement_learning	/pdf/132cc87da52c6c789e88b2669aa752004f576c09.pdf
-PL1Gk4jt7	4781	Key Design Choices for Double-transfer in Source-free Unsupervised Domain Adaptation	['Transfer Learning', 'Unsupervised Domain Adaptation']	We systematically analyze the impact of the main design choices in Source-free Unsupervised Domain Adaptation through a large-scale empirical study.	Unsupervised and Self-supervised learning	anonymous|key_design_choices_for_doubletransfer_in_sourcefree_unsupervised_domain_adaptation	/pdf/ba7215e81ca2b7229d2077024ad0a899f59221cc.pdf
_5Q4covjmH	4782	A Simulation-based Framework for Robust Federated Learning to Training-time Attacks	['Robust federated learning', 'training-time attacks', 'game theory']	We frame robust distributed learning problem as a game between a server and an adversary that optimizes strong training-time attacks.	General Machine Learning (ie none of the above)	anonymous|a_simulationbased_framework_for_robust_federated_learning_to_trainingtime_attacks	/pdf/5f061bf6254407ae4c4b81f480bbfce9a7329bec.pdf
8gd4M-_Rj1	4783	Hebbian Deep Learning Without Feedback	['Hebbian', 'winner-take-all', 'cortical circuits', 'unsupervised', 'online', 'biologically plausible', 'neuromorphic']	Advancing the state of the art in bio-plausible Deep Learning, and the plausibility of DL, through Hebbian plasticity and soft winner-take-all nets.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|hebbian_deep_learning_without_feedback	/pdf/9d04a4e7342fc4c10ca3392a80520a43c95674d0.pdf
lpxeg8dhJ-	4784	Training Equilibria in Reinforcement Learning	['theory', 'reinforcement learning', 'learning dynamics', 'partial observability', 'MDP', 'POMDP', 'markov decision processes']	We study conditions under which RL algorithms get stuck in local optima, and how to mitigate them.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|training_equilibria_in_reinforcement_learning	/pdf/1dc74c3731369f28de2794f686e615fcb9acd4f3.pdf
JzrPpPnTUhk	4785	Unleash Model Capacity for Universal Dense Retrieval by Task Specialty Optimization	['Dense Retrieval', 'Multi-task', 'Parameter sensitivity']		Applications (eg, speech processing, computer vision, NLP)	anonymous|unleash_model_capacity_for_universal_dense_retrieval_by_task_specialty_optimization	/pdf/41326cdbe7d720a61acb918c10983726016c00d4.pdf
Lr8cOOtYbfL	4786	Planning with Large Language Models for Code Generation	['Large Language Model', 'Code Generation', 'Planning']	We provide a novel framework for code generation by combining the advantages of a large language model and a planning algorithm.	Deep Learning and representational learning	anonymous|planning_with_large_language_models_for_code_generation	/pdf/627d89b4af37a84b0ee81e28bc64b6d0c6baaa2f.pdf
ooxDOe7ZtBe	4787	Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees	[]	An interpretable framework for abstractive summarization with neural modular trees	Applications (eg, speech processing, computer vision, NLP)	anonymous|summarization_programs_interpretable_abstractive_summarization_with_neural_modular_trees	/pdf/7d88d1fb2f3a0e09231f498c9ad5420c126de3d6.pdf
Z2Kgq-czhh	4788	FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels	['Hawkes processes', 'Neuroscience']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|fadin_fast_discretized_inference_for_hawkes_processes_with_general_parametric_kernels	/pdf/c9e9a181352cbbbedf9d430aa9ae6d4d6023d3f9.pdf
9rRhMKNOkeT	4789	Concept-based Explanations for Out-of-Distribution Detectors	['out-of-distribution detection', 'interpretability', 'concept-based explanations']	We propose the first work to provide concept-based explanations for out-of-distribution detectors.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|conceptbased_explanations_for_outofdistribution_detectors	/pdf/e897284ea4d23ed002a58f08513bb83054aa8826.pdf
GKB566-8WkZ	4790	Explainability as statistical inference	['Interpretability', 'Explainability', 'Statistical Learning', 'Imputation']	We propose to embed any classification or regression model in a framework that casts interpretability as a maximum likelihood problem.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|explainability_as_statistical_inference	/pdf/bc3e8259cee77915dbeb24fa63a0adf569f83f6e.pdf
coLtCLTHFbW	4791	DP-SGD-LF: Improving Utility under Differentially Private Learning via Layer Freezing	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|dpsgdlf_improving_utility_under_differentially_private_learning_via_layer_freezing	/pdf/9b50e5f6c211353ca52c3206b2b5d2bbfa24f423.pdf
9ZpciCOunFb	4792	Symmetries, Flat Minima and the Conserved Quantities of Gradient Flow	['symmetry', 'gradient flow', 'conserved quantity', 'flat minima', 'Lie group', 'Lie algebra']	We introduce a framework for finding linear and nonlinear continuous symmetries in deep learning and show how they lead to extended local minima and conserved quantities	Optimization (eg, convex and non-convex optimization)	anonymous|symmetries_flat_minima_and_the_conserved_quantities_of_gradient_flow	/pdf/170c0bd26de5de607c996e152d98f1f2b6b37fad.pdf
S80ioOGLpD9	4793	Joint-Predictive Representations for Multi-Agent Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|jointpredictive_representations_for_multiagent_reinforcement_learning	/pdf/fd38a4671d8914e031e8c493744aaf8403e4d41e.pdf
XKq49kJ5mZX	4795	How to Enable Uncertainty Estimation in Proximal Policy Optimization	['Reinforcement Learning', 'Uncertainty Estimation', 'Out-of-distribution detection', 'Proximal Policy Optimizaiton']	A setup and comparison of out-of-distribution detection methods for PPO, with Masksembles as a novel, well-performing method in the setting of RL	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|how_to_enable_uncertainty_estimation_in_proximal_policy_optimization	/pdf/94ab6d6222a2a82ff55826249c29c0e31ff805d4.pdf
mBkUeW8rpD6	4798	DiscoBAX - Discovery of optimal intervention sets in genomic experiment design	['Optimal experiment design', 'Bayesian Algorithm Execution', 'Active learning', 'Genetic intervention', 'Drug design']	We introduce DiscoBAX — a sample-efficient algorithm for the discovery of genetic interventions that maximize the movement of a phenotype in a direction of interest while covering a diverse set of underlying mechanisms	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|discobax_discovery_of_optimal_intervention_sets_in_genomic_experiment_design	/pdf/a3611b008950142091c527a4e48446bd246e18bf.pdf
nAgdXgfmqj	4800	Hyperparameter Optimization through Neural Network Partitioning	['Hyperparameter optimization', 'invariances', 'data-augmentation', 'marginal likelihood', 'federated learning']	We introduce partitioned networks and an out-of-training sample loss for scalable optimization of hyperparameters	Deep Learning and representational learning	anonymous|hyperparameter_optimization_through_neural_network_partitioning	/pdf/c506dc7e80dfadf46c349072e9c66a5970fb324a.pdf
WDX-0gwK7C	4801	Quantitative Universal Approximation Bounds for Deep Belief Networks	['Deep belief network', 'restricted Boltzmann machine', 'universal approximation property', 'expressivity', 'Kullback-Leibler approximation', 'probability density']	We prove quantitative approximation results for deep belief networks with binary hidden units.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|quantitative_universal_approximation_bounds_for_deep_belief_networks	/pdf/5bf4ec99ce4f89fcf1022ed1ba234c6a887787e2.pdf
a70lGJ-rwy	4802	Few-shot Backdoor Attacks via Neural Tangent Kernels	['kernel regression', 'backdoor attack', 'data poisoning', 'robust machine learning', 'neural tangent kernel']	We provide a new algorithm based on intuitions from kernel regression that uses neural tangent kernels to design stronger backdoor attacks.	Deep Learning and representational learning	anonymous|fewshot_backdoor_attacks_via_neural_tangent_kernels	/pdf/4fc8222ac5b4cd79e4f602d2fe02fcd90fcc8296.pdf
nAvBCvT5oA	4803	Learning Portable Skills by Identifying Generalizing Features with an Attention-Based Ensemble	['Hierarchical reinforcement learning', 'Skill transfer', 'Ensembling']	We learn a generalizing state feature for skill transfer using an attention-based ensemble.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_portable_skills_by_identifying_generalizing_features_with_an_attentionbased_ensemble	/pdf/1b58438c4e2ff3a7396f037027fdb8707d327853.pdf
Gid_Z_oUV5q	4804	SARNET: SARCASM VS TRUE-HATE DETECTION NETWORK	"['Game Theory', 'Hate Speech', 'Sarcasm', 'Nash Equilibrium', ""Prisoner's Dilemma""]"	This research paper focuses on quasi-ternary classification of hate and sarcasm in a tweet using game theory, Nash Equilibrium and deep learning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sarnet_sarcasm_vs_truehate_detection_network	/pdf/f85b657e2cd4f791a7fc8bd23edbbbb7b9b0a2a8.pdf
AfmFjelAqW6	4805	Hierarchical Neural Program Synthesis	[]		Deep Learning and representational learning	anonymous|hierarchical_neural_program_synthesis	/pdf/c2bf4dc9192114a824aaa8c7eb7d734e31a806d3.pdf
2a3aR6geXxy	4807	Explanation Uncertainty with Decision Boundary Awareness	['Explainability', 'Interpretability', 'XAI', 'Feature Importance', 'Explanation Uncertainty', 'Reliability']	We introduce a method that generates uncertainty estimates for feature attribution explanations.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|explanation_uncertainty_with_decision_boundary_awareness	/pdf/ec4c2faf440a46763f49c973c8aaed642d60032c.pdf
Q5uQecAw0vO	4808	Reinforcement Learning for Bandits with Continuous Actions and Large Context Spaces	['Contextual bandits', 'Continuous actions', 'Image context', 'reinforcement learning']	We propose a reinforcement learning approach for the challenging contextual bandits scenario with continuous actions that can generalise to large context' spaces, unlike the current literature. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|reinforcement_learning_for_bandits_with_continuous_actions_and_large_context_spaces	/pdf/ad9b6cd2119904472a3c0d57b64d81fa80eb5f8e.pdf
US0hgxTfU7i	4809	Unscented Autoencoder	['generative models', 'variational autoencoders', 'deterministic autoencoders', 'unscented transform', 'wasserstein metric']	Sampling fixed sigma points and regularizing posterior moments in VAEs promotes reconstruction quality while preserving a smooth latent space.	Generative models	anonymous|unscented_autoencoder	/pdf/cc052500fb305adc572c7e8684b6f2c19c0ea1cd.pdf
47C06k5D2cn	4811	Blessing from Experts: Super Reinforcement Learning in Confounded Environments	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|blessing_from_experts_super_reinforcement_learning_in_confounded_environments	/pdf/4ee6914d4ee87bddbf2b71c76df6d72462653da9.pdf
R370fuGO7JJ	4812	Multi-scale Attention for Diabetic Retinopathy Detection in Retinal Fundus Images	['diabetes', 'deep learning', 'diabetic retinopathy', 'microvascular complication', 'hyperglycemia', 'attention', 'CNN']	This paper proposed a novel deep learning-based approach for grading of Diabetic Retinopathy in fundus photograph	Applications (eg, speech processing, computer vision, NLP)	anonymous|multiscale_attention_for_diabetic_retinopathy_detection_in_retinal_fundus_images	/pdf/1a1a9a1c13278e783fb763f143332781b4a98087.pdf
fa7PVbrgpj	4813	P2PRISM - Peer to peer learning with individual prism for secure aggregation	['peer-to-peer', 'decentralized learning', 'byzantine-robust']	We highlight the vulnerabilities in peer-to-peer learning towards malicious attacks and propose a byzantine-robust defense against the same.	General Machine Learning (ie none of the above)	anonymous|p2prism_peer_to_peer_learning_with_individual_prism_for_secure_aggregation	/pdf/5d551f754e2315a68cf54726b809fb6d3dbe6f1c.pdf
bAz2DBS35i	4814	Noise-Robust De-Duplication at Scale	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|noiserobust_deduplication_at_scale	/pdf/524f1e0748bc02c4e8c9d80eb74f3788a0082394.pdf
SoyOsp7i_l	4815	Logical Message Passing Networks with One-hop Inference on Atomic Formulas	['knowledge graph', 'complex query answering', 'graph neural network', 'representation learning']		Deep Learning and representational learning	anonymous|logical_message_passing_networks_with_onehop_inference_on_atomic_formulas	/pdf/b081188171ee7c06eab56c3bd92cfb3da6ea5d45.pdf
I8ly64E5Nt	4816	Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models	['sparsity', 'language model', 'efficient']	We develop a new class of large language models that is embarrassingly parallel: different parts of the model are independently trained on different subsets of the data, with no need for multi-node training or inference.	Applications (eg, speech processing, computer vision, NLP)	anonymous|branchtrainmerge_embarrassingly_parallel_training_of_expert_language_models	/pdf/aa04f2c9567612c353bfed6b0556af18426d2ec2.pdf
5IND3TXJRb-	4818	Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation	[]		Deep Learning and representational learning	anonymous|lossless_adaptation_of_pretrained_vision_models_for_robotic_manipulation	/pdf/906c3a655026b336012ad8b34562f8549c72e5ff.pdf
SKat5ZX5RET	4819	Self-Programming Artificial Intelligence Using Code-Generating Language Models	['Self-programming AI', 'NLP', 'code generation', 'AutoML']	We develop and experimentally validate the first practical implementation of a self-reprogramming AI system. 	Deep Learning and representational learning	anonymous|selfprogramming_artificial_intelligence_using_codegenerating_language_models	/pdf/442c14257f8c1d2d2adcb2351d27dc64a739f5d7.pdf
K1DdnjL6p7	4821	A simple Training-Free Method for Rejection Option	['rejection option', 'safety AI', 'deep learning']	We present a simple yet effective method to implement the rejection option for a pre-trained classifier. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_simple_trainingfree_method_for_rejection_option	/pdf/950ddc64e56822dcd1d784958da615c0b1ce0984.pdf
T5nUQDrM4u	4822	Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints	['mixture of experts', 'sparse', 'vision', 'language', 'deep learning', 'superglue', 'imagenet']	We create sparsely activated Mixture-of-Experts models from pre-existing dense models, showing significant performance improvements and computational savings in doing so.	Deep Learning and representational learning	anonymous|sparse_upcycling_training_mixtureofexperts_from_dense_checkpoints	/pdf/99d9371d468a5f6f793c4c89bd616cdc8fccfcf4.pdf
fGMKL9dNR1	4823	EF21-P and Friends: Improved Theoretical Communication Complexity for Distributed Optimization with Bidirectional Compression	['communication compression', 'bidirectional compression', 'error feedback', 'distributed optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|ef21p_and_friends_improved_theoretical_communication_complexity_for_distributed_optimization_with_bidirectional_compression	/pdf/f38fe82f5899566cd7afbcc789af60cf3ce75aca.pdf
SGQi3LgFnqj	4827	Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction	['Molecular property prediction', 'Graph grammar', 'Data-efficient model']	We propose a data-efficient molecular property predictor based on an explicit geometry of the space of molecular graphs induced by a learnable hierarchical molecular grammar.	Applications (eg, speech processing, computer vision, NLP)	anonymous|grammarinduced_geometry_for_dataefficient_molecular_property_prediction	/pdf/2056abfa7313bfd4837379ed5b105bfed78a39eb.pdf
77lSWa-Tm3Z	4828	Variational Information Pursuit for Interpretable Predictions	['Interpretable ML', 'Explainable AI', 'Information Pursuit']	A Framework for Interpretable ML	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|variational_information_pursuit_for_interpretable_predictions	/pdf/18b6b0ff141d8fc9011b2382e4c2722b96c05b93.pdf
h1o7Ry9Zctm	4829	Revisiting Robustness in Graph Machine Learning	['graph neural networks', 'adversarial robustness', 'label propagation', 'node-classification', 'stochastic block models', 'Bayes classifier', 'non-i.i.d. data', 'graph learning', 'graphs', 'robustness']	GNNs suffer from over-robustness, that is robustness beyond the point of semantic change, which can be combated by including the known label-structure at inference time.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revisiting_robustness_in_graph_machine_learning	/pdf/5056929f22495603ed08c604fed7f6902bcaa554.pdf
JVlyfHEEm0k	4830	Understanding Train-Validation Split in Meta-Learning with Neural Networks	['meta-learning', 'neural networks', 'deep learning', 'train-validation split', 'convolutional neural network']		Deep Learning and representational learning	anonymous|understanding_trainvalidation_split_in_metalearning_with_neural_networks	/pdf/d5b7192d244e5807816ebf2ab5abd904dbd11da2.pdf
bwss-i6lG45	4832	Speeding up Policy Optimization with Vanishing Hypothesis and Variable Mini-Batch Size	['reinforcement learning', 'policy optimization', 'noisy evaluation', 'variable mini-batch size', 'vanishing hypothesis', 'optimal placement of sensors']	We propose a novel reinforcement learning method to speed up policy optimization by using a vanishing hypothesis term, and a varying mini-batch size.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|speeding_up_policy_optimization_with_vanishing_hypothesis_and_variable_minibatch_size	/pdf/ada346e86597bcb35abfe5f401a9d2c1ea30b011.pdf
eQzLwwGyQrb	4834	Can We Find Nash Equilibria at a Linear Rate in Markov Games?	['Multi-Agent Reinforcement Learning', 'Markov Games', 'Linear Convergence', 'Policy Optimization']	A decentralized algorithm for finding Nash equilibria in two-player zero-sum discounted Markov games with global linear convergence.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|can_we_find_nash_equilibria_at_a_linear_rate_in_markov_games	/pdf/68cc89fa6ec47dcb8191cff949f58411782e7901.pdf
eR2dG8yjnQ	4835	Using Language to Extend to Unseen Domains	['vision and language', 'robust training', 'domain adaptation']	Transforming multimodal embeddings with language improves accuracy on an unseen domain. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|using_language_to_extend_to_unseen_domains	/pdf/22bcf215488fc67b6ea6cf2b8d7990bce8d866c9.pdf
_eTZBs-yedr	4838	CrAM: A Compression-Aware Minimizer	['compression', 'sparsity', 'one shot pruning', 'optimization']	We propose a method for training accurate models that are robust to compression in a single step. 	Deep Learning and representational learning	anonymous|cram_a_compressionaware_minimizer	/pdf/0be75e5b2e9ca3bbddeebf35fd7461e5f06d66aa.pdf
K75z1mX4VTo	4839	An Empirical Study on the Efficacy of Deep Active Learning Techniques	['deep neural networks', 'active learning', 'semi-supervised learning']	Our paper provides a comprehensive empirical study of existing deep active learning methods.	General Machine Learning (ie none of the above)	anonymous|an_empirical_study_on_the_efficacy_of_deep_active_learning_techniques	/pdf/18c88c7f5e1e879a25bc80d387586cea8f118761.pdf
b0RuGUYo8pA	4840	Transfer Learning with Deep Tabular Models	['tabular data', 'transfer learning', 'tabular models', 'representation learning']	We find that transfer learning with deep tabular models provides a definitive advantage over gradient boosted decision tree methods when downstream data is limited.	Deep Learning and representational learning	anonymous|transfer_learning_with_deep_tabular_models	/pdf/59cff4b0046f9a928d7a889098179cd3cb2c9e61.pdf
PDG4-Y3aboN	4842	FIT: A Metric for Model Sensitivity	['Fisher Information', 'Quantization']	We propose the Fisher Information Trace (FIT) metric, to quantify the effects of mixed-precision quantization. FIT facilitates zero-shot performance prediction of quantized models, and is fast to compute.	General Machine Learning (ie none of the above)	anonymous|fit_a_metric_for_model_sensitivity	/pdf/7fa9899f68663e60aa2f56ab577870eeb55bf019.pdf
sSt9fROSZRO	4843	Investigating Multi-task Pretraining and Generalization in Reinforcement Learning	['generalization', 'transfer', 'atari']	Multi-task training and generalization on Atari game variants, showing benefits from fine-tuning over zero shot and scaling data size and model capacity.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|investigating_multitask_pretraining_and_generalization_in_reinforcement_learning	/pdf/09d7fe0167896db0b9e3470eec5eda92e34adee5.pdf
I1Mdyc2Bg5x	4844	Pre-train Graph Neural Networks for Brain Network Analysis	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pretrain_graph_neural_networks_for_brain_network_analysis	/pdf/9bc1fd9bd21c4bf3ba116913babfffc2d11a18df.pdf
T6HPzkhaKeS	4845	Action Matching: A Variational Method for Learning Stochastic Dynamics from Samples	[]	We propose Action Matching for modeling stochastic dynamics by learning an underlying mechanism to move samples.	Generative models	anonymous|action_matching_a_variational_method_for_learning_stochastic_dynamics_from_samples	/pdf/592c82c49d7101d1b2f062e41bda3fd26ce55150.pdf
EGIvMUk5duH	4846	Exploring Connections Between Memorization And Membership Inference	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|exploring_connections_between_memorization_and_membership_inference	/pdf/2247e7c663e56434e86aa61a961767bcfb97995d.pdf
_geIwiOyUhZ	4847	Bayes-MIL: A New Probabilistic Perspective on Attention-based Multiple Instance Learning for Whole Slide Images	['Multiple instance learning', 'medical imaging', 'histopathology', 'Bayesian neural network']	Bayesian modeling of multiple instance learning addresses untrustworthy and unsatisfactory interpretability problem of related methods. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|bayesmil_a_new_probabilistic_perspective_on_attentionbased_multiple_instance_learning_for_whole_slide_images	/pdf/412015a221292395507ce01f907ed905af3cacd8.pdf
uyqks-LILZX	4848	Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization	[]		Deep Learning and representational learning	anonymous|modeling_the_datagenerating_process_is_necessary_for_outofdistribution_generalization	/pdf/2c7700a6c56d45ead04d1e30d972e647dcae4abc.pdf
RIJM-pJF_3K	4849	Causally Constrained Data Synthesis For Private Data Release	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|causally_constrained_data_synthesis_for_private_data_release	/pdf/accaf0a0c437aa4aa099c6d5ada1e2c443734628.pdf
gOoONbY02OUz	4850	A Deep Dive into Dataset Imbalance and Bias in Face Identification	['face recognition', 'dataset imbalance', 'bias', 'fairness']	In this work, we explore the effects of different kinds of data imbalance on bias in face identification problem. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_deep_dive_into_dataset_imbalance_and_bias_in_face_identification	/pdf/81d68f16a422349e582ddc39f880d69593a34e7a.pdf
j8IiQUM33s	4851	Task-customized Masked Autoencoder via Mixture of Cluster-conditional Experts	[]		Unsupervised and Self-supervised learning	anonymous|taskcustomized_masked_autoencoder_via_mixture_of_clusterconditional_experts	/pdf/ee763683df6b8774b28fc46712047697e9650afc.pdf
guSxooOK9E	4852	On the (Non-)Robustness of Two-Layer Neural Networks in Different Learning Regimes	['robustness', 'adversarial robustness', 'over-parametrization', 'lazy training', 'parent-student', 'regression']	Tradeoffs between test-error and robustness for 2-layer neural networks in different learning regimes (RF, lazy training, SGD)	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_nonrobustness_of_twolayer_neural_networks_in_different_learning_regimes	/pdf/df812223689b0f94e07843e46ab0ca794e67813a.pdf
5MkYIYCbva	4853	Long Range Language Modeling via Gated State Spaces	['Long range language modeling', 'language modeling', 'state space models']	Explore and improve state space model family on long range language modeling tasks	Generative models	anonymous|long_range_language_modeling_via_gated_state_spaces	/pdf/8d99956d8e226d02e882023ecd467ee05e216163.pdf
vOEXS39nOF	4854	Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions	['generative models', 'video generation', 'video prediction', 'text to video']	Generating videos from text, with prompts that can change over time, and videos that can be as long as multiple minutes.	Generative models	anonymous|phenaki_variable_length_video_generation_from_open_domain_textual_descriptions	/pdf/61f9d41630425ee44f4974c6886c27e02966770a.pdf
Kyz1SaAcnd	4855	Adversarial Policies Beat Professional-Level Go AIs	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adversarial_policies_beat_professionallevel_go_ais	/pdf/b435af4e4daada3868562b7f6021bc492a91b930.pdf
VO-HUrkHSY	4856	FedLite: Improving Communication Efficiency in Federated Split Learning	[]		General Machine Learning (ie none of the above)	anonymous|fedlite_improving_communication_efficiency_in_federated_split_learning	/pdf/df7fab45c918a404119ffbbebea27a4fcd76d0f0.pdf
G2AA1eB1vVE	4857	Learning Robust Representations via Nuisance-extended Information Bottleneck	['out-of-distribution robustness', 'information bottleneck', 'representation learning', 'autoencoder']	We propose to model the nuisance of information bottleneck for out-of-distribution generalization.	Deep Learning and representational learning	anonymous|learning_robust_representations_via_nuisanceextended_information_bottleneck	/pdf/db93d29fe269d61750d08c0d0675a4c56ee6edb7.pdf
pKu077C57fH	4858	Towards a Mathematics Formalisation Assistant using Large Language Models	['Large Language Models', 'Mathematics Formalisation']	Large language models have the potential to be useful for mathematics formalization	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|towards_a_mathematics_formalisation_assistant_using_large_language_models	/pdf/c0cdcd692795c4d88b558b5b2ea56024167cbbf8.pdf
j1zQGmQQOX1	4860	Differentially Private Adaptive Optimization with Delayed Preconditioners	['adaptive optimization', 'differential privacy']	We propose a private adaptive optimization framework that constructs delayed but less noisy preconditioners, yielding improved privacy/utility trade-offs without the need to access auxiliary data.	Optimization (eg, convex and non-convex optimization)	anonymous|differentially_private_adaptive_optimization_with_delayed_preconditioners	/pdf/7c6e9662b584c61b15539e3085fe019b88af18bc.pdf
TAVBJ4aHsWt	4862	SemPPL: Predicting Pseudo-Labels for Better Contrastive Representations	['contrastive learning', 'representation learning', 'semi-supervised learning']		Deep Learning and representational learning	anonymous|semppl_predicting_pseudolabels_for_better_contrastive_representations	/pdf/bc8241aabd2f8b658ed5e7fce1fae147bebf39dc.pdf
djfoLX57p9L	4864	Learning the Visualness of Text Using Large Vision-Language Models	['text visualness', 'vision-language models', 'multimodal learning', 'natural language processing', 'deep learning']	We propose the task of predicting sentence visualness, curate a human-annotated dataset, and develop a fine-tuning strategy to predict sentence visualness using large vision-language models. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_the_visualness_of_text_using_large_visionlanguage_models	/pdf/54ce2c5a24afc88784432c13346527986a41a9d1.pdf
lYP6zG2I1i	4866	The Crossword Puzzle: Simplifying Deep Neural Network Pruning with Fabulous Coordinates	['Pruning']	Fabulous coordinates can make pruning more simplified, efficient and effective.	Deep Learning and representational learning	anonymous|the_crossword_puzzle_simplifying_deep_neural_network_pruning_with_fabulous_coordinates	/pdf/f37a666d3709e93693716ea3f743ee2b2782683c.pdf
GK5m7a3Uy4	4867	A distinct unsupervised reference model from the environment helps continual learning	['continual Learning', 'open-set semi-supervised continual learning', 'knowledge distillation']	In this paper, we introduced open-set semi-supervised continual learning as a realistic, practical scenario and proposed a novel dual-structured method to perform in this scenario.	Deep Learning and representational learning	anonymous|a_distinct_unsupervised_reference_model_from_the_environment_helps_continual_learning	/pdf/90010a116dd9224c27a23d426bbc131fd4f989bf.pdf
p_jIy5QFB7	4868	Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for Deep Neural Networks	['Calibration', 'Kernel Density Estimation', 'Neural Networks', 'Healthcare', 'Classification']	Provable full calibration for neural network classifiers using kernel density estimation.	Deep Learning and representational learning	anonymous|taking_a_step_back_with_kcal_multiclass_kernelbased_calibration_for_deep_neural_networks	/pdf/56d60d51870aea27cc6f42f86c83547a211e2f20.pdf
dPOLZ2u4SKV	4872	Expected Probabilistic Hierarchies	['Hierarchical Clustering', 'Graph Clustering', 'Clustering', 'Probabilistic Models']	Probabilistic model learning hierarchies in data by using gradient descent based optimizers outperforming several baselines.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|expected_probabilistic_hierarchies	/pdf/b9c46167f1665270dc6cb50a8cf31bafe89d89d1.pdf
K7CbYQbyYhY	4873	Agree to Disagree: Diversity through Disagreement for Better Transferability	['OOD generalization', 'Diversity', 'Ensemble']		Deep Learning and representational learning	anonymous|agree_to_disagree_diversity_through_disagreement_for_better_transferability	/pdf/d8e99837a14898a916b8c34f70265b34da4c5469.pdf
Ho7W1yr8tV	4874	Handling Covariate Shifts in Federated Learning  with Generalization Guarantees	['Federate Learning', 'Generalization', 'Covariate Shift', 'Importance Weighting']	We optimize a global FL model focusing on the overall generalization performance under both intra-client and inter-client covariate shifts.	General Machine Learning (ie none of the above)	anonymous|handling_covariate_shifts_in_federated_learning_with_generalization_guarantees	/pdf/8e6438fde06b5013b65467294e8e5de03074bf1f.pdf
9EAQVEINuum	4875	Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning	['Named Entity Recognition', 'NER', 'Bi-Encoder', 'Contrastive Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|optimizing_biencoder_for_named_entity_recognition_via_contrastive_learning	/pdf/2fbdebcf238d6335d06d043ec1e92d980ad4f250.pdf
QsCSLPP55Ku	4876	Effective passive membership inference attacks in federated learning against overparameterized models	['membership inference attack', 'federated learning', 'overparameterization', 'neural networks', 'image classification']	The observation that gradients of large overparameterized neural networks that generalize well behave like high-dimensional independent isotropic random vectors, leads to a new class of passive membership inference attacks in federated learning.	Deep Learning and representational learning	anonymous|effective_passive_membership_inference_attacks_in_federated_learning_against_overparameterized_models	/pdf/1d07ca9206af48ec6d2cfc03a3dd1e1f65676c4f.pdf
JL7Va5Vy15J	4877	The Lie Derivative for Measuring Learned Equivariance	[]		Deep Learning and representational learning	anonymous|the_lie_derivative_for_measuring_learned_equivariance	/pdf/18dba3c05d4e7b07aea6d15ccda87d083af4a58f.pdf
IW3vvB8uggX	4878	Understanding the Complexity Gains of Contextual Multi-task RL with Curricula	['policy gradient methods', 'multi-task RL']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|understanding_the_complexity_gains_of_contextual_multitask_rl_with_curricula	/pdf/62707b03330f2beb8ee6aa899d6087db06f2a50a.pdf
VpYBxaPLaj-	4879	Robust Universal Adversarial Perturbations	['Adversarial Machine Learning', 'Trustworthy Machine Learning', 'Universal Adversarial Perturbation', 'Expectation over Transformation', 'Robustness', 'Adversarial Perturbation']	This paper introduces the concept of Robust Universal Adversarial Perturbations and a new algorithm, RobustUAP, which can be used to generate UAPs robust under human-interpretable, real-word transformations, such as rotation, contrast changes, etc.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robust_universal_adversarial_perturbations	/pdf/fa790bdec4cda324d018d12ebf689228b876a044.pdf
cfkKMKnqCzb	4880	Loop Unrolled Shallow Equilibrium Regularizer (LUSER) - A Memory-Efficient Inverse Problem Solver	['Deep Equilibrium Models', 'Inverse Problems', 'Deep Learning', 'Loop Unrolled']	This paper proposes a memory efficient loop unrolled architecture for solving inverse problems.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|loop_unrolled_shallow_equilibrium_regularizer_luser_a_memoryefficient_inverse_problem_solver	/pdf/4736837faeb53f86f586c650e3d97c7728e0c671.pdf
Oh5nigv45PI	4881	NAG-GS: semi-implicit, accelerated and robust stochastic optimizer.	['Accelerated gradient methods', 'stochastic optimization', 'stochastic differential equations', 'semi-implicit solver', 'convergence analysis', 'deep neural networks']		Optimization (eg, convex and non-convex optimization)	anonymous|naggs_semiimplicit_accelerated_and_robust_stochastic_optimizer	/pdf/2a33221b6c571cbf5407aa3f3a31f9e148afb534.pdf
LIV7-_7pYPl	4883	DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics	['Deformable Object Manipulation', 'Dexterous Manipulation', 'Differentiable Physics']	We investigate the problem of learning dexterous manipulation of deformable objects using multi-fingered hands.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|dexdeform_dexterous_deformable_object_manipulation_with_human_demonstrations_and_differentiable_physics	/pdf/e23a10cc5e99017315c55069dc553e7fab89e683.pdf
DrtSx1z40Ib	4884	Compositional Task Generalization with Discovered Successor Feature Modules	['deep reinforcement learning', 'successor features', 'generalization', 'compositional generalization']	A modular neural network for discovering, composing, and transferring predictive knowledge and behavior via Successor Features & Generalized Policy Improvement.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|compositional_task_generalization_with_discovered_successor_feature_modules	/pdf/c2314d6c9a2df7f4042ec0b755a3270b3d0b6f1f.pdf
VTYvxbr5E-A	4888	Emergence of shared sensory-motor graphical language from visual input	['Emergent Communication', 'Visual Communication', 'Sensory-motor communication', 'Contrastive Learning', 'Language Game']	We use contrastive multimodal learning to train artificial agents to communicate via a sensory-motor system producing drawings. We then show that the emerging graphical language has compositional properties	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|emergence_of_shared_sensorymotor_graphical_language_from_visual_input	/pdf/b2acd12dab4510ecfbf973232a0d2d7871058220.pdf
vFvw8EzQNLy	4890	Parallel $Q$-Learning: Scaling Off-policy Reinforcement Learning	['GPU-based simulation', 'off-policy learning', 'distributed training', 'reinforcement learning']	We present a parallel training framework that scales up $Q$-learning algorithms on a single workstation and achieves faster learning speed than PPO.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|parallel_qlearning_scaling_offpolicy_reinforcement_learning	/pdf/b9f4002aff838f2f4e2ef8b89283a46efcd46edc.pdf
20gBzEzgtiI	4891	Performance Bounds for Model and Policy Transfer in Hidden-parameter MDPs	['Reinforcement learning', 'Meta learning', 'Transfer learning', 'Theory']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|performance_bounds_for_model_and_policy_transfer_in_hiddenparameter_mdps	/pdf/8da2801adcf6acc6b06fa120f93067c36bae6a61.pdf
P4MUGRM4Acu	4892	The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry	['Equivariant Learning', 'Reinforcement Learning', 'Robotics']	This paper discovers that equivariant models are surprisingly effective in domains with latent or partial symmetries. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_surprising_effectiveness_of_equivariant_models_in_domains_with_latent_symmetry	/pdf/2f25b5027eacdc696e8b4872407c773f665993d0.pdf
hO8qWILpJ3J	4894	Complete Likelihood Objective for Latent Variable Models	['Posterior Collapse', 'Latent Variable Models', 'Complete Likelihood', 'Empirical Distribution', 'Assignment Problem']	Use sample from the prior to construct a family informative distribution and use complete likelihood to both the target from the family and tune the model.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|complete_likelihood_objective_for_latent_variable_models	/pdf/6bbe50fafd4c98861ef2b59e032de2e1ecce43f1.pdf
bNozP02z7XO	4895	MaxMin-Novelty: Maximizing Novelty via Minimizing the State-Action Values in Deep Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|maxminnovelty_maximizing_novelty_via_minimizing_the_stateaction_values_in_deep_reinforcement_learning	/pdf/01ade5f3f0bc495cdf3490e25a1196ae2427d0f3.pdf
Yg7ExbCxzt6	4896	What Matters In The Structured Pruning of Generative Language Models?	['Neural Network Pruning', 'Natural Language Generation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|what_matters_in_the_structured_pruning_of_generative_language_models	/pdf/9cdfa6b6d667ea73b981d63d874ca1681264ce62.pdf
ZpzkcSqsdmX	4898	UnDiMix: Hard Negative Sampling Strategies for Contrastive Representation Learning	['Contrastive Learning', 'Self-Supervised Learning', 'Hard Negative Sampling']	We introduce UnDimix, a hard negative sampling strategy that takes into account anchor similarity, model uncertainty and representativeness	Unsupervised and Self-supervised learning	anonymous|undimix_hard_negative_sampling_strategies_for_contrastive_representation_learning	/pdf/13909fca54e5f7fa2c1d973ebbe7c1fe6fefa589.pdf
yLCCfzv_8Yx	4899	'I pick you choose': Joint human-algorithm decision making in multi-armed bandits	['human algorithm collaboration', 'multi-armed bandits', 'complementarity']	Analysis of joint human-algorithm multi-armed bandit systems: human picks the final arms from a subset the algorithm selects. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|i_pick_you_choose_joint_humanalgorithm_decision_making_in_multiarmed_bandits	/pdf/58f3942ab289828b9fd8d97200441ad359cb875e.pdf
b3itJyarLM0	4900	Distributed Extra-gradient with Optimal Complexity and Communication Guarantees	['Unbiased Quantization', 'Variational Inequality', 'Extra-gradient', 'Adaptive Sep-size']	We propose quantized generalized extra-gradient, which is an unbiased and adaptive compression method tailored to a generic unifying framework for solving variational inequality problems.	General Machine Learning (ie none of the above)	anonymous|distributed_extragradient_with_optimal_complexity_and_communication_guarantees	/pdf/df9cc99d151702f443b027eb99b7c4edd57c8501.pdf
hWwY_Jq0xsN	4902	Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes	['Interpretable Machine Learning', 'Deep Reinforcement Learning', 'Prototypes', 'User Study']	"An ""interpretable-by-design"" deep reinforcement learning agent is proposed which uses prototypes for decision making."	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_interpretable_deep_reinforcement_learning_with_humanfriendly_prototypes	/pdf/b00f8dc0cbd2a3a907651220c9e5332147916e05.pdf
HRwN7IQLUKA	4904	Accelerated Single-Call Methods for Constrained Min-Max Optimization	['min-max optimization', 'nonconvex-nonconcave', 'variational inequalities', 'saddle point problem', 'first-order method']	We propose the first single-call single-projection algorithms with optimal convergence rate for constrained min-max optimization problems in the nonconvex-nonconcave setting.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|accelerated_singlecall_methods_for_constrained_minmax_optimization	/pdf/19498d891f32e67583822d42b089937ba7e247ed.pdf
SM7XkJouWHm	4906	ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond	[]		Deep Learning and representational learning	anonymous|contranorm_a_contrastive_learning_perspective_on_oversmoothing_and_beyond	/pdf/5321c05f0598a396a838f693367fa111835de90c.pdf
MCe881WzBr0	4907	Variational Classification	['Latent priors', 'classification']	We show how we can view a classifier as a latent variable model and impose class conditional priors on this latent space that renders the classifier more robust to OOD and adversarial data	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|variational_classification	/pdf/560e13ad99c07d3ceaee8529d43bd2116b231755.pdf
39z0zPZ0AvB	4908	Don’t forget the nullspace! Nullspace occupancy as a mechanism for out of distribution failure	[]		Deep Learning and representational learning	anonymous|dont_forget_the_nullspace_nullspace_occupancy_as_a_mechanism_for_out_of_distribution_failure	/pdf/0a0db3ec69a3bc90e1112ebdf56caf5bcc03cdee.pdf
DUfpVGCXfwa	4909	REM: Routing Entropy Minimization for Capsule Networks	['capsule networks', 'deep learning', 'entropy', 'parse tree', 'routing']	 REM is a technique for Capsule Networks which combines pruning and quantization driving these models towards a higher interpretability. REM generate a significantly lower number of parse trees, with no performance loss.	Deep Learning and representational learning	anonymous|rem_routing_entropy_minimization_for_capsule_networks	/pdf/cc8f9c5cd0c72f0a16b8da2b7d26536597fbcbf8.pdf
Gp91Et4LeRf	4910	Auditing Fairness Online through Interactive Refinement	['fairness', 'metrics', 'verification', 'inference', 'online', 'monitoring']	A visual inference-based optimization framework that facilitates the specification and auditing of fairness on blackbox ML models efficiently.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|auditing_fairness_online_through_interactive_refinement	/pdf/2937ec4caf66911909bfcd10eb1ea274b89a5a28.pdf
T9iojz-kOfU	4911	Panoptically guided Image Inpainting with Image-level and Object-level Semantic Discriminators	['Generative model', 'image inpainting', 'image manipulation']	Guided Image Inpainting and image inpainting with a novel discriminator design.	Generative models	anonymous|panoptically_guided_image_inpainting_with_imagelevel_and_objectlevel_semantic_discriminators	/pdf/e1e4050bac51ba46007a6804d6b5a70989f44471.pdf
zlbci7019Z3	4912	Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning	['Continual Learning', 'Catastrophic Forgetting', 'Multi memory System', 'Experience Replay', 'Error-Sensitivity modulation', 'Brain inspired Algorithm', 'Representation Drift']	A novel method that employs a principled mechanism for modulating the error sensitivity in a dual-memory rehearsal-based system for effective continual learning	Deep Learning and representational learning	anonymous|error_sensitivity_modulation_based_experience_replay_mitigating_abrupt_representation_drift_in_continual_learning	/pdf/f8fed0c619bb17f25c7945345e1377dc3c103f81.pdf
rUb1-7H4q6a	4913	Progressive Data Dropout: An Adaptive Training Strategy for Large-Scale Supervised Learning	['data dropout', 'training optimization', 'adaptive training', 'classification', 'large-scale']	PDD is a model-agnostic strategy for removing class-level data as learned by the model during training.	General Machine Learning (ie none of the above)	anonymous|progressive_data_dropout_an_adaptive_training_strategy_for_largescale_supervised_learning	/pdf/49d0bdc07952bc0592c637b52711dd0ca3e4b8eb.pdf
4lw-X9jRi1c	4914	UniS-MMC: Learning Unimodality-supervised Multimodal Contrastive Representations	['multimodal learning', 'contrastive learning', 'multi-task learning']	This paper proposes a novel multi-task-based multimodal contrastive method for multimodal representation learning (multimodal classification task).	Deep Learning and representational learning	anonymous|unismmc_learning_unimodalitysupervised_multimodal_contrastive_representations	/pdf/fae8e3dea74e1ce43a3b92b2fe1237247b0cfdcc.pdf
Zb6c8A-Fghk	4917	Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations	['spurious correlations', 'robustness']	We propose a simple method based on retraining the last layer of a neural network which achieves strong results on spurious correlation benchmarks.	Deep Learning and representational learning	anonymous|last_layer_retraining_is_sufficient_for_robustness_to_spurious_correlations	/pdf/77786815db749a2e5d9f11bcb69c5a4841a26975.pdf
Rvee9CAX4fi	4918	The Union of Manifolds Hypothesis	['manifold hypothesis', 'geometry', 'generative models']	We show data of interest has varying intrinsic dimension, thus conforming to a union of manifolds hypothesis rather than the manifold hypothesis; and we study some implications in deep learning.	Deep Learning and representational learning	anonymous|the_union_of_manifolds_hypothesis	/pdf/f340b9d8c3506a95bc86bafcf0ffed47113abbfe.pdf
cVFD6qE8gnY	4919	Planning with Language Models through Iterative Energy Minimization	['Reinforcement Learning', 'Planning', 'Language Model', 'Decision Transformer']	Planning with Transformers through the energy minimization (MCMC sampling)	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|planning_with_language_models_through_iterative_energy_minimization	/pdf/097956ccdc5a2331e92ac587e7dcf03e06a457a4.pdf
8onXkaNWLHA	4920	Self-supervised video pretraining yields strong image representations	['self-supervised', 'contrastive', 'video', 'representation learning', 'image segmentation', 'object detection']	We achieve SoTA transfer to image scene understanding tasks using frame-based models pre-trained using contrastive learning on videos. 	Deep Learning and representational learning	anonymous|selfsupervised_video_pretraining_yields_strong_image_representations	/pdf/10cc69ec8449b3d27da8ed707096eaa8bf9658be.pdf
yI_xwoYO6cF	4922	Contrastive introspection (ConSpec) to rapidly identify invariant steps for success	['Reinforcement learning', 'long term credit assignment', 'rapid credit assignment', 'contrastive learning', 'few-shot learning in RL']	In ConSpec, a contrastive loss rapidly identifies invariances among successful episodes, even in tasks with sparse rewards and multiple contingencies.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|contrastive_introspection_conspec_to_rapidly_identify_invariant_steps_for_success	/pdf/969f1299b94e81970ab6bb804a27d178b732d6a1.pdf
98J48HZXxd5	4923	Autoregressive Diffusion Model for Graph Generation	['graph generation', 'diffusion based generative model']	A new autoregressive diffusion model for graph generation	Generative models	anonymous|autoregressive_diffusion_model_for_graph_generation	/pdf/2483b705648026c9c9b49d81c1aa2aa90b28e808.pdf
9_gsMA8MRKQ	4924	Pseudoinverse-Guided Diffusion Models for Inverse Problems	['diffusion models', 'inverse problems']	We introduce pseudoinverse guidance, an approach to solve inverse problems with generative diffusion models.	Generative models	anonymous|pseudoinverseguided_diffusion_models_for_inverse_problems	/pdf/ccf25358a8a8ee305aa3525f64bfb3de5d9eac78.pdf
kPPVmUF6bM_	4925	Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation	['Knowledge Distillation', 'Data Augmentation', 'Natural Language Processing']	We proposed an effective and efficient data augmentation paradigm for knowledge distillation	Deep Learning and representational learning	anonymous|augmentation_with_projection_towards_an_effective_and_efficient_data_augmentation_paradigm_for_distillation	/pdf/f1ae3586954a46fa8e562e5c6446febe1bd42a0e.pdf
ThXqBsRI-cY	4927	Provable Defense Against Geometric Transformations	['Certified robustness', 'geometric transformations']	We present a training framework and verifier for deterministic certified robustness against geometric transformations.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|provable_defense_against_geometric_transformations	/pdf/c4e9d6ea721ffb151897b7e511601e5d62d85ebb.pdf
Fsd-6ax4T1m	4928	Evaluating Representations with Readout Model Switching	['Representation Learning', 'Evaluation', 'Expert Switching', 'Minumum Description Length']	We propose an evaluation framework that is based on MDL and model switching for evaluating representations.	Deep Learning and representational learning	anonymous|evaluating_representations_with_readout_model_switching	/pdf/69cbcc7bf0822f06de890c7236f7a986d480a7f3.pdf
kKNVu-2J89s	4929	A Large Scale Sample Complexity Analysis of Neural Policies in the Low-Data Regime	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_large_scale_sample_complexity_analysis_of_neural_policies_in_the_lowdata_regime	/pdf/b75c2508af41e4fdd697cd559775cd7530b37e7e.pdf
YlvyUw4wDgs	4930	Combining pretrained speech and text encoders for spoken language processing	['Spoken language processing', 'Multi-modal SLU', 'Encoder fusion']	we propose to combine pretrained speech and text encoders via cross-attention, and we show the application of the proposed architecture in multiple spoken language processing systems	Applications (eg, speech processing, computer vision, NLP)	anonymous|combining_pretrained_speech_and_text_encoders_for_spoken_language_processing	/pdf/e865e36ea87e9eb4fdab20f5b72b68a93af211ef.pdf
gSHyqBijPFO	4932	TEMPERA: Test-Time Prompt Editing via Reinforcement Learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|tempera_testtime_prompt_editing_via_reinforcement_learning	/pdf/3a92c0ab415ab0d515899e2aecd18a789f3ab407.pdf
1KtU2ya2zh5	4933	META-STORM: Generalized Fully-Adaptive Variance Reduced SGD for Unbounded Functions	['Nonconvex Optimization', 'Stochastic Optimization', 'Adaptive Algorithms', 'Variance Reduction']	We propose new fully adaptive variance reduced algorithms removing bounded function values and bounded gradients assumptions and improving upon previous work both in the theoretical convergence rate and empirical performance.	Optimization (eg, convex and non-convex optimization)	anonymous|metastorm_generalized_fullyadaptive_variance_reduced_sgd_for_unbounded_functions	/pdf/95457a1b41fcd5cf615136a60eac1f0bf94eb37e.pdf
sP1fo2K9DFG	4940	Is Conditional Generative Modeling all you need for Decision Making?	['Offline Reinforcement Learning', 'Conditional Generative Modeling', 'Sequential Decision Making', 'Diffusion Models']	Framing (offline) sequential decision making as conditional diffusion generative modeling	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|is_conditional_generative_modeling_all_you_need_for_decision_making	/pdf/72d94f2fc8194d07ec0c4fda67cb6e72ac772641.pdf
WF7dU23lRCo	4941	A $2$-parameter Persistence Layer for Learning	['topological data analysis', 'graph representation', 'persistent homology', '2-parameter persistence', 'graph neural network']	A differentiable topological layer based on a novel vector representation on $2$-parameter persistence modules.	Deep Learning and representational learning	anonymous|a_2parameter_persistence_layer_for_learning	/pdf/d102b1441dd064cf5db42bb7d50ddf7e3b77ce04.pdf
dGdoZds9qAs	4942	Data Feedback Loops: Model-driven Amplification of Dataset Biases	['feedback loops', 'bias amplification', 'deep learning', 'self-supervised learning', 'CV', 'NLP']	We theoretically and experimentally characterize bias amplification when training a model on its own outputs.	General Machine Learning (ie none of the above)	anonymous|data_feedback_loops_modeldriven_amplification_of_dataset_biases	/pdf/b06936d05189b577e25b421905757f70bd268ca1.pdf
i3DLC5xIAJN	4943	Optimizing the Performance of Text Classification Models by Improving the Isotropy of the Embeddings using a Joint Loss Function	[]		Deep Learning and representational learning	anonymous|optimizing_the_performance_of_text_classification_models_by_improving_the_isotropy_of_the_embeddings_using_a_joint_loss_function	/pdf/e9502c25eed0293a3408162c75080e84a8349a70.pdf
jxAle6zdyTI	4944	BIG-Graph: Brain Imaging Genetics by Graph Neural Network	['Imaging Genetics', 'Graph Neural Network', 'Brain Network', 'genome-wide association studies']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|biggraph_brain_imaging_genetics_by_graph_neural_network	/pdf/806032ecd7654fe69dad2561effa376dc104044b.pdf
XKjz6mR3iqe	4945	On the System-Level Effectiveness of Physical Object-Hiding Adversarial Attack in Autonomous Driving	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_systemlevel_effectiveness_of_physical_objecthiding_adversarial_attack_in_autonomous_driving	/pdf/3d71007d95727f0838ab3c8e0e2a43774bf9d2fc.pdf
w22mvGyIysy	4946	Synthetic Pre-Training Tasks for Neural Machine Translation	['machine translation', 'synthetic data pre-training', 'toxicity and bias']		Applications (eg, speech processing, computer vision, NLP)	anonymous|synthetic_pretraining_tasks_for_neural_machine_translation	/pdf/d593b94caccf0a34063961c1fba8ef1505dcbe73.pdf
ayPPc0SyLv1	4948	Do We Really Need Complicated Model Architectures For Temporal Networks?	['temporal graph', 'link prediction']	This paper propose a conceptually and technically simple method for temporal graph link prediction	Applications (eg, speech processing, computer vision, NLP)	anonymous|do_we_really_need_complicated_model_architectures_for_temporal_networks	/pdf/7db6f9d0a2837ee74ebcfd54de5d27a04ebe6ba2.pdf
Pkb5FA5AjqP	4949	Automatically Auditing Large Language Models via Discrete Optimization	['large language models', 'safety', 'auditing', 'robustness']	We cast auditing as a discrete optimization problem, and demonstrate how this reduction uncovers large language model failure modes. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|automatically_auditing_large_language_models_via_discrete_optimization	/pdf/066c31b1cee1b9b5cd0422e09d55632f8df5a81d.pdf
EBC60mxBwyw	4950	How gradient estimator variance and bias impact learning in neural networks	['Computational Neuroscience', 'learning and plasticity', 'Credit assignment', 'Imperfect gradient descent', 'Gradient approximation', 'Biologically-plausible learning', 'Neuromorphic computing', 'Neural networks']	We characterize the impact of variance and bias in gradient estimates on learning and generalization and study how network architecture properties modulate these effects.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|how_gradient_estimator_variance_and_bias_impact_learning_in_neural_networks	/pdf/e608d7831bb8e59dc6360c21caa3cb11b2fc956d.pdf
UrzBg1Zz7ob	4951	Towards a More Rigorous Science of Blindspot Discovery in Image Models	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_a_more_rigorous_science_of_blindspot_discovery_in_image_models	/pdf/51d998560ec0d5bb53370e7bc09f768675b6001b.pdf
_VTkMy81R3x	4953	PGASL: Predictive and Generative Adversarial Semi-supervised Learning for imbalanced data	['semi-supervised learning', 'imbalanced learning', 'GAN model', 'adversarial learning']		General Machine Learning (ie none of the above)	anonymous|pgasl_predictive_and_generative_adversarial_semisupervised_learning_for_imbalanced_data	/pdf/869594dbedc2f845e84ef3cb851b3a58525d0078.pdf
kJqXEPXMsE0	4954	3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|3d_equivariant_diffusion_for_targetaware_molecule_generation_and_affinity_prediction	/pdf/907d4f5a8b4e87b499a67b16f5750ffc86261a09.pdf
tyvshLxFUtP	4956	GraphEditor: An Efficient Graph Representation Learning and Unlearning Approach	['graph representation learning', 'graph unlearning', 'machine unlearning', 'linear-GNNs']	This paper propose an efficient graph representation learning and unlearning method for linear-GNNs. The methods could also be extended to non-linear GNNs under some assumptions on input data.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|grapheditor_an_efficient_graph_representation_learning_and_unlearning_approach	/pdf/c7cd594062c64df19a09f64257c76ac2a51d39de.pdf
9krnQ-ue9M	4957	Explicitly Minimizing the Blur Error of Variational Autoencoders	['Variational Autoencoders', 'Generative Modelling', 'Blur']	We propose a new reconstruction term for VAEs that explicitly focuses on minimizing the blur of generated/reconstructed images while still optimizing the ELBO.	Generative models	anonymous|explicitly_minimizing_the_blur_error_of_variational_autoencoders	/pdf/b91901e7892c30f98e9ab7350202094c959cfeaf.pdf
m9LCdYgN8-6	4960	DAG Learning via Sparse Relaxations	['directed acyclic graph', 'causal discovery', 'differentiable sorting']	We propose a continuous optimization framework over the Permutahedron for discovering (DAGs) from observations that does not relax acyclicity and accommodates any edge-optimization procedure, edge structural parameterization, and optimization loss	General Machine Learning (ie none of the above)	anonymous|dag_learning_via_sparse_relaxations	/pdf/937282ff4482fe2ec0d47569568474d7307c94ae.pdf
pPUoahHadAX	4961	Evaluation of Active Feature Acquisition Methods under Missing Data	['Active feature acquisition', 'active sensing', 'missing data', 'reinforcement learning', 'distribution-shift', 'off-environment policy evaluation', 'AFA graph', 'AFAPE', 'AFAIS', 'MCAR', 'MAR', 'MNAR', 'causal inference']	Evaluation of active feature acquisition methods under missing data corresponds to a distribution shift which requires adjustment	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|evaluation_of_active_feature_acquisition_methods_under_missing_data	/pdf/5224b227c7135c2b067ae5d388e7e36a1808d225.pdf
9piH3Hg8QEf	4962	SMART: Self-supervised Multi-task pretrAining with contRol Transformers	['pretrain', 'transformer', 'multi-task reinforcement learning', 'sequential decision making', 'self-supervised']	We propose a pretraining framework for sequential decision making based on a self-supervised objectives and a control transformer architecture, leading to significantly higher learning efficiency in various downstram control tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|smart_selfsupervised_multitask_pretraining_with_control_transformers	/pdf/244fcff752a42b749c3cbd11a701a6be13434008.pdf
tDG-zrQ8S1Q	4964	SPRINT: Scalable Semantic Policy Pre-training via Language Instruction Relabeling	['reinforcement learning', 'language-guided RL', 'offline RL', 'policy pre-training']	We propose a scalable offline policy pre-training approach based on natural language instructions that automatically generates new pre-training tasks with language-model relabeling.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|sprint_scalable_semantic_policy_pretraining_via_language_instruction_relabeling	/pdf/d84a2b4ce2b020392a6c2837c33ce2634f61ea1b.pdf
Q9yT-pxvWn8	4967	CADet: Fully Self-Supervised Anomaly Detection With Contrastive Learning	['Contrastive learning', 'OOD detection', 'adversarial detection', 'MMD', 'ImageNet-O', 'Anomaly detection']	We leverage self-supervised contrastive learning to simultaneously perform adversarial and unseen label detection using a statistic inspired by MMD, and without seeing out-of-distribution examples.	Unsupervised and Self-supervised learning	anonymous|cadet_fully_selfsupervised_anomaly_detection_with_contrastive_learning	/pdf/64403e14a87d20a5c4ca59b2a3335f96166f2e22.pdf
3UDAU2unja	4968	Perceptual Grouping in Vision-Language Models	['vision-language models', 'multimodal learning', 'perceptual grouping', 'image segmentation']	We describe a minimal set of changes to vision-language models to endow these models with perceptual grouping and localization information.	Deep Learning and representational learning	anonymous|perceptual_grouping_in_visionlanguage_models	/pdf/0c37979331135f5e886f47a082741396f81fcacc.pdf
FE99-fDrWd5	4969	Semi Parametric Inducing Point Networks	[]		Deep Learning and representational learning	anonymous|semi_parametric_inducing_point_networks	/pdf/7f63f67bc2f7e4f936fd4b81f82b1d725747a010.pdf
n0okuXMlI7V	4970	Catastrophic overfitting is a bug but it is caused by features	['Adversarial robustness', 'catastrophic overfitting', 'understanding deep learning', 'single-step adversarial training', 'FGSM', 'fast adversarial training']	We analyse the phenomena of catastrophic overfitting trough active interventions and show it is a shortcut for the network to avoid learning complex robust solutions. 	Deep Learning and representational learning	anonymous|catastrophic_overfitting_is_a_bug_but_it_is_caused_by_features	/pdf/009269e6e9bb4dca9d8136b1a79b05ee8f26d20b.pdf
HmdOxc8zIWx	4972	Can we achieve robustness from data alone?	[]		Deep Learning and representational learning	anonymous|can_we_achieve_robustness_from_data_alone	/pdf/133356039d9f0aaffe0b1a3b9d2c916d60c3e880.pdf
7XHiDnUb_hj	4973	Detecting Small Query Graphs in A Large Graph via Neural Subgraph Search	['subgraph matching', 'subgraph isomorphism search']		Applications (eg, speech processing, computer vision, NLP)	anonymous|detecting_small_query_graphs_in_a_large_graph_via_neural_subgraph_search	/pdf/c0207190baac48b573b95b9f1ebae1a2fa458b0b.pdf
ZCStthyW-TD	4974	Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception	['associative memory', 'memory augmented neural network', 'spatiotemporal representation', 'event-based camera', 'event-based perception', 'object recognition', 'attention', 'set processing']	We propose EventFormer, an asynchronous spatiotemporal representation learning framework augmented by an associative memory to efficiently perform event-based perception.	Applications (eg, speech processing, computer vision, NLP)	anonymous|associative_memory_augmented_asynchronous_spatiotemporal_representation_learning_for_eventbased_perception	/pdf/bae80ab168ccf364f9a35a1ab21781a55475713c.pdf
JUNKYmGGuEw	4975	Neural multi-event forecasting on spatio-temporal point processes using probabilistically enriched transformers	['Stochastic Point Processes', 'Multi-event Prediction', 'Transformers', 'Normalizing Flows', 'Hawkes Process', 'Deep Learning', 'Generative Models']	 In this work, we introduce a novel neural network that is capable of simultaneous multi-event forecasting of spatio-temporal distributions associated with stochastic discrete events.	Deep Learning and representational learning	anonymous|neural_multievent_forecasting_on_spatiotemporal_point_processes_using_probabilistically_enriched_transformers	/pdf/7e9bb163bb2f8572e9f39fe17107206bd2e14514.pdf
GRZtigJljLY	4976	Scalable Batch-Mode Deep Bayesian Active Learning via Equivalence Class Annealing	['Bayesian Neural Network', 'Batch-Mode Active Learning', 'Decision-Centric Data Acquisition', 'Scalability']	We propose a new scalable batch-mode active learning algorithm	General Machine Learning (ie none of the above)	anonymous|scalable_batchmode_deep_bayesian_active_learning_via_equivalence_class_annealing	/pdf/85ec607a60c5ef8e082437fc8db2896df9b5f95b.pdf
0LJRS7B3r4_	4978	Advantage Constrained Proximal Policy Optimization in Multi-Agent Reinforcement Learning	['Multi agent', 'reinforcement learning', 'neural network', 'deep learning', 'trust region.']	A multi-agent policy gradient reinforcement learning based on local advantage constraned.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|advantage_constrained_proximal_policy_optimization_in_multiagent_reinforcement_learning	/pdf/8441bdf7caa8a9e3ffa807b1eef3347da04951a9.pdf
6Lh_wgIaT9l	4979	Optimal Membership Inference Bounds for Adaptive Composition of Sampled Gaussian Mechanisms	['Membership inference', 'DP-SGD', 'Gaussian Mechanism']	We prove optimal membership inference bounds for DP-SGD, beating previously known upper bounds on membership inference.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|optimal_membership_inference_bounds_for_adaptive_composition_of_sampled_gaussian_mechanisms	/pdf/c155ca8bb3fd7160128be8d56e559f6265e5f4a9.pdf
-p5ZEVGtojQ	4980	Continuous Depth Recurrent Neural Differential Equations	['neural ordinary differential equations', 'recurrent neural networks', 'sequence data']	Proposing novel RNN models based on differential equations that  continuously transform hidden states in both temporal and depth dimensions.	Deep Learning and representational learning	anonymous|continuous_depth_recurrent_neural_differential_equations	/pdf/2a2a863f2c49ca8145ef1909f9b40b3a202b63db.pdf
cMJo1FTwBTQ	4981	DINO as a von Mises-Fisher mixture model	['self-supervised learning', 'vision transformers', 'mixture models']	Improving DINO with unnormalized prototypes based on a flexible von Mises-Fisher mixture model interpretation.	Unsupervised and Self-supervised learning	anonymous|dino_as_a_von_misesfisher_mixture_model	/pdf/ce447f24806af82a87cba3d2045155925b252576.pdf
lGz9u1ubUXE	4982	Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences	['Neuro-Symbolic', 'Human-AI Interaction']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|relative_behavioral_attributes_filling_the_gap_between_symbolic_goal_specification_and_reward_learning_from_human_preferences	/pdf/74337c3282cc1e5ce238a04b7642019b60010faa.pdf
TSqKS0lQQA6	4983	Prompt Tuning with Prompt-aligned Gradient for Vision-Language Models 	['prompt tuning', 'vision-language models', 'CLIP']	We present Prompt-aligned Gradient to prevent prompt tuning from forgetting the general knowledge learned from CLIP.	Applications (eg, speech processing, computer vision, NLP)	anonymous|prompt_tuning_with_promptaligned_gradient_for_visionlanguage_models	/pdf/77c396c751f367fb2fc784d42f53f9d76bf91639.pdf
HB2HBIQKhp-	4984	Illusory Adversarial Attacks on Sequential Decision-Makers and Countermeasures	['reinforcement learning', 'adversarial attacks']	We present illusory attacks on sequential decision-makers, which are undetectable.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|illusory_adversarial_attacks_on_sequential_decisionmakers_and_countermeasures	/pdf/69eea9dfadfeaecce04d1a17ff5e0c92e09b307d.pdf
VD-AYtP0dve	4985	Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation	['uncertainty estimation', 'natural language generation']	Semantic entropy is a novel uncertainty estimation method for natural language generation that captures uncertainty over meanings rather than sequences.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|semantic_uncertainty_linguistic_invariances_for_uncertainty_estimation_in_natural_language_generation	/pdf/4fe8915f37c3ca84d58d08b2c536f5c6abef66a1.pdf
5R96mIU85IW	4986	Effectively using  public data in privacy preserving Machine learning	['Privacy preserving machine learning', 'dp-sgd', 'public data in privacy']	improving the effect of public data in DP-SGD and improving the accuracy significantly	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|effectively_using_public_data_in_privacy_preserving_machine_learning	/pdf/e68ca351508c3318a5d914e6f99f517eb9e5d09b.pdf
rCtDTKgxyMz	4987	The Minimal Feature Removal Problem in Neural Networks	[]		Deep Learning and representational learning	anonymous|the_minimal_feature_removal_problem_in_neural_networks	/pdf/fa36afaf8957649322aba88afc98d656e4ad9a9e.pdf
YaPPldR6te	4988	Explainable Machine Learning Predictions for the Long-term Performance of Brain-Computer Interfaces	['SHAP', 'Explainability', 'feature importance', 'BCI', 'Neural interfaces', 'longitudinal intracortical recordings', 'neural engineering']	Development of an explainable AI pipeline that can predict with high accuracy and elucidate the most important factors involved in the long-term stability of intracortical brain computer interfaces	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|explainable_machine_learning_predictions_for_the_longterm_performance_of_braincomputer_interfaces	/pdf/a53cf735c32358c49ad168eb82b94ecc5b550771.pdf
aZlmMFHaqPg	4989	Zero-shot Human-Object Interaction Recognition by Bridging Generative and Contrastive Image-Language Models	['Zero-shot', 'knowledge distillation', 'Human-Object Interaction']	Our zero-shot HOI classifier outperforms supervised SOTAs by using a heterogeneous teach-student framework which bridges generative and contrastive pre-trained image-language models through pseudo-label distillation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|zeroshot_humanobject_interaction_recognition_by_bridging_generative_and_contrastive_imagelanguage_models	/pdf/d5074ab4dd9e1f79d457e9bba27436e7597592cd.pdf
hDDV1lsRV8	4991	Federated Learning from Small Datasets	['federated learning', 'distributed', 'sparse data', 'daisy chain', 'small datasets']	We propose federated daisy chaining to allow multiple parties to successfully train a joint model collaboratively from small local datasets, retaining the privacy benefits of federated learning.	Deep Learning and representational learning	anonymous|federated_learning_from_small_datasets	/pdf/06da71fe2ce573bcf1d1aafbaf44d504436bead7.pdf
PsIk0kO3hKd	4992	Spatio-temporal point processes with deep non-stationary kernels	['point process', 'neural network', 'non-stationary kernel', 'low-rank model']	Deep non-stationary kernel for spatio-temporal point process data modeling with low-rank structure, and a barrier method for constraint MLE optimization.	General Machine Learning (ie none of the above)	anonymous|spatiotemporal_point_processes_with_deep_nonstationary_kernels	/pdf/74b22a2bbc5dddaf567fc960d624f91bc84c0262.pdf
MB_O268uCY	4993	The ethical ambiguity of AI data enrichment:  Measuring gaps in research ethics norms and practices	['ethics', 'disclosures', 'crowdsourcing', 'data enrichment']	This paper shows how AI researchers engage with research ethics when employing crowdworkers. The work finds research ethics disclosures are infrequent in AI papers, inconsistently following venue publication policies.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|the_ethical_ambiguity_of_ai_data_enrichment_measuring_gaps_in_research_ethics_norms_and_practices	/pdf/991edd7770ece59514d4f296e28ab9b2cc5a4074.pdf
eWKfMBL5to	4994	Contrastive Corpus Attribution for Explaining Representations	['explainable artificial intelligence', 'interpretable machine learning', 'feature attributions', 'contrastive explanations']	A novel method to explain representations (from unsupervised and supervised models) in terms of input features.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|contrastive_corpus_attribution_for_explaining_representations	/pdf/e9c13728a4614759bd76c379d81e576509bd14b7.pdf
osei3IzUia	4995	Where to Diffuse, How to Diffuse and How to get back: Learning in Multivariate Diffusions	['Diffusion models', 'score based generative model', 'generative models', 'variational inference']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|where_to_diffuse_how_to_diffuse_and_how_to_get_back_learning_in_multivariate_diffusions	/pdf/d34c358edbd435842ac90688afe2aad70420cfb0.pdf
JOix_wb4AeM	4996	In-distribution and Out-of-distribution Generalization for Graph Neural Networks	['Graph Neural Networks', 'Generalization Bounds', 'Out-of-distribution generalization', 'Learning theory']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|indistribution_and_outofdistribution_generalization_for_graph_neural_networks	/pdf/38bf2abd684925de9a0be875298e62f5b98be51e.pdf
BLNZwf-9k09	4997	Architectural Backdoors in Neural Networks	[]	paper demonstrates a backdoor that can be planted at the architectural definition level of a neural network	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|architectural_backdoors_in_neural_networks	/pdf/c202e3f7b58579019c2ae7534b94815d06eda13d.pdf
mb7PtrUbHa	4999	Skill Decision Transformer	['Transformer', 'Offline Reinforcement Learning']	We introduce a skill conditioned Decision Transformer that utilizes learned offline behaviors	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|skill_decision_transformer	/pdf/6571de85cd785f794fa238076f8542f67a1c4112.pdf
jsZsEd8VEY	5000	Grounding Graph Network Simulators using Physical Sensor Observations	['graph network simulators', 'deformable object simulation', 'point clouds']	We ground Graph Network Simulators with physical sensor information to resolve uncertainties and improve long-term prediction quality.	Deep Learning and representational learning	anonymous|grounding_graph_network_simulators_using_physical_sensor_observations	/pdf/dd2cb984f73a92abaa8c29d74db4b68a9e6f8811.pdf
bGC7Ai125lR	5003	Towards Understanding How Machines Can Learn Causal Overhypotheses 	['causal reasoning', 'intervention', 'causal overhypotheses', 'Reinforcement learning', 'gpt-3']	We present a new flexible environment which allows for the evaluation of existing techniques under variable causal overhypotheses	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|towards_understanding_how_machines_can_learn_causal_overhypotheses	/pdf/436aaf32e1b486629ded2a43e9948561a33e4882.pdf
gUTKBS34Q5c	5005	Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks	['warm-start', 'generalization', 'online learning', 'weight reinitialization', 'active forgetting', 'Anytime learning']	An efficient online learning paradigm which interchanges between the unlearning phase (selective forgetting) and relearning phase (retraining) to improve generalization of the DNNs through weight reinitialization.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learn_unlearn_and_relearn_an_online_learning_paradigm_for_deep_neural_networks	/pdf/e61ee961464c8ff0055125464944b1b3ca4bb37a.pdf
p7hvOJ6Gq0i	5007	DensePure: Understanding Diffusion Models towards Adversarial Robustness	['adversarial robustness', 'certified robustness', 'diffusion model']	We theoretically analyze the fundamental properties of diffusion models to understand why and how it enhances certified robustness. Inspired by the analysis, we propose a new method to improve the certified robustness of the clearn classifier	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|densepure_understanding_diffusion_models_towards_adversarial_robustness	/pdf/e6d172dd5853827542b74104d73a8b53aa0e9228.pdf
i_1rbq8yFWC	5008	Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise	['Structure learning', 'Causal discovery', 'Time series', 'Structure equation model', 'deep generative model']	We propose a causal discovery method for time series, which combines deep learning and variational inference to model instantaneous effect and history-dependent noise with structure identifiability guarantee.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|rhino_deep_causal_temporal_relationship_learning_with_historydependent_noise	/pdf/bd28d1567319a4aafc601cee65645c6c2c643034.pdf
QjHSvrwkT8S	5009	The Use of Open-Source Boards for Data Collection and Machine Learning in Remote Deployments	['Open-source hardware', 'single board computer', 'microcontroller', 'on-board processing', 'edge computing', 'field programmable gate array']	This paper describes how open source hardware are used for data collection and machine learning tasks in off-grid setups.  	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|the_use_of_opensource_boards_for_data_collection_and_machine_learning_in_remote_deployments	/pdf/bcbce12cbf31ccb7aff30ddd0fada11f79e87886.pdf
mFDU0fP3EQH	5010	Meta-Learning Black-Box Optimization via Black-Box Optimization	['Meta-Learning', 'Evolution Strategies', 'Gradient-Free Optimization']	We meta-learn evolution strategies, which flexibly generalize to unseen optimization problems, population sizes and optimization horizons. 	General Machine Learning (ie none of the above)	anonymous|metalearning_blackbox_optimization_via_blackbox_optimization	/pdf/5b14a7117358514b868dc41ce12ecdb2fa95006d.pdf
eAR9bgWrUsa	5013	Generative Pretraining for Black-Box Optimization	['decision making', 'generative modelling', 'transformers']		Deep Learning and representational learning	anonymous|generative_pretraining_for_blackbox_optimization	/pdf/0da4114ab1a6a518219db6530b5f0374546bb0f9.pdf
LMuVjYmHNh4	5014	Ensemble Homomorphic Encrypted Data Classification	['Machine Learning Privacy', 'Homomorphic Encrypted Data Classification', 'Ensemble Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|ensemble_homomorphic_encrypted_data_classification	/pdf/d1f5306ae7b2aea7b5d7a5a698862438b7f38f04.pdf
4BPFwvKOvo5	5015	Towards convergence to Nash equilibria in two-team zero-sum games	['no-regret-learning', 'no-regret', 'optimization', 'learning-in-games', 'nash-equilibrium', 'game-theory', 'min-max-optimization', 'min-max']	Common no-regret algorithms fail to converge to a Nash equilibrium in two-team zero-sum games but a novel approach does converge locally.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|towards_convergence_to_nash_equilibria_in_twoteam_zerosum_games	/pdf/0fb3849a6c54f99f6bcaa1fbdd6359b17cb74476.pdf
WE_vluYUL-X	5016	ReAct: Synergizing Reasoning and Acting in Language Models	['Language model', 'agent', 'reasoning', 'decision making']	We synergize reasoning and action taking in language models and make them more capable, versatile and interpretable.	Applications (eg, speech processing, computer vision, NLP)	anonymous|react_synergizing_reasoning_and_acting_in_language_models	/pdf/fc4661056a038f6431e77b6f9a84d74109493e18.pdf
5Qt6ZqXSDEZ	5017	From Adaptive Query Release to Machine Unlearning	['machine unlerarning', 'stochastic convex optimization']	Efficient algorithms for exact machine unlearning for stochastic convex optimization	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|from_adaptive_query_release_to_machine_unlearning	/pdf/0b30ad427f319bde208a59141b4254e060725488.pdf
wGvzQWFyUB	5018	Personalized Reward Learning with Interaction-Grounded Learning (IGL)	['interaction-grounded learning', 'recommendation systems', 'interactive machine learning', 'contextual bandits']	Eliminating reward engineering for recommendation systems	Applications (eg, speech processing, computer vision, NLP)	anonymous|personalized_reward_learning_with_interactiongrounded_learning_igl	/pdf/9c17b8c1fed99ecb4ad306e4b77f34804319f711.pdf
rRgLJ8TwXe	5020	Learning Useful Representations for Shifting Tasks and Distributions 	['rich representation learning', 'supervised transfer learning', 'self-supervised transfer learning', 'few shot learning', 'out-of-distribution robust learning']		Deep Learning and representational learning	anonymous|learning_useful_representations_for_shifting_tasks_and_distributions	/pdf/1f9bf051ee6c33f179de3f61cc7d3e58142d7795.pdf
mKNAOg7CLX	5022	Towards Dynamic Sparsification by Iterative Prune-Grow LookAheads	['Network pruning', 'Network growing', 'Efficient Networks']	Network pruning via an iterative Grow-and-Prune approach	Deep Learning and representational learning	anonymous|towards_dynamic_sparsification_by_iterative_prunegrow_lookaheads	/pdf/165d5fcf419bafac035e18b6a80c711ead8630c8.pdf
wEP-3nECiUE	5023	Pushing the limits of self-supervised learning: Can we outperform supervised learning without labels?	['self-supervised learning', 'contrastive learning', 'ImageNet']		Unsupervised and Self-supervised learning	anonymous|pushing_the_limits_of_selfsupervised_learning_can_we_outperform_supervised_learning_without_labels	/pdf/e072a66d2375a09304e524a12b8c8e7856ced822.pdf
9_VrvV7d-FK	5025	Unsupervised Adaptation for Fairness under Covariate Shift	['Out of Distribution', 'Fairness', 'Unsupervised', 'Adaptation']	We propose an unsupervised adaptation algorithm to address fairness under covariate shift. Our proposed objective involves the standard training loss along with a novel min-max entropy formulation to handle shift and a wasserstein loss for fairness.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|unsupervised_adaptation_for_fairness_under_covariate_shift	/pdf/1b50a1dc093b08eb03f36a3f94f8337643aafd4e.pdf
k8hq5rkmsJ_	5026	EiX-GNN : Concept-level eigencentrality explainer for graph neural networks	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|eixgnn_conceptlevel_eigencentrality_explainer_for_graph_neural_networks	/pdf/2d9bbe0accb67dbbe0930767b818e6045c808817.pdf
nJfylDvgzlq	5027	Make-A-Video: Text-to-Video Generation without Text-Video Data	[]		Generative models	anonymous|makeavideo_texttovideo_generation_without_textvideo_data	/pdf/bd4289221faa8cb65505e11159e78b7c6cad1e98.pdf
U5XOGxAgccS	5028	Solving Continuous Control via Q-learning	['reinforcement learning', 'continuous control', 'learning efficiency']	Decoupling action dimensions during optimization and exploration for DQN in combination with bang-bang action discretization achieves state-of-the-art performance on a variety of continuous control tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|solving_continuous_control_via_qlearning	/pdf/68bec8b80bfb4674b6467e6af72ff728c1027cfa.pdf
7bns2VTdMAx	5029	Deep Learning of Intrinsically Motivated Options in the Arcade Learning Environment	['reinforcement learning', 'intrinsic motivation', 'exploration', 'options', 'auxiliary task learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|deep_learning_of_intrinsically_motivated_options_in_the_arcade_learning_environment	/pdf/5e4ea25582afcb2f4e73a27ce99108d3bc04cb22.pdf
AatUEvC-Wjv	5030	Hyper-Decision Transformer for Efficient Online Policy Adaptation	['Offline Reinforcement Learning', 'One-shot Imitation Learning', 'Parameter-efficient Fine-tuning']	We propose Hyper-Decision Transformer (HDT), a transformer-based model which generalizes to novel unseen tasks maintaining strong data and parameter efficiency.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|hyperdecision_transformer_for_efficient_online_policy_adaptation	/pdf/ef902abb05b6f2e3c7456df124aafce2b6f2bbf7.pdf
C8by2OoY6Y2	5033	Zero-Shot Retrieval with Search Agents and Hybrid Environments	['learning to search', 'information retrieval', 'document ranking', 'relevance feedback', 'zero shot', 'language models', 'behavioral cloning']	A learning to search agent combined with a hybrid dense-sparse retrieval environment achieves sota on zero shot retrieval (BEIR).	Applications (eg, speech processing, computer vision, NLP)	anonymous|zeroshot_retrieval_with_search_agents_and_hybrid_environments	/pdf/6ec6fcac6cac34e5acfc6bd320497306bf0ff845.pdf
pOyi9KqE56b	5034	Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD	['Gradient Descent', 'Generalization Error', 'Smooth Nonconvex/Convex Optimization']	We show generalization and excess risk guarantees for the full-batch Gradient Descent (GD) algorithm	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|beyond_lipschitz_sharp_generalization_and_excess_risk_bounds_for_fullbatch_gd	/pdf/9eb1ca568247a83a5d8879f0f377844154b0f54b.pdf
slHNW9yRie0	5035	Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise	[]		Generative models	anonymous|cold_diffusion_inverting_arbitrary_image_transforms_without_noise	/pdf/2df266ac17820215deddbe6196273fe0b8d1fd93.pdf
xnsg4pfKb7	5036	Bispectral Neural Networks	['invariance', 'group theory', 'representation theory', 'geometry', 'representation learning', 'symmetry']		Deep Learning and representational learning	anonymous|bispectral_neural_networks	/pdf/2e816081466f4bad4e8f14d56f5dbfb3b2f9cb93.pdf
VWqiPBB_EM	5037	$O(T^{-1})$ Convergence of Optimistic-Follow-the-Regularized-Leader in Two-Player Zero-Sum Markov Games 	['multi-agent reinforcement learning', 'policy optimization', 'Markov game']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|ot^1_convergence_of_optimisticfollowtheregularizedleader_in_twoplayer_zerosum_markov_games	/pdf/baa8e2679edb12160fec7f7b8b452fe81751f46c.pdf
H71l8_zALJ	5038	ProSampler: Improving Contrastive Learning by Better Mini-batch Sampling	['global hard negative sampling', 'contrastive learning']		Unsupervised and Self-supervised learning	anonymous|prosampler_improving_contrastive_learning_by_better_minibatch_sampling	/pdf/d8bae247398cefbcbc52edf3aed54f953cc546fa.pdf
dMsyUtZxj_	5039	Pareto Rank-Preserving Supernetwork for HW-NAS	['Neural Architecture Search', 'Supernetwork', 'Computer Vision']		Optimization (eg, convex and non-convex optimization)	anonymous|pareto_rankpreserving_supernetwork_for_hwnas	/pdf/44383b4b9c0fe66b532641bf72e3361ad18072a0.pdf
dLAYGdKTi2	5040	Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach	['Multi-objective Optimization', 'Machine Learning']	We propose a gradient based multi-objective optimization algorithm which provably convergence to a Pareto stationary point in stochastic convex and non-convex settings.	Optimization (eg, convex and non-convex optimization)	anonymous|mitigating_gradient_bias_in_multiobjective_learning_a_provably_convergent_approach	/pdf/f9c801cec033f84d08e97e032639ae27a70eac1d.pdf
9OL2fIfDLK	5042	ESC: A Benchmark For Multi-Domain End-to-End Speech Recognition	['speech', 'end-to-end', 'evaluation', 'benchmark']		Applications (eg, speech processing, computer vision, NLP)	anonymous|esc_a_benchmark_for_multidomain_endtoend_speech_recognition	/pdf/14c5746a02975f1e7521a7db3521e6c9d2d13afb.pdf
dcN0CaXQhT	5043	Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning	['causality', 'causal discovery', 'causal inference', 'structural equation model', 'latent confounders', 'variational inference']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|causal_reasoning_in_the_presence_of_latent_confounders_via_neural_admg_learning	/pdf/f786b785d49a912e82655c45338cc02a4a48ce3b.pdf
pm4Wuso4da1	5046	Discerning Hydroclimatic Behavior with a Deep Convolutional Residual Regressive Neural Network	['water', 'climate', 'sustainability', 'supervised representation learning', 'societal considerations']	We analyze and visualize the water cycles of four large US watersheds using representation learning techniques.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|discerning_hydroclimatic_behavior_with_a_deep_convolutional_residual_regressive_neural_network	/pdf/34993076341c963def3199867832c65ab03a382f.pdf
7ZcyRF7Y3S	5055	Synergies Between Disentanglement and Sparsity: a Multi-Task Learning Perspective	['Disentanglement', 'identifiability', 'multi-task learning', 'sparsity', 'transfer learning', 'meta-learing']	We show how disentangled representations combined with sparse base-predictors can improve generalization and how, in a multi-task learning setting, sparsity regularization on the task-specific predictors can induce disentanglement.	Deep Learning and representational learning	anonymous|synergies_between_disentanglement_and_sparsity_a_multitask_learning_perspective	/pdf/e84d1d5d84fa56199ae2583d40bdb5d36ea51dda.pdf
ipRGZ91NvG4	5056	SGD with large step sizes learns sparse features	['SGD', 'large step sizes', 'implicit regularization', 'feature learning']	Loss stabilization achieved via SGD with large step sizes leads to a hidden dynamics that promotes sparse feature learning 	Deep Learning and representational learning	anonymous|sgd_with_large_step_sizes_learns_sparse_features	/pdf/fb37927e7831533be99a5ee4997fac29cdc94a2b.pdf
oKTl_-4qLJ	5058	The Challenges of Exploration for Offline Reinforcement Learning	['Offline Reinforcement Learning', 'Exploration', 'Robotics']	We compare existing and new exploration methods as a new way to generate useful data for offline reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_challenges_of_exploration_for_offline_reinforcement_learning	/pdf/23ceeef37846af170ade3dd9fb8f013c47aaa9bc.pdf
7UudBVsIrr	5060	MolJET: Multimodal Joint Embedding Transformer for Conditional de novo Molecular Design and Multi-Property Optimization	['Transformers', 'Multimodal', 'Molecules', 'Generative', 'Drug-design', 'LLM']	MolJET is a foundational generative chemistry model for molecular design that uses joint embeddings learned from three chemistry-related modalities to perform conditional multi-property optimization.	Generative models	anonymous|moljet_multimodal_joint_embedding_transformer_for_conditional_de_novo_molecular_design_and_multiproperty_optimization	/pdf/ed35d0c2de2e4cd613f633e31543e0572b2701fb.pdf
n7CPzMPKQl	5061	Integrating Symmetry into Differentiable Planning with Steerable Convolutions	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|integrating_symmetry_into_differentiable_planning_with_steerable_convolutions	/pdf/dd5551f422b1e1e0c9676e21bd09c3ca6275abba.pdf
2_I3JQ70U2	5062	Asynchronous Message Passing: A new Framework for Learning in Graphs	[]	A new framework for neural networks in graphs: messages are handled one at a time giving beneits in expressiveness and longrange propagation.	Deep Learning and representational learning	anonymous|asynchronous_message_passing_a_new_framework_for_learning_in_graphs	/pdf/b3397f7a414cebbc550fe40092e93c0924b66569.pdf
Zz8_2A4iPS	5063	Continual Learning with Soft-Masking of Parameter-Level Gradient Flow	['continual learning', 'catastrophic forgetting', 'knowledge transfer']	This work aims to (1) overcome catastrophic forgetting, (2) encourage knowledge transfer, and (3) tackle the capacity problem in continual learning.	Deep Learning and representational learning	anonymous|continual_learning_with_softmasking_of_parameterlevel_gradient_flow	/pdf/e55f5c8de8b3e444f9eb169d7a9165e22ffab916.pdf
sVx6FKx1iv	5065	Domain Invariant Q-Learning for model-free robust continuous control under visual distractions	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|domain_invariant_qlearning_for_modelfree_robust_continuous_control_under_visual_distractions	/pdf/9c66113df89ab2e132cc41b3ad6132d413bba669.pdf
Pgtn4l6eKjv	5066	DySR: Adaptive Super-Resolution via Algorithm and System Co-design	['super-resolution', 'quality of service', 'inference', 'deep learning', 'systems']	We present DySR, an algorithm and system co-design approach to maintain super-resolution streaming task QoS on mobile devices via fast model adaptation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dysr_adaptive_superresolution_via_algorithm_and_system_codesign	/pdf/79afc9c0511e923efd3b21ea6d118faa29d80cc6.pdf
wkZcA4Lb7Mw	5067	Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue	['neural language generation', 'sequence-to-sequence', 'knowledge injection', 'medical dialogue data', 'care plan generation', 'EHR auto-charting']	We propose an approach for injecting domain knowledge into neural autoregressive language models using marginal probability regularization during training and apply it to the care plan generation task.	Applications (eg, speech processing, computer vision, NLP)	anonymous|injecting_knowledge_into_language_generation_a_case_study_in_autocharting_aftervisit_care_instructions_from_medical_dialogue	/pdf/c3247281d03a6160dba797b93e6ced161707dfdb.pdf
QWQM0ZwZdRS	5068	Fake It Until You Make It : Towards Accurate Near-Distribution Novelty Detection	[]		Unsupervised and Self-supervised learning	anonymous|fake_it_until_you_make_it_towards_accurate_neardistribution_novelty_detection	/pdf/07dec17ab8a2f8d50ee7edf49e59de3fcdbade3a.pdf
SRIQZTh0IK	5069	Analogical Networks for Memory-Modulated 3D  Parsing	[]		Deep Learning and representational learning	anonymous|analogical_networks_for_memorymodulated_3d_parsing	/pdf/dea64ad884f17d44ce0252734613b5be3a328112.pdf
HnLFY8F9uS	5070	Robust Policy Optimization in Deep Reinforcement Learning	['Deep Reinforcement Learning', 'Policy Optimization']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|robust_policy_optimization_in_deep_reinforcement_learning	/pdf/9f352523bbc84d6b728a09bc6af40bdca3e50e30.pdf
uzFQpkEzOo	5071	Depth Separation with Multilayer Mean-Field Networks	['depth separation', 'mean-ﬁeld', 'nonconvex optimization']	We show that, using gradient flow, 3-layer networks can efficiently learn a function that no 2-layer networks can efficiently approximate.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|depth_separation_with_multilayer_meanfield_networks	/pdf/226bcf58c6ee5b4991f11c55e50344f22323e78d.pdf
6iDHce-0B-a	5072	Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions	['Deep Neural Networks', 'implicit bias', 'representation cost', 'sparsity']	The representation cost of DNNs converges to a notion of nonlinear rank as the depth grows to infinity. This bias towards low-rank functions extends to large but finite widths.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|implicit_bias_of_large_depth_networks_a_notion_of_rank_for_nonlinear_functions	/pdf/8d2b2b4fa7d1dcf6293658edbb951866e3b14882.pdf
Jg-oXkENo2p	5073	Re-calibrated Wasserstein GAN for large-scale imputation with informative missing	['deep learning', 'data imputation', 'missing data', 'neural networks', 'Wasserstein GAN', 'quantile regression']	We develop a novel method for imputing missing data in large scale health records using a Wasserstein GAN whose loss function is reweighted by missingness probability estimates	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|recalibrated_wasserstein_gan_for_largescale_imputation_with_informative_missing	/pdf/9b7ef9029b1056e73b3688eba7b938e803848576.pdf
nMAbvsQo5YY	5075	Constant-Factor Approximation Algorithms for Socially Fair $k$-Clustering	['Clustering', 'k-means', 'fairness', 'approximation algorithms', 'iterative rounding']	We present a constant-factor approximation algorithm for the socially fair k-means and k-medians problems.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|constantfactor_approximation_algorithms_for_socially_fair_kclustering	/pdf/ce3a035a1e5275d912cc69f285b03bd69098d36f.pdf
89GT-S49mGd	5076	Function-space regularized Rényi divergences	['Rényi divergence', 'integral probability metrics', 'variational formulas', 'worst-case-regret']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|functionspace_regularized_rényi_divergences	/pdf/908e82042731457eeccccbaa4aa5b7bcf51fe73d.pdf
svCcui6Drl	5077	Why (and When) does Local SGD Generalize Better than SGD?	['local SGD', 'SDE', 'regularization', 'implicit bias', 'deep learning theory', 'optimization', 'distributed training']	We derive a Stochastic Differential Equation (SDE) that captures the long-term behavior of Local SGD and provide a theoretical explanation why Local SGD generalizes better than SGD.	Optimization (eg, convex and non-convex optimization)	anonymous|why_and_when_does_local_sgd_generalize_better_than_sgd	/pdf/5f6e4e05e4dc2aff58afe4ac86952d4b96ca482f.pdf
9IlzJa5cAv	5078	DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees	[]	A new GNN architecture that allows for full explanation not only of the important imputs but also the full decision making process how the inputs are used.	Deep Learning and representational learning	anonymous|dtgnn_a_fully_explainable_graph_neural_network_using_decision_trees	/pdf/b1d2ce5bb92b7c53fa43a4e633fa43f64caa6028.pdf
5o8oFs5D9Z	5079	SurCo: Learning Linear Surrogates for Combinatorial Nonlinear Optimization Problems	['Differentiable Optimization', 'Machine Learning', 'Nonlinear Optimization', 'Combinatorial Optimization']	SurCo learns linear surrogate problems for nonlinear combinatorial optimization by training high-quality linear surrogates using end-to-end gradient descent with better performance in two industrial domains	Optimization (eg, convex and non-convex optimization)	anonymous|surco_learning_linear_surrogates_for_combinatorial_nonlinear_optimization_problems	/pdf/b8fc5bfb1b81f89f5dac0586352747a8213fdf4b.pdf
ddad0PNUvV	5080	Images as Weight Matrices: Sequential Image Generation Through Synaptic Learning Rules	['learning rules', 'Fast Weight Programmers', 'linear Transformers', 'image generation', 'GANs']	We train neural nets to execute sequences of synaptic learning rules to sequentially generate natural images (instead of weight matrices).	Deep Learning and representational learning	anonymous|images_as_weight_matrices_sequential_image_generation_through_synaptic_learning_rules	/pdf/50b191369920b4a927190cce1596361453ac2792.pdf
k9CF4h3muD	5083	Learning Low Dimensional State Spaces with Overparameterized Recurrent Neural Networks	['RNN', 'gradient descent', 'implicit bias', 'extrapolation']	Linear RNNs optimized with gradient descent have implicit bias leading to solutions with low dimensional state spaces leading to non-trivial extrapolation.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|learning_low_dimensional_state_spaces_with_overparameterized_recurrent_neural_networks	/pdf/1abdabff640be2696f973ea0da13a0e474925464.pdf
8abnSMeFaqA	5085	Finding and only finding local Nash equilibria by both pretending to be a follower	['game theory', 'general-sum games', 'local Nash equilibrium', 'optimization']	We propose double Follow-the-Ridge (double-FTR), an algorithm with local convergence guarantee to differential Nash equilibria in general-sum two-player differential games.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|finding_and_only_finding_local_nash_equilibria_by_both_pretending_to_be_a_follower	/pdf/ae1afdea253f6cdd77b5afec6e194d475879a44e.pdf
K2spEiswXVf	5086	MALIBO: Meta-Learning for Likelihood-free Bayesian Optimization	['Bayesian Optimization', 'Meta-learning']	A Meta-learning method for likelihood-free Bayesian optimization, scalable and robust to different scales across datasets.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|malibo_metalearning_for_likelihoodfree_bayesian_optimization	/pdf/63bc592388932853e040bdfbcab44b67d22b7855.pdf
_SQ-303Iu6G	5087	EENet: Learning to Early Exit for Adaptive Inference	['deep learning', 'edge computing', 'computational efficiency']	We introduce EENet, a novel, lightweight early exit policy optimization method for budgeted adaptive inference with early exits.	General Machine Learning (ie none of the above)	anonymous|eenet_learning_to_early_exit_for_adaptive_inference	/pdf/c861d92e8fdefab1d0acf1ffc52aebceda428893.pdf
YsNlFsG-jj	5089	When Rigid Coherency Hurts: Distributional Coherency Regularization for Probabilistic Hierarchical Time Series Forecasting	['Hierarchical Forecasting', 'Time Series Forecasting', 'Deep Probabilistic Models']	A novel probabilistic neural model for calibrated and accurate probabilistic forecasting on datasets of varying hierarchical consistency.	Applications (eg, speech processing, computer vision, NLP)	anonymous|when_rigid_coherency_hurts_distributional_coherency_regularization_for_probabilistic_hierarchical_time_series_forecasting	/pdf/508728f42ee177126342f7357ba264dd3bb4c7e4.pdf
GdimRqV_S7	5090	Homotopy Learning of Parametric Solutions to Constrained Optimization Problems	['homotopy', 'deep learning', 'constrained optimization', 'nonlinear programming', 'constrained deep learning', 'differentiable parametric programming']		Optimization (eg, convex and non-convex optimization)	anonymous|homotopy_learning_of_parametric_solutions_to_constrained_optimization_problems	/pdf/a0ced374431c75e1ba48182a73a80e92d94e2aaa.pdf
AgQ4GpzzRT	5091	Unsupervised Pretraining for Neural Value Approximation	['reinforcement learning', 'Neural Tangent Kernels', 'unsupervised pretraining', 'neural value approximation']	The paper presents an unsupervised pretraining approach that learns initializations of the critic/value network which possess desirable generalization properties in the context of deep reinforcement learning. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|unsupervised_pretraining_for_neural_value_approximation	/pdf/b60847d335070fcb1f9eb91c4ca32871a84c7c70.pdf
94bybXmOLz-	5093	Generative Adversarial Federated Model	[]		General Machine Learning (ie none of the above)	anonymous|generative_adversarial_federated_model	/pdf/6f6fadee9c0476e701522bdd533bfbace5002165.pdf
bvgHBkSBdcj	5094	HyperTime: Implicit Neural Representations for Time Series Generation	['Time Series', 'Implicit Neural Representations', 'Time Series Generation']	We propose a time series specific implicit neural representation architecture, and use it to generate synthetic data. 	Deep Learning and representational learning	anonymous|hypertime_implicit_neural_representations_for_time_series_generation	/pdf/d413fa02e19134d29aa58ba3ada15c703b600a36.pdf
lLu1Xel2qfh	5095	Cross-Silo Training of Differentially Private Models with  Secure Multiparty Computation	['Privacy-preserving machine learning', 'Secure multi party computation', 'Differential privacy']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|crosssilo_training_of_differentially_private_models_with_secure_multiparty_computation	/pdf/4c8c9f72bcc98799384ddcdcbf930c85452e61ce.pdf
2BruD7pa7E	5096	Global View For GCN: Why Go Deep When You Can Be Shallow?	['GCN', 'GNN', 'Clustering', 'Semi-supervised Learning']		General Machine Learning (ie none of the above)	anonymous|global_view_for_gcn_why_go_deep_when_you_can_be_shallow	/pdf/44976c2d55653bf9461922c323ec6f3386e261ac.pdf
wWg_Ee5q_W	5097	Speed Up Iterative Non-Autoregressive Transformers by Distilling Multiple Steps	['non-autoregressive machine translation', 'knowledge distillation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|speed_up_iterative_nonautoregressive_transformers_by_distilling_multiple_steps	/pdf/ca8e509a552b650dbca76851a7f34166d069b972.pdf
m2A7e4fMvT	5099	An Exploration of Conditioning Methods in Graph Neural Networks	['graph neural networks', 'geometric deep learning', 'deep learning']	We unify three conditioning methods in graph neural networks in a common formulation and compare their performance on several tasks in computational chemistry.	Deep Learning and representational learning	anonymous|an_exploration_of_conditioning_methods_in_graph_neural_networks	/pdf/c4ccfdbe1aede5ad84105c8ececfa5c67ce66426.pdf
WhoOFXdnys6	5100	MAD for Robust Reinforcement Learning in Machine Translation	['Machine Translation', 'Reinforcement Learning']	New distributed policy gradient algorithm that outperforms existing reward-aware training procedures such as REINFORCE, minimum risk training (MRT) and proximal policy optimization (PPO) when optimizing machine translation models.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|mad_for_robust_reinforcement_learning_in_machine_translation	/pdf/3f4c2f04f030720f267d77a94b5af35fafb8522a.pdf
wfU0emciOcM	5102	On the Importance of Contrastive Loss in Multimodal Learning	['multimodal learning', 'contrastive learning']	We show that contrastive pairs are important for models to learn aligned and balanced representations in multimodal learning. 	Unsupervised and Self-supervised learning	anonymous|on_the_importance_of_contrastive_loss_in_multimodal_learning	/pdf/4186ecbe08ddddeedbb82b90e12dd5ebfad197aa.pdf
J7Uh781A05p	5105	Learning rigid dynamics with face interaction graph networks	['graph networks', 'rigid body dynamics', 'physics']	Face to face, multi-index collisions improve accuracy and efficiency of graph network models for rigid body dynamics	Deep Learning and representational learning	anonymous|learning_rigid_dynamics_with_face_interaction_graph_networks	/pdf/fd598c5574252ebd1ad724584f1f7f96092ece2c.pdf
Q120_4COf-K	5106	Synthetic Data Generation of Many-to-Many Datasets via Random Graph Generation	['synthetic data generation', 'random graph generation', 'differential privacy']	We synthesise datasets with many-to-many relationships by first generating the relationships via random graph generation and then generating the data attributes.	Generative models	anonymous|synthetic_data_generation_of_manytomany_datasets_via_random_graph_generation	/pdf/04af9a3058b73eec8b3639c64acf682b19483788.pdf
XZRmNjUMj0c	5107	Efficient One-Shot Neural Architecture Search With Progressive Choice Freezing Evolutionary Search	[]		General Machine Learning (ie none of the above)	anonymous|efficient_oneshot_neural_architecture_search_with_progressive_choice_freezing_evolutionary_search	/pdf/7c731b204790b51769b1f70c6a7625c872879d26.pdf
_omKGvXq0oX	5108	ESEAD: An Enhanced Simple Ensemble and Distillation Framework for Natural Language Processing	['Natural Language Processing', 'Knowledge Distillation']	A simple yet effective logits-based distillation method for natural language processing.	Applications (eg, speech processing, computer vision, NLP)	anonymous|esead_an_enhanced_simple_ensemble_and_distillation_framework_for_natural_language_processing	/pdf/88893d3cc55a9e591e02dce1ca324b8227f3360b.pdf
9Z_GfhZnGH	5109	Disentangling with Biological Constraints: A Theory of Functional Cell Types	['Disentangling', 'neurosciece', 'representation learning', 'hippocampus', 'cortex']	We prove biological constraints of nonnegativity and energy efficiency lead to disentanged representations, and empirically demonstrate this in machine learning and neuroscience tasks.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|disentangling_with_biological_constraints_a_theory_of_functional_cell_types	/pdf/e752da3d6169b6ddfa4a7419d06c5676cde7e4f6.pdf
0DwzMsUNIr	5111	From Points to Functions: Infinite-dimensional Representations in Diffusion Models	['representation learning', 'diffusion models', 'score-based learning']	We perform an analysis on the trajectory-based representation obtained from Diffusion Based Representation Learning to measure how different points of the trajectory encode semantically different information.	Deep Learning and representational learning	anonymous|from_points_to_functions_infinitedimensional_representations_in_diffusion_models	/pdf/7468ebbb4a24dcec5d669794571b7162e93f854d.pdf
wAQU0Frxoa	5112	Neural Networks as Paths through the Space of Representations	['representational similarity', 'metrics', 'geodesic', 'neural network expressivity', 'visualization']	We visualize how information is transformed through a network using geometry derived from representational distance metrics.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|neural_networks_as_paths_through_the_space_of_representations	/pdf/3b2c04fa87774efff1b8cfdaa76a36f78431f1e6.pdf
p5DeuCSE9q	5113	Recurrent Back-Projection Generative Adversarial Network for Video Super Resolution	['Video Super Resolution', 'GANs', 'Temporal Coherence', 'Recurrent Projection.']	Enhancing videos quality through the exploitation of Recurrent Back-Projection Generative Adversarial Networks	Generative models	anonymous|recurrent_backprojection_generative_adversarial_network_for_video_super_resolution	/pdf/4f2cb643e7d131beaa96020f2565d15f9d8d04f9.pdf
hNyJBk3CwR	5114	Is Model Ensemble Necessary? Model-based RL via a Single Model with Lipschitz Regularized Value Function	['Model-based Reinforcement Learning', 'Probabilistic Dynamics Model Ensemble', 'Lipschitz Regularization']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|is_model_ensemble_necessary_modelbased_rl_via_a_single_model_with_lipschitz_regularized_value_function	/pdf/54a5887a0b646869e89a6306983c2a594cc52aed.pdf
9hp9PIFDhsK	5115	SuperFed: Weight Shared Federated Learning	['Weight Shared', 'Federated Learning']	Federated Training of K models in O(1) (amortized) communication and computation cost. 	Deep Learning and representational learning	anonymous|superfed_weight_shared_federated_learning	/pdf/ab922769d45011403fa772e5cdbc3839c2f04abe.pdf
gY25_vAwX6G	5116	Attribution Scores are Redundant: Explaining Feature Contribution By Trajectories	['Interpretability', 'Trajectory Importance', 'Combinatorial Optimization']	We propose a novel form of explanation that not only outperforms attribution methods in the most commonly used insertion/deletion metric, but also is able to theoretically achieve the best possible explanations under such metric.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|attribution_scores_are_redundant_explaining_feature_contribution_by_trajectories	/pdf/5de28fa9edeb875e23cef7ed09975aecdfe5e875.pdf
MsjB2ohCJO1	5117	How to Do a Vocab Swap?  A Study of Embedding Replacement for Pre-trained Transformers	['transfer learning', 'transformers', 'language models']	We investigate strategies for swapping the vocabularies of transformer encoders using smart initializations.	Deep Learning and representational learning	anonymous|how_to_do_a_vocab_swap_a_study_of_embedding_replacement_for_pretrained_transformers	/pdf/52161e1704ddec28125f644b4481fc8c99130ffc.pdf
bhfp5GlDtGe	5118	Adversarial Imitation Learning with Preferences	['preference learning', 'learning from demonstration', 'adversarial imitation learning']	We extend Adversarial Imitation Learning to simultaneously utilize both demonstrations and preferences.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|adversarial_imitation_learning_with_preferences	/pdf/7be01e3c04ee7f719286b2ad5b6e66253e3e60bb.pdf
gmufyyjyjnN	5119	Semi-supervised consistency regularization for accurate cell type fraction and gene expression estimation	['Cell deconvolution', 'consistency regularization']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|semisupervised_consistency_regularization_for_accurate_cell_type_fraction_and_gene_expression_estimation	/pdf/d1e81065ba7da3a21b2630db8bea76d38474febc.pdf
NmZXv4467ai	5120	Decision Transformer under Random Frame Dropping	['Decision Transformer', 'Reinforcement Learning', 'Frame Dropping']	Learning to control against random frame dropping through three original modifications to the Decision Transformer.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|decision_transformer_under_random_frame_dropping	/pdf/a7adf6c9698d485ef6e5ad27e6e395a8eaf587e0.pdf
BYWWwSY2G5s	5122	Score-based Continuous-time Discrete Diffusion Models	['discrete space diffusion', 'discrete score matching', 'continuous-time diffusion']	a generalized discrete score matching for learning continuous-time diffusion in categorical spaces, with new parameterization and novel analytical sampling.	Generative models	anonymous|scorebased_continuoustime_discrete_diffusion_models	/pdf/8852057fc804f70a07099e15f17bd7d83057ea99.pdf
vKXd1m74DkN	5123	Artificial Replay: A Meta-Algorithm for Harnessing Historical Data in Bandits	['multi-armed bandits', 'historical data', 'adaptive discretization', 'online learning']	We propose a meta-algorithm for multi-armed bandits that most efficiently uses historical data, overcoming challenges of spurious data and imbalanced data coverage.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|artificial_replay_a_metaalgorithm_for_harnessing_historical_data_in_bandits	/pdf/cffc27a7f289a857284a31d079fa8c1e2252026d.pdf
8taH4yjN62m	5124	UNDERSTANDING THE ROLE OF POSITIONAL ENCODINGS IN SENTENCE REPRESENTATIONS	['Positional Encodings', 'Sentence Representations', 'Pre-trained Language Models']	In this work, we investigate the role of positional encodings systematically.	Deep Learning and representational learning	anonymous|understanding_the_role_of_positional_encodings_in_sentence_representations	/pdf/e40b0503caed317877a1e4632c91099fe3a9ab2c.pdf
5ycxwq2VFAX	5125	DECODING LAYER SALIENCY IN TRANSFORMERS	['saliency', 'explainability', 'transparency', 'transformers', 'NLP', 'feature attribution']		Deep Learning and representational learning	anonymous|decoding_layer_saliency_in_transformers	/pdf/2151a9b6926db5558204450b6d861ef4c4fd28d1.pdf
qyBgN5bLasw	5126	Learning parsimonious dynamics for generalization in reinforcement learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_parsimonious_dynamics_for_generalization_in_reinforcement_learning	/pdf/4b6b7a173d3bf603e0c6c8620405424e74fa0679.pdf
9BXSGPfRhX	5127	Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN’s	['Few-Shot Learning', 'Object Detection', 'Distribution Shift']	We propose Cooperating RPN’s for improving the fairness to object aspect ratio distribution in few-shot object detection.	Applications (eg, speech processing, computer vision, NLP)	anonymous|improving_aspect_ratio_distribution_fairness_in_detector_pretraining_via_cooperating_rpns	/pdf/4ffec6b0e2e0e229c08c3e51d2248f598898f99d.pdf
PYbe4MoHf32	5128	Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|scaling_up_and_stabilizing_differentiable_planning_with_implicit_differentiation	/pdf/92d34831ef41b2bcef5e7c82c3717a0819a34a38.pdf
MdKAP5oHJ5l	5129	In-Time Refining Optimization Trajectories Toward Improved Robust Generalization	['Adversarial Robustness', 'Optimization Trajectories', 'Robust overfitting']	We propose a new method named weighted optimization trajectories (WOT) that refines the optimization trajectories of adversarial training in time to improve robust generalization.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|intime_refining_optimization_trajectories_toward_improved_robust_generalization	/pdf/d51097a1b4f0de32b3105d950631020881be7f01.pdf
6yaLHYv5L91	5130	The Ultimate Combo: Boosting Adversarial Example Transferability by Composing Data Augmentations	['Adversarial machine learning', 'transferability', 'evasion', 'black-box attacks']	We comprehensively studied data-augmentation methods for enhancing the transferability of adversarial examples, finding compositions that work best, and advancing the state of the art.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|the_ultimate_combo_boosting_adversarial_example_transferability_by_composing_data_augmentations	/pdf/26d8c09059f27994f6a82f44a985bdf1cd32e2f7.pdf
sKDtBKYOdIP	5131	Beam Tree Recursive Cells	['Recursive Neural Networks', 'RvNNs', 'length generalization', 'systematicity']	We apply beam search on easy-parsing strategy to simulate RvNN without ground truth tree supervision and experiment its different extensions.	Deep Learning and representational learning	anonymous|beam_tree_recursive_cells	/pdf/621347f4f152086464bf89d50f21ab10af7f9866.pdf
dNqxZgyjcYA	5133	Conservative Bayesian Model-Based Value Expansion for Offline Policy Optimization	['Offline reinforcement learning', 'model-based reinforcement learning', 'model-based value expansion', 'Bayesian inference']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|conservative_bayesian_modelbased_value_expansion_for_offline_policy_optimization	/pdf/7703cefa246bdfc8c62b0a2951d13e2244eb2cf0.pdf
2T80ygeeWE0	5134	Graph schemas as abstractions for transfer learning, inference, and planning	['Schema learning', 'abstractions', 'higher order graphs', 'perceptual aliasing', 'aliased graphs', 'planning', 'spatial navigation', 'cognitive science']	We propose schemas in a higher order graph structures as a model for abstractions that can be used for rapid transfer learning, inference, and planning.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|graph_schemas_as_abstractions_for_transfer_learning_inference_and_planning	/pdf/0e89df31b222beada25449baefdbd78c065d66ec.pdf
70_umOqc6_-	5137	Motif-based Graph Representation Learning with Application to Chemical Molecules	['Graph Neural Networks', 'Molecular Graph Representation']	We propose a motif-based representation learning method to better capture local structure information and demonstrate the performance and explainability advantages on molecular benchmarks. 	Deep Learning and representational learning	anonymous|motifbased_graph_representation_learning_with_application_to_chemical_molecules	/pdf/580d86c5a9cd650d98be5533fff345c8025c2b3b.pdf
YhKScHeK4Ed	5138	The Game of Hidden Rules: A New Challenge for Machine Learning	['benchmark', 'environment', 'rule learning']	We present a new learning environment allowing researchers to rigorously study how the characteristics of learning tasks affect difficulty.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|the_game_of_hidden_rules_a_new_challenge_for_machine_learning	/pdf/74d87bf201ce8e89ffa0b69ca35d3e8155e41036.pdf
88nT0j5jAn	5139	Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching	['few-shot learning', 'dense prediction tasks']	a universal few-shot learner for general dense prediction tasks	Deep Learning and representational learning	anonymous|universal_fewshot_learning_of_dense_prediction_tasks_with_visual_token_matching	/pdf/a91716100ded627d1fcc318245fa2a1d3750d60c.pdf
XkwkFYPT6t	5140	DSI++: Updating Transformer Memory with New Documents	['Differentiable Search Index', 'Transformer Memory', 'Catastrophic Forgetting', 'Continual Learning', 'Lifelong Learning', 'Incremental Learning']	We introduce DSI++, a continual learning challenge for DSI that requires incrementally adding documents to the model and propose a two-fold approach focusing on training dynamics and data-based regularization to enable it.	Deep Learning and representational learning	anonymous|dsi_updating_transformer_memory_with_new_documents	/pdf/08e6d22388805564f1a19f1be9615a8672c2bfb3.pdf
3vzguDiEOr	5141	Membership Leakage in Pre-trained Language Models	['membership leakage', 'pre-trained language models', 'natural language processing']	This paper evaluates membership leakage of pre-trained language models	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|membership_leakage_in_pretrained_language_models	/pdf/a7089ef98e085c500f17fbdb66352ad667b81eb7.pdf
w9WUQkBvpI	5142	Subsampling in Large Graphs Using Ricci Curvature	['Graph subsampling', 'Ricci curvature']		Deep Learning and representational learning	anonymous|subsampling_in_large_graphs_using_ricci_curvature	/pdf/4cfbccdb8ae4d25e19a30120fb701b93f2de00ec.pdf
L9pW5fknjO	5144	Resource Efficient Self-Supervised Learning for Speech Recognition	['SSL', 'ASR']		Unsupervised and Self-supervised learning	anonymous|resource_efficient_selfsupervised_learning_for_speech_recognition	/pdf/6c4549351da9f7d21e2a7247bf1e0dab6f24a8ea.pdf
sMsShmoszg	5145	Mind the Privacy Budget: How Generative Models Spend their Privacy Budgets	['synthetic data', 'differential privacy', 'generative models', 'graphical models', 'GANs']	We analyze the specific steps in which different DP generative approaches ``spend'' their privacy budget and evaluate the effects on downstream tasks performance with increasingly wider and taller training datasets.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|mind_the_privacy_budget_how_generative_models_spend_their_privacy_budgets	/pdf/daaecd76c5fd7ec4ba7da0be8aa9e5cccaa35aa4.pdf
8cST_EWo9X	5146	Understanding ReLU Network Robustness Through Test Set Certification Performance	['Robustness Certificates', 'Robust Machine Learning', 'Out-Of-Distribution Detection']	Robustness certificates for ReLU networks are strongly correlated with network accuracy for data in-distribution and are highly unreliable for data out-of-distribution.	Deep Learning and representational learning	anonymous|understanding_relu_network_robustness_through_test_set_certification_performance	/pdf/8e382cbb5589d24a7bc7c5c229844607896dc29d.pdf
biGSK6L5JiT	5147	Online Continual Learning with Feedforward Adaptation	['Online adaptation', 'Online Learning', 'Continual Learning']	We propose an online adaptation method with feedforward compensation.	Optimization (eg, convex and non-convex optimization)	anonymous|online_continual_learning_with_feedforward_adaptation	/pdf/2a7e53c7a36399938d12dafc8be2c617758fcb36.pdf
zyLVMgsZ0U_	5148	Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions	['diffusion models', 'score-based generative models', 'sampling', 'score estimation', 'Langevin', 'stochastic differential equations']	We prove that given an L2-accurate score estimate, diffusion models can sample from (essentially) any data distribution, even if it is highly non-log-concave and/or supported on a low dimensional manifold.	Generative models	anonymous|sampling_is_as_easy_as_learning_the_score_theory_for_diffusion_models_with_minimal_data_assumptions	/pdf/02c0292f537146ab60a761978ab363edd4b35784.pdf
VZX2I_VVJKH	5149	Learning multi-scale local conditional probability models of images	['Image priors', 'Markov wavelet conditional models', 'multi-scale score-based image synthesis', 'denoising', 'super-resolution']	We develop a spatially Markov wavelet conditional probability model for images, and demonstrate (through, denoising, super-resolution and synthesis) its effectiveness in capturing global dependencies.	Generative models	anonymous|learning_multiscale_local_conditional_probability_models_of_images	/pdf/f4cb3e8bf565a11e4c814fe0ffb7561e05fc300a.pdf
lX478WYy0Up	5150	Towards A Unified View of Sparse Feed-Forward Network in Transformer	['Mixture of Expert', 'Neural Memory', 'Pre-trained Language Model', 'NLP']	We present a unified framework for large and sparse feed-forward networks in transformer, and use it to arrive at a better method.	Applications (eg, speech processing, computer vision, NLP)	anonymous|towards_a_unified_view_of_sparse_feedforward_network_in_transformer	/pdf/3c6cef74b504e82337a52bef05c53fb5fa4b6ac3.pdf
8aHzds2uUyB	5151	Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization	['natural language processing', 'reinforcement learning', 'language models', 'feedback learning']	We provide an open-source framework, benchmark, and novel algorithm to train large language models to better align to automated measures of human preferences.	Applications (eg, speech processing, computer vision, NLP)	anonymous|is_reinforcement_learning_not_for_natural_language_processing_benchmarks_baselines_and_building_blocks_for_natural_language_policy_optimization	/pdf/2fd04fec101d333918c75ae5fc0bcbcbb8bb6fad.pdf
t8Jk_Vo1jHS	5152	FedorAS: Federated Architecture Search under system heterogeneity	['Federated Learning', 'Neural Architecture Search', 'Deep Learning', 'Efficient DNN Training']	FedorAS is a system that performs cross-device Federated Neural Architecture Search under heterogeneous system and data distributions.	Deep Learning and representational learning	anonymous|fedoras_federated_architecture_search_under_system_heterogeneity	/pdf/92f28f09555778f7330853df529917776faafdc3.pdf
MhuFzFsrfvH	5154	Optimal Transport for Offline Imitation Learning	['offline reinforcement learning', 'optimal transport', 'imitation learning']	We present an offline imitation learning based on optimal transport that demonstrates strong performance and sample efficiency	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|optimal_transport_for_offline_imitation_learning	/pdf/5e349ac47ac9fd431693beae971e5584de10c4b8.pdf
wHfVEDi_N9E	5157	Knowledge Cascade: Reverse Knowledge Distillation	['Knowledge distillation', 'subsampling', 'large-scale data', 'nonparametric', 'reproducing kernel Hilbert space', 'asymptotic theory']		Deep Learning and representational learning	anonymous|knowledge_cascade_reverse_knowledge_distillation	/pdf/e1b27c32a7cda0b9f84473a8cff3626525337ac1.pdf
xsNTv784iah	5158	Towards Efficient Gradient-Based Meta-Learning in Heterogenous Environments	['few-shot learning', 'heterogeneous datasets', 'cross-domain adaptation']	In our paper, we propose a nonparametric version of MAML which is able to solve problems in heterogeneous enviroments	Deep Learning and representational learning	anonymous|towards_efficient_gradientbased_metalearning_in_heterogenous_environments	/pdf/367b8cf23579e3cd717143dff970214845f82d85.pdf
uNHWPiNJBsV	5160	Laser: Latent Set Representations for 3D Generative Modeling	['generative models', 'nerf', 'computer vision', '3D scenes', 'novel view synthesis', 'variational auto-encoder']	Generative NeRF with fast inference that can handle large scenes and can inpain unobserved parts of these scenes.	Generative models	anonymous|laser_latent_set_representations_for_3d_generative_modeling	/pdf/c5c637e6b95499f10a4896c62d2595c8e2b4f23c.pdf
a60Jo7_RUd2	5161	Improving Adversarial Robustness of Deep Neural Networks via Self-adaptive Margin Defense	['adversarial robustness', 'adversarial training', 'deep neural network']		General Machine Learning (ie none of the above)	anonymous|improving_adversarial_robustness_of_deep_neural_networks_via_selfadaptive_margin_defense	/pdf/ac6b724be1e88deadef56e0f8f859f2733acf7df.pdf
3ZHX6_Mydd7	5162	Invariant Aggregator for Defending against Federated Backdoor Attacks	['Federated learning', 'robustness', 'backdoor attack', 'invariant learning']	This paper shows how to defend against federated backdoor attacks by focusing on the invariant directions in the model optimization trajectory. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|invariant_aggregator_for_defending_against_federated_backdoor_attacks	/pdf/e521dab2c86b4640e78fa330f87810c85842266b.pdf
FUiDMCr_W4o	5163	A Statistical Framework for Personalized Federated Learning and Estimation: Theory, Algorithms, and Privacy	['Personalized Federated Learning', 'Personalized Statistical Estimation', 'Differential Privacy', 'Empirical/Hierarchical Bayes']	We utilize a statistical framework to enable our design of new personalized Federated Learning/Estimation algorithms with privacy guarantees.	General Machine Learning (ie none of the above)	anonymous|a_statistical_framework_for_personalized_federated_learning_and_estimation_theory_algorithms_and_privacy	/pdf/22d0c4d7d71527c826f846f1851cdf858c054577.pdf
NGIFt6BNvLe	5164	Double Wins: Boosting Accuracy and Efficiency of Graph Neural Networks by Reliable Knowledge Distillation	['Graph Neural Networks', 'Reliable Knowledge Distillation', 'Model Inference Acceleration']		Deep Learning and representational learning	anonymous|double_wins_boosting_accuracy_and_efficiency_of_graph_neural_networks_by_reliable_knowledge_distillation	/pdf/494e815d166428fb0069b16709c2eb5a2310063a.pdf
adgYjVvm9Xy	5165	Robust Federated Learning with Majority Adversaries via Projection-based Re-weighting	['Federated learning', 'robustness', 'adversarial attack', 'majority adversary']	This paper shows two methods for improving the adversarial robustness of federated learning under a majority adversary regime.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robust_federated_learning_with_majority_adversaries_via_projectionbased_reweighting	/pdf/c7d6887db6124b595ff0aeb9732c11fc625328a1.pdf
zWudXc9343	5166	Open-Vocabulary Panoptic Segmentation MaskCLIP	['open-vocabulary', 'panoptic segmentation', 'semantic segmentation', 'CLIP']		Applications (eg, speech processing, computer vision, NLP)	anonymous|openvocabulary_panoptic_segmentation_maskclip	/pdf/9a1b15a192d36936e29dfa9520f0cb02a46608ef.pdf
QsVditUhXR	5167	Soft Diffusion: Score Matching For General Corruptions	['diffusion', 'score-based models', 'generative models']	We define a broader family of corruption processes that generalizes previously known diffusion models and we show how to learn to reverse them.	Generative models	anonymous|soft_diffusion_score_matching_for_general_corruptions	/pdf/26d9f5f7411da08773c7ed3efb0e2f5449b7e045.pdf
IM4xp7kGI5V	5168	The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks	['margin', 'maximum-margin', 'implicit regularization', 'neural networks', 'neural collapse', 'gradient flow', 'implicit bias', 'robustness', 'homogeneous', 'symmetry', 'classification']	We generalize implicit max-margin bias to a class of models which describes nearly all networks, identifying a competition between maximizing margin and minimizing an asymmetric parameter norm, which can degrade robustness and explain Neural Collapse	Deep Learning and representational learning	anonymous|the_asymmetric_maximum_margin_bias_of_quasihomogeneous_neural_networks	/pdf/4ad5fe5de03373678ffb297c800926852331303b.pdf
VQfSsOTrLIy	5169	Pessimistic Model-Based Actor-Critic for Offline Reinforcement Learning: Theory and Algorithms	['Actor-critic', 'Model-based offline RL', 'PAC guarantee', 'Pessimism']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pessimistic_modelbased_actorcritic_for_offline_reinforcement_learning_theory_and_algorithms	/pdf/2fadf2f2b38baf6cf9713bb116af7d546e42466b.pdf
QPtMRyk5rb	5172	Contrastive Audio-Visual Masked Autoencoder	['multi-modal learning', 'audio-visual learning', 'self-supervised learning', 'masked autoencoder', 'contrastive learning']	We propose the Contrastive Audio-Visual Masked Auto-Encoder that combines contrastive learning and masked data modeling, two major self-supervised learning frameworks, to learn a joint and coordinated audio-visual representation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|contrastive_audiovisual_masked_autoencoder	/pdf/7fb8b72bc426b5c23507918709e69914cbe55290.pdf
uWpq1-rQbV	5173	Replay Buffer with Local Forgetting for Adaptive Deep Model-Based Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|replay_buffer_with_local_forgetting_for_adaptive_deep_modelbased_reinforcement_learning	/pdf/27fb3e701c94cfd07c8151490ba79727f6687aa9.pdf
KdwnGErdT6	5174	Calibrating the Rigged Lottery: Making All Tickets Reliable	[]		Deep Learning and representational learning	anonymous|calibrating_the_rigged_lottery_making_all_tickets_reliable	/pdf/dc7c8fa61a7d25e903f9ec402daaf69d0af53b71.pdf
10uNUgI5Kl	5175	Reward Design with Language Models	['reward design', 'foundation models', 'gpt3', 'reward specification', 'reinforcement learning', 'human-ai interaction']	We make reward design easier by using large language models models (like GPT-3) as a proxy for a user's reward function given that a user provides a few examples (or a description) of the desired behavior.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|reward_design_with_language_models	/pdf/a35c0f9ec76a6383d801cdd0cbbe26cbde226e26.pdf
W1cQ9FPFdb	5176	Two-Tailed Averaging: Anytime Adaptive Once-in-a-while Optimal Iterate Averaging for Stochastic Optimization	['optimization', 'polyak', 'iterate averaging', 'anytime', 'adaptive', 'online']	New approximately optimal iterate averaging algorithm with no hyperparameters that approximates the optimal average at all optimization steps.	Optimization (eg, convex and non-convex optimization)	anonymous|twotailed_averaging_anytime_adaptive_onceinawhile_optimal_iterate_averaging_for_stochastic_optimization	/pdf/4a56c6da02230cef5b371ba881b4bf2a55a30abb.pdf
Kk-kJl9fmm	5177	The Power of Feel-Good Thompson Sampling: A Unified Framework for Linear Bandits	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_power_of_feelgood_thompson_sampling_a_unified_framework_for_linear_bandits	/pdf/f4ec56015dc37b5e61aef9a07eedd3d567bbc6ab.pdf
b-WNV1iPro	5178	Credible, Sealed-bid, Optimal Repeated Auctions With Differentiable Economics	['Mechanism Design', 'Differentiable Economics', 'Deep Learning', 'Zero-Knowledge Proofs']	We propose an approach to run computationally efficient, credible, revenue-maximizing repeated auctions with cryptographic tools.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|credible_sealedbid_optimal_repeated_auctions_with_differentiable_economics	/pdf/f8e2dc0bd82ce55ad564a80d0b997277b6ea9b60.pdf
p0JSSa1AuV	5179	KwikBucks: Correlation Clustering with Cheap-Weak and Expensive-Strong Signals	['correlation clustering', 'text clustering', 'learning-augmented algorithms', 'weak and strong signals', 'query efficient clustering', 'query efficient', 'budgeted clustering']	Inspired by text clustering, we study correlation clustering where similarities must be queried via an expensive model (e.g. a large language model) with additional help from a cheap but noisy model (e.g. an embedding based model).	Unsupervised and Self-supervised learning	anonymous|kwikbucks_correlation_clustering_with_cheapweak_and_expensivestrong_signals	/pdf/0849045e7e13b7f01a2c6ff05b3fa238057e3357.pdf
GC5MsCxrU-	5180	Continual Active Learning	['Active Learning', 'Deep Learning', 'Efficient Machine Learning', 'Continual Learning']	We reduce Active Learning (AL) training time with the help of replay based Continual Learning algorithms all while maintaining performance on par with standard AL.  	Deep Learning and representational learning	anonymous|continual_active_learning	/pdf/e79e8be7ca18c02918beaf23fa3185ca77d8c5e6.pdf
-cqvvvb-NkI	5181	Recitation-Augmented Language Models	['Large Language Models', 'In-context Learning', 'Memorization', 'Closed-book Question Answering', 'CBQA']	We propose a novel recitation-augmented generation framework to improve language models’ performance in the closed-book question-answering setting.	Applications (eg, speech processing, computer vision, NLP)	anonymous|recitationaugmented_language_models	/pdf/fcd2d0d2667b0bdcbf8f0cc557c1e69239c0ee6c.pdf
FjNys5c7VyY	5182	DreamFusion: Text-to-3D using 2D Diffusion	['diffusion models', 'score-based generative models', 'NeRF', 'neural rendering', '3d synthesis']	DeepDream on a pretrained 2D diffusion model enables text-to-3D synthesis	Generative models	anonymous|dreamfusion_textto3d_using_2d_diffusion	/pdf/baad8c4b3fbb4b1804f21965ae3d7090aad51643.pdf
fR3wGCk-IXp	5184	Language models are multilingual chain-of-thought reasoners	['multilingual', 'reasoning', 'large language model']	We introduce the Multilingual Grade School Math (MGSM) benchmark, and analyze the multilingual multi-step reasoning abilities of large language models. 	Applications (eg, speech processing, computer vision, NLP)	anonymous|language_models_are_multilingual_chainofthought_reasoners	/pdf/0d11fcfb90f52a8757e5d374e5925b6ab564868f.pdf
fHT8kZcyyT	5185	CausalBench: A Large-scale Benchmark for Network Inference from Single-cell Perturbation Data	['causal discovery', 'gene regulatory networks', 'gene-gene interaction networks', 'network inference', 'single cell RNA sequencing', 'scRNAseq']	We introduce CausalBench - a comprehensive benchmark suite for evaluating network inference methods on perturbational single-cell gene expression data.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|causalbench_a_largescale_benchmark_for_network_inference_from_singlecell_perturbation_data	/pdf/911555fbd1947b69643a643e1e16d45b7f2daed9.pdf
25VgHaPz0l4	5186	Selection Collider Bias in Large Language Models	['large language models', 'causal inference', 'selection bias']	Using causal inference methods, we explain and demonstrate how sample selection bias causes spurious correlations during training, and how those spurious correlations can be used to classify prediction tasks as underspecified during inference.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|selection_collider_bias_in_large_language_models	/pdf/573b7b64462fbd1ad98052a9b5f6d1cc16db1ae8.pdf
jnpGR7xu_P_	5187	The Right Losses for the Right Gains: Improving the Semantic Consistency of Deep Text-to-Image Generation with Distribution-Sensitive Losses	['Generative Adversarial Networks', 'Attention', 'GAN', 'Text to Image', 'Contrastive learning']		Generative models	anonymous|the_right_losses_for_the_right_gains_improving_the_semantic_consistency_of_deep_texttoimage_generation_with_distributionsensitive_losses	/pdf/4fb00b07fe7fa835d884ba4dd5c3e2a169655329.pdf
Nvlqsofsc6-	5188	A Neural PDE Solver with Temporal Stencil Modeling	['neural PDE solver', 'Navier-Stokes equation', 'turbulent flow', 'Computational Fluid Dynamics', 'CFD']	We propose a novel Temporal Stencil Modeling (TSM) method for solving time-dependent PDEs in conservation form.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_neural_pde_solver_with_temporal_stencil_modeling	/pdf/ff0e8fa04bdee05587c55ccd1305ef8520424d74.pdf
NyR8OZFHw6i	5189	FIGARO: Controllable Music Generation using Learned and Expert Features	['symbolic music', 'style transfer', 'music generation', 'controllable generation', 'human-interpretability', 'self-supervised learning']	We achieve state-of-the-art results in symbolic music style transfer by enabling human-interpretable control over the generation process while improving sample quality at the same time.	Applications (eg, speech processing, computer vision, NLP)	anonymous|figaro_controllable_music_generation_using_learned_and_expert_features	/pdf/f62fc0862f6be9f8141b75536c64ace50e3b2455.pdf
f9eHl5mKx5i	5190	The Brainy Student: Scalable Unlearning by Selectively Disobeying the Teacher	['deep machine unlearning', 'machine unlearning', 'scalable unlearning']	We propose a new approach for deep machine unlearning that breaks free of limiting assumptions made in previous work, scales significantly better and consistently outperforms previous methods across a wide range of scenarios	Deep Learning and representational learning	anonymous|the_brainy_student_scalable_unlearning_by_selectively_disobeying_the_teacher	/pdf/c81214d4ce9345c2e0b18959ebb31c2141fd8c22.pdf
nXmU89Rfmgg	5191	Few-Shot Incremental Learning Using HyperTransformers	['few-shot learning', 'incremental learning', 'continual learning', 'transformers', 'hypernetworks']	An attention-based recurrent hypernetwork for incremental few-shot learning using prototypical loss	Deep Learning and representational learning	anonymous|fewshot_incremental_learning_using_hypertransformers	/pdf/35a172279fc7be7daaa969ca554f0ad78125f583.pdf
kDEL91Dufpa	5192	On the duality between contrastive and non-contrastive self-supervised learning	['Self-supervised learning', 'contrastive', 'non-contrastive']	We show that contrastive and non-contrastive self-supervised methods can be shown to be closely related, and then study how implementation details impact performance. We validate empirically our findings and significantly improve known behaviours.	Unsupervised and Self-supervised learning	anonymous|on_the_duality_between_contrastive_and_noncontrastive_selfsupervised_learning	/pdf/114280a7bf65948ce02b57c96716c196757c736b.pdf
20tAZh6Ut3	5193	Improving Accuracy and Explainability of Online Handwriting Recognition	['Machine Learning', 'Deep Learning', 'Explainability', 'Computer vision', 'Ensemble Learning']		General Machine Learning (ie none of the above)	anonymous|improving_accuracy_and_explainability_of_online_handwriting_recognition	/pdf/1a4048a60382231b2700e9e82bf939ce02f180c1.pdf
4u42KCQxCn8	5194	Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks	['natural language for robotics', 'instruction following', 'learning from demonstrations', 'multi-task learning', 'robotic manipulation']	Conditioning robotic manipulation policies on both demonstrations and language instructions improves sample efficiency and generalization to novel tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|using_both_demonstrations_and_language_instructions_to_efficiently_learn_robotic_tasks	/pdf/51f4390c18c7de90543a6565d6136f3c68281986.pdf
8vJcsZ-3Ly	5196	Does the Half Adversarial Robustness Represent the Whole? It Depends... A Theoretical Perspective of Subnetwork Robustness	['Adversarial Learning', 'Adversarial Robustness', 'Subnetworks', 'Semirobustness', 'Information-Theoretic Measures', 'Mutual Dependency']	We prove with theory and experimental results that if a subnetwork is adversarially robust and highly correlated with the rest of the network, then the remaining layers are also robust.	Deep Learning and representational learning	anonymous|does_the_half_adversarial_robustness_represent_the_whole_it_depends_a_theoretical_perspective_of_subnetwork_robustness	/pdf/5399b9b1c9d3fee966d76172b7d5a768edf7b53f.pdf
UAmH4nDH4l	5197	Contrastive Vision Transformer for Self-supervised Out-of-distribution Detection	['Out-of-distribution', 'self-supervised learning', 'contrastive learning', 'vision transformer']		Unsupervised and Self-supervised learning	anonymous|contrastive_vision_transformer_for_selfsupervised_outofdistribution_detection	/pdf/e9be925451c3385a8855bdb1dab0f11eba14bdcf.pdf
Bq1-IOPKet	5198	Optimal Transport-Based Supervised Graph Summarization	['Graph Summarization', 'Optimal Transport', 'Supervised Learning', 'Mutual Information']		General Machine Learning (ie none of the above)	anonymous|optimal_transportbased_supervised_graph_summarization	/pdf/56c9300d18dfcdbdb5e325056582e39fd2fe3db0.pdf
avNxfA4IXj	5199	Information-Theoretic Underpinnings of Generalization and Translation in Emergent Communication	['Emergent Communication', 'Information Theory']	Controlling emergent communication complexity and informativeness allows agents to generalize better and understand translations of natural language	Deep Learning and representational learning	anonymous|informationtheoretic_underpinnings_of_generalization_and_translation_in_emergent_communication	/pdf/0aebb1cb0393be813b35f08e73ef3adaebf21743.pdf
D7srTrGhAs	5200	HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers	['Knowledge Distillation', 'Structured Pruning', 'Pre-trained Transformer Language Models', 'Model Compression']	We propose a novel task-agnostic distillation method for Transformer-based language models equipped with iterative pruning.	Deep Learning and representational learning	anonymous|homodistil_homotopic_taskagnostic_distillation_of_pretrained_transformers	/pdf/50e1f08ef67d044e4d3d625a8b46ca2ff8261722.pdf
Fh97BDaR6I	5201	On The Specialization of Neural Modules	['Systematic Generalization', 'Linear Neural Networks', 'Neural Module Networks']	We use the linear neural networks framework to mathematically study the ability of neural modules to specialize and facilitate systematic generalization in modular network architectures.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_specialization_of_neural_modules	/pdf/ac3070f75759752d25d87b623961725ef0369010.pdf
Cs3r5KLdoj	5203	Learning MLPs on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency	['Graph Representation Learning', 'Knowledge Distillation']	We propose NOSMOG, a novel method to learn noise-robust and structure-aware MLPs on graphs, with superior effectiveness, outstanding robustness, and exceptional efficiency.	Deep Learning and representational learning	anonymous|learning_mlps_on_graphs_a_unified_view_of_effectiveness_robustness_and_efficiency	/pdf/94726ffd4aff418ba4b425a97471da78ad825693.pdf
6QkjC_cs03X	5204	A VAE for Transformers with Nonparametric Variational Information Bottleneck	['VAE', 'VIB', 'Bayesian nonparametrics', 'Transformers', 'natural language']	We propose a Variational AutoEncoder using Bayesian nonparametrics to regularise a Transformer encoder-decoder with latent mixture distributions.	Deep Learning and representational learning	anonymous|a_vae_for_transformers_with_nonparametric_variational_information_bottleneck	/pdf/5709cd055006e7ce7d8acd9b3d63c1e1c6df9c6d.pdf
ngCT1EelZk	5205	Aging with GRACE: Lifelong Model Editing with Key-Value Adaptors	[]	We continually fix large models' mistakes by caching learned activations in a codebook for a selected layer. The cached activations can be re-used to influence the model's behavior for future instances that are similar to previously-fixed errors.	Deep Learning and representational learning	anonymous|aging_with_grace_lifelong_model_editing_with_keyvalue_adaptors	/pdf/38fb284bb7845dd2f2d004ebab934aee908b1cbe.pdf
en9V5F8PR-	5206	Learning where and when to reason in neuro-symbolic inference	[]		General Machine Learning (ie none of the above)	anonymous|learning_where_and_when_to_reason_in_neurosymbolic_inference	/pdf/e106c25ff3c8ce8eebed57ee4537c80ddc67cad0.pdf
krFbWKl3Sz	5207	Achieving Communication-Efficient Policy Evaluation for Multi-Agent Reinforcement Learning: Local TD-Steps or Batching?	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|achieving_communicationefficient_policy_evaluation_for_multiagent_reinforcement_learning_local_tdsteps_or_batching	/pdf/e28be0476aa1721ba1fe1b74cf717158c6f3c859.pdf
FJXf1FXN8C	5208	Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation	[]	Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|towards_understanding_gd_with_hard_and_conjugate_pseudolabels_for_testtime_adaptation	/pdf/6f57008e792a0cd4191f19a48428a52052a76091.pdf
UcKEodTPtfI	5209	Optimal Data Sampling for Training Neural Surrogates of Programs	['programming languages', 'surrogates', 'program analysis']	We show how to optimally sample different paths of a program to construct a neural network surrogate of that program.	Deep Learning and representational learning	anonymous|optimal_data_sampling_for_training_neural_surrogates_of_programs	/pdf/6abf9493abb188252aa5b40c3da92a84627aadfb.pdf
T-qVtA3pAxG	5210	Serving Graph Compression for Graph Neural Networks	['Model compression', 'Graph Neural Networks']	Compressing the graph for graph neural networks inference	Deep Learning and representational learning	anonymous|serving_graph_compression_for_graph_neural_networks	/pdf/299ff558bf2b4935ca2aae77d0cc455c5fe05dcc.pdf
Frt6LTRFhui	5212	General Policy Evaluation and Improvement by Learning to Identify Few But Crucial States	['Reinforcement Learning', 'Off-Policy Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|general_policy_evaluation_and_improvement_by_learning_to_identify_few_but_crucial_states	/pdf/f1d2cb14f7ba3a5ce36ba80b62e941379d47830b.pdf
fVm3nZMZs9	5213	On Achieving Optimal Adversarial Test Error	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_achieving_optimal_adversarial_test_error	/pdf/0beb910f06e4793b537049e89b6592f730e7b1ba.pdf
35QyoZv8cKO	5216	ESCHER: Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regret	['game theory', 'two-player zero-sum', 'CFR', 'Reinforcement learning']	We propose a principled deep CFR algorithm that can scale to large games by removing importance sampling	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|escher_eschewing_importance_sampling_in_games_by_computing_a_history_value_function_to_estimate_regret	/pdf/99d709ffe68a0b0fa6f0df6a6de71c94750aae25.pdf
Pb-SC2gFOO	5219	Backdoor Attacks in the Supply Chain of Masked Image Modeling	['backdoor attack', 'masked image modeling']	In this paper, we perform the first security risk quantification of MIM through the lens of backdoor attacks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|backdoor_attacks_in_the_supply_chain_of_masked_image_modeling	/pdf/0c5ec0b08ce9e3512fdc3d80cd06802dbb8ef089.pdf
0nI0G46i6kT	5221	Real Data Distributions Prefer Simplicity and So Do Our Models: Why Machine Learning and Model Selection Are Possible	['No Free Lunch', 'PAC-Bayes', 'Simplicity Bias', 'Model Selection', 'Meta-Learning']	We demonstrate that neural networks, trained or randomly initialized, prefer the low-complexity data we observe in practice, and we explain how model selection can be automated.	General Machine Learning (ie none of the above)	anonymous|real_data_distributions_prefer_simplicity_and_so_do_our_models_why_machine_learning_and_model_selection_are_possible	/pdf/f70b71e745a87520d34ba58bd4dc7d6089d7e25d.pdf
935WW9F8ALr	5222	Learning to Improve Code Efficiency	['Machine Learning for Code', 'Program Synthesis', 'Program Optimization']	We propose a generative model trained on programming competition submissions to transform programs into faster versions of those programs.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_to_improve_code_efficiency	/pdf/01acafc2ac11ddac6b988b6e7f6c2e68f094759d.pdf
OYKIo3ySkxA	5226	DIGEST: FAST AND COMMUNICATION EFFICIENT DECENTRALIZED LEARNING WITH LOCAL UPDATES	['Decentralized Learning', 'Distributed Optimization', 'Communication Efficient Learning', 'Local SGD', 'Federated Learning']		Optimization (eg, convex and non-convex optimization)	anonymous|digest_fast_and_communication_efficient_decentralized_learning_with_local_updates	/pdf/15d23d406b0bb952d4ec06910609632533341a28.pdf
uXeEBgzILe5	5227	Blockwise self-supervised learning with Barlow Twins	['Blockwise training', 'self-supervised learning', 'local learning']	We extend current self-supervised learning methods to blockwise training scheme	Unsupervised and Self-supervised learning	anonymous|blockwise_selfsupervised_learning_with_barlow_twins	/pdf/9abf7a825e74341e07ffe38f5debe5754211e7e9.pdf
HVoJCRLByVk	5228	Can Neural Networks Learn Implicit Logic from Physical Reasoning?	['logic', 'logical operators', 'logical reasoning', 'intuitive physics', 'physical reasoning', 'representation learning', 'developmental psychology', 'cognitive science']		Deep Learning and representational learning	anonymous|can_neural_networks_learn_implicit_logic_from_physical_reasoning	/pdf/1924d794e11994802f25e91f69e79cec97064b15.pdf
TdBaDGCpjly	5230	Transformer-based World Models Are Happy With 100k Interactions	['Model-based Reinforcement Learning', 'World Models', 'Transfomers', 'Atari 100k benchmark']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|transformerbased_world_models_are_happy_with_100k_interactions	/pdf/4d87dd5299adc21d0e17ec93aeaee3f67d8c6b48.pdf
4hsI9zyNSfw	5231	Online Learning for Obstacle Avoidance	['obstacle avoidance', 'online optimization', 'regret minimization']	Regret bounds for online learning obstacle avoidance policies	Optimization (eg, convex and non-convex optimization)	anonymous|online_learning_for_obstacle_avoidance	/pdf/09c33971a4d0f04f740d097e7e706b30d4eb2d3f.pdf
j3GK3_xZydY	5233	Revisiting Curiosity for Exploration in Procedurally Generated Environments	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|revisiting_curiosity_for_exploration_in_procedurally_generated_environments	/pdf/9c61558815bc2a580de2465e3770cc11d0ecd6cf.pdf
-Ov808Vm7dw	5234	Less is More: Task-aware Layer-wise Distillation for Language Model Compression	['Knowledge Distillation', 'Pre-trained Language Models', 'Model Compression']	We propose a task-aware layer-wise knowledge distillation method for language model compression.	Deep Learning and representational learning	anonymous|less_is_more_taskaware_layerwise_distillation_for_language_model_compression	/pdf/641f2d65bc2a387b952480b7a6c02c9bdcb33f9d.pdf
uGEBxC8dnEh	5236	RankMe: Assessing the Downstream Performance of Pretrained Self-Supervised Representations by Their Rank	['self-supervised learning', 'evaluation', 'dimensional collapse', 'hyperparameter selection']	We show how the rank of representations can be used to measure their dowstream performance, even on unseen datasets. We validate this simple metric with thorough experiments and show its power for hyperparameter selection.	Unsupervised and Self-supervised learning	anonymous|rankme_assessing_the_downstream_performance_of_pretrained_selfsupervised_representations_by_their_rank	/pdf/71c2b07c7f58bb2ae6f8065547a2d5729edc6eed.pdf
rtTHBnBx4vO	5237	A Simple Approach for State-Action Abstraction using a Learned MDP Homomorphism	[]	MDP Homomorphism with a forwards-backwards model	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_simple_approach_for_stateaction_abstraction_using_a_learned_mdp_homomorphism	/pdf/5cf99a3a4b91671c59e2ab2a5125dc852dad0e9b.pdf
3BOwNcqM_Wq	5238	Learning to reason with relational abstractions	['mathematical reasoning', 'language models', 'relational abstraction']	Sequences with abstract relations can help models solve mathematical reasoning tasks with a significantly higher accuracy compared to those that are trained with human-generated sequences and other baselines.	Deep Learning and representational learning	anonymous|learning_to_reason_with_relational_abstractions	/pdf/8077fddac54d6cde5ee6b396d0374cdfb0148b9b.pdf
2SXIFDczAJG	5240	Domain Transfer with Large Dynamics Shift in Offline Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|domain_transfer_with_large_dynamics_shift_in_offline_reinforcement_learning	/pdf/c577fb7853d22d3ab4afae5e58f3b0d72d48b1a3.pdf
vSsnEd0Jmou	5243	Simulating Environments for Evaluating Scarce Resource Allocation Policies	['Simulation', 'Evaluation', 'Validation']	We provide a principled method for evaluating organ-allocation policies before deployment.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|simulating_environments_for_evaluating_scarce_resource_allocation_policies	/pdf/34e0fe1555e9159d0bed729408239729b12ab8e1.pdf
2b2s9vd7wYv	5244	LogicDP: Creating Labels for Graph Data via Inductive Logic Programming	['Data Programming', 'Graph Reasoning', 'Inductive Logic Programming']	A data programming framework for generating training labels for graph data	General Machine Learning (ie none of the above)	anonymous|logicdp_creating_labels_for_graph_data_via_inductive_logic_programming	/pdf/12a9921befc2497817740822cf3052986be13c80.pdf
KaKXygtEGK	5245	Efficient Approximations of Complete Interatomic Potentials for Crystal Property Prediction	['graph neural network', 'material property prediction', 'crystal property prediction', 'crystal structure modeling', 'interatomic potential']	We propose to directly model complete interactions for crystals with potential summations	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|efficient_approximations_of_complete_interatomic_potentials_for_crystal_property_prediction	/pdf/bcf47f25bc7ee3c44f3da5e0206a0798a260aab3.pdf
sE-9hkZL5wV	5246	Progressive Knowledge Distillation:  Constructing Ensembles for Efficient Inference	['progressive distillation', 'anytime inference', 'efficient inference', 'resource constrained ML', 'devices']		Deep Learning and representational learning	anonymous|progressive_knowledge_distillation_constructing_ensembles_for_efficient_inference	/pdf/ccff8171a7f5f5cdf36d71a9e1dd72469db3d087.pdf
DEGjDDV22pI	5247	Dichotomy of Control: Separating What You Can Control from What You Cannot	['Offline reinforcement learning', 'return-conditioned supervised learning', 'stochastic environments', 'decision transformer']	We propose dichotomy of control (DoC) for supervised learning in stochastic environments by separating things within a policy's control (actions) from those outside of a policy’s control (env stochasticity) through a mutual information constraint.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|dichotomy_of_control_separating_what_you_can_control_from_what_you_cannot	/pdf/1c091ced0d2d1322d3943d297ac928dfb56cb0f7.pdf
d8tJcOxnzF9	5248	Learning Multiobjective Program Through Online Learning	['Learning Multiobjective Program', 'Multiobjective Optimization']		General Machine Learning (ie none of the above)	anonymous|learning_multiobjective_program_through_online_learning	/pdf/0622a338f68b4bc5b07e41f9b4c62fe288715bfe.pdf
IrzkT99fDJH	5249	AGRO: Adversarial discovery of error-prone Groups for Robust Optimization	['robust optimization', 'distributionally robust', 'slice discovery', 'error analysis', 'adversarial learning']	AGRO is an end-to-end robust optimization technique that discovers error-prone groups and optimizes for their accuracy, resulting in improved robustness to test-time distributional shifts.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|agro_adversarial_discovery_of_errorprone_groups_for_robust_optimization	/pdf/5081bfc687572db5b696fd0fd5fd9ade5b508444.pdf
orbnZE-4UvD	5250	Test-Time Training on Video Streams	[]		Unsupervised and Self-supervised learning	anonymous|testtime_training_on_video_streams	/pdf/f35dbaf316d62cf449531e41c7ae42238629bbff.pdf
fJY2iCssvIs	5251	Improving the Strength of Human-Like Models in Chess	['Human-like AI', 'Curriculum Learning']	We efficiently train Human-like AI models to play chess at a stronger level, while retaining their human-like style, by extending the concept of curriculum learning to support multiple teachers..	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|improving_the_strength_of_humanlike_models_in_chess	/pdf/a2e615f8bb97f2161a68c2909defa7fe2c96859f.pdf
2x8EKbGU51k	5252	Fine-Tuning Offline Policies With Optimistic Action Selection	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|finetuning_offline_policies_with_optimistic_action_selection	/pdf/5ab6d6ab4d39d8d5d0f79def210ddd392ccdb6b6.pdf
nQBQByfLeSC	5253	Axiomatic Explainer Locality With Optimal Transport	['Interpretability', 'Explainability', 'Optimal Transport', 'Wasserstein']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|axiomatic_explainer_locality_with_optimal_transport	/pdf/52e7d3fed4ac9a2992b58b54fbccc1d9f70aa000.pdf
bth6XbnDmib	5254	Approximating any Function via Coreset for Radial Basis Functions: Towards Provable Data Subset Selection For Efficient Neural Networks training	['Data subset selection', 'Coresets', 'Radial basis functions neural networks', 'deep learning']		Deep Learning and representational learning	anonymous|approximating_any_function_via_coreset_for_radial_basis_functions_towards_provable_data_subset_selection_for_efficient_neural_networks_training	/pdf/b29caed09bd45913ca66a60a65589aef0b37a0a2.pdf
4TyNEhI2GdN	5256	TypeT5: Seq2seq Type Inference using Static Analysis	['Type inference', 'Code completion', 'Static analysis', 'Transformers', 'Pre-training']	Combining the strengths of CodeT5 and static analysis to predict Python type annotations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|typet5_seq2seq_type_inference_using_static_analysis	/pdf/8cca8118a15d86dcd965dd62b1866abbe812a540.pdf
aCuFa-RRqtI	5261	Label Propagation with Weak Supervision	['Semi-supervised learning', 'Weakly supervised learning', 'Label propagation']	Theoretical analysis of label propagation with prior information and connection to weak supervision	General Machine Learning (ie none of the above)	anonymous|label_propagation_with_weak_supervision	/pdf/4daf90abba6104302bb16a14a616029ca6e8f005.pdf
K1CNgCJtLLr	5262	CrystalBox: Efficient Model-Agnostic Explanations for Deep RL Controllers	['explainability', 'reinforcement learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|crystalbox_efficient_modelagnostic_explanations_for_deep_rl_controllers	/pdf/f98e9101fd2e0ff11ee98e4bf0825802f998c667.pdf
SbEvg8qlasl	5263	TEXTCRAFT: ZERO-SHOT GENERATION OF HIGH FIDELITY AND DIVERSE SHAPES FROM TEXT	['Text to shape generation', '3D shape generation', 'Zero-Shot Method', 'CLIP', 'Vision-Text models']		Applications (eg, speech processing, computer vision, NLP)	anonymous|textcraft_zeroshot_generation_of_high_fidelity_and_diverse_shapes_from_text	/pdf/881f0e812cb87844c43c5d98ffacec113b6e436c.pdf
qDgEEVS3TYM	5264	A Framework for Comprehensive Evaluations of Graph Neural Network based Community Detection using Node Clustering	['graph neural networks', 'clustering', 'community detection']		Unsupervised and Self-supervised learning	anonymous|a_framework_for_comprehensive_evaluations_of_graph_neural_network_based_community_detection_using_node_clustering	/pdf/dea6fac26084dc16ec4d7f54984efa0d0e43b1f9.pdf
BT4N_v7CLrk	5265	FunkNN: Neural Interpolation for Functional Generation	[]		Generative models	anonymous|funknn_neural_interpolation_for_functional_generation	/pdf/417a1c64f37326f2244e8bd14095daf93c7e7e93.pdf
mCmerkTCG2S	5266	Brain-like representational straightening of natural movies in robust feedforward neural networks	['Perceptual straightening', 'invertibility', 'robustness', 'visual cortex']	Brain-like temporal straightening of natural movies emerge in robust neural networks trained on static images 	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|brainlike_representational_straightening_of_natural_movies_in_robust_feedforward_neural_networks	/pdf/70a8d2e932f6dcac6c85a64f3491ee27b8f07672.pdf
Jbfd7BpQaa-	5267	Balance is Essence: Accelerating Sparse Training via Adaptive Gradient Correction	[]		Deep Learning and representational learning	anonymous|balance_is_essence_accelerating_sparse_training_via_adaptive_gradient_correction	/pdf/fa5dd52a9f74f3457c071b0ebeb8d2ab64314b2e.pdf
gmL46YMpu2J	5268	Promptagator: Few-shot Dense Retrieval From 8 Examples	['large language model', 'few-shot prompting', 'information retrieval']		Applications (eg, speech processing, computer vision, NLP)	anonymous|promptagator_fewshot_dense_retrieval_from_8_examples	/pdf/d3cc8859c1c20f52a68d99bec26d8563f84883d4.pdf
7J-30ilaUZM	5269	Learning Structured Representations by Embedding Class Hierarchy	['structured representations', 'representation learning', 'tree embedding']	We propose to learn structured representations that preserve the hierarchy between label classes by using CPCC as a regularizer.	Deep Learning and representational learning	anonymous|learning_structured_representations_by_embedding_class_hierarchy	/pdf/79a28fedf93a7eb99dec71223ec0b2552db89774.pdf
Ke2uzCpFcP0	5270	High-Precision Regressors for Particle Physics	['Boosted Decision Trees', 'Skip Connections', 'Deep Neural Networks', 'Particle Physics', 'Monte Carlo Simulation', 'Symmetry']	We design and build high-precision regressors that speed up Monte Carlo simulations in particle physics by a thousand to a million times	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|highprecision_regressors_for_particle_physics	/pdf/c0b8a1f280eb9b6a43af670156835a6332bf7c1b.pdf
dL35lx-mTEs	5271	Is Forgetting Less a Good Inductive Bias for Forward Transfer?	['continual learning', 'transfer learning']	Study if forgetting less is a good inductive bias for forward transfer. 	Deep Learning and representational learning	anonymous|is_forgetting_less_a_good_inductive_bias_for_forward_transfer	/pdf/8b680ae5a148e36ff7c783575efc84bd17706ab4.pdf
nJYAl6pVlc	5272	TKIL: Tangent Kernel Optimization for Class Balanced Incremental Learning	['Incremental Learning']	Tangent Kernel optimization for class balanced Incremental Learning that addresses the imbalances in memory-based incremental learning.	Deep Learning and representational learning	anonymous|tkil_tangent_kernel_optimization_for_class_balanced_incremental_learning	/pdf/82ee92a0b22faaed3bdf02069c752e2e67a6a455.pdf
nBi2tQ_Wba	5273	System identification of neural systems: If we got it right, would we know?	['Computational Neuroscience', 'Neural Networks']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|system_identification_of_neural_systems_if_we_got_it_right_would_we_know	/pdf/e3bdb590661bd334a411125c56668db64e76e06e.pdf
eGtS3Cuj1Zo	5274	Efficient Proxy for NAS is Extensible Now	['Neural Architecture Search', 'Zero Cost Neural Architecture Search', 'Efficient NAS', 'Self-supervised Learning', 'Computer Vision']	We proposed a configurable and extensible efficient proxy task for evaluating neural architectures with a search method to extend the proxy to various downstream tasks and search spaces.	Deep Learning and representational learning	anonymous|efficient_proxy_for_nas_is_extensible_now	/pdf/09c3676f71572311e1ca649dbb6520f79337b5ae.pdf
X4Jj-SmWX_i	5275	Improving Subgraph Representation Learning via Multi-View Augmentation	['Graph Learning', 'Subgraph Representation Learning', 'Graph Data Augmentation', 'Multi-view Augmentation']	We develop a novel multi-view augmentation mechanism to improve subgraph representation learning models and thus the accuracy of downstream prediction tasks.	Deep Learning and representational learning	anonymous|improving_subgraph_representation_learning_via_multiview_augmentation	/pdf/1f1cebe9bf0a3718b36ef803239fbc0a3acf55fd.pdf
4cOfD2qL6T	5276	Exploring perceptual straightness in learned visual representations	['adversarial robustness', 'deep learning', 'representation learning', 'computer vision', 'neuroscience', 'human vision']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|exploring_perceptual_straightness_in_learned_visual_representations	/pdf/119518c766bf67310b763743694bbf90c6dd4ac6.pdf
XC_yGI-0j9	5277	Efficient approximation of neural population structure and correlations with probabilistic circuits	['Computational neuroscience', 'Probabilistic circuits', 'Sum Product networks', 'AI for science']	We present a computationally efficient generative model for a wide range of population structures with higher order correlations and a large number of neurons. 	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|efficient_approximation_of_neural_population_structure_and_correlations_with_probabilistic_circuits	/pdf/ff107f2dd4a94206129a2ffaa134daa43478e7a8.pdf
ceDaKReXBdY	5279	Fairness via Adversarial Attribute Neighbourhood Robust Learning	[]	We propose a principled Robust Adversarial Attribute Neighbourhood (RAAN) loss to debias the classification head and to promote a fairer representation distribution across different sensitive attribute groups with a theoretical guarantee	Deep Learning and representational learning	anonymous|fairness_via_adversarial_attribute_neighbourhood_robust_learning	/pdf/566dbfe2b09d613db6bdffe5a1092b83bbc3a3ee.pdf
49N06mWPFUm	5280	Provably Efficient Reinforcement Learning for Online Adaptive Influence Maximization	['influence maximization', 'reinforcement learning']	We propose a model-based optimistic RL approach to solve the content-dependent online adaptive influence maximization problem.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|provably_efficient_reinforcement_learning_for_online_adaptive_influence_maximization	/pdf/8b426c8887e43e6aaa2998ac612436f6f764827e.pdf
YnPpdxEcZbi	5281	Temporal Change Sensitive Representation for Reinforcement Learing	['Reinforcement Learning', 'Representation Learning']	TCSR is a self-supervised representation learning auxiliary task designed for reinforcement learning methods with a latent dynamic model.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|temporal_change_sensitive_representation_for_reinforcement_learing	/pdf/c10838a1e45f8c6bd4ee51e808f7f0fc2e3f825d.pdf
F8VKQyDgRVj	5282	Neural Compositional Rule Learning for Knowledge Graph Reasoning	['Logical Rule', 'Knowledge Graph', 'Reasoning', 'Compositionality', 'Systematicity']	In this paper, we propose an end-to-end neural model for learning compositional logic rules called NCRL. NCRL treats logic rules as a hierarchical tree, and breaks the rule body into small atomic compositions during inference.	Deep Learning and representational learning	anonymous|neural_compositional_rule_learning_for_knowledge_graph_reasoning	/pdf/9c687a71c1272e31b61f28eb11a7e25fb75999da.pdf
2PI2EKASh_Z	5283	Revisiting Information-Based Clustering with Pseudo-Posterior Models	[]		Unsupervised and Self-supervised learning	anonymous|revisiting_informationbased_clustering_with_pseudoposterior_models	/pdf/c77028dcaab3e58b720a08d404b2691d43c18053.pdf
Jzliv-bxZla	5285	Mitigating Propagation Failures in PINNs using Evolutionary Sampling	['Physics-informed Neural Networks', 'Adaptive Sampling', 'Failure Modes of PINNs.']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|mitigating_propagation_failures_in_pinns_using_evolutionary_sampling	/pdf/cae8bad87b5d771d905e49d7f7ee75d71e4affca.pdf
H7M_5K5qKJV	5286	Progressive Mix-Up for Few-Shot Supervised Multi-Source Domain Transfer	['Representation Learning', 'Domain Adaptation']		Deep Learning and representational learning	anonymous|progressive_mixup_for_fewshot_supervised_multisource_domain_transfer	/pdf/c39a5db709d44e1af9cea53bf84feed916db5866.pdf
yRkNJh5WgRE	5287	Accelerated Training via Principled Methods for Incrementally Growing Neural Networks	[]		Deep Learning and representational learning	anonymous|accelerated_training_via_principled_methods_for_incrementally_growing_neural_networks	/pdf/9101e69ce3cd553ed68a54d9f69821f416caede8.pdf
RZT4uwbZ5qr	5288	Memory Efficient Dynamic Sparse Training	['Dynamic Sparse Training', 'Sparse Neural Networks']		Deep Learning and representational learning	anonymous|memory_efficient_dynamic_sparse_training	/pdf/cbfb25ddd5cc474e8abe2c6d9743deeda0893b4a.pdf
1C6nCCaRe6p	5291	A Simple Approach for Visual Room Rearrangement: 3D Mapping and Semantic Search	['Embodied AI', 'Deep Learning', 'Object Rearrangement']	A System For Exploring A Scene, Mapping Objects, and Rearranging Objects To A Visual Goal	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_simple_approach_for_visual_room_rearrangement_3d_mapping_and_semantic_search	/pdf/48bc312f2b09da1c81e6058fb85900f3ff951817.pdf
86_enbV-pNB	5292	Semi-Supervised Single Domain Generalization with Label-Free Adversarial Data Augmentation	['Representation Learning', 'Domain Generalization']		Deep Learning and representational learning	anonymous|semisupervised_single_domain_generalization_with_labelfree_adversarial_data_augmentation	/pdf/7d3f629222d10e51d9fe9b0672937e71acd89d3a.pdf
JLINxPOVTh7	5293	The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes	['Feature Learning', 'Neural Tangent Kernel', 'Scaling Laws', 'Deep Ensembles']	Empirical study of neural networks in the overparameterized regime shows how finite-width effects are brought on by initialization variance as sample size grows.	Deep Learning and representational learning	anonymous|the_onset_of_variancelimited_behavior_for_networks_in_the_lazy_and_rich_regimes	/pdf/da4388909f789581450c955a5c2f3083d38bc2a9.pdf
-AEYAk13n_a	5294	DeepReShape: Redesigning  Neural Networks for Private Inference	['Private Inference', 'Neural network design', 'ReLU efficiency']	Redesigning the neural network by distributing the network's ReLU in their order of criticality for higher ReLU-efficiency, and enabling FLOPs-ReLU-Accuracy balance for fast Private Inference. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|deepreshape_redesigning_neural_networks_for_private_inference	/pdf/69fb4143ce4f28d3e74142801e829ccdf4d89661.pdf
TwCGI3rVddj	5295	FLGAME: A Game-theoretic Defense against Backdoor Attacks In Federated Learning	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|flgame_a_gametheoretic_defense_against_backdoor_attacks_in_federated_learning	/pdf/a6657c2c63a1178e53f3fc6218eaac7d4db2998d.pdf
MGnPyYQ2QAA	5296	On a Benefit of Masked Language Model Pretraining: Robustness to Simplicity Bias	['language model', 'robustness', 'pretraining']	We theoretically and empirically show that MLM pretraining makes models robust to lexicon-level spurious features.	Deep Learning and representational learning	anonymous|on_a_benefit_of_masked_language_model_pretraining_robustness_to_simplicity_bias	/pdf/c7e29f41f5f4c2b31033fcb14c466477735eaae4.pdf
U086TJFWy4p	5298	Causally-guided Regularization of Graph Attention improves Generalizability	['graph neural network', 'attention', 'generalization', 'regularization', 'causal effect', 'causal interventions', 'interpretability']	We introduce a general regularization framework for graph attention networks that aligns attention weights with the causal effects of interventions on graph connectivity.	Deep Learning and representational learning	anonymous|causallyguided_regularization_of_graph_attention_improves_generalizability	/pdf/ae5866602dba73ab028ddb0912b01e3587f6577e.pdf
ZCTvSF_uVM4	5300	A Theoretical Framework for Inference and Learning in Predictive Coding Networks	['predictive coding', 'backpropagation', 'target propagation', 'machine learning', 'neuroscience']	We provide a comprehensive mathematical framework for understanding predictive coding networks including novel links with target propagation and expectation maximisation and prove that they converge to the same minima as backdrop	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|a_theoretical_framework_for_inference_and_learning_in_predictive_coding_networks	/pdf/547186f95ecdad75291f5946bb31ace1665ed9d5.pdf
nIMifqu2EO	5302	Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning	['predictive coding', 'equilibrium propagation', 'contrastive hebbian learning', 'backprop', 'machine learning', 'computational neuroscience']	We unify and provide a single limit for many papers in the literature concerning when energy based models approximate backdrop, typically in the context of biologically plausible learning algorithms	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|backpropagation_at_the_infinitesimal_inference_limit_of_energybased_models_unifying_predictive_coding_equilibrium_propagation_and_contrastive_hebbian_learning	/pdf/f43b714b2dbb74467a77066e712e9e8af0645590.pdf
p4X5ZrM2AY	5304	An Empirical Study of the Neural Contextual Bandit Algorithms	['Contextual Bandits', 'Neural Network', 'Neural Bandits']		Deep Learning and representational learning	anonymous|an_empirical_study_of_the_neural_contextual_bandit_algorithms	/pdf/4d9568f7c1bcbd5194267d1a5490e35aac791b4a.pdf
iBdwKIsg4m	5306	f-DM: A Multi-stage Diffusion Model via Progressive Signal Transformation	['diffusion models', 'progressive signal transformation']	We propose a generalized family of diffusion models that incorporates progressive signal transformation including downsampling, blurring and VAEs.	Generative models	anonymous|fdm_a_multistage_diffusion_model_via_progressive_signal_transformation	/pdf/c49140bbfe0d397e5323ca2e919b7833f3a8c27e.pdf
tCsdRTELrZs	5308	A Retrieve-and-Read Framework for Knowledge Graph Reasoning	['Knowledge Graph Reasoning', 'Graph Neural Networks', 'Transformer']	We introduce a Retrieve-and-Read Framework for Knowledge Graph Reasoning	Deep Learning and representational learning	anonymous|a_retrieveandread_framework_for_knowledge_graph_reasoning	/pdf/b0e76653f39e6f3827394a775e98b417d1aa62fb.pdf
4FBUihxz5nm	5309	A Mixture-of-Expert Approach to RL-based Dialogue Management	['Reinforcement learning']	A mixture-of-expert based dialogue manager that is amenable to sequential decision making techniques	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_mixtureofexpert_approach_to_rlbased_dialogue_management	/pdf/e32018d8aff14fe4b07d61b96ced3d0988b2fa2d.pdf
lgYzzQ0fX5D	5310	Graph Neural Networks Are More Powerful Than we Think	['graph neural networks', 'expressive power', 'representation', 'graph isomorphism', 'classification', 'spectral decomposition']		Deep Learning and representational learning	anonymous|graph_neural_networks_are_more_powerful_than_we_think	/pdf/f6f5526c134bbca03c6775a1f3128f9d5a6eb194.pdf
IPrzNbddXV	5311	FedExP: Speeding up Federated Averaging via Extrapolation	['Federated Learning', 'Optimization', 'Step Size']	We propose FedExP, a method to adaptively determine the server step size in FedAvg for faster convergence.  	Optimization (eg, convex and non-convex optimization)	anonymous|fedexp_speeding_up_federated_averaging_via_extrapolation	/pdf/741d6467b3a682a515996d4becbc34aa60177b24.pdf
NGv_ui-1wz	5312	Fair Graph Message Passing with Transparency	['Fairness', 'Transparency', 'Graph Neural Networks']	We aim to achieve fair message passsing with transparency to explictly use sensitive attributes in forward progagation instead of backward propagation..	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fair_graph_message_passing_with_transparency	/pdf/80b15bdf5559f1ef0a9d7e925b87d086f68cb300.pdf
8efJYMBrNb	5313	Multiple sequence alignment as a sequence-to-sequence learning problem	['sequence alignment', 'molecular evolution', 'natural language processing', 'bioinformatics']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|multiple_sequence_alignment_as_a_sequencetosequence_learning_problem	/pdf/4b8f14e12a9c6ad67322bfa88acebdfcc0957687.pdf
J41IW8Z7mE	5314	Membership Inference Attacks Against Text-to-image Generation Models	['Text-to-image Generation Model', 'Membership inference attacks']	We perform the first privacy analysis of text-to-image generation models through the lens of membership inference.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|membership_inference_attacks_against_texttoimage_generation_models	/pdf/17a2dee76bcd3ce9e94567ae8c438bb30fb4c252.pdf
ZHyTtEd4lXz	5317	Differentiable Channel Selection for Self-Attention	['Differentiable Channel Selection', 'Self-Attention', 'Differentiable Neural Architecture Search', 'Re-IDentification', 'Object Detection', 'Image Classification']	We propose Differentiable Channel Selection (DCS) which searches for informative channels so as to compute semantic attention weights in a self-attention module.	Deep Learning and representational learning	anonymous|differentiable_channel_selection_for_selfattention	/pdf/7b7869c244935893d8d3acd6184b1d4a95259e3d.pdf
1P8eOmWgdk	5319	Model-free Reinforcement Learning that Transfers Using Random Reward Features	['Reinforcement Learning', 'Model-free', 'Transfer', 'Random Features']	We develop model-free reinforcement learning algorithms that transfer across tasks using random features to approximate reward functions.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|modelfree_reinforcement_learning_that_transfers_using_random_reward_features	/pdf/cd1905b7764780c913a943e094a3598d5b1a976a.pdf
k8_yVW3Wqln	5320	Systematic Rectification of Language Models via Dead-end Analysis	['Language Models', 'Detoxification', 'Dead-end Theory', 'Reinforcement Learning.']		Applications (eg, speech processing, computer vision, NLP)	anonymous|systematic_rectification_of_language_models_via_deadend_analysis	/pdf/68e98ee9726267032c1a13c1cea7dcef1acd172c.pdf
-Yzz6vlX7V-	5321	Variable Compositionality Reliably Emerges in Neural Networks	['compositionality', 'emergence', 'generalization', 'regularity']	Compositional systems reliably emerge between neural networks- just with natural language like variation.	Deep Learning and representational learning	anonymous|variable_compositionality_reliably_emerges_in_neural_networks	/pdf/94428396bc760d508590e08307a9004cfe16c85c.pdf
erHaiO9gz3m	5322	A Kernel-Based View of Language Model Fine-Tuning	['language models', 'fine-tuning', 'neural tangent kernels', 'tensor programs']	We show when language model fine-tuning can be in the kernel regime and derive a new kernel formula to describe Adam, and we empirically validate that this kernel can solve many downstream tasks.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_kernelbased_view_of_language_model_finetuning	/pdf/f58fe11bbc37e580117f827829e615a0252ded96.pdf
7wrq3vHcMM	5323	First Steps Toward Understanding the Extrapolation of Nonlinear Models to Unseen Domains	['extrapolation of nonlinear models', 'theory', 'structured domain shift', 'gaussian kernel']	We prove the first result for understanding the extrapolation of nonlinear model class with structured domain shifts.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|first_steps_toward_understanding_the_extrapolation_of_nonlinear_models_to_unseen_domains	/pdf/10d4e8b6af99da4a1cb40430db00b941605ee27a.pdf
yEsj8pGNl1	5324	Projective Proximal Gradient Descent for Nonconvex Nonsmooth Optimization: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property	['Nonconvex Nonsmooth Optimization', 'Projective Proximal Gradient Descent', 'Kurdyka-Lojasiewicz Property', 'Optimal Convergence Rate.']	We propose Projected Proximal Gradient Descent (PPGD) which solves a class of non-convex and non-smooth optimization problems with the Nesterov's optimal convergence rate.	Optimization (eg, convex and non-convex optimization)	anonymous|projective_proximal_gradient_descent_for_nonconvex_nonsmooth_optimization_fast_convergence_without_kurdykalojasiewicz_kl_property	/pdf/cf9b4bae59a2fac992c920d92fa0c52d9f4025a0.pdf
ctLFd1-gHJ	5325	Just Avoid Robust Inaccuracy: Boosting Robustness Without Sacrificing Accuracy	['robustness']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|just_avoid_robust_inaccuracy_boosting_robustness_without_sacrificing_accuracy	/pdf/30562d7f103c494e211655106a7422d8dc3f4cea.pdf
apxFz3xWhF	5326	Provable Re-Identification Privacy	['privacy', 'membership inference', 're-identification']	We propose a novel privacy notion with easily interpretable guarantees and a practical algorithm for achieving it on many machine learning tasks. We precisely characterize the relationship with differential privacy and experiments confirm our theory.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|provable_reidentification_privacy	/pdf/2146416855b6654a87932ffe7b3bad5c47709ed3.pdf
gL68u5UuWa	5327	Maximum Likelihood Learning of Energy-Based Models for Simulation-Based Inference	['Simulation Based Inference', 'Energy Based Models', 'Maximum Likelihood']	We introduce two Synthetic Likelihood methods for Simulation-Based Inference using Conditional Energy-Based Models	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|maximum_likelihood_learning_of_energybased_models_for_simulationbased_inference	/pdf/1591ce170fc911938fe47e95f6f908718709cb01.pdf
_qVhsWyWB9	5330	Deep Learning From Crowdsourced Labels: Coupled Cross-Entropy Minimization, Identifiability, and Regularization	['deep learning', 'learning under noisy labels', 'neural classifier', 'end-to-end learning', 'crowdsourcing']		Deep Learning and representational learning	anonymous|deep_learning_from_crowdsourced_labels_coupled_crossentropy_minimization_identifiability_and_regularization	/pdf/300bdad6402aafdf78276d3417be403735bf5889.pdf
zHSaBQtj-l	5331	Differentiable Rendering with Reparameterized Volume Sampling	['neural radiance fields', 'differentiable rendering', 'importance sampling', 'reparameterization trick']	An importance sampling-based rendering algorithm for neural radiance fields based alleviates the costs of redundant radiance computation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|differentiable_rendering_with_reparameterized_volume_sampling	/pdf/b1961e8136f2b02f6a228ccab87d2fd59ef71c2a.pdf
UJTgQBc91_	5332	Progressive Prompts: Continual Learning for Language Models without Forgetting	['natural language processing', 'continual learning', 'prompt tuning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|progressive_prompts_continual_learning_for_language_models_without_forgetting	/pdf/8a24ef2bae5ec8b2ed5e165fe2fe011e4df98dbd.pdf
_TbyZ0OxvC	5333	A Reproducible and Realistic Evaluation of Partial Domain Adaptation Methods	['Domain adaptation', 'benchmark', 'reproducible research', 'model selection']		Unsupervised and Self-supervised learning	anonymous|a_reproducible_and_realistic_evaluation_of_partial_domain_adaptation_methods	/pdf/9d7092e6450d7be317cc9aea5247a0b2fd59226c.pdf
dWhS55KGSKy	5334	Query by Self	['Active learning', 'Kalman Filter', 'Variance']		Deep Learning and representational learning	anonymous|query_by_self	/pdf/6cccd1bd56dd5a1334a5275935235c0bf32fc69e.pdf
fPVRcJqspu	5336	GOGGLE: Generative Modelling for Tabular Data by Learning Relational Structure	['tabular data', 'synthetic data', 'generative model']		Generative models	anonymous|goggle_generative_modelling_for_tabular_data_by_learning_relational_structure	/pdf/7c42d020b8a4b65bf74370ef84d6d14cff69cfe6.pdf
wyjAf9GPD_	5337	Koopman Operator Learning for Accelerating Quantum Optimization and Machine Learning	['Koopman operators', 'quantum optimization', 'machine learning']	Koopman opeartor learning for accelerating quantum optimization and quantum machine learning.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|koopman_operator_learning_for_accelerating_quantum_optimization_and_machine_learning	/pdf/180b18e16db865ff702c92fe18dfd17eb2cc9842.pdf
6u7mf9s2A9	5338	Interpretable Geometric Deep Learning via Learnable Randomness Injection	['Geometric Deep Learning', 'Interpretation', 'Graph Neural Networks']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|interpretable_geometric_deep_learning_via_learnable_randomness_injection	/pdf/c51dcf066f80c10b03fbaaa0008204dcea7102e1.pdf
GAGpLgWAWX	5339	Factors Influencing Generalization in Chaotic Dynamical Systems	['generalization', 'multi-task learning', 'chaos', 'dynamical systems', 'representation learning']	We explore factors influencing in- and out-of-distribution generalisation in forecasting chaotic dynamics.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|factors_influencing_generalization_in_chaotic_dynamical_systems	/pdf/5a8832e44e1ba4c9a180d96e74a4216907c3289a.pdf
MzQEMwIzlL	5340	Cross-Domain Few-Shot Relation Extraction via Representation Learning and Domain Adaptation	['few-shot', 'domain adaptation', 'relation extraction']		Applications (eg, speech processing, computer vision, NLP)	anonymous|crossdomain_fewshot_relation_extraction_via_representation_learning_and_domain_adaptation	/pdf/b43f277e8d3c6ead5a7f14f25f7b02618adb3080.pdf
6BLZcpw1sh	5341	Image Classification by Throwing Quantum Kitchen Sinks at Tensor Networks	[]		General Machine Learning (ie none of the above)	anonymous|image_classification_by_throwing_quantum_kitchen_sinks_at_tensor_networks	/pdf/21fe7ce467d46d3f689d05ed7375b0fb1c3c6443.pdf
Lmff9URfo5	5343	Cooperation or Competition: Avoiding Player Domination for Multi-target Robustness by Adaptive Budgets	['Multi-target Adversarial Training', 'Bargaining Game']	For multi-target adversarial training, we identify a phenomenon named player domination which leads to the non-convergence of previous algorithms and further design a novel adaptive budget method to achieve better robustness.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|cooperation_or_competition_avoiding_player_domination_for_multitarget_robustness_by_adaptive_budgets	/pdf/c9af44b2e943627209543202930acb8c2f97b68b.pdf
u9o4qgwJlj	5347	SaiT: Sparse Vision Transformers through Adaptive Token Pruning	['pruning', 'vision transformer', 'computer vision', 'deep learning']	This work proposes a general dense/sparse training framework and adaptive token pruning strategies for efficient vision transformer model acceleration.	Applications (eg, speech processing, computer vision, NLP)	anonymous|sait_sparse_vision_transformers_through_adaptive_token_pruning	/pdf/c05211970a5ad6b7eb89ea177806ded1eefe318c.pdf
qMK1Zd49IS	5348	Recursive Neural Programs: Variational Learning of Image Grammars and Part-Whole Hierarchies	['computer vision', 'generative models', 'composing representations', 'image grammar']	We introduce a neural generative model that addresses the part-whole hierarchy learning problem by modeling images as recursive hierarchical trees of probabilistic sensory-motor programs, enabling intuitive composition and learning of image grammars.	Generative models	anonymous|recursive_neural_programs_variational_learning_of_image_grammars_and_partwhole_hierarchies	/pdf/9e6d6422f69f57d63efa1ba1a7e8eaec54310b6a.pdf
ZS8L3Fbv-L	5349	The Value of Out-of-distribution Data	['Distribution Shift', 'Learning Theory']	We study the distribution shifts that could occur within datasets and demonstrate that under such shifts, the generalization error of the desired target task can be a non-monotonic function of the number of OOD samples.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|the_value_of_outofdistribution_data	/pdf/06a3164a13aa5fb6e9d8c79c4b834306b9aa8af9.pdf
_nF5imFKQI	5352	How I Learned to Stop Worrying and Love Retraining	[]		Deep Learning and representational learning	anonymous|how_i_learned_to_stop_worrying_and_love_retraining	/pdf/0da457f7fd31415922f695f418f4e4fcd66a8619.pdf
8pvnfTAbu1f	5353	Denoising Diffusion Samplers	['diffusion models', 'importance sampling', 'monte carlo', 'variational inference']	How to use denoising diffusion models ideas to sample unnormalized target densities and estimate their normalizing constants	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|denoising_diffusion_samplers	/pdf/696e7ad3825e95c32ce7780f4007d4e3995649d3.pdf
xTWoeTdHgH-	5354	Evaluating Unsupervised Denoising Requires Unsupervised Metrics	['Denoising', 'Unsupervised Learning', 'Evaluation Metrics', 'Statistical Estimation', 'Imaging', 'Electron Microscopy']	We introduce two novel unsupervised metrics, uMSE and uPSNR, computed exclusively from noisy data, which are asymptotically consistent estimators of the corresponding supervised metrics, MSE and PSNR, and yield accurate approximations in practice	Unsupervised and Self-supervised learning	anonymous|evaluating_unsupervised_denoising_requires_unsupervised_metrics	/pdf/d42ea0b3bb7c29426d80cf73396bb0bc4757ff43.pdf
XHjFakRjPsk	5355	Meta-Learning with Explicit Task Information	['meta-learning', 'climate change', 'agriculture', 'remote sensing']	A meta-learning algorithm which incorporates task-specific metadata to learn context across tasks	Applications (eg, speech processing, computer vision, NLP)	anonymous|metalearning_with_explicit_task_information	/pdf/edf4aa9eef506563ef2c8d981ad1285d3a095a72.pdf
goLFJ0ZNwl	5356	Forget Unlearning: Towards True Data-Deletion in Machine Learning	['Unlearning', 'Differential Privacy', 'Data Deletion', 'Noisy Gradient Descent']	"We show that unlearning guarantees do not ensure the ""right to be forgotten"" in the online setting, and we certify noisy GD as a trustworthy and utility-preserving deletion algorithm under our improved notion of data deletion."	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|forget_unlearning_towards_true_datadeletion_in_machine_learning	/pdf/596e93053416fc472bc24bc47364d19d5c26d28d.pdf
YtntjusJV6	5359	Interpretations of Domain Adaptations via Layer Variational Analysis	['deep learning theory', 'domain adaptation', 'transfer learning', 'variational analysis', 'knowledge transfer']	Interpretations of Domain Adaptations via Layer Variational Analysis	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|interpretations_of_domain_adaptations_via_layer_variational_analysis	/pdf/a274e9a63c86a209a7bc7ef209b6c2448b566049.pdf
EFTpmFg9cb	5360	GROOT: Corrective Reward Optimization for Generative Sequential Labeling	['sequential labeling', 'reward optimization', 'natural language processing']	This paper proposes a novel framework for iteratively training Seq2Seq models to directly optimize a given blackbox reward metric, showing its effectiveness on sequential labeling tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|groot_corrective_reward_optimization_for_generative_sequential_labeling	/pdf/dde152202b91f1680b3c7fac32af7bd980df807a.pdf
HJFVrpCaGE	5363	Provable Robustness against Wasserstein Distribution Shifts via Input Randomization	['Distributional Robustness', 'Wasserstein Distance', 'Certified Robustness']	We present provable robustness guarantees on the accuracy of a model under Wasserstein shifts of the input distribution.	Deep Learning and representational learning	anonymous|provable_robustness_against_wasserstein_distribution_shifts_via_input_randomization	/pdf/eb34de2ee2c17f50f067c692507309386adc9c4c.pdf
Lnxl5pr018	5364	Empowering Graph Representation Learning with Test-Time Graph Transformation	['graph neural networks', 'out-of-distribution generalization', 'adversarial robustness']	Transforming the test graph data can enhance the generalization and robustness of graph neural networks.	Deep Learning and representational learning	anonymous|empowering_graph_representation_learning_with_testtime_graph_transformation	/pdf/9b97873ed0d2593f43fdf3120af507403be94b03.pdf
Dzmd-Cc8OI	5365	How Does Self-supervised Learning Work? A Representation Learning Perspective	[]		Unsupervised and Self-supervised learning	anonymous|how_does_selfsupervised_learning_work_a_representation_learning_perspective	/pdf/381871c3d7548509d00e254246e14af1a6daab3c.pdf
LUQ2Csy_LUm	5366	INSPIRE: A Framework for Integrating Individual User Preferences in Recourse	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|inspire_a_framework_for_integrating_individual_user_preferences_in_recourse	/pdf/5271e1e1fa036e2a4d63867e647bd9e65de2a2c2.pdf
BxXXPvrL1Pg	5367	Movement-to-Action Transformer Networks for Temporal Action Proposal Generation	['Temporal Action Proposal Generation', 'Video Action Segmentation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|movementtoaction_transformer_networks_for_temporal_action_proposal_generation	/pdf/33fba958683fe42f879b0e850f6276b596cf2564.pdf
UXPrt1ffxYD	5370	AsymQ: Asymmetric Q-loss to mitigate overestimation bias in off-policy reinforcement learning	['reinforcement learning', 'estimation bias']	a lightweight approach to mitigate estimation bias without extra computational costs	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|asymq_asymmetric_qloss_to_mitigate_overestimation_bias_in_offpolicy_reinforcement_learning	/pdf/b5d5e6f1bb7a46a2a46cd8486bfe175c9d75f00b.pdf
rGeZuBRahju	5374	Learning Language Representations with Logical Inductive Bias	['Pretraining', 'model architecture', 'language representation learning', 'inductive bias']	We develop a novel neural architecture for learning language representations.	Deep Learning and representational learning	anonymous|learning_language_representations_with_logical_inductive_bias	/pdf/a6fd22f82c17f76fd91eb8303bd0bcf00b3ca241.pdf
k09v6oRxQPq	5375	Understanding Multi-Task Scaling in Machine Translation	['scaling laws', 'machine translation', 'multilinguality', 'multi-task optimization']	We study the scaling behavior of multilingual, multi-task neural machine translation models. 	Deep Learning and representational learning	anonymous|understanding_multitask_scaling_in_machine_translation	/pdf/b25047c51bc723cf93c5b268613a99a3695e75a5.pdf
2_B-eiVbgBs	5376	A Differentiable Loss Function for Learning Heuristics in A*	['Differentiable Loss Function', 'a star', 'heuristic search']	A novel loss function	General Machine Learning (ie none of the above)	anonymous|a_differentiable_loss_function_for_learning_heuristics_in_a	/pdf/5e2356fd6fe67f6abc1fdc3403a837f41dafc790.pdf
UvziTI2JGP7	5377	Controllable Concept Transfer of Intermediate Representations	['concept transfer', 'transfer learning', 'transferrable representations']	We propose a novel approach for controlling the transfer of user-determined semantic concepts from source to target task	Deep Learning and representational learning	anonymous|controllable_concept_transfer_of_intermediate_representations	/pdf/89e1fe4fbaf027ecb6cf05aa143ad7f700d26cd0.pdf
He7UIpiEq_O	5378	Linkless Link Prediction via Relational Distillation	['link prediction', 'knowledge distillation']		Deep Learning and representational learning	anonymous|linkless_link_prediction_via_relational_distillation	/pdf/1140f7defb91ba5fd9070f25cf33b92f378f25e5.pdf
dBk3hsg-n6	5379	Artificial Neuronal Ensembles with Learned Context Dependent Gating	['Continual Learning', 'Catastrophic Forgetting']	A method to alleviate catastrophic forgetting in artificial neural networks using learned context dependent activity gates	General Machine Learning (ie none of the above)	anonymous|artificial_neuronal_ensembles_with_learned_context_dependent_gating	/pdf/3b59fb998382724ae474ad010abe55f1ee24c24f.pdf
A9WQaxYsfx	5380	Panning for Gold in Federated Learning: Targeted Text Extraction under Arbitrarily Large-Scale Aggregation	['Federated Learning', 'Privacy', 'Security', 'Privacy attack']	We propose a method that extracts target sequences by keywords under extremely large-scale aggregation in federated learning.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|panning_for_gold_in_federated_learning_targeted_text_extraction_under_arbitrarily_largescale_aggregation	/pdf/d21413198980bcb5c4ce926b24e12a4526685f7d.pdf
1hKE9qjvz-	5381	gDDIM: Generalized denoising diffusion implicit models	['Fast sampling', 'diffusion model']	a small but delicate modification in parameterization to accelerate general diffusion models	Generative models	anonymous|gddim_generalized_denoising_diffusion_implicit_models	/pdf/8c780b91d4186a93a5a48bfa8936d29b58981d9f.pdf
Kn43SKplAn	5382	3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data	['3D reconstruction', 'pose estimation', 'shape deformation']	A method for single view 3D reconstruction without camera pose supervision	Applications (eg, speech processing, computer vision, NLP)	anonymous|3d_surface_reconstruction_in_the_wild_by_deforming_shape_priors_from_synthetic_data	/pdf/8b1aed9921d784ec7c95bc453cf61207c2508d69.pdf
Rpo9dvNlEYW	5383	Federated Representation Learning via Maximal Coding Rate Reduction	['Federated Learning', 'Representation Learning', 'Information Theory']	We propose a federated way of learning low dimensional representations. 	Deep Learning and representational learning	anonymous|federated_representation_learning_via_maximal_coding_rate_reduction	/pdf/f14dcce2e6857c89968fac255eb1702e63b1fcf2.pdf
6dZqGFB8g-O	5384	STay-On-the-Ridge (STON'R): Guaranteed Convergence to Local Minimax Equilibrium in Nonconvex-Nonconcave Games	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|stayontheridge_stonr_guaranteed_convergence_to_local_minimax_equilibrium_in_nonconvexnonconcave_games	/pdf/5166997f8f6a558ca72d0d1fd41b6aad29262687.pdf
Loek7hfb46P	5385	Fast Sampling of Diffusion Models with Exponential Integrator	['Fast diffusion model', 'generative model']	Training-free acceleration for diffusion model, 4.17 FID with 10 NFEs on CIFAR10	Generative models	anonymous|fast_sampling_of_diffusion_models_with_exponential_integrator	/pdf/ef4f400b6d7608f041c06d8acf65607edb224eb1.pdf
loIfC8WHevK	5386	Characteristic Neural Ordinary Differential Equation	['Neural ODE', 'Differential Equation', 'Method of characteristics']		Deep Learning and representational learning	anonymous|characteristic_neural_ordinary_differential_equation	/pdf/ec2a04bdfa55e48d6433d0b5dbe128cca23d1570.pdf
aOBs18ycBr	5387	NOTELA: A Generalizable Method for Source Free Domain Adaptation	['source-free domain adaptation', 'robustness to distribution shifts', 'bioacoustics']	We evaluate popular source-free domain adaptation methods on a new realistic set of distribution shifts in audio, and design a more robust method.	Unsupervised and Self-supervised learning	anonymous|notela_a_generalizable_method_for_source_free_domain_adaptation	/pdf/0470507a066cb90ae1a643d8c4921b0bb47975e5.pdf
VBB4fh45HF	5388	Learning Interpretable Dynamics from Images of a Freely Rotating 3D Rigid Body	['Deep Learning', 'Dynamics', '3D', 'Rigid Body', 'Images', 'Physics informed']	Using Hamiltonian structure to learn interpretable dynamics from images of rotating 3D objects	Deep Learning and representational learning	anonymous|learning_interpretable_dynamics_from_images_of_a_freely_rotating_3d_rigid_body	/pdf/00883ad655c0d8ce1226268e814193b80d803fb6.pdf
DbLtChzghG	5390	Event-former: A Self-supervised Learning Paradigm for Temporal Point Processes	['event sequences', 'self-supervised learning', 'point process', 'transformer']	We propose a new paradigm for self-supervised learning for multivariate temporal point processes.  Our approach demonstrates performance boost of as high as up to 16% compared to state-of-the art models for next event prediction. 	Unsupervised and Self-supervised learning	anonymous|eventformer_a_selfsupervised_learning_paradigm_for_temporal_point_processes	/pdf/e9f89053a1724af4b06b3a1c07c9670a8e897a3b.pdf
p3UGLrWofT	5391	CNN Compression and Search Using Set Transformations with Width Modifiers on Network Architectures	['cnn', 'compression', 'efficient search', 'sets', 'embedded systems']	convnet compression that is fast, not resource hungry and uses width modifiers applied with a new twist.	Applications (eg, speech processing, computer vision, NLP)	anonymous|cnn_compression_and_search_using_set_transformations_with_width_modifiers_on_network_architectures	/pdf/ddba0aac86173ad80f23d1c6eb0f6c3ae49e74d7.pdf
UntYZBCdypc	5392	Graph Mixup with Soft Alignments	[]		Deep Learning and representational learning	anonymous|graph_mixup_with_soft_alignments	/pdf/2e687ea88767c3ee7a20f83b941f99c71400b61f.pdf
cyg2YXn_BqF	5394	Efficiently Controlling Multiple Risks with Pareto Testing	['conformal prediction', 'risk control', 'multi-objective optimization', 'hypothesis testing']	This paper presents a statistically efficient strategy for performing multiple hypothesis testing in order to find risk-controlling model configurations that are also useful with respect to arbitrary auxiliary objectives. 	General Machine Learning (ie none of the above)	anonymous|efficiently_controlling_multiple_risks_with_pareto_testing	/pdf/214b24a5f32ca8552dc8d00b0d3f4e2c2f9d6829.pdf
sVV0KK3COzD	5395	Preserving In-Context Learning Ability in Large Language Model Fine-tuning	['in-context learning', 'large language models']		Deep Learning and representational learning	anonymous|preserving_incontext_learning_ability_in_large_language_model_finetuning	/pdf/db6df926187bec3f83e200b401c79fe1d373a09a.pdf
-kAWfaLkPT3	5396	Multi-Environment Pretraining Enables Transfer to Action Limited Datasets	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multienvironment_pretraining_enables_transfer_to_action_limited_datasets	/pdf/9c9a66381a5703e47a583d811344de52b9e6016f.pdf
IJn-rxhkZsN	5397	VISION TRANSFORMER FOR MULTIVARIATE TIME- SERIES CLASSIFICATION (VITMTSC)	['time-series classification', 'vision-transformer', 'transformer']	A Vision Transformer based Multivariate Time-Series Classification model that significantly outperforms current SOTA on commercial datasets.	Deep Learning and representational learning	anonymous|vision_transformer_for_multivariate_time_series_classification_vitmtsc	/pdf/b2163e53603a9ec930ab3fef5bcc67944270c5a4.pdf
eSQh8rG8Oa	5399	Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement	['actor-critic', 'policy gradient', 'entropy', 'cross-entropy method', 'greedy actor-critic', 'policy optimization']	We propose an alternative update for the actor in actor-critic algorithms that does not rely on entropy-regularization	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|greedy_actorcritic_a_new_conditional_crossentropy_method_for_policy_improvement	/pdf/d66f55c787cd1067b2db49438c69f9af4b22b62b.pdf
uvSQ8WhWHQ	5400	Plansformer: Generating Multi-Domain Symbolic Plans using Transformers	['automated planning', 'language models', 'transfer learning']	Plansformer, an LLM fine-tuned on planning problems and capable of generating plans with favorable behavior in terms of correctness and length with minimal knowledge-engineering efforts. 	Deep Learning and representational learning	anonymous|plansformer_generating_multidomain_symbolic_plans_using_transformers	/pdf/8747a5f6bd3e05b1c29bd439adfec125cc8dc248.pdf
Hvcmr6FSIX8	5401	When is Offline Hyperparameter Selection Feasible for Reinforcement Learning?	['Offline policy selection', 'offline reinforcement learning', 'off-policy policy evaluation']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|when_is_offline_hyperparameter_selection_feasible_for_reinforcement_learning	/pdf/8ebacd9011b0db8a559e1eac0b06eed91b013db6.pdf
ySCL-NG_I3	5402	Learning Harmonic Molecular Representations on Riemannian Manifold	['Riemannian manifold', 'molecular surface', 'harmonic analysis', 'functional map', 'binding site prediction', 'rigid protein docking']	We propose a harmonic molecular representation learning framework to achieve multi-resolution molecular encoding on 2D Riemannian manifold.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|learning_harmonic_molecular_representations_on_riemannian_manifold	/pdf/6d4a1e4172e4e71ef6cf9f76e17c60696cc3697c.pdf
z9C5dGip90	5403	Dynamical systems embedding with a physics-informed convolutional network	['dynamical systems', 'convolutional networks', 'computational physics', 'physics-informed']	Unsupervised framework for learning high-quality, physically-meaningful embeddings of dynamical systems. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|dynamical_systems_embedding_with_a_physicsinformed_convolutional_network	/pdf/d9a4a8324c5ce32b6e756cc257e96a60a67404d0.pdf
Su_HbZ0Sdz	5404	Feasible Adversarial Robust Reinforcement Learning for Underspecified Environments	['reinforcement learning', 'robust rl', 'sim-to-real', 'game-theory', 'psro']	We propose a method to train a robust RL agent to feasible parameters even when the adversary has access to infeasible parameters.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|feasible_adversarial_robust_reinforcement_learning_for_underspecified_environments	/pdf/291996770b6bd3d0d945c5a7c5a020fe256ab5db.pdf
BgLTe3a4FO	5405	Fed-Cor: Federated Correlation Test with Secure Aggregation	['Federated Analytics', 'Privacy and Security']	We propose the first secure federated correlation test protocol Fed-Cor, which minimizes both privacy leakage and communication cost.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fedcor_federated_correlation_test_with_secure_aggregation	/pdf/a9e0f80be005f29d3698d44b93b0c69698f22f9a.pdf
bQB6qozaBw	5406	Information Plane Analysis for Dropout Neural Networks	['information plane', 'deep learning', 'mutual information', 'dropout', 'continuous distributions']	Information plane analysis is a promising tool for neural networks analysis, for which mutual information can be measured more reliable with continuous dropout	Deep Learning and representational learning	anonymous|information_plane_analysis_for_dropout_neural_networks	/pdf/a5f6b17f2fc1c8a3706fbf512740750b0c20c77c.pdf
ED3WvUgu09	5407	Kernel Regression with Infinite-Width Neural Networks on Millions of Examples	['gaussian processes', 'neural tangent kernel', 'infinite-width neural networks']	We enable kernel regression with infinite-width neural networks at a larger scale than was previously possible to calculate scaling laws across many orders of magnitude and achieve SotA results on protein and small molecule prediction benchmarks.	General Machine Learning (ie none of the above)	anonymous|kernel_regression_with_infinitewidth_neural_networks_on_millions_of_examples	/pdf/93d49737009fccc8fea95eb84d3532a182e0d179.pdf
cPhfgGIbVfZ	5408	ErrorAug: Making Errors to Find Errors in Semantic Segmentation	['Semantic Segmentation', 'Uncertainty Quantification', 'Error Detection']	Introduces Error Augmentation as a framework for reliably producing error detectors for semantic segmentation with less architectural and computational complexity.	Deep Learning and representational learning	anonymous|erroraug_making_errors_to_find_errors_in_semantic_segmentation	/pdf/2225f9b1a14f1f5ecec1d0f959ce0ac6eae9e56f.pdf
W0-FISdkHtZ	5409	Optimal control neural networks for data-driven discovery of gradient flows.	['neural network', 'data-driven', 'dynamical system', 'gradient flow', 'optimal control']	This paper proposes an optimal control neural network to discover nonlinear dynamical systems from time series data sampled from solution trajectories.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|optimal_control_neural_networks_for_datadriven_discovery_of_gradient_flows	/pdf/615032904b4f2a2400d3e92e7352ac4215fa161f.pdf
imIlOpuEsi	5410	Robustness for Free: Adversarially Robust Anomaly Detection Through Diffusion Model	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|robustness_for_free_adversarially_robust_anomaly_detection_through_diffusion_model	/pdf/df25ca5e89afa93184eddcf60d0136105ad4153c.pdf
5tKXUZil3X	5411	TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|textgrad_advancing_robustness_evaluation_in_nlp_by_gradientdriven_optimization	/pdf/ba3cbe3982846cfd74dc53bb2f4455cee7442aa9.pdf
Ovnwe_sDQW	5413	BC-IRL: Learning Generalizable Reward Functions from Demonstrations	['inverse reinforcement learning', 'reward learning', 'reinforcement learning', 'imitation learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|bcirl_learning_generalizable_reward_functions_from_demonstrations	/pdf/05382205dd3dd0c9b21a09b3b915f77f155246f2.pdf
cxCEOSF99f	5414	Understanding Influence Functions and Datamodels via Harmonic Analysis	['theory', 'datamodels', 'influence functions', 'fourier analysis', 'harmonic analysis']	This paper establishes connections between datamodels, influence functions and Fourier coefficients using theoretical tools from harmonic analysis of Boolean functions	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|understanding_influence_functions_and_datamodels_via_harmonic_analysis	/pdf/343b853005dc395edff663c2e8ec2e6ccba6498e.pdf
IskSBCo0-0	5415	Recycling Scraps: Improving Private Learning by Leveraging Intermediate Checkpoints	['Differential privacy', 'training checkpoints', 'confidence intervals', 'uncertainty']	DP-ML benchmarks and deployments typically use only the final model to make predictions. In this work, for the first time, we comprehensively explore various methods that aggregate intermediate checkpoints to improve the utility of DP training.	Deep Learning and representational learning	anonymous|recycling_scraps_improving_private_learning_by_leveraging_intermediate_checkpoints	/pdf/6e88773e4c89f0f4eaac0947b99934225686ae98.pdf
hfaNXjEQB47	5417	Dissecting adaptive methods in GANs	['deep learning theory', 'generative adversarial networks', 'adaptive methods']		Deep Learning and representational learning	anonymous|dissecting_adaptive_methods_in_gans	/pdf/3251d7fce069e477dc990b17ebfb3ed7d63648f7.pdf
Z4s73sJYQM	5418	Evolve Smoothly, Fit Consistently: Learning Smooth Latent Dynamics For Advection-Dominated Systems	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|evolve_smoothly_fit_consistently_learning_smooth_latent_dynamics_for_advectiondominated_systems	/pdf/bc324f0b5e3b8523dd99176d8a1530d7ff55c002.pdf
vep-Hlmn0tc	5422	Stochastic Constrained DRO with a Complexity Independent of Sample Size	[]		Optimization (eg, convex and non-convex optimization)	anonymous|stochastic_constrained_dro_with_a_complexity_independent_of_sample_size	/pdf/e577c2c554a3ec903820000c2a5cde92feba7f6e.pdf
gpmL0D4VjN4	5424	Fundamental limits on the robustness of image classifiers	['Theory', 'Computer vision', 'Isoperimetry']	Image classifiers are fundamentally sensitive to small perturbations in their inputs.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|fundamental_limits_on_the_robustness_of_image_classifiers	/pdf/ebb9d40fce4a986884cf978f73db6979c403c1c1.pdf
5XrQ2mskPQz	5426	Matrix factorization under the constraint of connectivity between observed and source data ~ Muscle synergy analysis based on connectivity between muscle and brain activities ~	['Matrix factorization', 'Muscle synergy']		Deep Learning and representational learning	anonymous|matrix_factorization_under_the_constraint_of_connectivity_between_observed_and_source_data_muscle_synergy_analysis_based_on_connectivity_between_muscle_and_brain_activities_	/pdf/87e16cca07b3e8c1fb99b77da99a11aa833f6f2f.pdf
qxRscesArBZ	5427	Robust Graph Dictionary Learning	['Graph Learning', 'Optimal Transport']	This paper proposes a robust graph dictionary learning method based on a novel robust variant of GWD.	Unsupervised and Self-supervised learning	anonymous|robust_graph_dictionary_learning	/pdf/ddd6747dbb6a03b49fadcff3a43c53ff17a97e37.pdf
ABqIh51jNQm	5429	Spatial Reasoning Network for Zero-shot Constrained Scene Generation	['Spatial Reasoning Network', 'Constrained Scene Generation']	This paper introduces the Spatial Reasoning Network for zero-shot constrained scene generation.	Generative models	anonymous|spatial_reasoning_network_for_zeroshot_constrained_scene_generation	/pdf/3c3fe29cca4c6a1e7af9e858475c52309bc0f992.pdf
4phxC1MmcfN	5431	Fast exploration and learning of latent graphs with aliased observations	['graph learning', 'fast exploration', 'aliased environments', 'POMDPs']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|fast_exploration_and_learning_of_latent_graphs_with_aliased_observations	/pdf/1c1e8549ef5f294250702b4c69c63aab3950ba74.pdf
3aQs3MCSexD	5433	How Much Data Are Augmentations Worth?  An Investigation into Scaling Laws, Invariance, and Implicit Regularization	['Data Augmentations', 'Stochasticity', 'Flatness', 'Neural Networks', 'Invariance']	We uncover mechanisms by which data augmentations regularize training and inform the relationship between augmentations and extra data, invariance, stochasticity, and flatness.	Deep Learning and representational learning	anonymous|how_much_data_are_augmentations_worth_an_investigation_into_scaling_laws_invariance_and_implicit_regularization	/pdf/1939b7c32a56275f8f59069ef810d1aef5707723.pdf
1jDN-RfQfrb	5434	Unveiling Transformers with LEGO: A Synthetic Reasoning Task	['transformers', 'logical reasoning', 'role of pretraining', 'attention pattern']	We propose a synthetic task for logical reasoning on which we study transformer models' intriguing behaviors regarding generalization and the role of pre-training; we gain insights leading to large-scale practical improvements.	Deep Learning and representational learning	anonymous|unveiling_transformers_with_lego_a_synthetic_reasoning_task	/pdf/08e6fc4abf40e2487258fefbc0edb25ebe638d9c.pdf
l1tSyx67_J	5436	Towards Fair Classification against Poisoning Attacks	['Poisoning Attacks', 'Fairness', 'Robustness']	We propose new poisoning attack and defense for fair classification methods. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|towards_fair_classification_against_poisoning_attacks	/pdf/138acd1f6465ff2b8d7a6f4d02468e29c0b68758.pdf
hAcApnx50F	5437	Greedy Information Maximization for Online Feature Selection	['Online learning', 'feature selection', 'greedy optimization', 'mutual information']	A greedy procedure for performing online feature selection by maximizing mutual information	Deep Learning and representational learning	anonymous|greedy_information_maximization_for_online_feature_selection	/pdf/759aaad03009f90f0b5711fff89c1ff953bb8daf.pdf
8mQrCW_JO3	5438	Less Is More: Training on Low-Fidelity Images Improves Robustness to Adversarial Attacks	[]		Deep Learning and representational learning	anonymous|less_is_more_training_on_lowfidelity_images_improves_robustness_to_adversarial_attacks	/pdf/0537dd15e34ddeea1cda0950d66beabb70c50322.pdf
H3HcEJA2Um	5440	Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection	['Computer Vision', '3D Object Detection', 'Stereo Matching']	We leverage complementary coarse, long-term and fine-grained, short-term multi-view stereo for camera-only 3D object detection.	Deep Learning and representational learning	anonymous|time_will_tell_new_outlooks_and_a_baseline_for_temporal_multiview_3d_object_detection	/pdf/7b5125cbf4d05e686e0e0e4e5adbe6dc9557580d.pdf
fFAV-_MCTd	5442	Multi-Sample Contrastive Neural Topic Model as Multi-Task Learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|multisample_contrastive_neural_topic_model_as_multitask_learning	/pdf/4d24788582d9122121b19576023a7a278de152db.pdf
lgIPsrxrU7	5443	Probabilistic Categorical Adversarial Attack and Adversarial Training	['adversarial attacks', 'robustness', 'discrete input model']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|probabilistic_categorical_adversarial_attack_and_adversarial_training	/pdf/e80ca965fd85681d7bfdf6b920ca1753ddf5b57a.pdf
lH1PV42cbF	5444	Binding Language Models in Symbolic Languages	['semantic parsing', 'large language model', 'neural symbolic', 'code generation']	binding language models in symbolic languages	Applications (eg, speech processing, computer vision, NLP)	anonymous|binding_language_models_in_symbolic_languages	/pdf/ff59e5e6083b6fc3f2b4815e77696b00efa1c3f6.pdf
x9tAJ3_N0k	5445	Probability flow solution of the Fokker-Planck equation	['score-based diffusion', 'high-dimensional scientific computing']	We develop an efficient method to solve the Fokker-Planck equation in high-dimension by learning the score of the solution.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|probability_flow_solution_of_the_fokkerplanck_equation	/pdf/924c1b575eeafd530875ec62d62a4bbacdff7324.pdf
HVvqbDQdhW2	5446	DeepDFA: Dataflow Analysis-Guided Efficient Graph Learning for Vulnerability Detection	['deep learning', 'vulnerability detection', 'dataflow analysis', 'program analysis']	We present DeepDFA, a dataflow analysis-guided graph learning framework and embedding technique for vulnerability detection.	Applications (eg, speech processing, computer vision, NLP)	anonymous|deepdfa_dataflow_analysisguided_efficient_graph_learning_for_vulnerability_detection	/pdf/b282b99ff60864833fa6dac693b7ef4c1e7443d6.pdf
hJqGbUpDGV	5447	On the Sensitivity of Reward Inference to Misspecified Human Models	['reward learning', 'inverse reinforcement learning', 'misspecification']	We investigate the impact of assuming wrong human models on reward learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_sensitivity_of_reward_inference_to_misspecified_human_models	/pdf/5731133922f0ca65fc885cde3811156f48fa089d.pdf
lwVwTjNwNl	5448	FedX: Federated Learning for Compositional Pairwise Risk Optimization	['Federated Learning', 'Pairwise Loss', 'Compositional Optimization']	A communication-efficient algorithm to optimize pairwise	General Machine Learning (ie none of the above)	anonymous|fedx_federated_learning_for_compositional_pairwise_risk_optimization	/pdf/28220960989058133876293e66b473bd6e73be59.pdf
7NUTyhyQt9x	5449	Current Anomaly Detectors are Anomalous: On Semantic Treatment of OOD Inputs	['machine learning', 'training distribution', 'out-of-distribution', 'OODs', 'detection', 'semantic information']	We propose that in-distribution should not be tied to the training distribution but to the distribution of semantic information in training data, and therefore OOD detection should be performed on the semantic information extracted from training data	Deep Learning and representational learning	anonymous|current_anomaly_detectors_are_anomalous_on_semantic_treatment_of_ood_inputs	/pdf/12d901757b2134ae2b64d34dc8f9752851835ae0.pdf
Zeb5mTuqT5	5450	Confidence-Conditioned Value Functions for Offline Reinforcement Learning	['reinforcement learning', 'offline reinforcement learning', 'ensembles', 'adaptation']	We propose a new offline reinforcement learning algorithm that adapts how conservative its behavior will be.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|confidenceconditioned_value_functions_for_offline_reinforcement_learning	/pdf/90f29a7d8f8414eb04001cdfc0faaa12c10adada.pdf
LdUByi1hN3	5451	Label-Free Synthetic Pretraining of Object Detectors	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|labelfree_synthetic_pretraining_of_object_detectors	/pdf/a4a040e52eeef8eb9d8f50bcd26e5cecf77751e2.pdf
UERcQuXlwy	5452	Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding	['self-supervised', 'pretraining', 'screenshots', 'parsing', 'language', 'vision', 'transformers', 'interfaces', 'charts', 'figures', 'tables', 'documents']	We propose general-purpose pixel-to-text models that can be finetuned on tasks with visually-situated language, such as UIs, charts, figures, tables, documents, etc.	Unsupervised and Self-supervised learning	anonymous|pix2struct_screenshot_parsing_as_pretraining_for_visual_language_understanding	/pdf/e8a031f24c7e097ad2a74fae40546ccdfec5257c.pdf
V-RDBWYf0go	5453	How Hard is Trojan Detection in DNNs? Fooling Detectors With Evasive Trojans	['trojan detection', 'neural trojans', 'trojans', 'hidden functionality', 'monitoring']	We design hard-to-detect trojan attacks for deep neural networks.	Deep Learning and representational learning	anonymous|how_hard_is_trojan_detection_in_dnns_fooling_detectors_with_evasive_trojans	/pdf/9fcae9d0219a465d5653b226d9d015e0293f1912.pdf
ntIq8Wm79G-	5454	BertNet: Harvesting Knowledge Graphs from Pretrained Language Models	['knowledge graph', 'pretrained language models']	In this work, we aim at harvesting symbolic KGs from the LMs, and propose a new framework for automatic KG construction empowered by the neural LMs' flexibility and scalability.	Applications (eg, speech processing, computer vision, NLP)	anonymous|bertnet_harvesting_knowledge_graphs_from_pretrained_language_models	/pdf/2013fe5ffb34bd26b9095616ecfd3d3e6cea65f8.pdf
gUL6zYN4Uaf	5456	Cramming: Training a language model on a single GPU in one day	['Transformers', 'Scaling', 'Pretraining', 'Language']	Cramming transformer-based language model pretraining into less compute, what happens?	Applications (eg, speech processing, computer vision, NLP)	anonymous|cramming_training_a_language_model_on_a_single_gpu_in_one_day	/pdf/d7beb1caab0326c57b3a9aa9a19f160ee38fba09.pdf
r_4nJuPpCh-	5457	Graph Neural Networks as Multi-View Learning	['Graph Neural Networks', 'Alternating Optimization', 'Semi-Supervised Learning', 'Multi-View Learning']	A new Multi-View Learning perspective on GNN, which achieves better computation and memory efficiency.	Deep Learning and representational learning	anonymous|graph_neural_networks_as_multiview_learning	/pdf/6063287ce6c93ce86c7e61096c727080372db9a7.pdf
gLPkzWjdhBN	5459	Learning Iterative Neural Optimizers for Image Steganography	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_iterative_neural_optimizers_for_image_steganography	/pdf/ef9437b24f46e85268391e39d917d43fc1208771.pdf
yPMsKyrn5A-	5461	Robustness Evaluation Using Local Substitute Networks	['Robustness', 'verification', 'pruning', 'neural networks']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robustness_evaluation_using_local_substitute_networks	/pdf/84071b0b5aeba14ccdd4f8808cc926eb30626bae.pdf
W668diqwp4l	5462	Transformers Implement First-Order Logic with Majority Quantifiers	['transformers', 'complexity theory', 'logic', 'interpretability']	Transformers can be translated to formulae in first-order logic with majority quantifiers that compute the same function.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|transformers_implement_firstorder_logic_with_majority_quantifiers	/pdf/cfbb10dec4c3e740f3dc88d51d2eedcb39581344.pdf
GPJVuyX4p_h	5464	SIMPLE: A Gradient Estimator for k-Subset Sampling	[]		Deep Learning and representational learning	anonymous|simple_a_gradient_estimator_for_ksubset_sampling	/pdf/b08642ba1af81a66359c000faf210bb9c3a05095.pdf
BcbwGQWB-Kd	5465	What Spurious Features Can Pretrained Language Models Combat?	['spurious correlation', 'pretrained language models']		Applications (eg, speech processing, computer vision, NLP)	anonymous|what_spurious_features_can_pretrained_language_models_combat	/pdf/56987ef5bb6d4f4064a8075c3b4744ab293bc9e5.pdf
m2OeuIGTJW-	5469	Predictive Coding with Approximate Laplace Monte Carlo	['predictive coding', 'variational Bayes', 'Laplace approximation', 'generative modelling', 'free energy']	A novel method that improves the performance of predictive coding by incorporating information about the curvature of the energy landscape.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|predictive_coding_with_approximate_laplace_monte_carlo	/pdf/61312ff50e106e7b7076272abe293be36c66eab4.pdf
PQk-8VyP-dv	5470	Gradient Preconditioning for Non-Lipschitz smooth Nonconvex Optimization	[]		Optimization (eg, convex and non-convex optimization)	anonymous|gradient_preconditioning_for_nonlipschitz_smooth_nonconvex_optimization	/pdf/95218437e2f6e27d966a4470da37be6993f37abb.pdf
m1f8XUs-RQP	5473	Minimal Value-Equivalent Partial Models for Scalable and Robust Planning in Lifelong Reinforcement Learning	['reinforcement learning', 'lifelong learning', 'transfer learning', 'model-based reinforcement learning']	We propose new kinds of models to perform scalable and robust planning in lifelong reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|minimal_valueequivalent_partial_models_for_scalable_and_robust_planning_in_lifelong_reinforcement_learning	/pdf/77210f7f8681725c4f8ed623b7d09154d1bc0952.pdf
_tfLpF9mFiq	5474	No Pairs Left Behind: Improving Metric Learning with Regularized Triplet Objective	['Deep Metric Learning', 'Representation Learning', 'Machine Learning for Healthcare', 'Triplet Loss']	We propose a novel triplet objective that improves representation learning on a variety of applications without requiring additional sample mining or overhead costs.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|no_pairs_left_behind_improving_metric_learning_with_regularized_triplet_objective	/pdf/adf76f8520ac70a96b8909f73de89eb7c650c491.pdf
-syx4GzWdTM	5475	SpENCNN: Orchestrating Encoding and Sparsity for Fast Homomorphically Encrypted Neural Network Inference	['Cryptographic inference', 'model sparsity', 'data encoding']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|spencnn_orchestrating_encoding_and_sparsity_for_fast_homomorphically_encrypted_neural_network_inference	/pdf/81093db70f5e7a5a72ce958536a85518860f95c0.pdf
Uo3usD5FFSR	5477	Giving Robots a Hand: Broadening Generalization via Hand-Centric Human Video Demonstrations	['imitation learning', 'robotics', 'manipulation', 'learning from human demonstrations', 'learning from observations', 'generalization', 'visuomotor control']	We leverage hand-centric human video demonstrations to learn generalizable robotic manipulation policies via imitation learning, introducing a simple framework that allows one to avoid using explicit human-robot domain adaptation methods.	Applications (eg, speech processing, computer vision, NLP)	anonymous|giving_robots_a_hand_broadening_generalization_via_handcentric_human_video_demonstrations	/pdf/955f37ce2a8db8d6fe31db492ed3695df557d257.pdf
Ry-cTiH_cus	5478	Bandwith Enables Generalization in Quantum Kernel Models	['kernel methods', 'generalization error', 'quantum machine learning', 'spectral bias']		General Machine Learning (ie none of the above)	anonymous|bandwith_enables_generalization_in_quantum_kernel_models	/pdf/909cf3008d063856cbc4a6f9e823dd67e4e73ccd.pdf
UvmDCdSPDOW	5479	Information-Theoretic Diffusion	['diffusion', 'density models', 'information theory']	A new information-theoretic foundation for diffusion models leads to simpler and more computationally efficient density modeling. 	Unsupervised and Self-supervised learning	anonymous|informationtheoretic_diffusion	/pdf/c5cc8a1fae706fc50788c4a670460592cb311ce5.pdf
u_pS0sDr95-	5480	MolEBM: Molecule Generation and Design by Latent Space Energy-Based Modeling	['molecule design', 'energy-based model']	We propose a probabilistic generative model to model molecule and molecular properties jointly and naturally achieve molecule design by posterior sampling conditional on desired properties. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|molebm_molecule_generation_and_design_by_latent_space_energybased_modeling	/pdf/cc8b8a264beb7d5bd8250649adeaba9965e09b8e.pdf
gwPea8qxdzz	5481	Multi-Task Option Learning and Discovery for Stochastic Path Planning	['Option discovery', 'learning abstractions', 'planning and learning', 'reinforcement learning', 'RL for robotics', 'hierarchical methods', 'stochastic path planning']	This paper presents a novel approach for learning reusable multi-options to compute solutions for stochastic path planning problems using an hierarchical approach that combines planning and learning. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multitask_option_learning_and_discovery_for_stochastic_path_planning	/pdf/96ae5cf37d00f73a1832166903c730de81aa7bfb.pdf
ZZCJv2biATn	5482	Target Conditioned Representation Independence (TCRI); from Domain-Invariant to Domain-General Representations	['Domain Generalization', 'Out-of-distribution Generalization', 'Transfer Learning', 'Distribution Shift', 'Covariate Shift']	We propose a Target Conditioned Representation Independence (TCRI) objective to learn domain-general representations and predictors.	Deep Learning and representational learning	anonymous|target_conditioned_representation_independence_tcri_from_domaininvariant_to_domaingeneral_representations	/pdf/bb28d3e2328ad390dab4da9f3c2369bfc374bc54.pdf
vCJ9-Ri-6xU	5483	Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport	[]	This paper proposes accurate and efficient optimizers on Stiefel manifold based on a new variational principle and its careful discretization.	Optimization (eg, convex and non-convex optimization)	anonymous|momentum_stiefel_optimizer_with_applications_to_suitablyorthogonal_attention_and_optimal_transport	/pdf/2aeb00c78e46f33b2a870e607adb2e2a471392d9.pdf
wXdEKf5mV6N	5484	Is margin all you need? An extensive empirical study of active learning on tabular data	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|is_margin_all_you_need_an_extensive_empirical_study_of_active_learning_on_tabular_data	/pdf/20e4b001b3e446447b72ab1653fff0b644531197.pdf
cRCEabpC5XQ	5487	Connecting representation and generation via masked vision-language transformer	['Representation Learning', 'Pre-training', 'Generative Model', 'Conditional Generation']	Unified vision-language Transformer trained with masked token prediction for both representation learning and generation of image and text.	Deep Learning and representational learning	anonymous|connecting_representation_and_generation_via_masked_visionlanguage_transformer	/pdf/8c00d68ea315352c08893abada6cdfc90c4a6da5.pdf
vouQcZS8KfW	5488	Neural Causal Models for Counterfactual Identification and Estimation	['causal inference', 'deep learning', 'neural models', 'neural causal models', 'causal identification', 'causal estimation', 'counterfactual']	We solve the two problems of counterfactual identification and estimation from arbitrary surrogate experiments using a Generative Adversarial Network implementation of the Neural Causal Model.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|neural_causal_models_for_counterfactual_identification_and_estimation	/pdf/fccede41012986d68ef414fd46ed490629fa8f09.pdf
SjzFVSJUt8S	5489	Replay Memory as An Empirical MDP: Combining Conservative Estimation with Experience Replay	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|replay_memory_as_an_empirical_mdp_combining_conservative_estimation_with_experience_replay	/pdf/5fe4665b3dfcccc991aadfea79b843da5247d6ee.pdf
3pfNb4pZBNp	5490	Random Laplacian Features for Learning with Hyperbolic Space	['hyperbolic space', 'random features', 'kernel approximation']		Deep Learning and representational learning	anonymous|random_laplacian_features_for_learning_with_hyperbolic_space	/pdf/4f1b51b9572001f9be8db1a839bbb8cd4a854103.pdf
b1F-_7dUo0w	5491	Tabular Deep Learning when $d \gg n$ by Using an Auxiliary Knowledge Graph	['Tabular Deep Learning', 'Knowledge Graph', 'High Dimensional', 'Low Sample']	PLATO uses an auxiliary KG about input features to enable tabular deep learning prediction when $d \gg n$.	Deep Learning and representational learning	anonymous|tabular_deep_learning_when_d_\gg_n_by_using_an_auxiliary_knowledge_graph	/pdf/fb80360cc7ebf517a578b9bc83017d7ee8ac8806.pdf
bbf_lxmcpTQ	5493	MUG: Interactive Multimodal Grounding on User Interfaces	['Multimodal Grounding', 'UI', 'Mobile', 'Interaction']	We present MUG, a novel interactive task for multimodal grounding where a user and an agent work collaboratively on an interface screen.	Applications (eg, speech processing, computer vision, NLP)	anonymous|mug_interactive_multimodal_grounding_on_user_interfaces	/pdf/6ae0febe7ce1a59f456e6228ec687c29d7287ae1.pdf
-htnolWDLvP	5494	Transferable Unlearnable Examples	['Unlearnable Examples', 'Data Protection']		Deep Learning and representational learning	anonymous|transferable_unlearnable_examples	/pdf/bedff94a5168de91eb7ac035e34a2a0d6a217dbb.pdf
-hWhz9xfrB9	5496	Lovasz Theta Contrastive Learning	['Lovasz theta', 'Contrastive learning', 'Similarity graph', 'Graph Theory']		Unsupervised and Self-supervised learning	anonymous|lovasz_theta_contrastive_learning	/pdf/c9963f2f8490ec9f761a5c20d2bba4b4fe760b20.pdf
tOG2kU6h57B	5497	CORE-PERIPHERY PRINCIPLE GUIDED REDESIGN OF SELF-ATTENTION IN TRANSFORMERS	['Core-periphery Structure', 'Self-Attention']		Deep Learning and representational learning	anonymous|coreperiphery_principle_guided_redesign_of_selfattention_in_transformers	/pdf/04c190d642292c6088e6e0a69c011dab8fc938c9.pdf
kocBczDfBeT	5498	Marich: A Query-efficient & Online Model Extraction Attack using Public Data	['Privacy attacks', 'Model extraction', 'Membership inference', 'Black-box attack', 'Query efficiency', 'Active learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|marich_a_queryefficient_online_model_extraction_attack_using_public_data	/pdf/b83b0e2c5eb4a2717c93cf00df6ab2080afa2674.pdf
ZaQrYalGFIh	5499	GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous Graphs	['graph learning', 'node classification', 'homophily', 'heterophily', 'positional embeddings', 'knowledge graph embeddings', 'monophily', 'label propagation']	Scalable method for node classification for homophilous and heterophilous graphs	Deep Learning and representational learning	anonymous|glinkx_a_scalable_unified_framework_for_homophilous_and_heterophilous_graphs	/pdf/a449b0d165c007f129f7d753b6ba5bcace8efa62.pdf
8jU7wy7N7mA	5501	Supervision Complexity and its Role in Knowledge Distillation	['distillation', 'kernel methods', 'neural tangent kernel']	We provide a new theoretical perspective on knowledge distillation through the lens of supervision complexity -- a measure of alignment between the teacher-provided supervision and the student's neural tangent kernel.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|supervision_complexity_and_its_role_in_knowledge_distillation	/pdf/26826a3b4948c856dfc5d865ad5889b942841da6.pdf
faPdyjayCRi	5502	Efficient Stochastic Optimization for Attacking Randomness Involved Inference	[]		General Machine Learning (ie none of the above)	anonymous|efficient_stochastic_optimization_for_attacking_randomness_involved_inference	/pdf/fbd2ff68c28ee9e3a5cc2592ee3f0ae5c33e01da.pdf
086pmarAris	5503	Fantastic Rewards and How to Tame Them: A Case Study on Reward Learning for Task-Oriented Dialogue Systems	['task-oriented dialogue', 'reinforcement learning', 'reward learning']	we propose techniques for learning and utilizing reward functions that can be used for training task-oriented dialogue agents	Applications (eg, speech processing, computer vision, NLP)	anonymous|fantastic_rewards_and_how_to_tame_them_a_case_study_on_reward_learning_for_taskoriented_dialogue_systems	/pdf/8fbf42907725db4f35b69bf6669172081ed4045c.pdf
65P6pfeT3eg	5505	Protecting DNN from Evasion Attacks using Ensemble of High Focal Diversity	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|protecting_dnn_from_evasion_attacks_using_ensemble_of_high_focal_diversity	/pdf/65fde4d3dbad4cb54a3ec055617fa2d47b869551.pdf
Jbdc0vTOcol	5506	A Time Series is Worth 64 Words:  Long-term Forecasting with Transformers	['time series', 'transformer', 'forecasting', 'channel-independence', 'self-supervised learning', 'representation learning']	Channel-independent patch time series transformer works very well for long-term forecasting and representation learning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|a_time_series_is_worth_64_words_longterm_forecasting_with_transformers	/pdf/e04f6fc3c60006cd8f1ccc5e6b04eb530cb734cb.pdf
KRLUvxh8uaX	5507	When and why Vision-Language Models behave like Bags-of-Words, and what to do about it?	['vision-language models', 'clip', 'contrastive learning', 'retrieval', 'vision-language pretraining', 'multimodal representation learning']		Deep Learning and representational learning	anonymous|when_and_why_visionlanguage_models_behave_like_bagsofwords_and_what_to_do_about_it	/pdf/c67f6a3094e707c5a3bb4975e6370347e73f5569.pdf
YrZEKNLWhlp	5508	Forgetful causal masking makes causal language models better zero-shot learners	['Language modeling', 'casual language model', 'few shot language models']	A simple masking strategy for casual language models that significantly improves few shot and finetuning performance.	Deep Learning and representational learning	anonymous|forgetful_causal_masking_makes_causal_language_models_better_zeroshot_learners	/pdf/66b82adffd5a88e9b685e36ead8203ea3fd145c9.pdf
2EpjkjzdCAa	5509	Effectively Modeling Time Series with Simple Discrete State Spaces	['time series', 'forecasting', 'state-space models', 'time series classification']	We propose SpaceTime, a deep state space time series model that achieves state-of-the-art results on forecasting and classification benchmarks, by improving expressiveness, forecasting flexibility, and training efficiency over prior approaches. 	Deep Learning and representational learning	anonymous|effectively_modeling_time_series_with_simple_discrete_state_spaces	/pdf/ccbfb878996244badfb1cd79584e0f06def9a4b3.pdf
ZMz-sW6gCLF	5512	Energy-Inspired Self-Supervised Pretraining for Vision Models	[]		Deep Learning and representational learning	anonymous|energyinspired_selfsupervised_pretraining_for_vision_models	/pdf/ba611d20cb676d08fc2412ec8965d3f3f7f8ef98.pdf
lCr0UCYrSLz	5514	Learning the joint distribution of two sequences using little or no paired data	['generative modeling', 'semi-supervised learning', 'spoken language', 'sequence-to-sequence', 'variational inference', 'wake-sleep algorithm', 'identifiability']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|learning_the_joint_distribution_of_two_sequences_using_little_or_no_paired_data	/pdf/1e804cf4451399f7c5a2168b65f4e1f797ce0e56.pdf
pXDmbfVL_SB	5515	Systematic Generalization and Emergent Structures in Transformers Trained on Structured Tasks	['systematic generalization', 'transformers', 'representation', 'multi-task learning']	We present a causal transformer that learns multiple algorithmic tasks and generalizes to longer sequences, and show that it develops signs of task decomposition and exploits shared task structures.	Deep Learning and representational learning	anonymous|systematic_generalization_and_emergent_structures_in_transformers_trained_on_structured_tasks	/pdf/ba6491101f71c0f19ccdbdfff66dd4e12898c88f.pdf
3l36EPLnPzA	5516	Efficient parametric approximations of neural net function space distance	['Function space distance', 'memory-efficiency', 'continual learning', 'influence function estimation']	We propose an efficient parametric approximation of neural network function space distance that is memory-efficient and can be successfully applied to continual learning and influence function estimation tasks.	Deep Learning and representational learning	anonymous|efficient_parametric_approximations_of_neural_net_function_space_distance	/pdf/28d3089a9672550dc461d044455ffe260627e7a3.pdf
9MO7bjoAfIA	5517	Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors	['data protection', 'poisoning attack', 'self-ensemble', 'deep neural network']	We protect proprietary datasets by using intermediate checkpoints in a self-ensemble way, which more than halves the testing accuracy in unauthorized training compared to the best baselines.	Deep Learning and representational learning	anonymous|selfensemble_protection_training_checkpoints_are_good_data_protectors	/pdf/3ce3fe2eafd2390244cf9a21d19645a145f87ec1.pdf
WY0g8Gu58at	5518	Multi-scale Sinusoidal Embeddings Enable Learning on High Resolution Mass Spectrometry Data	['Cheminformatics for Life Sciences', 'Tandem Mass Spectrometry', 'Transformers']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|multiscale_sinusoidal_embeddings_enable_learning_on_high_resolution_mass_spectrometry_data	/pdf/800eef969385389fbb0dad96bff72371ac86212f.pdf
mzrNhoaHRDc	5520	Using the Training History to Detect and Prevent Overfitting in Deep Learning Models	['overfitting', 'early stopping', 'deep learning']	We propose a time series based method to: (1) detect overfitting in a trained model, and (2) prevent overfitting from happening in training. 	General Machine Learning (ie none of the above)	anonymous|using_the_training_history_to_detect_and_prevent_overfitting_in_deep_learning_models	/pdf/ae6cf5c1400127c6a4bd864cec69696cf1aee28e.pdf
n_SwMH9o-oT	5521	On The Impact of Machine Learning Randomness on Group Fairness	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_impact_of_machine_learning_randomness_on_group_fairness	/pdf/26bff2230ebf89e5a6c790f77533b4b908763d2a.pdf
lw1WKaIL3LR	5522	Proportional Multicalibration	['fairness', 'calibration', 'risk prediction', 'multicalibration', 'clinical decision support']	We study a fairness criteria called proportional multicalibration that unites two fairness measures, multicalibration and differential calibration, under one simple post-processing strategy.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|proportional_multicalibration	/pdf/6c92458efaa165afbe17bd2f90740faa0bc8fb7c.pdf
3C9Eqd0hCrr	5523	Beyond Deep Learning: An Evolutionary Feature Engineering Approach to Tabular Data Classification	['Automated Feature Construction', 'Automated Machine Learning', 'Genetic Programming', 'Evolutionary Algorithm']		Deep Learning and representational learning	anonymous|beyond_deep_learning_an_evolutionary_feature_engineering_approach_to_tabular_data_classification	/pdf/10a77532513d431ec4b79d60b154af974498a988.pdf
9XAZBUfnefS	5524	ProtFIM: Fill-in-Middle Protein Sequence Design via Protein Language Models	['Protein language modeling', 'Protein engineering', 'Text infilling']	 We propose a new evaluation scheme and protein language model for fill-in-middle protein sequence design.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|protfim_fillinmiddle_protein_sequence_design_via_protein_language_models	/pdf/febd94ef69a78dcee0e75a7b1cf00c767517055d.pdf
qDQRvlFfz-K	5525	Post-mortem on a deep learning contest: a Simpson’s paradox and the complementary roles of scale metrics versus shape metrics	"['model diagnostics', 'heavy-tailed self regularization', ""Simpson's paradox""]"	diagnostics for neural network models to understand better their performance	Deep Learning and representational learning	anonymous|postmortem_on_a_deep_learning_contest_a_simpsons_paradox_and_the_complementary_roles_of_scale_metrics_versus_shape_metrics	/pdf/6e540238d7a5d3cf34ac914ac75917135ab5ad8d.pdf
i0lHs3ji9xT	5526	Designing and Using Goal-Conditioned Tools	['Design', 'Manipulation', 'RL', 'Tool use']	We propose a framework for learning goal-conditioned design and manipulation policies for robotic tool use. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|designing_and_using_goalconditioned_tools	/pdf/84162cf8d730ce05232d4a950030213a23ae7eef.pdf
_nGgzQjzaRy	5527	Decomposed Prompting: A Modular Approach for Solving Complex Tasks	['prompting', 'decomposition', 'in-context learning', 'reasoning', 'few-shot prompts', 'multi-step reasoning']	A new few-shot prompting approach to solve complex task by decomposing complex tasks into a shared library of prompts.	Deep Learning and representational learning	anonymous|decomposed_prompting_a_modular_approach_for_solving_complex_tasks	/pdf/6c1eaaa33691c47f61ac71abcd7ee1a7d772fee8.pdf
z9SIj-IM7tn	5528	Competitive Physics Informed Networks 	['Physics informed learning', 'multi-agent games', 'Lagrange multipliers', 'partial differential equations']	We introduce competitive physics informed networks where two neural networks solve a partial differential equation by playing a zero-sum game.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|competitive_physics_informed_networks	/pdf/811825ee5433278194bfb979a1f1c61e4a54bdb1.pdf
7T2XgpklLDA	5529	Does progress on ImageNet transfer to real world datasets?	[]		Deep Learning and representational learning	anonymous|does_progress_on_imagenet_transfer_to_real_world_datasets	/pdf/4055ac2f8bee3d6f00303f84ac42ddb2190eb6ff.pdf
dhYUMMy0_Eg	5530	Equal Improvability: A New Fairness Notion Considering the Long-term Impact	['Fairness and Bias in Artificial Intelligence', 'Machine Learning']	We propose a new group fairness notion called Equal Improvability that equalizes the improvement of the rejected individuals across different groups.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|equal_improvability_a_new_fairness_notion_considering_the_longterm_impact	/pdf/9ba9e66e5f6d40baf58f39fead94ec8b4e0ff968.pdf
jH6pg6JaSP2	5531	Graph Fourier MMD for signals on data graphs	['Optimal transport', 'Data Geometry', 'Graph Signal Processing']	We introduce a new efficient MMD measure computed analytically with an explicit feature map for signals on data graphs. 	Unsupervised and Self-supervised learning	anonymous|graph_fourier_mmd_for_signals_on_data_graphs	/pdf/e293cfd0500da7b935ed5245ff972d1d6eafaf8a.pdf
nWTzIsgrYNN	5534	Composite Slice Transformer: An Efficient Transformer with Composition of Multi-Scale Multi-Range Attentions	['transformer', 'efficient transformer', 'efficient attention']	We propose an efficient Transformer based on composition of multi-scale attention with stacked slice representation and show that it outperforms the state-of-the-art efficient transformers in multiple benchmarks.	Deep Learning and representational learning	anonymous|composite_slice_transformer_an_efficient_transformer_with_composition_of_multiscale_multirange_attentions	/pdf/7208343d9a2ff47a1187d0b070622c0de8959531.pdf
Fj1S0SV8p3U	5535	Augmentation Curriculum Learning For Generalization in RL	['reinforcement learning', 'generalization', 'pixel-based RL', 'embodied learning']	Combining data augmentation, reinforcement learning and curriculum learning for generalization in reinforcement learning	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|augmentation_curriculum_learning_for_generalization_in_rl	/pdf/32887c122034c91c45393964a9b9f7210442572a.pdf
VE1s3e5xriA	5538	Dual Student Networks for Data-Free Model Stealing	[]		General Machine Learning (ie none of the above)	anonymous|dual_student_networks_for_datafree_model_stealing	/pdf/d1e018f47c6d11f8c449efc46ccd14dff4bdb84e.pdf
dz8i-yzXeVg	5539	Elicitation Inference Optimization for Multi-Principal-Agent Alignment	['alignment', 'large language models', 'LLMs', 'NLP', 'transfer learning', 'human-centered AI', 'LLMs', 'preference modeling']	We integrate an LLM with a latent factor model to predict individual’s agreement on text perspectives with increasing efficiency at scale	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|elicitation_inference_optimization_for_multiprincipalagent_alignment	/pdf/9dec46371a62e897121c0da40b0216b6ee408726.pdf
li7qeBbCR1t	5541	Building Normalizing Flows with Stochastic Interpolants	['normalizing flow', 'ODE', 'generative model']	A method is proposed to construct normalizing flows based on stochastic interpolants, yielding an efficient training algorithm compared to equivalent ODE methods, and providing a theoretical framework to map score based diffusions to ODEs.	Generative models	anonymous|building_normalizing_flows_with_stochastic_interpolants	/pdf/94ce0caa9b4e0470f8bcb27aa76c950dcc2e7479.pdf
sBfTc3SD9gp	5542	BiAdam: Fast Adaptive Bilevel Optimization Methods	['Bilevel Optimization', 'Momentum', 'Adaptive Learning Rate', 'Variance Reduced', 'Hyper-Parameter Learning']		Optimization (eg, convex and non-convex optimization)	anonymous|biadam_fast_adaptive_bilevel_optimization_methods	/pdf/6930777ebf633414013aad9bb662313baa0997e0.pdf
a65YK0cqH8g	5543	Heavy-tailed Noise Does Not Explain the Gap Between SGD and Adam, but Sign Descent Might	['optimization for deep learning', 'adaptive methods', 'adam', 'rmsprop', 'sgd', 'sign descent', 'noise', 'stochasticity', 'full batch']	A hypothesis for Adam's success is that it handles heavy-tailed noise better than SGD, but it works even better without noise; with big batch sizes, it performs very similarly to sign descent, which might help explain why it works.	Optimization (eg, convex and non-convex optimization)	anonymous|heavytailed_noise_does_not_explain_the_gap_between_sgd_and_adam_but_sign_descent_might	/pdf/7ddae29f2ba2866aa9c990452c49eb1e8fd22c67.pdf
WtW_s7EDWPe	5544	Data-Efficient Finetuning Using Cross-Task Nearest Neighbors	['multitasking', 'retrieval', 'few-shot', 'efficiency', 'nlp']	We use unlabelled task-specific data to select subsets of massive multitask datasets and show that language models fine-tuned on these subsets outperform models trained on all available data for unseen tasks in zero and few-shot settings.	Applications (eg, speech processing, computer vision, NLP)	anonymous|dataefficient_finetuning_using_crosstask_nearest_neighbors	/pdf/c38ae7e27f18fd4cd5b0e5171e9c8b5a6daa1050.pdf
VCyfx4aghT3	5545	Cross-Domain Self-Supervised Deep Learning for Robust Alzheimer's Disease Progression Modeling	['Self-supervision', 'regression', '3D imaging', 'transfer learning', 'predictive modeling']		Unsupervised and Self-supervised learning	anonymous|crossdomain_selfsupervised_deep_learning_for_robust_alzheimers_disease_progression_modeling	/pdf/78a17e897217cf78885f659f40b74d9013591cc2.pdf
MRfbe7VAoqu	5546	Sequential Brick Assembly with Efficient Constraint Satisfaction	['combinatorial problem', 'brick assembly']	We address the problem of generating a sequence of LEGO brick assembly with high-fidelity structures, satisfying physical constraints between bricks.	Generative models	anonymous|sequential_brick_assembly_with_efficient_constraint_satisfaction	/pdf/fcfabf2f966f62a2450bb8a5edee5191fed8ce58.pdf
oVPqFCI1g7q	5547	$\beta$-Stochastic Sign SGD: A Byzantine Resilient and Differentially Private Gradient Compressor for Federated Learning	['distributed systems', 'differential privacy', 'communication efficiency', 'convergence rate analysis', 'robust optimization']	Clients send stochastic sign-bits gradient estimates to a server, which aggregates updates based on majority vote. We show that this algorithm is provable differentially private, convergent, communication efficient, and Byzantine fault tolerant.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|\betastochastic_sign_sgd_a_byzantine_resilient_and_differentially_private_gradient_compressor_for_federated_learning	/pdf/999d2dac8cf18fd424e3d0239a26783e78f46c4b.pdf
po-oqRst4Xm	5548	Multi-Grid Tensorized Fourier Neural  Operator for High Resolution PDEs	['Fourier-Neural-Operators', 'Tensorization', 'Multi-Grid']	An efficient neural operator that leverages a novel multi-grid approach as well a tensorized architecture for better performance, generalization and scalability.	Deep Learning and representational learning	anonymous|multigrid_tensorized_fourier_neural_operator_for_high_resolution_pdes	/pdf/d01a52f2b56897d5d510f0aa22714948331c66d0.pdf
NEEtm5laNK1	5549	CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets	['open vocabulary models', 'CLIP', 'zero-shot learning', 'zero-shot image classification']		Deep Learning and representational learning	anonymous|chils_zeroshot_image_classification_with_hierarchical_label_sets	/pdf/184f1dccee679678396dbb1bbcc89355136a32e9.pdf
1PTeB4MWCfU	5550	Do Summarization Models Synthesize?	['Summarization', 'Factuality', 'Sentiment', 'Systematic Reviews', 'Evidence Synthesis']	We measure if multidocument summarization models can effectively synthesize contrasting inputs, and explore methods to change synthesis performance.	Applications (eg, speech processing, computer vision, NLP)	anonymous|do_summarization_models_synthesize	/pdf/1f7b0d1dce0abc3cfe3614705b3e9cb9d69afdb2.pdf
tGHi1HFNBx1	5551	Data Subset Selection via Machine Teaching	['Data pruning', 'data selection', 'machine teaching']	We propose, analyze, and evaluate a machine teaching approach to data subset selection.	General Machine Learning (ie none of the above)	anonymous|data_subset_selection_via_machine_teaching	/pdf/58e42c5490a166d72682a39fa312bd4e9bd000fc.pdf
j2ymLjCr-Sj	5552	How Can Deep Learning Performs Deep (Hierarchical) Learning	[]	We present a theory to study *how* deep neural networks (of even super-constantly many layers) can perform hierarchical feature learning, on tasks that are not known to be efficiently solvable by non-hierarchical methods (such as kernel methods).	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|how_can_deep_learning_performs_deep_hierarchical_learning	/pdf/164a696a156a4a9622d876f4c73a1862de6795de.pdf
npwbjVljAEU	5553	Shallow Learning In Materio.	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|shallow_learning_in_materio	/pdf/bb757e76877f60225f34bedacba63aa7f4e146d1.pdf
vsMyHUq_C1c	5555	A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks	['PDE', 'Neural PDE solvers', 'Initial value problems']	We develop Neural-IVP, a new method for solving initial value PDEs with Neural Networks that is both stable and scalable.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_stable_and_scalable_method_for_solving_initial_value_pdes_with_neural_networks	/pdf/4393b8fa99e54ca1ee30d6d202d382384b17a373.pdf
ncQCD9M8SwT	5556	Continual Learning Based on Sub-Networks and Task Similarity	['Continual learning', 'NLP tasks', 'Task Similarity', 'Sub-network']	A continual learning method based on sub-networks and task similarity is proposed and evaluated on NLP classification, generation, and extraction problems.	Applications (eg, speech processing, computer vision, NLP)	anonymous|continual_learning_based_on_subnetworks_and_task_similarity	/pdf/8d26bb1f78aacbcea04dfcb179bac88b89157f9d.pdf
rimcq1oIFeR	5557	A Control-Centric Benchmark for Video Prediction	['benchmarking', 'video prediction', 'visual MPC', 'manipulation']	We find that existing video evaluation metrics are not always indicative of a model's performance during control, and propose a benchmark that directly evaluates video prediction models on simulated manipulation tasks by using them for planning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|a_controlcentric_benchmark_for_video_prediction	/pdf/a144ed0fb7ad60f1dfb1b348d865e205706b0761.pdf
9yE2xEj0BH7	5558	Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus	['vision-language', 'UI', 'few-shot', 'finetuning', 'multi-task']	We propose an enhanced vision-language model for UI tasks that achieves SoTA on representative UI tasks and supports few-shot and multitask learning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|spotlight_mobile_ui_understanding_using_visionlanguage_models_with_a_focus	/pdf/55858d347f45234161686d0b5024ac93cdd2e415.pdf
7h5KSs2PCRi	5559	How Can GANs Learn Hierarchical Generative Models for Real-World Distributions	[]	We provide a theory to study how generative adversarial networks (GANs) can efficiently learn certain hierarchically generated distributions that are close to the distribution of images in practice.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|how_can_gans_learn_hierarchical_generative_models_for_realworld_distributions	/pdf/2efefc7dce0255885300202e528558f49725266e.pdf
dF0g-5k05h_	5560	The Vendi Score: A Diversity Evaluation Metric for Machine Learning	[]		General Machine Learning (ie none of the above)	anonymous|the_vendi_score_a_diversity_evaluation_metric_for_machine_learning	/pdf/640799ac02b1951e5e1938aacadc321295a6f73a.pdf
IsCg7qoy8i9	5562	Benchmarking Algorithms for Domain Generalization in Federated Learning	['Domain Generalization', 'Federated Learning', 'Benchmark.']	Benchmarking algorithms for domain generalization in federated learning on multiple realistic datasets.	Deep Learning and representational learning	anonymous|benchmarking_algorithms_for_domain_generalization_in_federated_learning	/pdf/3c8e1f6dea587a76b4890fa0b81e637c98e35019.pdf
rMQ1Wme3S0c	5563	A Score-Based Model for Learning Neural Wavefunctions	['Neural wavefunction', 'Quantum Monte Carlo', 'Score-based method']	We propose a score-based optimization framework for Quantum Monte Carlo which does not require explicit probability distribution.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_scorebased_model_for_learning_neural_wavefunctions	/pdf/1edf99b437702af57e51a9b673983d1c52924e2a.pdf
Uuf2q9TfXGA	5565	Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning	[]	We provide a theory to explain why ensemble and knowledge distillation work for Deep Learning. It matches practice well, while traditional theory such as boosting, random feature mappings or NTKs, cannot explain the same phenomena for DL.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|understanding_ensemble_knowledge_distillation_and_selfdistillation_in_deep_learning	/pdf/2d1190aae4c3c6428598c74ac8942be0f8cb1ce0.pdf
V2BQvSIWnYD	5566	Learning Arborescence with An Efficient Inference Algorithm	['minimum weight arborescence', 'arborescence Learning']	We propose an efficient algorithm for predicting minimum weight arborescence, that can  boost the training and inference time for arborescence learning tasks.	General Machine Learning (ie none of the above)	anonymous|learning_arborescence_with_an_efficient_inference_algorithm	/pdf/bc40b11773f87e44c9cbaad664670bd51ad5bf49.pdf
1n1c7cHl3Zc	5567	The Plug and Play of Language Models for Text-to-image Generation	['Text-to-Image Generation', 'Language Models', 'Efficiency']	This paper introduces a new method to efficiently plug new language models to exiting text-to-image generation models as enhancement in scalability.	Deep Learning and representational learning	anonymous|the_plug_and_play_of_language_models_for_texttoimage_generation	/pdf/4e2d9f019399b13c8b2fe36101f28ae01293b758.pdf
00kPgkoahtO	5568	IAE: Implicit Autoencoder for Point Cloud Self-supervised Representation Learning	['point cloud', 'self-supervised learning', 'representation learning', 'autoencoder', 'implicit function']	We propose a simple yet effective non-symmetric autoencoder for point cloud self-supervised learning which leverages implicit function.	Unsupervised and Self-supervised learning	anonymous|iae_implicit_autoencoder_for_point_cloud_selfsupervised_representation_learning	/pdf/d99ae2ed6bd5439fbad9f6d2589ea9ef75e9236f.pdf
PvDY71zKsvP	5569	Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning	['robust optimization', 'bilevel optimization', 'multi-objective optimization']	We study a generic min-max bilevel multi-objective optimization framework with novel theoretical analysis and applications in representation learning and hyperparameter optimization	Optimization (eg, convex and non-convex optimization)	anonymous|minmax_multiobjective_bilevel_optimization_with_applications_in_robust_machine_learning	/pdf/9729b58dcfb756fcd5ab8af6bf824db57f442e4a.pdf
m_GDIItaI3o	5570	Continual Post-Training of Language Models	['Continual learning', 'Domain-adaptive Pretraining', 'Post-training']	This paper proposes a continual post-training method based on soft-masking to learn a sequence of unlabeled domain corpora to adapt a language model to improve the end-task performances in these domains.	General Machine Learning (ie none of the above)	anonymous|continual_posttraining_of_language_models	/pdf/c3c003356dffa377d220fac80ad6af826caafa32.pdf
15lSKp0wBnm	5571	3D-IntPhys: Learning 3D Visual Intuitive Physics for Fluids, Rigid Bodies, and Granular Materials	['Visual Intuitive Physics', 'Neural Implicit Representations', 'Graph Neural Networks', 'Learning-Based Dynamics Modeling', 'Particle-Based Dynamics']	An intuitive physics model with explicit 3D and compositional structures learned from multi-view videos. The learned model can handle complicated objects (e.g., fluid, rigid objects, granular materials) and perform extrapolated generalization.	Deep Learning and representational learning	anonymous|3dintphys_learning_3d_visual_intuitive_physics_for_fluids_rigid_bodies_and_granular_materials	/pdf/73e44a63b8b8c3861aca4a5d4064103b62a77043.pdf
D8ulVmpjzYX	5572	PBES: PCA Based Exemplar Sampling Algorithm for Continual Learning	['Continual Learning', 'Incremental Learning', 'Machine Learning', 'PCA', 'principal directions', 'principal component analysis', 'Class-incremental learning']		Deep Learning and representational learning	anonymous|pbes_pca_based_exemplar_sampling_algorithm_for_continual_learning	/pdf/7c42b48d711215385f1e3abc23dcfab0d5b6a701.pdf
RDy3IbvjMqT	5573	$\mathrm{SE}(3)$-Equivariant Attention Networks for Shape Reconstruction in Function Space	['shape reconstruction', 'equivariance', 'neural fields', 'attention', '3D vision', 'point clouds']		Applications (eg, speech processing, computer vision, NLP)	anonymous|\mathrmse3equivariant_attention_networks_for_shape_reconstruction_in_function_space	/pdf/ddd773d65d4b34e48a7d81b7642b4541098fb993.pdf
8MneBPDxV9L	5575	Finding the smallest tree in the forest: Monte Carlo Forest Search for UNSAT solving	['Monte Carlo Tree Search', 'Reinforcement learning', 'Combinatorial optimization', 'SAT']	We develop Monte Carlo Forest Search (MCFS), an algorithm for finding small search trees within a forest that retains the benefits of the best MCTS approaches.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|finding_the_smallest_tree_in_the_forest_monte_carlo_forest_search_for_unsat_solving	/pdf/7599a44216bc55209ccde5e46c7c41fa096ec60a.pdf
bH-kCY6LdKg	5576	A new characterization of the edge of stability based on a sharpness measure aware of batch gradient distribution	['edge of stability', 'SGD', 'learning rate', 'batch size', 'optimization', 'generalization', 'implicit bias', 'implicit regularization', 'sharpness', 'scaling rule']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_new_characterization_of_the_edge_of_stability_based_on_a_sharpness_measure_aware_of_batch_gradient_distribution	/pdf/63e4299708921f88e03f25a7f87d2878a4ee79cf.pdf
8-2sjUPp_YD	5578	ADVL: Adaptive Distillation for Vision-Language Tasks	['vision language', 'kowledge distillation', 'vcr', 'vqa', 'snli-ve', 'visual question answering', 'commonsense reasoning', 'pretraining', 'multimodal', 'robust', 'low-shot', 'zero-shot', 'domain-shift', 'debiased']	Leveraging Pretrained Unimodal Encoders for Vision-Language Tasks via Adaptive Knowledge Distillation	Deep Learning and representational learning	anonymous|advl_adaptive_distillation_for_visionlanguage_tasks	/pdf/84fafd391242557178e79dbade15cfe0e582438f.pdf
oxIbD0j-GGo	5580	Dynamics Model Based Adversarial Training For Competitive Reinforcement Learning	['Adversarial Training', 'Competitive Reinforcement Learning', 'Adversarial Robustness']	We propose a dynamics model based adversarial training framework to train DRL agents robust against adversarial perturbations in two-agent games.	Deep Learning and representational learning	anonymous|dynamics_model_based_adversarial_training_for_competitive_reinforcement_learning	/pdf/37fc4e98a8933d40af659972e32efb8bf2192fa0.pdf
q2vsXnsjNB_	5581	ConserWeightive Behavioral Cloning for Reliable Offline Reinforcement Learning	['offline RL', 'behavioral cloning', 'conservatism']	Simple weighted sampling + conservative regularization based on l2 penalty improves robustness of conditional BC when conditioning on large out-of-distribution returns.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|conserweightive_behavioral_cloning_for_reliable_offline_reinforcement_learning	/pdf/7a91263bf9db805f9d9c4ea22b40f469af82b915.pdf
hA7XDfCD1y2	5586	Attentive MLP for Non-Autoregressive Generation	['Non-autoregressive', 'AMLP', 'linear complexity']	We propose Attentive Multi-Layer Perceptron (AMLP) to integrate the attention mechanism with the multi-layer perceptron (MLP) in non-autoregressive architecture.	Deep Learning and representational learning	anonymous|attentive_mlp_for_nonautoregressive_generation	/pdf/4333cb5d02b1858aba0d01d25a3358bdabc34468.pdf
Bo-1bxmCrrA	5589	Domain-Invariant Auxiliary Learning for Robust Few-Shot Predictions from Noisy Data	['meta-learning', 'few-shot learning', 'auxiliary task']	We propose a novel MetaAux framework using auxiliary tasks to effectively learn a robust representation for better generalization and adaptation in unseen few-shot tasks.	Deep Learning and representational learning	anonymous|domaininvariant_auxiliary_learning_for_robust_fewshot_predictions_from_noisy_data	/pdf/8690ea354de4e2d1ffef8c2c5c8a6aedc5d5de5b.pdf
tcbBPnfwxS	5595	GPTQ: Accurate Quantization for Generative Pre-trained Transformers	['compression', 'quantization', 'generative pre-trained transformers', 'GPT', 'second-order methods']	We show that Generative Pre-trained Transformer (GPT) models can be quantized down to 3-4 bits without significant loss of accuracy, which leads to significant computational and usability improvements. 	Deep Learning and representational learning	anonymous|gptq_accurate_quantization_for_generative_pretrained_transformers	/pdf/a66901099973e71250f06795075b9642c374fa6b.pdf
6G5DwFLYRM	5596	META-LEARNING FOR UNSUPERVISED OUTLIER DETECTION WITH OPTIMAL TRANSPORT	['unsupervised learning', 'automl', 'optimal transport']	A new meta learning for unsupervised machine learning problems with optimal transport.	Unsupervised and Self-supervised learning	anonymous|metalearning_for_unsupervised_outlier_detection_with_optimal_transport	/pdf/e7ca8c457cdf68d6d9ca988a7c5a41ea397c39e5.pdf
K1NKDaNM9i	5597	Counterfactual Vision-Language Data Synthesis with Intra-Sample Contrast Learning	['counterfactual', 'data augmentation', 'vision language', 'kowledge distillation', 'vcr', 'vqa', 'visual question answering', 'commonsense reasoning', 'multimodal', 'robust', 'domain-shift', 'debiased']	Counterfactual Vision-Language Data Synthesis with Intra-Sample Contrast Learning for Visual Commonsense Reasoning	Deep Learning and representational learning	anonymous|counterfactual_visionlanguage_data_synthesis_with_intrasample_contrast_learning	/pdf/d1b5c296ac9bf1fd5add23936a6a867caf241799.pdf
G7E_K3WaLpK	5601	Infusing Lattice Symmetry Priors in Neural Networks Using Soft Attention Masks	[]		Deep Learning and representational learning	anonymous|infusing_lattice_symmetry_priors_in_neural_networks_using_soft_attention_masks	/pdf/a5683c4fa2bb18d519ffcca4d46627c70f599d9a.pdf
U0jfsqmoV-4	5603	Instruction-Following Agents with Jointly Pre-Trained Vision-Language Models	['reinforcement learning', 'pre-training', 'multimodal representation', 'representation learning', 'transformer']	A simple model consists of a pretrained multimodal transformer and policy transformer for instruction following that significantly improves performance	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|instructionfollowing_agents_with_jointly_pretrained_visionlanguage_models	/pdf/14068fbe5ee5a336aa82b99b5288c3263579dfea.pdf
VM8batVBWvg	5604	Discrete Predictor-Corrector Diffusion Models for Image Synthesis	['discrete diffusion models', 'image synthesis']	We propose a learned predictor-corrector sampler for discrete diffusion models and empirically demonstrate its effectiveness for image generation.	Generative models	anonymous|discrete_predictorcorrector_diffusion_models_for_image_synthesis	/pdf/e1662b47dcccd0225d05a0b8f91dc7240fa74d83.pdf
hCmjBJeGXcu	5605	Enhancing Meta Learning via Multi-Objective Soft Improvement Functions	['Meta Learning', 'Multi-Objective Optimization']		Deep Learning and representational learning	anonymous|enhancing_meta_learning_via_multiobjective_soft_improvement_functions	/pdf/e0199dd7e7199258dbbda6fc2a3becd375dfad01.pdf
c5-qKzTbP2O	5606	Interpretable (meta)factorization of clinical questionnaires to identify general dimensions of psychopathology	['Factor analysis', 'matrix factorization', 'meta-factors', 'latent constructs', 'Healthy Brain Network Study']	We propose an interpretable factorization for multiple, partially-responded clinical questionnaires	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|interpretable_metafactorization_of_clinical_questionnaires_to_identify_general_dimensions_of_psychopathology	/pdf/ea7213cff2a0932770ec891b748ef8ce2a748335.pdf
CKATCkQFcdJ	5608	Gradient Descent Converges Linearly for Logistic Regression on Separable Data	['logistic regression', 'gradient descent', 'sparse optimization']	We theoretically show that gradient descent with increasing learning rate obtains favorable rates on logistic regression.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|gradient_descent_converges_linearly_for_logistic_regression_on_separable_data	/pdf/ffc856123dd713f4377f06c8fa59a7b77145d973.pdf
CPDtGLmXEfy	5609	On Representation Learning Under Class Imbalance	['Class Imbalance', 'Neural Networks', 'Representation Learning', 'Flatness', 'Self-Supervised Learning', 'Bayesian Learning']	We study foundational questions regarding representation learning under imbalanced data for a variety of model classes and across a wide range of domains 	Deep Learning and representational learning	anonymous|on_representation_learning_under_class_imbalance	/pdf/5d39445712ff9e725d33e46d6c4734a1121ad927.pdf
b5RD94lXu2j	5611	Protecting Bidder Information in Neural Auctions	['Mechanism design', 'neural auctions', 'privacy']	Neural auctions often reveal private bidder information; we apply stochasticity to make them private.	General Machine Learning (ie none of the above)	anonymous|protecting_bidder_information_in_neural_auctions	/pdf/c49d127f2dbfb227774f6b20c77d5f43e42cf7a7.pdf
9d13HEFFaea	5612	Learning to represent and predict evolving visual signals via polar straightening	['Video prediction', 'self-supervised representation learning', 'phase prediction', 'invariance / equivariance factorization']		Unsupervised and Self-supervised learning	anonymous|learning_to_represent_and_predict_evolving_visual_signals_via_polar_straightening	/pdf/93f988c6ffa3f8e07371258a8932bf46fc05b764.pdf
0g0X4H8yN4I	5613	​​What learning algorithm is in-context learning? Investigations with linear models	['in-context learning', 'transformers', 'sequence models', 'deep learning', 'meta learning']	We prove that the transformers can implement learning algorithms for linear models based e.g gradient descent, then observe they closely match the predictors of known algorithms, transitioning between different predictors as transformer depth vary.	Deep Learning and representational learning	anonymous|what_learning_algorithm_is_incontext_learning_investigations_with_linear_models	/pdf/a5b672871a890c86fbe7af18719566f18ded8dff.pdf
nareqzplSc9	5614	High-dimensional Continuum Armed and High-dimensional Contextual Bandit: with Applications to Assortment and Pricing	['bandit', 'high-dimensional statistics', 'assortment', 'pricing', 'reinforcement learning']	We propose a new model and an efficient theoretically guaranteed algorithm for high-dimensional continuum armed and high-dimensional contextual bandit, with applications to the joint assortment and pricing problem.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|highdimensional_continuum_armed_and_highdimensional_contextual_bandit_with_applications_to_assortment_and_pricing	/pdf/25cc9899f3a40dbb638af5a712e5c09a8f633e1f.pdf
i-DleYh34BM	5616	Pruning Deep Neural Networks from a Sparsity Perspective	['Adaptive Pruning', 'Model Collapse', 'Sparsity', 'Model Compression', 'Deep Learning']	This work develops PQ Index (PQI) as a new measure of sparsity and proposes a Sparsity-informed Adaptive Pruning (SAP) algorithm. 	Deep Learning and representational learning	anonymous|pruning_deep_neural_networks_from_a_sparsity_perspective	/pdf/ac0a8e2152f6862f9a90e5041ea4128f6f3836d7.pdf
6lUU0QaTOC	5617	TI-VAE: A temporally independent VAE with applications to latent factor learning in neuroimaging	['variational autoencoder', 'computational neuroscience', 'latent factor analysis', 'latent factor learning', 'fMRI', 'sequential variational autoencoder', 'somatomotor cortex', 'weight sharing', 'inductive bias']	 Our approach extends temporal ICA to the non-linear case and generalizes weight sharing to non-Euclidean neuroimaging data. 	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|tivae_a_temporally_independent_vae_with_applications_to_latent_factor_learning_in_neuroimaging	/pdf/5a59a721847173344c03bd2c1ccca0fb5c15d2c3.pdf
zV3Q0a8--A	5618	Spatiotemporal Modeling of Multivariate Signals with Graph Neural Networks and Structured State Space Models	['Multivariate Signals', 'Graph Neural Network', 'Graph Structure Learning', 'Structured State Spaces', 'Time Series']	Graph neural networks for spatiotemporal modeling of multivariate signals	Applications (eg, speech processing, computer vision, NLP)	anonymous|spatiotemporal_modeling_of_multivariate_signals_with_graph_neural_networks_and_structured_state_space_models	/pdf/b05d181c23a949c7d6241e9effe53c303d4af41d.pdf
2WmBMrCZSx	5619	FedTiny: Pruned Federated Learning Towards Specialized Tiny Models	[]		General Machine Learning (ie none of the above)	anonymous|fedtiny_pruned_federated_learning_towards_specialized_tiny_models	/pdf/c27b1e7744b565f504396eee07b5aa34c730976a.pdf
ohQPU2G3r3C	5621	Faster Hyperparameter Search for GNNs via Calibrated Dataset Condensation	['Graph Condensation', 'Dataset Condensation', 'Hyperparameter Optimization', 'Graph Neural Networks', 'Graph Compression']	We propose a novel hyperparameter-calibrated dataset condensation (HCDC) algorithm, which can be applied to speed up hyperparameter optimization on graphs.	Deep Learning and representational learning	anonymous|faster_hyperparameter_search_for_gnns_via_calibrated_dataset_condensation	/pdf/81f4d958508af21e68c924067af5a658e1fbf8e7.pdf
er_nz4Q9Km7	5622	Fast Yet Effective Graph Unlearning through Influence Analysis	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fast_yet_effective_graph_unlearning_through_influence_analysis	/pdf/7e9f6c88243285a6becdb94e569d82d574c758c3.pdf
FILleBqk31S	5623	Do Not Blindly Imitate the Teacher: Loss Perturbation for Knowledge Distillation	['distillation', 'loss function', 'natural language processing']	We propose a perturbed loss function for the knowledge distillation task which outperforms the underlying KL loss and other perturbation methods.	General Machine Learning (ie none of the above)	anonymous|do_not_blindly_imitate_the_teacher_loss_perturbation_for_knowledge_distillation	/pdf/8ee969e306496a349093b6c516778cfefd5e063c.pdf
92gvk82DE-	5624	Large Language Models are Human-Level Prompt Engineers	['few-shot learning', 'automated reasoning', 'large language models']	We propose an algorithm for automatic instruction generation and selection for large language models with human level performance.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|large_language_models_are_humanlevel_prompt_engineers	/pdf/adb87c732dc7b5b41ab448d7bd634184507923fc.pdf
N5gn1KjCWW	5625	Supervised Metric Learning for Retrieval via Contextual Similarity Optimization	['Image Retrieval', 'Metric Learning', 'Contextual Similarity']		Deep Learning and representational learning	anonymous|supervised_metric_learning_for_retrieval_via_contextual_similarity_optimization	/pdf/b49847b77eaa0711c70fd2b14d6177fbbbe5c157.pdf
M_MvkWgQSt	5628	Real-time variational method for learning neural trajectory and its dynamics	['neural dynamics', 'neural trajectory', 'online variational inference']	A real-time variational Bayesian method aimed at uncovering latent neural trajectories and their dynamical systems.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|realtime_variational_method_for_learning_neural_trajectory_and_its_dynamics	/pdf/320fb5e9579efe7b40fc2655c9fdee272d208754.pdf
Itn7dH7muI	5630	Getting away with more network pruning: From sparsity to geometry and linear regions	[]	If we prune with the maximum number of linear regions in mind, we can improve accuracy considerably	Deep Learning and representational learning	anonymous|getting_away_with_more_network_pruning_from_sparsity_to_geometry_and_linear_regions	/pdf/85bb99f52ce3fa0357d075ee6285364368f933b2.pdf
F0UQv_MNWCt	5631	ORCA: Interpreting Prompted Language Models via Locating Supporting Evidence in the Ocean of Pretraining Data	['interpretability', 'prompting language models', 'pretraining data as evidence']	We find supporting data evidence from pretraining data to interpret prompted language models.	Applications (eg, speech processing, computer vision, NLP)	anonymous|orca_interpreting_prompted_language_models_via_locating_supporting_evidence_in_the_ocean_of_pretraining_data	/pdf/259dbedfcaa901d98c2eb03bd119d64d2b085854.pdf
ZzdBhtEH9yB	5633	Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent	[]		Deep Learning and representational learning	anonymous|implicit_regularization_in_heavyball_momentum_accelerated_stochastic_gradient_descent	/pdf/6e978a5207468432769a54970ef7a7f9cc332467.pdf
TDUMUFa5zz	5634	Divide-and-Cluster: Spatial Decomposition Based Hierarchical Clustering	['Unsupervised Learning', 'High-dimensional features', 'World Centered Clustering', 'Points Centered Clustering', 'Hierarchical Clustering', 'Complexity', 'Minimal Spanning Tree']	This paper clusters n points located in a D-dimensional space by detecting their mutual clustering affinity within local neighborhoods, using more efficient local computations, and then hierarchically growing the local clusters outward.	Unsupervised and Self-supervised learning	anonymous|divideandcluster_spatial_decomposition_based_hierarchical_clustering	/pdf/94276a30121b0b0efc6f064f3da3802b8dbf791c.pdf
vdhco_34qV8	5635	Adaptive Anchor for Robust Keypoint Localization	['keypoint localization', 'human pose estimation']		Applications (eg, speech processing, computer vision, NLP)	anonymous|adaptive_anchor_for_robust_keypoint_localization	/pdf/ef14b97559d0f2f34acb311c650030a617ff460e.pdf
mKILD5MLR2C	5637	HesScale: Scalable Computation of Hessian Diagonals	[]		Deep Learning and representational learning	anonymous|hesscale_scalable_computation_of_hessian_diagonals	/pdf/7f759cd999202206d62e73be222944e35f82196e.pdf
hayd_QIsu1	5639	Stabilized training of joint energy-based models and its practical applications	[]	JEM with stabilized training using SGLD samples; it enables us to apply it to speech	Generative models	anonymous|stabilized_training_of_joint_energybased_models_and_its_practical_applications	/pdf/9e0d11cf1712551d5e95fc94de1d85a01ed4b643.pdf
4O4eoAVEdIs	5641	Why do Models with Conditional Computation Learn Suboptimal Solutions?	['neural networks', 'conditional computation', 'gradient estimation']		Deep Learning and representational learning	anonymous|why_do_models_with_conditional_computation_learn_suboptimal_solutions	/pdf/3304f7dc906d8484739173180b7d511999d498d0.pdf
d7Q0vVfJ0wO	5643	Implicit Regularization for Group Sparsity	['gradient descent', 'implicit regularization', 'structured/group sparsity', 'linear neural network']	We study the implicit regularization of gradient descent towards structured sparsity via a novel neural reparameterization.	Optimization (eg, convex and non-convex optimization)	anonymous|implicit_regularization_for_group_sparsity	/pdf/2d636d70e8a0bfa1c2e548c508ece408c3267dde.pdf
G_D6xThdQe4	5644	Mixture of Quantized Experts (MoQE): Complementary Effect of Low-bit Quantization and Robustness	['MoE', 'Quantization', 'Mixture of Experts', 'Sparse Model', 'Machine Translation']	We investigate robustness of MoE experts, and apply ultra low-bit quantization to them for achieving more efficient MoE model inference.	Applications (eg, speech processing, computer vision, NLP)	anonymous|mixture_of_quantized_experts_moqe_complementary_effect_of_lowbit_quantization_and_robustness	/pdf/84c26a1c83b89bd9b8636b1185487e763df3b444.pdf
R6zTkW_w_PV	5645	Correspondences between word learning in children and captioning models 	['cognitive science', 'child development', 'language', 'image captioning', 'computer vision']	We show that image captioning systems' performance correlates with the age at which children acquire words from a variety of word categories.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|correspondences_between_word_learning_in_children_and_captioning_models	/pdf/613b95176ac242b466e147e4228ce5be3d165928.pdf
e4qmg9HQJPr	5646	Federated Learning with Heterogeneous Label Noise: A Dual Structure Approach	['Federated learning', 'Heterogeneous lable noise']		General Machine Learning (ie none of the above)	anonymous|federated_learning_with_heterogeneous_label_noise_a_dual_structure_approach	/pdf/1c959f55f26a559356abdd8cf3e620e53e33b1a8.pdf
ttnf-Wibn2R	5647	An Analytic Framework for Robust Training of Differentiable Hypothesis	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|an_analytic_framework_for_robust_training_of_differentiable_hypothesis	/pdf/cc1f46613a197d4e78955037b667b39b48bd8b15.pdf
Nayau9fwXU	5649	Diffusion-based Image Translation using disentangled style and content representation	['DDPM', 'CLIP', 'Image Translation', 'ViT']	We propose a new method which enables image translation using Denoising Diffusion Probabilistic Model.	Generative models	anonymous|diffusionbased_image_translation_using_disentangled_style_and_content_representation	/pdf/bfd6d486e004333ae7be1c00f8ca7b915559fadb.pdf
D__ipVB0Z7	5652	Disentangled Conditional Variational Autoencoder for Unsupervised Anomaly Detection	['unsupervised anomaly detection', 'autoencoder', 'disentanglement learning', 'representation learning', 'information theory']	unsupervised anomaly detection architecture incorporating disentangled learning, information theory and conditional variational modeling. 	Unsupervised and Self-supervised learning	anonymous|disentangled_conditional_variational_autoencoder_for_unsupervised_anomaly_detection	/pdf/9f93e0d4c655779a0d34fa9c6b44695db75d747f.pdf
4-k7kUavAj	5653	Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes	['offline RL', 'multi-task Atari', 'large models']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_qlearning_on_diverse_multitask_data_both_scales_and_generalizes	/pdf/3a17f7960c172eddb1907b1a3778b78ce28d739d.pdf
6dlC7E1H_9	5654	Teaching Algorithmic Reasoning via In-context Learning	['in-context learning', 'algorithmic reasoning', 'LLMs', 'prompting']	We study how to teach algorithmic reasoning to LLMs via in-context learning. We show that algorithmic reasoning can be taught by increasing specificity in the way we explain the steps of an algorithm along with running examples.	Deep Learning and representational learning	anonymous|teaching_algorithmic_reasoning_via_incontext_learning	/pdf/661e75cbb7b7e3c0dd5c8f9b44797375fc3ba4da.pdf
3dH2aqKGzZe	5656	S$^6$-DAMON: Bridging Self-Supervised Speech Models and Real-time Speech Recognition	['automated speech recognition', 'self-supervised learning', 'model compression']	We propose a data-model co-compression framework dubbed S$^6$-DAMON for bridging self-supervised speech models with real-time speech recognition.	Deep Learning and representational learning	anonymous|s^6damon_bridging_selfsupervised_speech_models_and_realtime_speech_recognition	/pdf/3148a52d736c0e74e41870c65cd2b3c579317383.pdf
wNUgn1n6esQ	5658	Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-Free RL	['Reward-free RL', 'Safety constraint', 'Sample complexity', 'Pure exploration']	We developed a novel reward-free RL framework with safety constraint, and provide a unified provably efficient algorithm.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|safe_exploration_incurs_nearly_no_additional_sample_complexity_for_rewardfree_rl	/pdf/7e85ed2e5a072cd0181edc5f38baaf1b02060edf.pdf
lVdvYoIxsXm	5659	Pre-Training for Robots: Leveraging Diverse Multitask Data via Offline Reinforcement Learning	['pre-training', 'robotics', 'finetuning', 'offline RL']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pretraining_for_robots_leveraging_diverse_multitask_data_via_offline_reinforcement_learning	/pdf/d03e2a94088a55c1c88527340970515ba3480f10.pdf
w2mDq-p9EEf	5661	Learning Latent Structural Causal Models	['Causal discovery', 'Bayesian inference']	bayesian inference over latent structural causal models from low level data and random, known interventions for linear Gaussian additive noise SCMs. Such a model also performs image generation from unseen interventions,	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|learning_latent_structural_causal_models	/pdf/d461a171c9e5f2708d5e3bbd3a8c69ec10c77bcb.pdf
p5cvsNww5dB	5664	LEARNING CONTEXT-AWARE ADAPTIVE SOLVERS TO ACCELERATE QUADRATIC PROGRAMMING	['quadratic optimization', 'convex optimization', 'reinforcement learning for optimization', 'graph neural network', 'contextual learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_contextaware_adaptive_solvers_to_accelerate_quadratic_programming	/pdf/2fa4bbb7836b73928290c20b13eef63f11e69db1.pdf
5BaqCFVh5qL	5667	Avoiding spurious correlations via logit correction	['spurious correlation', 'robust learning', 'empirical risk minimization']	 We propose the logit correction (LC) loss, a simple yet effective improvement on the softmax cross-entropy loss, to mitigate spurious correlations	Deep Learning and representational learning	anonymous|avoiding_spurious_correlations_via_logit_correction	/pdf/17b5a8a541b001fca928d919f79c18fc5e2fef2b.pdf
VILHmvACcR	5668	Learning to perceive objects by prediction	['self supervised learning', 'predictive learning', 'object-centric representation', '3D perception', 'sensory grounding']	Object representation arise by predicting the future	Unsupervised and Self-supervised learning	anonymous|learning_to_perceive_objects_by_prediction	/pdf/07bf7a9bb819a7e18997f00a905fdde03f665130.pdf
sckjveqlCZ	5669	Broken Neural Scaling Laws	['Scaling Laws', 'Scaling', 'Scale', 'Big Learning', 'Deep Learning', 'Artificial Neural Networks']	"We present a functional form that accurately models the scaling behaviors for each task from a very large and diverse set of downstream (and upstream) tasks, even scaling behaviors that were previously believed to be ""unpredictable""."	Deep Learning and representational learning	anonymous|broken_neural_scaling_laws	/pdf/3aa1451c8d87cca616e3b4219e69d10ace55ab89.pdf
czL6NLxJsx	5672	Outlier-Robust Group Inference via Gradient Space Clustering	['Distributionally Robust Optimization', 'Outlier Robust Optimization', 'Group Identification', 'Subpopulation Shift']	We propose to perform clustering in the gradient space for outlier-robust group identification, thereby learning distributionally and outlier robust models when group labels are unavailable.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|outlierrobust_group_inference_via_gradient_space_clustering	/pdf/8a426193fa43bc7c4bcd449c44ced07ba9dc514e.pdf
pX21pH4CsNB	5673	Differentially Private Diffusion Models	['Diffusion models', 'Differential Privacy', 'Generative Modeling']	Training diffusion models with differential privacy achieves state-of-the art performance on image generation benchmarks.	Generative models	anonymous|differentially_private_diffusion_models	/pdf/746f5b6635abe2016fa29c0ae7c5922648898ecb.pdf
NFzHAognkpQ	5674	Steerable Equivariant Representation Learning	['representation', 'visual', 'equivariance', 'equivariant']		Deep Learning and representational learning	anonymous|steerable_equivariant_representation_learning	/pdf/446eb10d225f1ae0aaf2f286083ddc4b17b94d76.pdf
43nOUI4VHUw	5675	Deep Watermarks for Attributing Generative Models	['Model Attribution', 'Watermarking', 'Generative Models']		Generative models	anonymous|deep_watermarks_for_attributing_generative_models	/pdf/33742fa5aed2d5eee8a655ef31caf8773fd74d8f.pdf
CZmHHj9MgkP	5678	Guiding Energy-based Models via Contrastive Latent Variables	['energy-based model', 'contrastive representation learning']	We propose a simple yet effective framework for improving energy-based models (EBMs) via contrastive representation learning.	Generative models	anonymous|guiding_energybased_models_via_contrastive_latent_variables	/pdf/26481360225b0b26ff719fd50bfa9dd0b9eb0fee.pdf
MMKqOJgRiw4	5679	Pyramidal Denoising Diffusion Probabilistic Models	['Diffusion Model', 'Image Generation', 'Super Resolution']		Generative models	anonymous|pyramidal_denoising_diffusion_probabilistic_models	/pdf/1af90a775ee2ae87168f5fb21384be9c49228056.pdf
zgVDqw9ZUES	5681	Adaptive Optimization in the $\infty$-Width Limit	['Infinite width', 'neural tangent kernels', 'feature learning', 'theory', 'adaptive optimization', 'tensor programs']	We derive the infinite width limits of neural networks trained with adaptive optimizers	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|adaptive_optimization_in_the_\inftywidth_limit	/pdf/b3c3dd3a98a4e3cae76ffdcf5bcd6c4b70214620.pdf
r0BrY4BiEXO	5682	Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models	['Federated Learning', 'Attack', 'Privacy', 'Transformers', 'Gradient Inversion']		Deep Learning and representational learning	anonymous|decepticons_corrupted_transformers_breach_privacy_in_federated_learning_for_language_models	/pdf/521ff14eb1396e4bc9511b3381f545bad919a335.pdf
01LMSeReNvY	5684	PromptBoosting: Black-Box Text Classification with Ten Forward Passes	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|promptboosting_blackbox_text_classification_with_ten_forward_passes	/pdf/7d1968fca8621c7c086aa180629204bc93ee654d.pdf
TdTGGj7fYYJ	5686	Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning	['unsupervised meta-learning', 'supervised contrastive learning', 'self-supervised learning']		Unsupervised and Self-supervised learning	anonymous|unsupervised_metalearning_via_fewshot_pseudosupervised_contrastive_learning	/pdf/37209cb0dae4f2d814a5c745f89c1f5addfab6a7.pdf
cC0VNCNCqpK	5688	DyG2Vec: Representation Learning for Dynamic Graphs With Self-supervision	[]		Deep Learning and representational learning	anonymous|dyg2vec_representation_learning_for_dynamic_graphs_with_selfsupervision	/pdf/56af4a9165b2003020178c99003ba6f4e4ebc68f.pdf
YrxOdjYd1j8	5689	Latent Topology Induction for Understanding Contextualized Representations	[]	We discover the hidden topology within the representation space of contextualized representations	Applications (eg, speech processing, computer vision, NLP)	anonymous|latent_topology_induction_for_understanding_contextualized_representations	/pdf/d5f23a7171a9baa12babafeb0491006a0de6c3c8.pdf
-ENYHCE8zBp	5690	Unsupervised Learning for Combinatorial Optimization Needs Meta Learning	['combinatorial optimization', 'unsupervised learning', 'meta learning', 'graph neural networks']		Unsupervised and Self-supervised learning	anonymous|unsupervised_learning_for_combinatorial_optimization_needs_meta_learning	/pdf/5207d0520881189c2e63ed2a757ae6b139284c0b.pdf
k1lUZZzE6b-	5691	Learning Frequency-aware Network for Continual Learning	['Continual Learning', 'Incremental Learning', 'Vision Transformer']		Deep Learning and representational learning	anonymous|learning_frequencyaware_network_for_continual_learning	/pdf/a91e33ec939bae3aae0a4812df713ef02c902dca.pdf
R2M14I9LEwW	5693	A second order regression model shows edge of stability behavior	['deep learning theory', 'non-linear dynamics', 'optimization']	Recently observed non-linear learning effects like progressive sharpening and edge of stability occur generically in a simple, second order regression model.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_second_order_regression_model_shows_edge_of_stability_behavior	/pdf/3b1de23a81d9c91c43ae11276d3216f59a14f7a8.pdf
RPVgoRFYWHB	5694	TOWARD RELIABLE NEURAL SPECIFICATIONS	['formal verification', 'specification', 'neural network verfication', 'trustworthy AI', 'interpretability']	We propose a new family of specifications based on neural activation patterns and evaluate its effectiveness through both statistical analysis and formal verification.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|toward_reliable_neural_specifications	/pdf/357e27021046c78aebd00158fd74962b5fedb3dd.pdf
ObWiIiKihBf	5696	Boomerang: Local sampling on image manifolds using diffusion models	['Diffusion models', 'local sampling', 'image manifolds']		Generative models	anonymous|boomerang_local_sampling_on_image_manifolds_using_diffusion_models	/pdf/21cd33806d18eae612f35b631aaf4ea23d6f5278.pdf
Kpdewuy7RU6	5698	Reparameterization through Spatial Gradient Scaling	['reparameterization', 'deep learning', 'convolutional neural networks', 'neural architectures']		Deep Learning and representational learning	anonymous|reparameterization_through_spatial_gradient_scaling	/pdf/addcfdc69cd47808563b26a7fa35f17b4ac3263e.pdf
8IMz713Bxcq	5699	Towards Unsupervised Time Series Representation Learning: A Decomposition Perspective	['Time Series', 'Representation Learning', 'Contrastive Learning']	An unsupervised time series representation learning approach with the help of time series decomposition and contrastive learning	Deep Learning and representational learning	anonymous|towards_unsupervised_time_series_representation_learning_a_decomposition_perspective	/pdf/288a0d316b7fbf22e1a3e50358b67ab0273a1100.pdf
cWmtUcsYC3V	5700	Mind the Pool: Convolutional Neural Networks Can Overfit Input Size	['Convolutional Neural Networks', 'Pooling', 'Input Size', 'Overfitting']	Standard pooling arithmetic can cause CNNs to overfit the input size used during; an adjustment improves generalization to arbitrary sizes and robustness to translation shifts.	Deep Learning and representational learning	anonymous|mind_the_pool_convolutional_neural_networks_can_overfit_input_size	/pdf/9a422c25a44db332f12657fdd6657e67aabd07a5.pdf
Io0mSpdqnHJ	5701	Contextual Subspace Approximation with Neural Householder Transforms	['robotics', 'RL', 'representation learning']	We propose a method that trains a neural network to compute a context-dependent basis for high dimensional actuation commands. 	Deep Learning and representational learning	anonymous|contextual_subspace_approximation_with_neural_householder_transforms	/pdf/94f83085465ec0b9350b8a252c16ec412265ed83.pdf
HZf7UbpWHuA	5702	Diffusion-GAN: Training GANs with Diffusion	['deep generative models', 'diffusion models', 'data-efficient stable GAN training', 'adaptive data augmentation']		Generative models	anonymous|diffusiongan_training_gans_with_diffusion	/pdf/07e50a7f912235e41883a0a0d3301873ae5a6382.pdf
E2KNgQVJMiP	5703	UNICO: Efficient Unified Hardware-Software Co-Optimization For Deep Neural Networks	['Neural accelerator optimization', 'Hardware-Software co-design', 'Hardware optimization', 'HW design robustness', 'HW design generalizability', 'Successive halving', 'Holistic time-efficient search', 'Multi-objective Bayesian optimization', 'High-fidelity search', 'Tensor computation']	UNICO is a fast and high-fidelity neural accelerator HW-SW co-search solution that can find high-quality HW configurations that are generalizable to unseen DNN applications at the time of co-search.	General Machine Learning (ie none of the above)	anonymous|unico_efficient_unified_hardwaresoftware_cooptimization_for_deep_neural_networks	/pdf/e986e241fd52c9f776d23918f3f0bddef7f52abb.pdf
nQtcJ24_45K	5704	MILE: Memory-Interactive Learning Engine for Solving Mathematical Problems	['mathematical reasoning', 'symbolic reasoning', 'neural networks with memory']	A new learning framework interacting with memory embeddings for solving mathematical problems	Deep Learning and representational learning	anonymous|mile_memoryinteractive_learning_engine_for_solving_mathematical_problems	/pdf/7850fb4ba897194638a6ea5d854ca2899c3b2b70.pdf
fCO0_zsXk3j	5705	Boosting Adversarial Training with Masked Adaptive Ensemble	['Deep Learning Security', 'Adversarial Example Detection', 'Adversarial Training']	This paper boosts adversarial training by proposing a novel framework, including a detector and a classifier, making the DNN model withstand both dense attacks and sparse attacks and maintain high standard accuracy.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|boosting_adversarial_training_with_masked_adaptive_ensemble	/pdf/e859805a821a58192c61c0d40ef8d9237c73ed8d.pdf
OE4uriQtuDJ	5706	Multi-View Masked Autoencoders for Visual Control	['visual control', 'masked autoencoder', 'representation learning', 'world model']	We present a framework for multi-view representation learning via masked view reconstruction.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multiview_masked_autoencoders_for_visual_control	/pdf/80587f9be40962223bd522fba9ebbd747c821491.pdf
gU5sJ6ZggcX	5707	Linear Mode Connectivity of Deep Neural Networks via Permutation Invariance and Renormalization	['Permutation', 'Invariance', 'Mode Connectivity', 'Barrier', 'Loss landscape', 'Deep Learning']	In this paper we empirically investigate the conjecture from Entezari et al. 2021 which states that if permutation invariance is taken into account, then there should be no  barrier in the linear interpolation between SGD solutions.	Deep Learning and representational learning	anonymous|linear_mode_connectivity_of_deep_neural_networks_via_permutation_invariance_and_renormalization	/pdf/ff5ca9ab94729e14cbf63581376feedf3d0bcdf8.pdf
RlxNpChToM_	5708	A Picture of the Space of Typical Learning Tasks	['Information Geometry', 'Space of learning tasks']	We develop a technique to analyze the learned representation on a task, and its relationship to other tasks. We identify several surprising phenomena, e.g., the manifold of probabilistic models learned on different tasks is low-dimensional.	Deep Learning and representational learning	anonymous|a_picture_of_the_space_of_typical_learning_tasks	/pdf/15af840967875aa7841e10f0fe09ec1a9e5c44ca.pdf
us3brYx_ZBZ	5709	Pretraining One Language Model for All With the Text-To-Text Framework Using Model-Generated Signals	['natural language understanding', 'natural language generation', 'sequence-to-sequence', 'language models', 'language pretraining', 'prompting', 'zero-shot prompting']	Improve the performance of encoder-decoder language models (like T5) in unifying NLP tasks by pretraining with ELECTRA-style model-generated signals.	Unsupervised and Self-supervised learning	anonymous|pretraining_one_language_model_for_all_with_the_texttotext_framework_using_modelgenerated_signals	/pdf/77af9a1ec13629e6bc6327eef92a0bdcfdd925bd.pdf
D1Sawu2y1QG	5710	TILDE-Q: a Transformation Invariant Loss Function for Time-Series Forecasting	['Time-Series Forecasting', 'Deep Learning', 'Loss functions', 'Time-series similarity']	We designed a novel, lightweight, and shape-aware loss function for time-series forecasting.	Deep Learning and representational learning	anonymous|tildeq_a_transformation_invariant_loss_function_for_timeseries_forecasting	/pdf/efe9a7488cc4b4db9d42901b9655e841d4ce4fc2.pdf
QcA9iGaLpH4	5712	What do large networks memorize?	['memorization', 'overparameterization', 'example difficulty']	Increasing model size may increase memorisation of certain training samples, while distillation inhibits memorisation	Deep Learning and representational learning	anonymous|what_do_large_networks_memorize	/pdf/b9b62ca1ac601bdd04b5e9a3d7a19c3e472afabb.pdf
6axIMJA7ME3	5713	Compositional Task Representations for Large Language Models	[]		Deep Learning and representational learning	anonymous|compositional_task_representations_for_large_language_models	/pdf/ba97606dee8f357f26fda40a2112fb118aa73c12.pdf
38m4h8HcNRL	5714	Federated Neural Bandits	['neural contextual bandits', 'federated bandits']	We introduce federated neural-UCB, which uses a weighted combination of two UCBs that respectively, (a) accelerates exploration using observations from other agents and (b) improves reward prediction using a neural network with aggregated parameters.	General Machine Learning (ie none of the above)	anonymous|federated_neural_bandits	/pdf/836b3f76629ad0a431aa69344bc9531831f0d8ab.pdf
-ng-FXFlzgK	5716	Neural Image-based Avatars: Generalizable Radiance Fields for Human Avatar Modeling	['Generalizable human radiance fields', 'Human performance capture', 'Human NeRF', 'Neural radiance fields']		Applications (eg, speech processing, computer vision, NLP)	anonymous|neural_imagebased_avatars_generalizable_radiance_fields_for_human_avatar_modeling	/pdf/174f281d304435fd09d483934850c8bc1fdced15.pdf
VPCi3STZcaO	5717	CodeT5Mix: A Pretrained Mixture of Encoder-decoder Transformers for Code Understanding and Generation	['Language model pretraining', 'multimodal learning', 'code understanding and generation']	We propose a new pretrained mixture of encoder-decoder Transformers for code and achieve new SoTA results on a wide range of code understanding like code retrieval and generation tasks such as code synthesis and math programming.	Deep Learning and representational learning	anonymous|codet5mix_a_pretrained_mixture_of_encoderdecoder_transformers_for_code_understanding_and_generation	/pdf/48670f0e75eb1ed1a9df214ae781c7db000756cc.pdf
JQc2VowqCzz	5720	Interaction-Based Disentanglement of Entities for Object-Centric World Models	['object-centric', 'object-oriented', 'world models', 'self-supervised learning', 'probabilistic deep learning', 'structured models', 'video prediction', 'physics prediction', 'planning', 'variational autoencoders', 'model-based reinforcement learning', 'VAEs', 'unsupervised']	We present a structured, action-conditioned probabilistic model that learns to disentangle object representations based on interactions and demonstrate its ability to solve downstream tasks.	Generative models	anonymous|interactionbased_disentanglement_of_entities_for_objectcentric_world_models	/pdf/3acfcc510d3131323e125ebf5379cc1dea09921d.pdf
c9QTkDGJ_cB	5721	Tight Non-asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm	['non-asymptotic inference', 'uncertainty quantification', 'concentration inequality', 'multi-armed bandit']	Tight Non-asymptotic Inference	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|tight_nonasymptotic_inference_via_subgaussian_intrinsic_moment_norm	/pdf/aabcb81a2671fd9a93d44221c2afb0e2fd476752.pdf
1yclzf1DWsf	5723	Open-Set 3D Detection via Image-level Class and Debiased Cross-modal Contrastive Learning	['open vocabulary', '3d detection', 'contrastive learning']	We propose an open-set 3D detection method that detects unseen categories without corresponding 3D labels	Deep Learning and representational learning	anonymous|openset_3d_detection_via_imagelevel_class_and_debiased_crossmodal_contrastive_learning	/pdf/92e01cccbd461c758d03c23e609fde2ef62e430b.pdf
Yp_dRGS-TlC	5724	Iterative Task-adaptive Pretraining for Unsupervised Word Alignment	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|iterative_taskadaptive_pretraining_for_unsupervised_word_alignment	/pdf/07819aedb45bd8e0e46ae42b36fadb34a475c6d9.pdf
NUl0ylt7SM	5728	Simple Emergent Action Representations from Multi-Task Policy Training	['action representation', 'reinforcement learning', 'representation learning']	We discover emergent action representations from multi-task training and further use them to perform task generalization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|simple_emergent_action_representations_from_multitask_policy_training	/pdf/a3fdbccf2844e272f20de7b267b6fb1fc1ef258f.pdf
YfUICnZMwk7	5729	Weighted Clock Logic Point Process	['Multivariate event data', 'Neuro-symbolic models', 'Temporal point process', 'Propositional logic']	A novel neuro-symbolic framework for modeling temporal point processes with interpretability and high computation efficiency.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|weighted_clock_logic_point_process	/pdf/99e4a3787c410db0805c99d3b4a4a2980f427519.pdf
4K2SRejNGEI	5730	Boosting Drug-Target Affinity Prediction from Nearest Neighbors	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|boosting_drugtarget_affinity_prediction_from_nearest_neighbors	/pdf/c08896dfcac883d76afdce589528110a21d14859.pdf
HN0ehX-ov5Q	5732	A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel	['neural tangent kernels', 'deep learning theory']	A fast and provable approximation to the empirical Neural Tangent Kernel	Deep Learning and representational learning	anonymous|a_fast_wellfounded_approximation_to_the_empirical_neural_tangent_kernel	/pdf/c147800c8c81e2d0f2f18c2288dd6e05dca55ab6.pdf
2G-vUJ7XcSB	5733	On the Power of Pre-training for Generalization in RL: Provable Benefits and Hardness	['Reinforcement Learning', 'Generalization', 'Learning Theory']	A theoretical research on how much pre-training in reinforcement learning can help improve performance in target environment.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|on_the_power_of_pretraining_for_generalization_in_rl_provable_benefits_and_hardness	/pdf/9f5a8f1cf8a2d693b384041ca86c28afea4d6b8c.pdf
rB3zRN0lBYr	5734	Memorization Capacity of Neural Networks with Conditional Computation	['Memorization capacity', 'conditional computation.']	"In classical ""unconditional"" ReLU nets, one needs $O(\sqrt{n})$ arithmetic operations to recall any one of $n$ stored patterns. Conditional computation reduces this to $O(\log n)$ and this is the best possible. "	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|memorization_capacity_of_neural_networks_with_conditional_computation	/pdf/63e0a86c5475b4dac62085f10541c0bda52d788d.pdf
bRwBpKrNzF7	5735	Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games	['zero-sum Markov game', 'entropy regularization', 'policy optimization', 'global convergence', 'multiplicative updates']	We achieve better last-iterate convergence result of policy optimization for two-player zero-sum Markov games, with single-loop and symmetric update rules.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|faster_lastiterate_convergence_of_policy_optimization_in_zerosum_markov_games	/pdf/60631f3e562e3caf1cd193c3a97894a9505b8eca.pdf
vl9TIwbQ_jg	5737	Many-Body Approximation for Tensors	['Tensor decomposition', 'Energy based model', 'Tensor networks']	We formulate rank-free tensor decomposition focusing on interactions between tensor modes. We also illustrate the relationship between our model and existing low-rank approximation models using tensor networks.	General Machine Learning (ie none of the above)	anonymous|manybody_approximation_for_tensors	/pdf/97d19de8602462e835856837e9f90f400883fc26.pdf
s0ceCGfcIKb	5738	How Useful are Gradients for OOD Detection Really?	[]		Deep Learning and representational learning	anonymous|how_useful_are_gradients_for_ood_detection_really	/pdf/56811e308388aeabf63b727d1ddd731e1e14e0bd.pdf
ZMO7nETTWg9	5740	Learning Deep Operator Networks: The Benefits of Over-Parameterization	['Deep Operator Networks', 'Optimization', 'Neural Tangent Kernel']	We show that stochastic gradient descent converges to the global minimum for a DeepONet model.	Optimization (eg, convex and non-convex optimization)	anonymous|learning_deep_operator_networks_the_benefits_of_overparameterization	/pdf/c836f9270ef28c356157bc2bf9be411ba698ed5c.pdf
FZdJQgy05rz	5741	Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification	['Bayes error', 'best achievable error', 'irreducible error']	A simple and direct Bayes error estimator that just takes the mean of the labels that show uncertainty of the classes.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|is_the_performance_of_my_deep_network_too_good_to_be_true_a_direct_approach_to_estimating_the_bayes_error_in_binary_classification	/pdf/0102db1ca18ab0398cbaf8068894b5c85870e309.pdf
XYTwCOoKkLY	5742	Towards Out-of-Distribution Adversarial Robustness	['adversarial', 'robustness', 'REx', 'OOD']	We use the out-of-distribution generalisation approach of Risk Extrapolation (REx) to obtain superior robustness against multiple adversarial attacks, which generalises to attacks not seen during training.	Deep Learning and representational learning	anonymous|towards_outofdistribution_adversarial_robustness	/pdf/2a7f38c1620c09e4638d8762beb106d14b8cbd55.pdf
Y2E5-_HL0DV	5743	One cannot stand for everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems	['User simulators', 'Task-oriented Dialogue Systems.']	We propose to leverage multiple user simulators simultaneously to optimize ToD systems, leading to a framework called MUST.	Applications (eg, speech processing, computer vision, NLP)	anonymous|one_cannot_stand_for_everyone_leveraging_multiple_user_simulators_to_train_taskoriented_dialogue_systems	/pdf/96505880a324c3a81ec64118a6a852e58ad12204.pdf
SJjvXfape5U	5745	Sufficient Subgraph Embedding Memory for Continual Graph Representation Learning	['Graph', 'Class-incremental learning', 'continual learning', 'network']		Deep Learning and representational learning	anonymous|sufficient_subgraph_embedding_memory_for_continual_graph_representation_learning	/pdf/ea1db70714874d26f7932619f07bea08e01ba0ec.pdf
wtQxtWC9bra	5750	Comparing Human and Machine Bias in Face Recognition	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|comparing_human_and_machine_bias_in_face_recognition	/pdf/81068839ac1550220b3eb37447fae0a7d888abc8.pdf
Z63RvyAZ2Vh	5752	UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|unikgqa_unified_retrieval_and_reasoning_for_solving_multihop_question_answering_over_knowledge_graph	/pdf/ab18bb2bee45ad23b65c181c22d8c7ba31fd793e.pdf
R0Xxvr_X3ZA	5753	A Study of Causal Confusion in Preference-Based Reward Learning	['reward learning', 'robustness', 'preference-based learning']	We identify and analyze important factors that influence causal confusion when learning rewards from human preference labels.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|a_study_of_causal_confusion_in_preferencebased_reward_learning	/pdf/6aa3a80c360d5fef488aa674904a8025f3704d25.pdf
V7CYzdruWdm	5755	Bias Propagation in Federated Learning	['Fairness', 'Algorithmic Bias', 'Federated Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|bias_propagation_in_federated_learning	/pdf/243421d637eb0f81b38e3c856df9282e05260d7c.pdf
VoplHXsPKLE	5761	LUNA: Language as Continuing Anchors for Referring Expression Comprehension	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|luna_language_as_continuing_anchors_for_referring_expression_comprehension	/pdf/b232e9ece187ddb1661ff9f741a48df5c6028e34.pdf
u-RuvyDYqCM	5763	The In-Sample Softmax for Offline Reinforcement Learning	['Offline Reinforcement Learning']	A novel Bellman operator that avoids bootstrapping on out-of-sample actions. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_insample_softmax_for_offline_reinforcement_learning	/pdf/10bb82477fd59621f675966dfea62379734f3499.pdf
YvrAyFZq0ID	5765	Long Term Fairness via Performative Distributionally Robust Optimization	['fairness', 'distributionally robust optimization', 'performative prediction', 'distribution shift']	We develop a model for long-term fairness by considering a distributionally robust optimization objective in the performative prediction framework.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|long_term_fairness_via_performative_distributionally_robust_optimization	/pdf/e279f9f1283f8cd1bf884c5a73360792d16d4eb5.pdf
SnBDX5k-KuJ	5770	Solving Continual Learning via Problem Decomposition	['Continual learning', 'lifelong learning']		Deep Learning and representational learning	anonymous|solving_continual_learning_via_problem_decomposition	/pdf/1121a6b561817cc464359329bd3cd55b2c082851.pdf
5H1MT1RuWP4	5771	TG-Gen: A Deep Generative Model Framework for Temporal Graphs	['graph neural networks', 'generative models', 'temporal graphs']	We propose, TG-Gen, a generic framework for generating synthetic temporal graph data. 	Generative models	anonymous|tggen_a_deep_generative_model_framework_for_temporal_graphs	/pdf/6627c0f79c7055861985f6e2e7f8286f7bd38213.pdf
cOOQruYU7Bh	5772	A Computationally Efficient Sparsified Online Newton Method	['Optimization', 'Second order methods']		Optimization (eg, convex and non-convex optimization)	anonymous|a_computationally_efficient_sparsified_online_newton_method	/pdf/692771e70ac8d88d9b78434e932dec3042bfa072.pdf
QK1R-vPGsop	5773	Robust Generative Flows on Reliable Image Reconstruction without Training Data	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|robust_generative_flows_on_reliable_image_reconstruction_without_training_data	/pdf/d9567f7f71dd2b761a46e53d0e6f19722863fa7e.pdf
gKKUZ4fTEqh	5774	Finding Private Bugs: Debugging Implementations of Differentially Private Stochastic Gradient Descent 	['DP', 'DP-SGD', 'debugging', 'model distance']	We proposed an easy method to detect common implementation errors in DP-SGD for practitioners.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|finding_private_bugs_debugging_implementations_of_differentially_private_stochastic_gradient_descent	/pdf/3b14cb7db5f3e0ba7a116e24c63b3166f5e6b25c.pdf
Rg1LG7wtd2D	5775	Offline Reinforcement Learning from Heteroskedastic Data Via Support Constraints	['offline RL', 'support constraints', 'heteroskedastic data']	We show that conventional distributional constraint RL algorithms are need with heteroskedatic datasets. We propose an offline RL method to handle such settings.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_reinforcement_learning_from_heteroskedastic_data_via_support_constraints	/pdf/f0080c77db3bcc250ad216aa5657ac9e60b4a585.pdf
8mQSpCL36Lg	5776	Neural Autoregressive Refinement for Self-Supervised Outlier Detection beyond Images	[]		General Machine Learning (ie none of the above)	anonymous|neural_autoregressive_refinement_for_selfsupervised_outlier_detection_beyond_images	/pdf/8672b09fc4cd9fe2b02f6edb4d1e06fb80d65b5b.pdf
nJ3Vx78Nf7p	5778	Neural Bregman Divergences for Distance Learning	['metric learning', 'Bregman divergences', 'distance learning', 'embedding']	We develop the first effective deep learning tooling for learning arbitrary Bregman divergences	Deep Learning and representational learning	anonymous|neural_bregman_divergences_for_distance_learning	/pdf/3fa62dd2af40996df03195eba4366d8fa53d8732.pdf
Bvnjqe3ZroD	5780	Principal Trade-off Analysis	['Learning theory', 'Representation Learning', 'algorithmic game theory', 'Functional form games', 'matrix decomposition']	A decomposition method that represents a game as a sum of planar embeddings 	Deep Learning and representational learning	anonymous|principal_tradeoff_analysis	/pdf/4b6c91397d3a22289d0f4f1f4e74d0515671b8df.pdf
SNONkz5zEUF	5781	Convergence Analysis of Split Learning on Non-IID Data	['Federated Learning', 'Split Leanring', 'Convergence analysis']	Convergence Analysis of Split Learning on Non-IID Data	Deep Learning and representational learning	anonymous|convergence_analysis_of_split_learning_on_noniid_data	/pdf/58cf358104466e5481241fe20b73ba017865b036.pdf
lhPLT5gnBrH	5782	NEURAL HAMILTONIAN FLOWS IN GRAPH NEURAL NETWORKS	[]		General Machine Learning (ie none of the above)	anonymous|neural_hamiltonian_flows_in_graph_neural_networks	/pdf/b06df6d7ef14141a4f36ed635a12c52e043413e3.pdf
ZDpSoddiLRR	5783	Diffusion-based point cloud generation with smoothness constraints	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|diffusionbased_point_cloud_generation_with_smoothness_constraints	/pdf/5eee09569d951821816410a4fdb97b8947f2e20a.pdf
wwHOYTpfRqH	5784	ACE-EM: Boosted ab initio Cryo-EM 3D Reconstruction with Asymmetric Complementary Autoencoder	['autoencoder', 'electron microscopy', 'cryo-EM', '3D reconstruction', 'pose inference', 'asymmetric complementary autoencoder']	3D cryo-EM reconstruction with ACE-EM	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|aceem_boosted_ab_initio_cryoem_3d_reconstruction_with_asymmetric_complementary_autoencoder	/pdf/224c304e48c35a090f85117dbe981fdbfe028445.pdf
2RjnzZqax1J	5785	Persistence-based Contrastive Learning with Graph Neural Recurrent Networks for Time-series Forecasting	['Spatio-temporal forecasting', 'graph neural network', 'topological data analysis', 'contrastive learning']		Deep Learning and representational learning	anonymous|persistencebased_contrastive_learning_with_graph_neural_recurrent_networks_for_timeseries_forecasting	/pdf/898cc9333a84e567241fa5e90224b599bfef0d12.pdf
gcD2UtCGMc2	5786	Reproducible Bandits	['Interactive Learning', 'Reproducible Learning', 'Bandit Algorithms']	We provide a definition of reproducibility in the context of stochastic bandit problems and we develop algorithms with low regret in various environments.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|reproducible_bandits	/pdf/833aef030bdb5dcf0b1e2fff4222a90475407207.pdf
5vM51iamNeL	5787	Augmentation Component Analysis: Modeling Similarity via the Augmentation Overlaps	[]		Unsupervised and Self-supervised learning	anonymous|augmentation_component_analysis_modeling_similarity_via_the_augmentation_overlaps	/pdf/bb0cd9fb045fa58b2ad1411f0b9c4895421273b6.pdf
sdlplaOsLdw	5789	NOVEL FEATURE REPRESENTATION STRATEGIES FOR TIME SERIES FORECASTING WITH PREDICTED FUTURE COVARIATES	['time series forecasting', 'future covariates', 'shifting', 'padding', 'periodicity', 'deep learning']	We propose two novel feature representation strategies for time series forecasting with predicted future covariates.	Deep Learning and representational learning	anonymous|novel_feature_representation_strategies_for_time_series_forecasting_with_predicted_future_covariates	/pdf/6ff14d56f7dc40f18c89e2f662622ac68aef3081.pdf
NUU2tFxUjRa	5790	Consistent Data Distribution Sampling for Large-scale Retrieval	['Retrieval', 'Neural Networks', 'Deep Learning', 'Recommender Systems', 'Information Systems']	A novel negative sampling strategy to tackle training-inference inconsistency of data distribution for large-scale retrieval.	Deep Learning and representational learning	anonymous|consistent_data_distribution_sampling_for_largescale_retrieval	/pdf/4c71c197c3b93689c5228bc1d2598c9be4cc4fe3.pdf
r0LQFDOwfbU	5791	Similarity-Based Cooperation	['multi-agent reinforcement learning', 'cooperative AI', 'program equilibrium']	If ML agents observe how similar they are to each other, they can cooperate in the one-shot Prisoner's Dilemma.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|similaritybased_cooperation	/pdf/d9ad1b9ac5d753b84c98c1ce080381003fa27768.pdf
i9UlAr1T_xl	5792	SmartFRZ: An Efficient Training Framework using Attention-Based Layer Freezing	[]		Deep Learning and representational learning	anonymous|smartfrz_an_efficient_training_framework_using_attentionbased_layer_freezing	/pdf/b441b02c3d664f0e907bb92097838e8f0c540cb9.pdf
tuE-MnjN7DV	5793	What Do We Maximize in Self-Supervised Learning And Why Does Generalization Emerge?	['Self Supervised Learning', 'Neural Networks', 'Information Theory', 'Generalization Bounds']	Analyzing self-supervised learning from an information-theoretic perspective	Unsupervised and Self-supervised learning	anonymous|what_do_we_maximize_in_selfsupervised_learning_and_why_does_generalization_emerge	/pdf/a93e0bc5de0936e182608ae7f4b1015ce58fcf2d.pdf
sAOOeI878Ns	5797	Characterizing intrinsic compositionality in transformers with Tree Projections	['Transformers', 'Unsupervised syntax', 'hierarchical computation', 'compositionality']	We provide a method to functionally project a transformer into the space of tree structured models and use it to uncover intrinsic compositionality of transformers trained on language data.	Applications (eg, speech processing, computer vision, NLP)	anonymous|characterizing_intrinsic_compositionality_in_transformers_with_tree_projections	/pdf/9e5f08c8d4a8b1ef2031acf8266f02ec3640c200.pdf
z70d8UBFDKF	5798	Actor-Critic Alignment for Offline-to-Online Reinforcement Learning	['Offline Reinforcement Learning', 'Offline-to-Online']	We propose a new actor-critic alignment method that allows safe offline-to-online reinforcement learning and achieves strong empirical performance.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|actorcritic_alignment_for_offlinetoonline_reinforcement_learning	/pdf/d1e4ae60d55afca4fb75b5d2b941e96f982b408d.pdf
8tYRqb05pVn	5799	Linearly Mapping from Image to Text Space	['representation learning', 'deep learning', 'grounded language learning', 'nlp', 'dl', 'image', 'image captioning', 'language grounding', 'grounded']	Language models (LMs) can 'understand' images through a single tuned linear layer between a frozen image encoder and the LM input, showcasing the similarities in their conceptual representation spaces.	Deep Learning and representational learning	anonymous|linearly_mapping_from_image_to_text_space	/pdf/bdbf165b9b5e725e7534db14445d4ee2a2b56fe3.pdf
Gy8vD-zGQqH	5800	FoveaTer: Foveated Transformer for Image Classification	[]		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|foveater_foveated_transformer_for_image_classification	/pdf/6f76c641f67a704b812dddec1703246500e3ffe7.pdf
BgoOPulkznY	5803	Unsupervised 3D Scene Representation Learning via Movable Object Inference	['3D representation learning', 'self-supervised learning', 'object-discovery', 'neural rendering']	Unsupervised, category-agnostic, object-centric 3D representation learning for complex scenes 	Unsupervised and Self-supervised learning	anonymous|unsupervised_3d_scene_representation_learning_via_movable_object_inference	/pdf/502b01dc9beacb29daa00bd935a2e131ac50724a.pdf
aKcS3xojnwY	5804	GEASS: Neural causal feature selection for high-dimensional biological data	['Granger causality', 'feature selection', 'neural networks', 'single-cell genomics', 'spatial transcriptomics']	 We propose a new method (GEASS) to identify causally interacting features for high-dimensional spatial/temporal structured data, and apply it to several biological data to infer causal regulatory patterns.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|geass_neural_causal_feature_selection_for_highdimensional_biological_data	/pdf/0363e3267a3d1a5043853a39353441b2c8287042.pdf
4hhtHQLGDQO	5805	Automatic Data Augmentation via Invariance-Constrained Learning	['Automatic data augmentation', 'Invariance', 'Constrained Learning', 'Image classification']	Imposing Invariance Constraints to models enables learning Data augmentation policies that can improve generalization.	Deep Learning and representational learning	anonymous|automatic_data_augmentation_via_invarianceconstrained_learning	/pdf/3f568b6a88f073d7770e3964528e5e49664552f2.pdf
6doXHqwMayf	5809	Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods	['Deep learning theory', 'optimization', 'learning theory', 'excess risk']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|excess_risk_of_twolayer_relu_neural_networks_in_teacherstudent_settings_and_its_superiority_to_kernel_methods	/pdf/bfcc11266ad6982f1a7cfb595437ec0dd364885e.pdf
-3br92QL76O	5810	Neural Integral Equations	['integral equations', 'dynamical systems', 'non-local equations', 'self-attention', 'brain dynamics']	Neural Integral Equations are a novel method that allows to model non-local dynamics with complex spatio-temporal relations through neural networks	Deep Learning and representational learning	anonymous|neural_integral_equations	/pdf/2689f582f1d94c56ac79960768af4c4c22b2ce7c.pdf
BKuboEUJd8u	5812	Return Augmentation gives Supervised RL Temporal Compositionality	['reinforcement learning', 'offline reinforcement learning', 'decision transformer', 'behavioral cloning', 'dynamic programming', 'data augmentation']	We propose a new data augmentation algorithm that enables RL via supervised methods to extrapolate beyond the best performing trajectories in the offline dataset using bootstrapping.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|return_augmentation_gives_supervised_rl_temporal_compositionality	/pdf/54a9ce1852f5a90234cacc0f049453ec4ad744de.pdf
ZBMpG7fWwOP	5815	Game Theoretic Mixed Experts for Combinational Adversarial Machine Learning	['Adversarial Machine Learning', 'Security']		Applications (eg, speech processing, computer vision, NLP)	anonymous|game_theoretic_mixed_experts_for_combinational_adversarial_machine_learning	/pdf/3e71a339ded8488564441d24aa882e6c17808b69.pdf
ewYNygoJpa6	5816	State Decomposition for Model-free Partially observable Markov Decision Process	['POMDP', 'Reinforcement Learning', 'Decomposition', 'Shannon Entropy']	This paper proposes a novel theory of state decomposition in POMDP and a simple algorithm to estimate the gap between state and observation.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|state_decomposition_for_modelfree_partially_observable_markov_decision_process	/pdf/83121dc4946f39279d2840f08f59725f24c289b9.pdf
WBXbRs63oVu	5818	PINTO: Faithful Language Reasoning Using Prompted-Generated Rationales	['Commonsense reasoning', 'free-text rationale', 'rationale generation', 'faithful reasoning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|pinto_faithful_language_reasoning_using_promptedgenerated_rationales	/pdf/d05fa772ca603129cc782bc71fbb7704c939a3c0.pdf
GBU1mm8_WkV	5821	Semi-Autoregressive Energy Flows: Towards Determinant-Free Training of Normalizing Flows	[]		Generative models	anonymous|semiautoregressive_energy_flows_towards_determinantfree_training_of_normalizing_flows	/pdf/fd9ae6c34fd534c645dc41ade0100fc749ffa5d0.pdf
NDWl9qcUpvy	5822	Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward	['deep reinforcement learning', 'structured exploration']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_achievement_structure_for_structured_exploration_in_domains_with_sparse_reward	/pdf/56733075ddeb77a14fd89107f14be301b337df27.pdf
AqiB_Tqqc8z	5824	Kuiper: Moderated Asynchronous Federated Learning on Heterogeneous Mobile Devices with Non-IID Data	['Federated Learning', 'Edge devices', 'Non-IID', 'Video action recognition']	We develop a moderated asynchronous algorithm for training on a video action recognition task on embedded devices with mobile GPUs. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|kuiper_moderated_asynchronous_federated_learning_on_heterogeneous_mobile_devices_with_noniid_data	/pdf/ab91b8b2998974bc836566b6933898da5b5d6186.pdf
NxPQ3QOGTWl	5826	KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding	['natural language processing', 'long document understanding', 'knowledge graphs']		Applications (eg, speech processing, computer vision, NLP)	anonymous|kalm_knowledgeaware_integration_of_local_document_and_global_contexts_for_long_document_understanding	/pdf/e504fdbc90387642a175b32214354d570919c120.pdf
GVMwL15UrZO	5828	UNDERSTANDING HTML WITH LARGE LANGUAGE MODELS	['html understanding', 'web navigation', 'large language models', 'semantic classification', 'description generation']	Large language models are very effective at understanding HTML including navigating web pages, classifying elements, and generating descriptions of elements.	Applications (eg, speech processing, computer vision, NLP)	anonymous|understanding_html_with_large_language_models	/pdf/bc3877541a4dff7e823d346711ae425c2b7533b9.pdf
B4maZQLLW0_	5830	Stateful Active Facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|stateful_active_facilitator_coordination_and_environmental_heterogeneity_in_cooperative_multiagent_reinforcement_learning	/pdf/28eefff0ad4d163f557956c7daaed3f9e77e9652.pdf
GVWySHBD3Cl	5831	Estimating Treatment Effects using Neurosymbolic Program Synthesis	['Causal effect', 'treatment effect', 'neurosymbolic programming', 'domain specific language']	We estimate treatment effects/ causal effects using neurosymbolic program synthesis by designing a domain specific language 	Deep Learning and representational learning	anonymous|estimating_treatment_effects_using_neurosymbolic_program_synthesis	/pdf/7e8e90a51693e2335518984330227719b741d6a1.pdf
36g8Ept_CCj	5833	Learning Mixture Models with Simultaneous Data Partitioning and Parameter Estimation	['mixture models', 'resource constrained learning']	PRESTO learns a mixture models such that each model performs well on a data partition	General Machine Learning (ie none of the above)	anonymous|learning_mixture_models_with_simultaneous_data_partitioning_and_parameter_estimation	/pdf/44a6b16c3b124a781c8675fb5183a06f7f7fadb2.pdf
LQIjzPdDt3q	5834	The Role of Coverage in Online Reinforcement Learning	['reinforcement learning theory', 'online RL', 'offline RL', 'learnability', 'general function approximation']	This paper shows surprising connections between online and offline learnability, in particular, how coverage in offline RL enables exploration in online RL.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|the_role_of_coverage_in_online_reinforcement_learning	/pdf/cc13ad253ab63a0b056112f00e1b85fa22076fdb.pdf
YlGsTZODyjz	5835	The Tilted Variational Autoencoder: Improving Out-of-Distribution Detection	['Variational Autoencoder', 'OOD', 'Unsupervised']	A generalization of the Gaussian distribution improves the performance of out-of-distribution detection with variational autoencoders.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|the_tilted_variational_autoencoder_improving_outofdistribution_detection	/pdf/fe0b961cc25bc42e4cd3d86a1f1215770eac4f5c.pdf
CQsmMYmlP5T	5836	Git Re-Basin: Merging Models modulo Permutation Symmetries	[]		Deep Learning and representational learning	anonymous|git_rebasin_merging_models_modulo_permutation_symmetries	/pdf/c9a3f3c49c77c31f853f255bbeda12d678714331.pdf
XYUaprBSDjp	5837	Knowledge-Grounded Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|knowledgegrounded_reinforcement_learning	/pdf/cf0bcfe5bf2f140058bc94277e47d0e02b4750bb.pdf
SZYXyhE2c6f	5838	A Probabilistic Framework For Modular Continual Learning	['continual learning', 'modular', 'Bayesian networks', 'Bayesian optimisation']	We introduce a scalable modular continual learning algorithm that is capable of forward knowledge transfer across similar and dissimilar input domains.	General Machine Learning (ie none of the above)	anonymous|a_probabilistic_framework_for_modular_continual_learning	/pdf/01d3d75cefc36a89bf7ebc1b038b4bf5df0db866.pdf
sqPEs1wEizU	5841	Layer-wise Balanced Activation Mechanism	['activation', 'imbalanced activation', 'normalization', 'layer-wise balanced activation', 'layer-level activation', 'LayerAct']	Layer-wise Balanced Activation Mechanism	General Machine Learning (ie none of the above)	anonymous|layerwise_balanced_activation_mechanism	/pdf/49bdbbd66591f4d22e3ff09818a4bbe9ff17a791.pdf
Hcq7zGgcsOg	5845	Curriculum-inspired Training for Selective Neural Networks	['curriculum learning', 'selective classification']	We propose a curriculum-inspired method to train selective neural network models by leveraging example difficulty scores.	Deep Learning and representational learning	anonymous|curriculuminspired_training_for_selective_neural_networks	/pdf/7ad17376352dc9902024ce8bf899dda43eee6a59.pdf
MHgYMtHpKsC	5846	Learning Shareable Bases for Personalized Federated Image Classification	['Federated learning', 'Computer vision']		Deep Learning and representational learning	anonymous|learning_shareable_bases_for_personalized_federated_image_classification	/pdf/3244dc0f08bd0b6023e3ecb333fa980ca1c12178.pdf
3yEIFSMwKBC	5847	AutoMoE: Neural Architecture Search for Efficient Sparsely Activated Transformers	['Mixture-of-expert models', 'Neural architecture search', 'Efficiency']	AutoMoE: a flexible Neural Architecture Search framework to design efficient sparse models under latency constraints.	Applications (eg, speech processing, computer vision, NLP)	anonymous|automoe_neural_architecture_search_for_efficient_sparsely_activated_transformers	/pdf/ddf8a7e2d6960e94cc62efed90f55d7cdc0a691c.pdf
qYO0f9WnUup	5851	Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|dynamic_neural_network_is_all_you_need_understanding_the_robustness_of_dynamic_mechanisms_in_neural_networks	/pdf/7f3d1860bd1e4f005059a9adea0f85534890f366.pdf
4UbhxQIjeSH	5852	Text-Conditioned Graph Generation Using Discrete Graph Variational Autoencoders	[]		Generative models	anonymous|textconditioned_graph_generation_using_discrete_graph_variational_autoencoders	/pdf/e24bcccbcc7312e89616ca61d6a9a5cdc9d800fd.pdf
p6jsTidUkPx	5853	Quantile Risk Control: A Flexible Framework for Bounding the Probability of High-Loss Predictions	['distribution-free uncertainty quantification']	We propose a framework to rigorously and flexible control the quantiles of the loss distribution incurred by a predictor or set of predictors.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|quantile_risk_control_a_flexible_framework_for_bounding_the_probability_of_highloss_predictions	/pdf/e02f3a6c74e2924c88ef41b0a52457339d9c7f7e.pdf
0eTTKOOOQkV	5856	HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention	[]		Deep Learning and representational learning	anonymous|hiclip_contrastive_languageimage_pretraining_with_hierarchyaware_attention	/pdf/3abe4cd1c1efcc11de89486aef2688a0f18ed13c.pdf
JmkjrlVE-DG	5858	Over-Training with Mixup May Hurt Generalization	['Mixup', 'Generalization', 'Overfitting', 'Regularization']	We empirically discovered a U-shaped generalization curve of Mixup training.	Deep Learning and representational learning	anonymous|overtraining_with_mixup_may_hurt_generalization	/pdf/89fc45bb8746e3933c561d67c643783eda80eb16.pdf
Cj4aar5X65H	5859	Rewarding Episodic Visitation Discrepancy for Exploration in Reinforcement Learning	['reinforcement learning', 'exploration', 'intrinsic reward', 'computation-efficient']	The paper proposes a quantified and computation-efficient intrinsic reward method for improving exploration in reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|rewarding_episodic_visitation_discrepancy_for_exploration_in_reinforcement_learning	/pdf/78e11f36324f513c60e135eeb6b371f595223d1e.pdf
nN_nBVKAhhD	5861	Minimalistic Unsupervised Learning with the Sparse Manifold Transform	['Unsupervised Learning', 'Sparsity', 'Low-rank', 'Manifold learning', 'Spectral Embedding']	"We build a ""white-box"" unsupervised learning model with two parsimonious principles: sparsity and low-rankness, the model can be viewed as the simplest form of VICReg."	Unsupervised and Self-supervised learning	anonymous|minimalistic_unsupervised_learning_with_the_sparse_manifold_transform	/pdf/c29936267c43e8ed1f26a319aa67146e89cbcbb7.pdf
29V3AWjVAFi	5862	The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation	['Federated Learning', 'Representation Learning', 'Knowledge Distillation']		General Machine Learning (ie none of the above)	anonymous|the_best_of_both_worlds_accurate_global_and_personalized_models_through_federated_learning_with_datafree_hyperknowledge_distillation	/pdf/2aa28a709740431dd6cb20c12e9567450cacdb07.pdf
XFWLkEcLqDf	5865	Quasiconvex Shallow Neural Network	[]		Optimization (eg, convex and non-convex optimization)	anonymous|quasiconvex_shallow_neural_network	/pdf/430294781c3aef9047209022788c4ae9d517f5e9.pdf
afhc1a2x00V	5866	Who are playing the games?	['shapley values', 'model explainability']	"We show that one cannot get ""efficient"" Shapley values without correctly identifying the players (features) , and propose a solution to this conundrum"	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|who_are_playing_the_games	/pdf/de21f0e0f17088b7b53380a74a3b260e5e7d5758.pdf
yVqC6gCNf4d	5867	Simple initialization and parametrization of sinusoidal networks via their kernel bandwidth	['sinusoidal', 'periodic', 'neural tangent kernel', 'implicit models', 'physics informed']	We perform a theoretical analysis of a simplified sinusoidal network and use this to propose an informed initialization scheme.	Deep Learning and representational learning	anonymous|simple_initialization_and_parametrization_of_sinusoidal_networks_via_their_kernel_bandwidth	/pdf/f0e8fa8b08f444e5cfc3c90065cb00dd1f961f9e.pdf
TjxCJ1DK-dm	5869	Autoregressive Graph Network for Learning Multi-step Physics	['graph network', 'autoregressive model', 'physics simulation', 'forward model', 'inverse model']	An Autoregressive Graph Network (GN) that learns forward particle-based physics using inductive biases.	Deep Learning and representational learning	anonymous|autoregressive_graph_network_for_learning_multistep_physics	/pdf/89eac485ac015d3327eda379c14f1ab290a6d1e6.pdf
VZ5EaTI6dqa	5870	Scale-invariant Bayesian Neural Networks with Connectivity Tangent Kernel	[]		Deep Learning and representational learning	anonymous|scaleinvariant_bayesian_neural_networks_with_connectivity_tangent_kernel	/pdf/549204fbe4f83e0bcd12c5f2ea18c8aa4eb58bb2.pdf
fWWFv--P0xP	5871	On the Importance and Applicability of Pre-Training for Federated Learning	['federated learning', 'pre-training']		Deep Learning and representational learning	anonymous|on_the_importance_and_applicability_of_pretraining_for_federated_learning	/pdf/c12567fecc9f8c655ebe26693d233f2c65187496.pdf
cP2QVK-uygd	5874	On Representing Linear Programs by Graph Neural Networks	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_representing_linear_programs_by_graph_neural_networks	/pdf/19819c2deea06e2772195f1da93b452c5e973ffd.pdf
rieUBLynDqm	5875	Fighting Fire with Fire: Contrastive Debiasing without Bias-free Data via Generative Bias-transformation	['debiasing', 'contrastive learning', 'image-to-image translation']	In this paper, we propose Contrastive Debiasing via Generative Bias-transformation (CDvG) which is capable of operating without exploiting bias labels and bias-free samples explicitly.	Deep Learning and representational learning	anonymous|fighting_fire_with_fire_contrastive_debiasing_without_biasfree_data_via_generative_biastransformation	/pdf/7de97417e49b1635b87108dce0a5fcd4c335bfe0.pdf
Lb8ZnWW_In6	5877	LEARNING DYNAMIC ABSTRACT REPRESENTATIONS FOR SAMPLE-EFFICIENT REINFORCEMENT LEARNING	['Sequential Decision-Making', 'Reinforcement Learning', 'Learning Abstract Representations']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_dynamic_abstract_representations_for_sampleefficient_reinforcement_learning	/pdf/446bf1245c2869f0154fbf3b8f66e34057b9995e.pdf
4gc3MGZra1d	5879	On Representing Mixed-Integer Linear Programs by Graph Neural Networks	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_representing_mixedinteger_linear_programs_by_graph_neural_networks	/pdf/01e742d4b89ebbfd63cd751689aef2d7e564169d.pdf
Kot3IIgXGbb	5880	Learning Globally Smooth Functions on Manifolds	['Lipschitz functions', 'Manifolds', 'Machine Learning']	We present a constrained learning approach to learn smooth functions over manifold data. 	Optimization (eg, convex and non-convex optimization)	anonymous|learning_globally_smooth_functions_on_manifolds	/pdf/4f0906c9b033f20f26c3b03dffc6c950a0c3e162.pdf
eLxADkHrBcR	5882	Fully Online Meta Learning	['Meta learning', 'Online learning']	We propose a Fully Online Meta-Learning (FOML) algorithm, which does not require any ground truth knowledge about the task boundaries and stays learn fully online.	Deep Learning and representational learning	anonymous|fully_online_meta_learning	/pdf/5b8e783be2510637bbb9467416b03eee0ee78916.pdf
2rzFscFzJ0B	5883	Corruption-free Single-view Self-supervised Learning on Graphs	[]		Unsupervised and Self-supervised learning	anonymous|corruptionfree_singleview_selfsupervised_learning_on_graphs	/pdf/824a68811eb63eed48fc92d9554b2a75c3154613.pdf
YKoRmMhcpWk	5884	VQR: Automated Software Vulnerability Repair Through Vulnerability Queries	['Automated Vulnerability Repair', 'Cross-Attention Mechanism', 'Transformers-based Models']		Deep Learning and representational learning	anonymous|vqr_automated_software_vulnerability_repair_through_vulnerability_queries	/pdf/61d014bafeec736e1f10d852f03c9c2f8716eeab.pdf
d1oQqDvB7GQ	5886	Raisin: Residual Algorithms for Versatile Offline Reinforcement Learning	['reinforcement learning', 'offline RL', 'residual algorithms', 'residual gradient']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|raisin_residual_algorithms_for_versatile_offline_reinforcement_learning	/pdf/6a0b15ae77cf6f8204e03eb423f380d7d81e0198.pdf
cs3n00FQ7OI	5887	Training Neural Networks with Low-Precision Model Memory	['memory efficient deep learning', 'stochastic gradient descent', 'quantization']	We propose memory efficient optimizers for deep learning which keep model parameters, momentum and gradient accumulators in low numerical precision.	Deep Learning and representational learning	anonymous|training_neural_networks_with_lowprecision_model_memory	/pdf/190e8764b44eea3d765def5c3a01de1b86f0c681.pdf
7jk5gWjC18M	5890	Chasing All-Round Graph Representation Robustness: Model, Training, and Optimization	['Graph neural networks', 'Mixture of experts', 'Graph adversarial learning']	We identify a fundamental issue in graph adversarial learning and then propose a novel method to enlarge the model capacity and enrich the representation diversity of adversarial samples.	Deep Learning and representational learning	anonymous|chasing_allround_graph_representation_robustness_model_training_and_optimization	/pdf/d685b719fc0e8cca6cbf3418cd1d50927350ab25.pdf
I29Kt0RwChs	5893	Robust Algorithms on Adaptive Inputs from Bounded Adversaries	['streaming algorithms', 'adversarial robustness', 'sketching', 'kernel density estimation']	We give algorithms robust to adaptive input from adversaries with bounded capabilities and a general framework for achieving it.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|robust_algorithms_on_adaptive_inputs_from_bounded_adversaries	/pdf/4cd1c3d10745938ab872ac5e7e243be606967a88.pdf
dkLQ9dl4vcY	5894	Probe Into Multi-agent Adversarial Reinforcement Learning through Mean-Field Optimal Control	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|probe_into_multiagent_adversarial_reinforcement_learning_through_meanfield_optimal_control	/pdf/b3dfbdf997d92b49a91deb3d7d816ff4734296ed.pdf
GKpwIa9wgwR	5898	Efficient Data Subset Selection to Generalize Training Across Models: Transductive and Inductive Networks	['Data Subset Selection', 'Efficient Learning']	Trainable non-adaptive data subset selection that generalizes across different model training	General Machine Learning (ie none of the above)	anonymous|efficient_data_subset_selection_to_generalize_training_across_models_transductive_and_inductive_networks	/pdf/9884667befec8b416739e4fe76c43637f3f85536.pdf
gTph9AD_gx1	5899	Pseudometric guided online query and update for offline reinforcement learning	['Offline Reinforcement Learning', 'online query', 'optimal query', 'policy update']	We propose to utilize pseudometric to guide the online queries with optimality and efficient policy update.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|pseudometric_guided_online_query_and_update_for_offline_reinforcement_learning	/pdf/403d82243218990f9910cbd7d55b742615495054.pdf
RHWAEeEYmwW	5900	Conservative Exploration in Linear MDPs under Episode-wise Constraints	['Conservative Exploration', 'Sample Complexity', 'Linear MDP', 'Offline and Online RL']	We studied conservative exploration with offline dataset during online learning for Linear MDPs and prove that the regret of our algorithm matches the constraint-free counterpart.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|conservative_exploration_in_linear_mdps_under_episodewise_constraints	/pdf/50c93ec3474eb1f04a6b166b9e4a2b1b36f78bf0.pdf
oGDKSt9JrZi	5901	Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks	['reinforcement learning', 'representation learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|protovalue_networks_scaling_representation_learning_with_auxiliary_tasks	/pdf/f8810ffb8c14e578ae8ea344a56b3d09a2a86de5.pdf
uFC0HBseZxK	5902	An Integrated Multi-Label Multi-Modal Framework in Deep Metric Learning	['deep metric learning', 'healthcare', 'multimodal', 'multilabel']		Deep Learning and representational learning	anonymous|an_integrated_multilabel_multimodal_framework_in_deep_metric_learning	/pdf/054db0f68268d158f0a6b331ad5c16fda6413db5.pdf
PbXfwJEyKXT	5903	Do We Really Need Graph Models for Skeleton-Based Action Recognition? A Topology-Agnostic Approach with Fully-Connected Networks	['skeleton-based', 'action recognition', 'topology-agnostic', 'fully-connected']		Deep Learning and representational learning	anonymous|do_we_really_need_graph_models_for_skeletonbased_action_recognition_a_topologyagnostic_approach_with_fullyconnected_networks	/pdf/5fcd3182baa85e8d89659afe10a115b6aea2f61d.pdf
6jfbOWzWTcE	5904	Offline Reinforcement Learning with Differentiable Function Approximation is Provably Efficient	['Reinforcement Learning Theory']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|offline_reinforcement_learning_with_differentiable_function_approximation_is_provably_efficient	/pdf/bd06abdca77662baae2fda97b5bdac2d5fdacd9d.pdf
vaxnu-Utr4l	5905	WikiWhy: Answering and Explaining Cause-and-Effect Questions	['NLP', 'Question Answering', 'LLM', 'Dataset', 'Explanation']	"We propose WikiWhy, a dataset containing 9000+ ""why"" question-answer-rationale triplets to assess Large Language Models' cause-effect reasoning capability."	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|wikiwhy_answering_and_explaining_causeandeffect_questions	/pdf/99864877e6c19238c1e626f4118dcb566b758f83.pdf
PoU_NgCStE5	5906	Limits of Algorithmic Stability for Distributional Generalization	['Distribution Shift', 'Robustness', 'Evaluation']	In this paper we empirically show that the more stable a learning algorithm is the more robust the resulting model is to covariate, label, and subpopulation shifts. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|limits_of_algorithmic_stability_for_distributional_generalization	/pdf/9f6b8615696585fcf5b0f12a8ef2f0a95fa29273.pdf
pRUW8BuTEFI	5909	MixBin: Towards Budgeted Binarization	['Budgeted Binarization', 'Model Compression', 'Efficient deep learning']	We present $\texttt{MixBin}$, an iterative search-based strategy that constructs B2NN through optimized mixing of the binary and full-precision components.	Deep Learning and representational learning	anonymous|mixbin_towards_budgeted_binarization	/pdf/d07b9e122a7fca599afd41fd6b8c24471c3f1a70.pdf
bhUPJnS2g0X	5912	Ask Me Anything: A simple strategy for prompting language models	['large language models', 'prompt-engineering', 'in-context learning']	We propose a prompting strategy based on aggregating the predictions of multiple prompts, which enables a 6B parameter model to exceed the few-shot performance of GPT3-175B on 15/20 popular benchmarks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|ask_me_anything_a_simple_strategy_for_prompting_language_models	/pdf/2cb19dced07c3f55ef5aef55fa8d81b7d92e4609.pdf
nGyWzq-703u	5913	GNN Domain Adaptation using Optimal Transport	['domain adaptation', 'graph neural network', 'optimal transport']	We analyze the  OOD generalization and consequent domain adaptation limits of Graph Convolution Networks. An optimal transport based DA method is proposed for consistent improvement with a better transferability metric.	Deep Learning and representational learning	anonymous|gnn_domain_adaptation_using_optimal_transport	/pdf/821ccd2f40ff9a1fefb9a4bd5d71deccf7525794.pdf
eZr_xEPesc7	5914	Nuisances via Negativa: Adjusting for Spurious Correlations via Data Augmentation	['spurious correlations', 'out of distribution generalization', 'shortcuts', 'bias mitigation', 'data augmentation']	Corrupt semantic features with data augmentations and use their output to build models robust to spurious correlations	Deep Learning and representational learning	anonymous|nuisances_via_negativa_adjusting_for_spurious_correlations_via_data_augmentation	/pdf/9fcee0acaccbfafd07b3907de321cb310b125bda.pdf
14-kr46GvP-	5916	Efficient Deep Reinforcement Learning Requires Regulating Statistical Overfitting	['Reinforcement Learning', 'Sample Efficient RL', 'Statistical Overfitting']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|efficient_deep_reinforcement_learning_requires_regulating_statistical_overfitting	/pdf/04964b111b44602b189d2dd4cfef5f966d1f4c69.pdf
xIWfWvKM7aQ	5917	TextShield: Beyond Successfully Detecting Adversarial Sentences in NLP	['Natural language processing', 'Adversarial defense', 'Adversarial attack', 'Text Classification']	A defense that extends adversarial detection paradigm in NLP	Applications (eg, speech processing, computer vision, NLP)	anonymous|textshield_beyond_successfully_detecting_adversarial_sentences_in_nlp	/pdf/7cc3254314d98f26f1fcad062e2d2c0a79fd347d.pdf
ctmLBs8lITa	5918	Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms	['Multivariate Timeseries Forecasting']	Designs of Adversarial Attacks and Defense Mechanisms for Multivariate Forecasting Models	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|robust_multivariate_timeseries_forecasting_adversarial_attacks_and_defense_mechanisms	/pdf/17e1da4d729bdd6e4c981dd93be56aa41a07f6b4.pdf
mWRngkvIki3	5919	Masked Distillation with Receptive Tokens	[]		Deep Learning and representational learning	anonymous|masked_distillation_with_receptive_tokens	/pdf/78a0d8147f69402430d9d3e5cf862dc9df3ba93b.pdf
doShL95X0hd	5922	On Making Graph Continual Learning Easy, Fool-Proof, and Extensive: a Benchmark Framework and Scenarios	['Graph Continual Learning', 'Continual Learning Benchmark Framework']	We present BEGIN, an easy-to-use, fool-proof, and extensive benchmark framework for graph continual learning	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|on_making_graph_continual_learning_easy_foolproof_and_extensive_a_benchmark_framework_and_scenarios	/pdf/57e80fbc6eae474f4fad204577d89d8c26c3cbbc.pdf
ynD_LAMwar2	5924	Reinforcement Logic Rule Learning for Temporal Point Processes 	['temporal point processes', 'explainable models', 'rule learning']	We aim to learn a set of temporal logic rules to explain the temporal point processes.  	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|reinforcement_logic_rule_learning_for_temporal_point_processes	/pdf/cd92375111e851beadbac42d81291a26f4be60ea.pdf
WGApODQvwRg	5925	Understanding the Covariance Structure of Convolutional Filters	['initialization', 'init', 'covariance', 'gaussian', 'convolutional neural network', 'convmixer', 'convnext', 'transfer learning', 'spatial mixing', 'computer vision', 'convolution']	If you initialize depthwise convolutional filters from the right multivariate Gaussian distribution, they work so well that you may not even have to train them; we provide such Gaussians in closed-form.	Deep Learning and representational learning	anonymous|understanding_the_covariance_structure_of_convolutional_filters	/pdf/9f66bd1ce65af318e646adf0b5d3053af788a89e.pdf
8RExG-EKC22	5926	Adaptive IMLE for Few-shot Image Synthesis	[]		Generative models	anonymous|adaptive_imle_for_fewshot_image_synthesis	/pdf/c6d6e716bccb1273530237879266ae1a197d8eb5.pdf
wIzVS-RJjCB	5928	VER: Learning Natural Language Representations for Verbalizing Entities and Relations	[]	We propose VER: A Unified Model for Verbalizing Entites and Relations.	Applications (eg, speech processing, computer vision, NLP)	anonymous|ver_learning_natural_language_representations_for_verbalizing_entities_and_relations	/pdf/cd6d582e63132e541cde959b890d348a927a33f1.pdf
JjCAdMUlu9v	5929	Auto-Encoding Goodness of Fit	[]		Generative models	anonymous|autoencoding_goodness_of_fit	/pdf/19059180c529a261c040f97077d4acbfb3e6e395.pdf
5lgD4vU-l24s	5935	Recursive Time Series Data Augmentation	['Time Series', 'Data augmentation', 'Representation Learning', 'Deep Learning', 'Reinforcement Learning']		Deep Learning and representational learning	anonymous|recursive_time_series_data_augmentation	/pdf/16fca91ff900eb061f4294177c40a5c7e3e8865c.pdf
vbRRydfyFc	5938	ADELT: Unsupervised Transpilation Between Deep Learning Frameworks	['Applications', 'Programming Languages', 'Deep Learning', 'Unsupervised Learning', 'Adversarial Training']	We propose Adversarial DEep Learning Transpiler (ADELT) for source-to-source transpilation between deep learning frameworks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|adelt_unsupervised_transpilation_between_deep_learning_frameworks	/pdf/59d2a741b8f5c8fadf2db0064fc73fe91927c1ec.pdf
OxBl7cSgo6_	5939	Heterogeneous-Agent Mirror Learning	['deep multi-agent reinforcement learning', 'multi-agent reinforcement learning theory']	A general theoretical framework for development of multi-agent reinforcement learning algorithms.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|heterogeneousagent_mirror_learning	/pdf/256ae8feff99e607347805abeb1e28bd2efb32dd.pdf
ZADNbI_3sbS	5940	Reinforcement Learning-Based Estimation for Partial Differential Equations	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|reinforcement_learningbased_estimation_for_partial_differential_equations	/pdf/ba5a1d9ea65790894f116ffd8241bde5b7892222.pdf
HumfPzF2yeI	5941	Learning Rewards and Skills to Follow Commands with a Data Efficient Visual-Audio Representation	['Robotics', 'Representation Learning', 'Reinforcement Learning']	We learn a representation to generate a reward function to train command-following robots with reinforcement learning	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_rewards_and_skills_to_follow_commands_with_a_data_efficient_visualaudio_representation	/pdf/8a238d59798514327597e6354037256a061a926f.pdf
q_tgo-hvgPd	5943	Covariance Matrix Adaptation MAP-Annealing	['quality diversity optimization', 'derivative-free optimization', 'latent space exploration']	We propose a new variant of the quality diversity algorithm CMA-ME that addresses three major limitations affecting performance and robustness.	Optimization (eg, convex and non-convex optimization)	anonymous|covariance_matrix_adaptation_mapannealing	/pdf/9dda71d1ec308c6f2758d0d572907a277576b765.pdf
5C5ZcWvtI7S	5947	Machine Learning Force Fields with Data Cost Aware Training	['Machine Learning Force Fields', 'Data-Cost Aware Training', 'AI for Science']	We propose ASTEROID, a computational framework to reduce the data generation cost of training machine learning force fields.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|machine_learning_force_fields_with_data_cost_aware_training	/pdf/2322d1960eccebdbf065312a0420c577e5fe879a.pdf
CAsH4Z_Xzj7	5948	Architecture Matters in Continual Learning	['Continual Learning', 'Catastrophic Forgetting', 'Neural Network Architecture']	The choice of architecture can significantly impact the continual learning performance.	Deep Learning and representational learning	anonymous|architecture_matters_in_continual_learning	/pdf/ebb7836265aef87bb9ac7eb2a88c75408c44b88b.pdf
T-DKAYt6BMk	5950	Clustering Embedding Tables, Without First Learning Them	['Clustering', 'Sketching', 'Recommendation Systems', 'Embeddings', 'Sparse Matrices']	"We train recommendation systems using less memory than previous work. This is achieved using clustering of a ""pseudo embedding table"" trained via hashing."	Deep Learning and representational learning	anonymous|clustering_embedding_tables_without_first_learning_them	/pdf/cf2c5be6840a425b7a1b0bd6cc242cf445ec0df5.pdf
692oJ-QFuMC	5951	Teacher Intervention: Improving Convergence of Quantization Aware Training for Ultra-Low Precision Transformers	['Deep Learning', 'Quantization', 'QAT', 'Self-Attention', 'Transformer', 'BERT']	Efficient and accurate two-step Quantization Aware Training method of Finetuned Transformers	Deep Learning and representational learning	anonymous|teacher_intervention_improving_convergence_of_quantization_aware_training_for_ultralow_precision_transformers	/pdf/3153565cbe113bde7c658e4040c8571efbca54b9.pdf
uOAerdjbEZy	5953	Approximation ability of Transformer networks for functions with various smoothness of Besov spaces: error analysis and token extraction	['Transformer', 'approximation error', 'estimation error', 'minimax optimal rate', 'besov spaces', 'B-Splines', 'adaptive sampling recovery', 'token extraction']	This paper is written about the approximation ability of Transformers for functions with various smoothness, and, from a point of view of apporoximation, we prove the token extraction property of Transformers.	Deep Learning and representational learning	anonymous|approximation_ability_of_transformer_networks_for_functions_with_various_smoothness_of_besov_spaces_error_analysis_and_token_extraction	/pdf/cc0b819271ef788569310f90950c4310d75ae2a4.pdf
qFVVBzXxR2V	5954	Language Models Can (kind of) Reason: A Systematic Formal Analysis of Chain-of-Thought	['large language models', 'reasoning', 'question answering', 'chain-of-thought', 'in-context learning']	We present a new synthetic QA dataset called PrOntoQA to systematically explore the reasoning ability of language models via formal analysis, and find that while they can produce valid proof steps, they have difficulty with proof planning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|language_models_can_kind_of_reason_a_systematic_formal_analysis_of_chainofthought	/pdf/0ea41b4c012a51384138bac8686463cca3486dd6.pdf
hdkdCk6xm48	5956	Answer Me if You Can: Debiasing Video Question Answering via Answering Unanswerable Questions	['Video Question Answering', 'debiasing', 'causal inference']	We propose a novel framework for VideoQA which is possible to learn confounders existing in the dataset even when confounders are unobserved and to effectively remove the effects of learned confounders.	Deep Learning and representational learning	anonymous|answer_me_if_you_can_debiasing_video_question_answering_via_answering_unanswerable_questions	/pdf/7fb1f0b3649e7c27b9275cef39e4f151ab5bce33.pdf
22Hsbl8twlY	5958	Beyond the injective assumption in causal representation learning	['Representation learning', 'identifiability', 'ica', 'causal representation learning']	A hierarchy of generative functions for causal representation learning to consider that relaxes the injective assumption.	Deep Learning and representational learning	anonymous|beyond_the_injective_assumption_in_causal_representation_learning	/pdf/e24bda0e9f079b3f04d533ed1d2d7783a7dba7aa.pdf
5H9_FUPA9r8	5961	CommsVAE: Learning the brain's macroscale communication dynamics using coupled sequential VAEs	['variational autoencoder', 'computational neuroscience', 'graphs', 'fMRI', 'sequential variational autoencoder', 'graph learning', 'communications']	We address three issues with common connectivity approaches by explicitly modeling the directionality of communication, finding communication at each timestep, and encouraging sparsity.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|commsvae_learning_the_brains_macroscale_communication_dynamics_using_coupled_sequential_vaes	/pdf/fa9b4d9e43137d61ebb1226cb2be952e210c9c63.pdf
MuoduaZpQxE	5967	MetaP: How to Transfer Your Knowledge on Learning Hidden Physics	['meta-learning', 'neural operator', 'parametric PDEs']	Meta-learning method to transfer hidden physics	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|metap_how_to_transfer_your_knowledge_on_learning_hidden_physics	/pdf/a23472ea09652abdf36e8d7b81320e957e623a59.pdf
0pdSt3oyJa1	5968	Specformer: Spectral Graph Neural Networks Meet Transformers	['Spectral Graph Neural Networks', 'Transformer']	We propose a novel set-to-set spectral graph filter by using a spectral domain Transformer.	Deep Learning and representational learning	anonymous|specformer_spectral_graph_neural_networks_meet_transformers	/pdf/fc84be65088461a158f43582ae1edbc96c7a031a.pdf
ukWZS73ccwk	5970	Deep Latent State Space Models for Time-Series Generation	[]		Generative models	anonymous|deep_latent_state_space_models_for_timeseries_generation	/pdf/15147c6f75aa551cd28c0fac761a6f66e8bbeff9.pdf
B2ww5cqWq14	5971	Towards Diverse Perspective Learning with Switch over Multiple Temporal Pooling	['timeseries classification', 'temporal pooling', 'temporal relationship', 'perspective learning']		Deep Learning and representational learning	anonymous|towards_diverse_perspective_learning_with_switch_over_multiple_temporal_pooling	/pdf/eaf116227ee823aada8c5aa061ca0078e2310d0f.pdf
ZVnH2suWKRu	5973	HloEnv: A Graph Rewrite Environment for Deep Learning Compiler Optimization Research	['XLA', 'Compiler Optimization', 'Graph Rewrite', 'Reinforcement Learning Environment']		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|hloenv_a_graph_rewrite_environment_for_deep_learning_compiler_optimization_research	/pdf/4740ce3b01413f12998fa645438f48c01899fe38.pdf
eiuj6cNv4iI	5974	WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus	['factual generation', 'retrieval-augmented generation', 'new large-scale dataset']		Applications (eg, speech processing, computer vision, NLP)	anonymous|webbrain_learning_to_generate_factually_correct_articles_for_queries_by_grounding_on_large_web_corpus	/pdf/a37d11802784d9584bf30eda2c7aed1f32b01b97.pdf
jczReTpeJ0N	5978	BLOOM Large Language Models and the Chomsky Hierarchy	['Large Language Models', 'Chomsky Hierarchy']	The performance of the BLOOM large language models cannot be explained by the complexity of the languages in the Chomsky hierarchy.	Applications (eg, speech processing, computer vision, NLP)	anonymous|bloom_large_language_models_and_the_chomsky_hierarchy	/pdf/334210de7bee1b2ba6bf42f94139dcf7bb68f6ac.pdf
uARGOm09Vnr	5979	Towards A Unified Neural Architecture for Visual Recognition and Reasoning	['object-centric representation', 'detection', 'reasoning', 'pix2seq', 'transformers']	We propose a neural architecture that can unify visual recognition and spatiotemporal reasoning tasks, and use it to derive insights into how inductive biases, architectural choices, and recognition tasks can help enable reasoning capabilities.	Deep Learning and representational learning	anonymous|towards_a_unified_neural_architecture_for_visual_recognition_and_reasoning	/pdf/15577114fb4692c758381dbdb05d4847db9e49c6.pdf
WVYJ0BaytpF	5980	On the Convergence of Federated Deep AUC Maximization	[]		Optimization (eg, convex and non-convex optimization)	anonymous|on_the_convergence_of_federated_deep_auc_maximization	/pdf/17d590a54f9f5695563368dd9ead0b29362eebf7.pdf
z-lQRTEOpxV	5985	CLASSIFICATION OF INCOMPLETE DATA USING AUGMENTED MLP	['Classification', 'imputation', 'multi layer perceptron', 'missing data.']	A new way to train a multi layer perceptron such that it can classify incomplete data properly	General Machine Learning (ie none of the above)	anonymous|classification_of_incomplete_data_using_augmented_mlp	/pdf/a889f8deac2adb3c6f8551ce3718a3af2dd5b521.pdf
NZZoABNZECq	5987	Mechanistic Mode Connectivity	['Loss landscapes', 'Mechanisms', 'Mode Connectivity']		General Machine Learning (ie none of the above)	anonymous|mechanistic_mode_connectivity	/pdf/48c37a1f6a23aaa6f6c62bc319d5ca9636e99a09.pdf
hcLpFslHraT	5988	Importance of Class Selectivity in Early Epochs of Training	[]		Deep Learning and representational learning	anonymous|importance_of_class_selectivity_in_early_epochs_of_training	/pdf/6415c48a1ac09b9e5f88c4ba2363c757cb90e458.pdf
rde9B5ue32F	5990	Compressed Predictive Information Coding	['Predictive information', 'time series', 'variational inference']	This work proposes a novel information-theoretic framework, Compressed Predictive Information Coding (CPIC), to extract predictive latent representations from dynamic data	Deep Learning and representational learning	anonymous|compressed_predictive_information_coding	/pdf/b61ec387222ae4b282caaf98472db2d8a898a4e1.pdf
q_PkAzGFrmq	5991	The Role of Pre-training Data in Transfer Learning	['pretraining', 'transfer learning', 'supervised training', 'constrastive learning', 'clip', 'simclr']	We investigate the role of pretraining distribution, data curation, size, and loss and downstream transfer learning	Deep Learning and representational learning	anonymous|the_role_of_pretraining_data_in_transfer_learning	/pdf/6f26fad3365008416d5869841574e52c31f58a19.pdf
qHcR93949op	5993	MEDIC: Model Backdoor Removal by Importance Driven Cloning	['Backdoor Removal', 'Cloning']	We propose importance driven cloning to remove backdoor in machine learning models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|medic_model_backdoor_removal_by_importance_driven_cloning	/pdf/20ceeb0b0ec96a7b1f23a1b501b8d929bea77948.pdf
_xlsjehDvlY	5994	STUNT: Few-shot Tabular Learning with Self-generated Tasks from Unlabeled Tables	['Tabular representation learning', 'Few-shot learning', 'Unsupervised meta-learning']	We propose a few-shot tabular learning framework that meta-learns over the self-generated tasks from unlabeled tables.	Unsupervised and Self-supervised learning	anonymous|stunt_fewshot_tabular_learning_with_selfgenerated_tasks_from_unlabeled_tables	/pdf/93489d300bac154b6386efdac0c70599c641cf5a.pdf
CwFcw5DBVOR	5995	AMA: Asymptotic Midpoint Augmentation for Margin Balancing and Moderate Broadening	[]		Deep Learning and representational learning	anonymous|ama_asymptotic_midpoint_augmentation_for_margin_balancing_and_moderate_broadening	/pdf/e9eabe97d3fcad2c58e6a91776a8ad8d3a2d2b0f.pdf
vxln_lFKkfc	5997	Untangling Effect and Side Effect: Consistent Causal Inference in Non-Targeted Trials	['Causal Inference', 'Non Targeted Trials', 'Machine Learning', 'Heterogeneous Treatment Effects']	We propose an algorithm that provably  recovers hidden effect groups in causal studies	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|untangling_effect_and_side_effect_consistent_causal_inference_in_nontargeted_trials	/pdf/56cdd812acaceee6a2b77038f8b66c792ecc1a64.pdf
cBNfRYPtvFY	5999	Differentially Private Algorithms for Smooth Nonconvex ERM	['differential privacy', 'optimization', 'machine learning', 'ERM']	We develop simple differentially private optimization algorithms that move along directions of (expected) descent to find approximate second-order necessary solutions for non-convex ERM problems.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|differentially_private_algorithms_for_smooth_nonconvex_erm	/pdf/5a318c89189c87c547b93978a69f0f838f3e2b66.pdf
WFewvIEb0aT	6001	Substructure-Atom Cross Attention for Molecular Representation Learning	['Molecular representation learning', 'Molecular Substructure', 'Cross-attention']	This paper proposes a novel network that utilizes molecular substructure along with local atom embedding. 	Deep Learning and representational learning	anonymous|substructureatom_cross_attention_for_molecular_representation_learning	/pdf/b47098c654f66b925e069c070570437034eafe9d.pdf
UYsYdOn-A7e	6003	How Should I Plan? A Performance Comparison of Decision-Time vs. Background Planning	['Reinforcement learning', 'model-based reinforcement learning', 'dynamic programming', 'transfer learning']	Understanding under what conditions and which settings decision-time planning will perform better than background planning and vice versa.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|how_should_i_plan_a_performance_comparison_of_decisiontime_vs_background_planning	/pdf/01b8840c06d7cd579e1f63e690392d7a5f5a96a0.pdf
NE2911Kq1sp	6004	CktGNN:  Circuit Graph Neural Network for Electronic Design Automation	['Graph Neural Networks', 'Electronic Design Automation', 'Benchmark Graph Dataset']		Deep Learning and representational learning	anonymous|cktgnn_circuit_graph_neural_network_for_electronic_design_automation	/pdf/776e5229935e786839b9982bed2b9f6beb3c1bd6.pdf
NBES8BZ5wnZ	6005	SKTformer: A Skeleton Transformer for Long Sequence Data	['Efficient Trasnformer', 'Long Sequence Data', 'CUR decomposition', 'Robustness', 'matrix sketching']	We design an efficient Transformer model for long sequence data	Deep Learning and representational learning	anonymous|sktformer_a_skeleton_transformer_for_long_sequence_data	/pdf/119d27296227c78be115ee80f2accb8605e575f6.pdf
q9Tv6sR3jp2	6010	DYNAMIC BATCH NORM STATISTICS UPDATE FOR NATURAL ROBUSTNESS	[]		Deep Learning and representational learning	anonymous|dynamic_batch_norm_statistics_update_for_natural_robustness	/pdf/c19646c3542cecabe2e5f1b9bfc383401e6110f2.pdf
ipflrGaf7ry	6011	Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories	['Genralization', 'Reinforcement Learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|can_agents_run_relay_race_with_strangers_generalization_of_rl_to_outofdistribution_trajectories	/pdf/19a8fedebfa34ac1310412a3ed2aa4ffc14f484a.pdf
wNnaozRwl5O	6012	Speech denoising by listening to noise	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|speech_denoising_by_listening_to_noise	/pdf/71052188313d16f7c102df4efbec7574f9413346.pdf
YlmzborbHTy	6013	Context-Aware Image Completion	['Image Completion', 'Image Inpainting']		Generative models	anonymous|contextaware_image_completion	/pdf/8613bd58ae6ee426cd5fdf52cbd3a82ac27deeb1.pdf
TVMjn0RpLHf	6014	Topology Matters in Fair Graph Learning: a Theoretical Pilot Study	['Graph Neural Networks', 'Fairness', 'Topology']	A theoretical pilot study to show why GNN amplifies prediction bias	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|topology_matters_in_fair_graph_learning_a_theoretical_pilot_study	/pdf/93a451a173dfc6018357edecbe109d9032d5f086.pdf
_lPNXhQ4uvS	6015	Atomized Deep Learning Models	[]		Deep Learning and representational learning	anonymous|atomized_deep_learning_models	/pdf/52c1437e83cf3f24210904f85b1db2d185c2ea4c.pdf
PUIqjT4rzq7	6016	Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis	['Text-to-Image Synthesis', 'Diffusion Models', 'Compositional Generation']	We propose a training-free approach to incorporate language structured for compositional text-to-image synthesis	Applications (eg, speech processing, computer vision, NLP)	anonymous|trainingfree_structured_diffusion_guidance_for_compositional_texttoimage_synthesis	/pdf/1ee8387d55a5dbd22a4a01a453bcd58e8e368b3d.pdf
ZPHE4fht19t	6017	Structured World Representations via Block-Slot Attention	['object-centric learning', 'unsupervised representation learning', 'disentanglement', 'concept learning']	We propose a novel object-centric representation called block-slots, which unlike the conventional slots, provides within-slot disentanglement via vector-formed factor representations. 	Unsupervised and Self-supervised learning	anonymous|structured_world_representations_via_blockslot_attention	/pdf/2a00b0c1bb8b850158d9738cf95e49986678bbce.pdf
6t0Kwf8-jrj	6019	Editing models with task arithmetic	['pre-trained models', 'model editing', 'model patching', 'fine-tuning', 'transfer learning', 'weight interpolation', 'merging models']	We study a new paradigm for editing pre-trained models, where weight vectors obtained via fine-tuning can be combined to efficiently and effectively steer model behavior.	Deep Learning and representational learning	anonymous|editing_models_with_task_arithmetic	/pdf/85df93636556ad8ed8348ce0b0bb3c70080d9e80.pdf
_QkHfB07QMN	6020	M$^3$SAT: A Sparsely Activated Transformer for Efficient Multi-Task Learning from Multiple Modalities	['multi-task learning', 'multimodal learning', 'transformer', 'mixture of experts']	Adapt the mixture-of-experts (MoEs) into both the self-attention and the feed-forward networks (FFN) of a transformer backbone for efficient multi-task learning from multiple modalities.	Applications (eg, speech processing, computer vision, NLP)	anonymous|m^3sat_a_sparsely_activated_transformer_for_efficient_multitask_learning_from_multiple_modalities	/pdf/85949c68605b9b81737e9d6dfb7b1941e548816d.pdf
CUOhDJGy3Mn	6022	Progressive Mixup Augmented Teacher-Student Learning for Unsupervised Domain Adaptation	['Unsupervised Domain Adaptation', 'Progressive Mixup Augmentation', 'Teacher-Student Learning']		Unsupervised and Self-supervised learning	anonymous|progressive_mixup_augmented_teacherstudent_learning_for_unsupervised_domain_adaptation	/pdf/1b1a42b46c576264bad0ac672e9d45e7760af0be.pdf
TGJSPbRpJX-	6028	What Makes Convolutional Models Great on Long Sequence Modeling?	['Convolutional Neural Network', 'Deep Learning Architectures', 'Long-range dependence', 'Reparameterization']	We proposed a simple Strucured Global Convolution Kernel for long-range dependencies.	Deep Learning and representational learning	anonymous|what_makes_convolutional_models_great_on_long_sequence_modeling	/pdf/6255b77fa0e7a9645e0e229fc0a4e356ec20a2aa.pdf
qVI1MqX52Xm	6029	L2B: Learning to Bootstrap for Combating Label Noise	['learning with noisy labels', 'bootstrapping', 'meta-learning', 'medical image analysis']	A simple and effective method for combating the label noise via joint instance and label reweighting	Deep Learning and representational learning	anonymous|l2b_learning_to_bootstrap_for_combating_label_noise	/pdf/28d687079d59bda74c76efe0f6b4ef4e9a8e7024.pdf
yd5kGP5_VVE	6032	Meta-Learning for Bootstrapping Medical Image Segmentation from Imperfect Supervision 	['Semi-supervised learning', 'Meta-learning', 'Noisy labeling', 'Medical image segmentation']	A meta-based learning method for medical image segmentation under imperfect supervision	Deep Learning and representational learning	anonymous|metalearning_for_bootstrapping_medical_image_segmentation_from_imperfect_supervision	/pdf/758fb3a439e3e1f060fbbe70ca5d18c6e825022c.pdf
WzGdBqcBicl	6033	Understanding and Adopting Rational Behavior by Bellman Score Estimation	['Inverse Reinforcement Learning']	We estimate the Bellman score in order to solve IRL, reward transfer, and counterfactual prediction problems	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|understanding_and_adopting_rational_behavior_by_bellman_score_estimation	/pdf/7ce246ddc314abaf98c157baac8edbdfce1fb183.pdf
esFxSb_0pSL	6040	Pareto Invariant Risk Minimization	['Out-of-Distribution Generalization', 'Optimization', 'Multi-Objective Optimization', 'Causal Invariance']	We introduce a novel Multi-Objective Optimization perspective to understand and allieviate the optimization delimma in Out-of-Distribution generalization.	Deep Learning and representational learning	anonymous|pareto_invariant_risk_minimization	/pdf/7818d2e16ac20a365add47e2830b72c646a3fad9.pdf
wkg_b4-IwTZ	6041	A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias	['Transfer Learning', 'Robustness', 'Adaptation', 'Data Augmentation']	Mitigating feature distortion is not enough to ensure that transfer learning from large-scale, pretrained models leads to better safety and generalization on downstream tasks.	Deep Learning and representational learning	anonymous|a_closer_look_at_model_adaptation_using_feature_distortion_and_simplicity_bias	/pdf/55707f882842e21971ea090421e6856563208189.pdf
7zv_wSgP-LN	6046	Walking the Tightrope: An Investigation of the Convolutional Autoencoder Bottleneck	['autoencoders', 'unsupervised learning', 'representation learning', 'investigation']	We investigate the effect of feature map size vs. number of channels in the bottleneck of convolutional autoecoders and find that tuning the former is significantly more important than the latter.	Unsupervised and Self-supervised learning	anonymous|walking_the_tightrope_an_investigation_of_the_convolutional_autoencoder_bottleneck	/pdf/5ca6f1c5663b1746bbdd3e3caf6edb17b724dd80.pdf
DaYt6DAA-JK	6047	MiDAS: Multi-integrated Domain Adaptive Supervision for Fake News Detection	['multi-domain adaptation', 'lipschitz continuity', 'text classification', 'weak supervision', 'team-of-experts']	We use Lipschitz smoothness and probabilistic Lipschitzness to build a theoretical foundation for effective multi-domain adaptation using randomized perturbations on unseen data.	Deep Learning and representational learning	anonymous|midas_multiintegrated_domain_adaptive_supervision_for_fake_news_detection	/pdf/e5a910f2f057d756e39a11ae53c4ea826433fa6f.pdf
kpXJYIoMlho	6048	Rényi Supervised Contrastive Learning for Transferable Representation	['Supervised Learning', 'Representation Learning', 'Contrastive Learning', 'Tranfser Learning']	We present an effective and robust method to learn transferable representation by Rényi supervised contrastive learning.	Deep Learning and representational learning	anonymous|rényi_supervised_contrastive_learning_for_transferable_representation	/pdf/1cd31ad8bf74631442c325dee8bfa807e44ef466.pdf
C2ulri4duIs	6049	Computational Language Acquisition with Theory of Mind	['language acquisition', 'theory of mind', 'referential games', 'natural language processing']	Analyzing the effects of Theory of Mind and environment complexity on language acquisition models.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|computational_language_acquisition_with_theory_of_mind	/pdf/0dac201558669f9476dc11817fbc286c889319f7.pdf
rnFOPhTMB0Y	6051	How to fine-tune vision models with SGD	['fine-tuning', 'SGD', 'freezing layers', 'distribution shift']	SGD can do worse than AdamW under distribution shifts, but simple changes make SGD competitive	Deep Learning and representational learning	anonymous|how_to_finetune_vision_models_with_sgd	/pdf/eb13e8b477228ca3d329edbf2c7744ec88848d0e.pdf
pBBsrPzq7aF	6052	Combinatorial Pure Exploration of Causal Bandits	['Bandit', 'causal bandit', 'pure exploration']	Combinatorial pure exploration algorithm of causal bandits on two different models	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|combinatorial_pure_exploration_of_causal_bandits	/pdf/27ff360b24f9fc6ad2a209c5dadae3f80686c313.pdf
AuEgNlEAmed	6054	A theoretical study of inductive biases in contrastive learning	['theory of self-supervised learning', 'theory of contrastive learning']	We provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases of model classes.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_theoretical_study_of_inductive_biases_in_contrastive_learning	/pdf/1358cb051bfe89855836da3f5a8e5f93c00ddafe.pdf
uzwakrSKHyT	6055	Simple and Deep Graph Attention Networks	['Graph Attention Networks', 'Deep Graph Neural Networks']		Deep Learning and representational learning	anonymous|simple_and_deep_graph_attention_networks	/pdf/8f0cd3ad90e9fce447c538eb32a926dcd24636df.pdf
3ULaIHxn9u7	6056	Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning	['Imitation Learning', 'Heterogeneous Observation', 'Importance Weighting', 'Learning with Rejection']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|seeing_differently_acting_similarly_heterogeneously_observable_imitation_learning	/pdf/7971df30b45d2b0280ebc61202dcc94b91f4a70d.pdf
CTX5JcDaUX9	6057	Prefer to Classify: Improving Text Classifier via Pair-wise Preference Learning	['NLP', 'text classification', 'annotation', 'disagreement', 'preference']		Applications (eg, speech processing, computer vision, NLP)	anonymous|prefer_to_classify_improving_text_classifier_via_pairwise_preference_learning	/pdf/0fa02930cc3c9aaede070f2f844639612fc8eb26.pdf
6lUEy1J5R7p	6058	Imitating Graph-Based Planning with Goal-Conditioned Policies	['Reinforcement Learning', 'Goal-Conditioned Reinforcement Learning']	We train goal-conditioned policies guided by decisions from graph-based planning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|imitating_graphbased_planning_with_goalconditioned_policies	/pdf/587c42937a6e59ec7c5b4075988bc0fbddc069e7.pdf
uR6x8Be7o_M	6060	Learning to reason over visual objects	[]		Deep Learning and representational learning	anonymous|learning_to_reason_over_visual_objects	/pdf/6d0a9a9f949d2b8557f8ec00d6466d34116bcce8.pdf
LoOd40EaGA8	6061	Challenging Common Assumptions about Catastrophic Forgetting	['Continual Learning', 'Knowledge Accumulation', 'Scaling']	We propose a framework SCoLe (Scaling Continual Learning) to study knowledge accumulation in continual learning with SGD training.	Deep Learning and representational learning	anonymous|challenging_common_assumptions_about_catastrophic_forgetting	/pdf/aef18ec3d6b7cfc683676d6468960065977007ab.pdf
zaq4LV55xHl	6062	On Pre-training Language Model for Antibody	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|on_pretraining_language_model_for_antibody	/pdf/316b03086af240327e3d6990b2f190913220323a.pdf
NAuVe6pQ7Jb	6063	Efficient, probabilistic analysis of combinatorial neural codes	['neural code', 'topology', 'algebra', 'information geometry']	We improve the computational complexity of previous methods and introduce a hypothesis-checking procedure to study algebraic, geometric, and topological features of neural codes.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|efficient_probabilistic_analysis_of_combinatorial_neural_codes	/pdf/6d27285f576ff67a743cbbeffb69c0eafdda1080.pdf
OPGy07PojsZ	6064	Rethinking Symbolic Regression: Morphology and Adaptability in the Context of Evolutionary Algorithms	[]		General Machine Learning (ie none of the above)	anonymous|rethinking_symbolic_regression_morphology_and_adaptability_in_the_context_of_evolutionary_algorithms	/pdf/21be99aebcdb492594e5c79dbd5c426d2327de72.pdf
J923QzIz8Sh	6065	Intra-Instance VICReg: Bag of Self-Supervised Image Patch Embedding Explains the Performance	['self-supervised learning', 'explainable machine learning', 'co-occurrence statistics modeling']	We show that Siamese-network-based SSL methods essentially learn a distributed representation of image patches and aggregate them to form the instance representation.	Unsupervised and Self-supervised learning	anonymous|intrainstance_vicreg_bag_of_selfsupervised_image_patch_embedding_explains_the_performance	/pdf/9715dc65f289837d0d1bb112fada520fb523a9cd.pdf
rqq6Dh8t4d	6066	GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks	['AI Interpretability', 'Graph Neural Networks', 'Model-Level Explanation of Neural Networks']	We propose a model-level explanation method for GNNs, which is more general, flexible, and computationally efficient than the current SOTA.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|gnninterpreter_a_probabilistic_generative_modellevel_explanation_for_graph_neural_networks	/pdf/f8fcdbe20335d57efbd406115262c3ab2061b505.pdf
V8isglQkt74	6068	Towards Learning Implicit Symbolic Representation for Visual Reasoning	['visual reasoning', 'self-supervised learning', 'implicit symbolic representation']	Implicit symbolic representation emerges from self-supervised pretrained neural networks.	Unsupervised and Self-supervised learning	anonymous|towards_learning_implicit_symbolic_representation_for_visual_reasoning	/pdf/f4333ffdd5ab73e3942773507421febb64c10bd3.pdf
wR08RrAsLz5	6070	Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|hyperparameter_tuning_for_fair_classification_without_sensitive_attribute_access	/pdf/6e205afbdeda35ea516ee8d5f2aa023c8e0cdffa.pdf
Krk0Gnft2Zc	6071	Discrete State-Action Abstraction via the Successor Representation	['reinforcement learning', 'abstraction', 'successor representation', 'options', 'discrete', 'sparse reward', 'representation learning', 'intrinsic motivation']	We give a max-entropy regularized model for clustering states based on their successor representation, then train options to navigate between clusters.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|discrete_stateaction_abstraction_via_the_successor_representation	/pdf/d12fce0aaadea87ff94ba68b3ab76ff0ee4b3dc7.pdf
kXwdL1cWOAi	6072	UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining	['Keywords: multilingual', 'pretraining', 'language models', 'language sampling', 'language distribution', 'low-resource languages', 'overfitting']	We propose a novel language sampling method that  is close to being uniform across languages without introducing harmful repetition and that outperforms the temperature-based sampling.	Deep Learning and representational learning	anonymous|unimax_fairer_and_more_effective_language_sampling_for_largescale_multilingual_pretraining	/pdf/7dfdd02d5f380f81a152a9379ed73f4850bd37a6.pdf
5c_nxk-dX1J	6075	GradientMix: A Simple yet Effective Regularization for Large Batch Training	['Large Batch Training', 'Deep Learning Optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|gradientmix_a_simple_yet_effective_regularization_for_large_batch_training	/pdf/cc6a3f411b7f3d6bc25a331045628b6c9a93de3b.pdf
ByaNEZdnx2O	6076	Learned Nearest-Class-Mean for Biased Representations in Long-Tailed Recognition	['Long-Tailed Recognition', 'Representation bias', 'Nearest-Class-Mean']	Representations in long-tailed recognition exhibit high tail variance; propose Learned NCM to mitigate representation bias.	Deep Learning and representational learning	anonymous|learned_nearestclassmean_for_biased_representations_in_longtailed_recognition	/pdf/0aedc3114aa06d6c0f6d1a2fe61d29beba3d3609.pdf
j8Ygylt1DYJ	6078	Robust attributions require rethinking robustness metrics	['Robustness', 'Attribution', 'Interpretable', 'Metrics']	The existing metrics for robustness of attributions to small impercetible perturbations don't capture local sensitivity. We propose new locality-sensitive metrics and show their usefulness.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robust_attributions_require_rethinking_robustness_metrics	/pdf/9db8e762f46099ce649077f3339539e94f2bd3c6.pdf
u8IcZZORLuq	6079	Towards Automatic Generation of Advanced Shift Networks	['Shift Neural Networks', 'Neural Architecture Search']	We propose AutoShiftNet, the first framework tailoring Neural Architecture Search (NAS) to substantially reduce the accuracy gap between bit-shift neural networks and their real-valued counterparts	General Machine Learning (ie none of the above)	anonymous|towards_automatic_generation_of_advanced_shift_networks	/pdf/bb8a347c4220f1ba41eb6537860e8133b46ee93e.pdf
Xo2E217_M4n	6082	FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning	['Federated learning', 'backdoor mitigation']		General Machine Learning (ie none of the above)	anonymous|flip_a_provable_defense_framework_for_backdoor_mitigation_in_federated_learning	/pdf/3d45929b1f8c4f64ab34e6894e60f917a075838d.pdf
Ji1_32XWMxK	6083	Optimistic Exploration in Reinforcement Learning Using Symbolic Model Estimates	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|optimistic_exploration_in_reinforcement_learning_using_symbolic_model_estimates	/pdf/450f2a46a3d1c06a60d243ffafdb137c650e7d0a.pdf
JknGeelZJpHP	6086	Sparse Distributed Memory is a Continual Learner	['Sparse Distributed Memory', 'Sparsity', 'Top-K Activation', 'Continual Learning', 'Biologically Inspired']	Improving Sparse Distributed Memory via additional neurobiology results in a deep learning model with strong, organic continual learning and insights into sparse models more broadly.	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|sparse_distributed_memory_is_a_continual_learner	/pdf/83e5944f430ca96454f70107cd31be546e1203d6.pdf
wKPmPBHSnT6	6087	Ordered GNN: Ordering Message Passing to Deal with Heterophily and Over-smoothing	['GNN', 'heterophily', 'over-smoothing']	In this paper, we propose a novel GNN model to tackle heterophily and over-smoothing simultaneously by aligning the rooted-tree hierarchy with node embedding structure.	Deep Learning and representational learning	anonymous|ordered_gnn_ordering_message_passing_to_deal_with_heterophily_and_oversmoothing	/pdf/af3ee81525c8489120b2bfa14f59c6a42d4f36fb.pdf
Zsl54T6OLBH	6088	SlothBomb: Efficiency Poisoning Attack against Dynamic Neural Networks	['Efficient ML', 'Poisoning Attack']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|slothbomb_efficiency_poisoning_attack_against_dynamic_neural_networks	/pdf/97a39e9e6ae3c0c4d954e834fc2c336aa7f578ca.pdf
6H_uOfcwiVh	6089	A Kernel Perspective of Skip Connections in Convolutional Networks	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|a_kernel_perspective_of_skip_connections_in_convolutional_networks	/pdf/bfefbbbd4f51904ea280bc3903641b398c2cfd46.pdf
osIppnySBTV	6093	DEFENDING BACKDOOR ATTACKS VIA ROBUSTNESS AGAINST NOISY LABEL	['Backdoor Attack', 'Deep Learning', 'Data Poisoning', 'Noisy Label']	We propose a principled approach to defend the backdoor attack by using existed robust algorithm against label noise.	Deep Learning and representational learning	anonymous|defending_backdoor_attacks_via_robustness_against_noisy_label	/pdf/84ee6ba3856600625ef0f6e7fe0a85cff86bafca.pdf
P9yXPbfqbvC	6094	Noise Transforms Feed-Forward Networks into Sparse Coding Networks	['Sparse Coding', 'Sparsity', 'Top-K Activation', 'Noise', 'Biologically Inspired']	We find that noise alone induces networks to become Top-K, sparse coding networks. This resolves a difference between biological and artificial neural networks with regards to how sparse they are and how this sparsity is implemented.. 	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|noise_transforms_feedforward_networks_into_sparse_coding_networks	/pdf/959d9133791c96465f1502ecd12bfb589d750046.pdf
IIyox3dwad0	6095	Fast-PINN for Complex Geometry: Solving PDEs with Boundary Connectivity Loss	['Physics-informed neural networks', 'physics-informed loss formulation', 'multi-layer perceptron', 'convolutional neural network', 'fluid dynamics']	We present a fast-PINN method based on the incorporation of boundary connectivity constraints into training loss, which can efficiently produce accurate solutions with order of magnitude fewer training samples, across multiple fluid dynamic problems.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|fastpinn_for_complex_geometry_solving_pdes_with_boundary_connectivity_loss	/pdf/d3c1cb0011545422921c2488d26cfc3d38f7bf4a.pdf
9_cba-ImPGb	6096	Robustness Guarantees for Adversarially Trained Neural Networks	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|robustness_guarantees_for_adversarially_trained_neural_networks	/pdf/a6a37744cc523cf48502857a618469a713fa7d80.pdf
0aAd19ZQp11	6097	Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Muliple Heterogeneous Datasets	['Pre-training', 'Bayesian optimization', 'Transformer', 'Transfer learning']		Optimization (eg, convex and non-convex optimization)	anonymous|efficient_bayesian_optimization_with_deep_kernel_learning_and_transformer_pretrained_on_muliple_heterogeneous_datasets	/pdf/fa972f7d3401955378ea1f6d7d4bc9f68dd76142.pdf
zqkfJA6R1-r	6098	Improved Training of Physics-Informed Neural Networks Using Energy-Based Priors: a Study on Electrical Impedance Tomography	['Physics-informed neural networks', 'electrical impedance tomography', 'energy-based models']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|improved_training_of_physicsinformed_neural_networks_using_energybased_priors_a_study_on_electrical_impedance_tomography	/pdf/d6e2c936bce895f96a2e9c3e03b4d890b12bb5d5.pdf
dKkMnCWfVmm	6099	Multi-Objective Online Learning	[]		Optimization (eg, convex and non-convex optimization)	anonymous|multiobjective_online_learning	/pdf/af9dcc714b164cebd44447bf081df7b9106a5d9f.pdf
ytNEuwH1yeL	6100	An Experiment Design Paradigm using Joint Feature Selection and Task Optimization	['Experiment Design', 'Populationwide Supervised Feature Selection', 'Quantitative Magnetic Resonance Imaging', 'Deep Learning']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|an_experiment_design_paradigm_using_joint_feature_selection_and_task_optimization	/pdf/6fad31d3406d484ba9bcd50a7ae3aaf022b673b6.pdf
ja4Lpp5mqc2	6102	TrojText: Test-time Invisible Textual Trojan Insertion	['Textual', 'Trojan', 'Backdoor', 'Syntactic', 'Trigger', 'Invisible', 'Attack', 'Defense', 'Test-time']	TrojText is a more realistic, efficient, test-time invisible textual Trojan Insertion method  against intelligent neuron models	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|trojtext_testtime_invisible_textual_trojan_insertion	/pdf/766b71165ce98aac8472d28399dc28bcc00f880e.pdf
b39dQt_uffW	6112	Safe Reinforcement Learning From Pixels Using a Stochastic Latent Representation	['safety', 'reinforcement learning', 'safe reinforcement learning', 'constrained Markov decision process', 'partially observable Markov decision process', 'MDP', 'POMDP']	This paper proposes Safe SLAC, a safety-constrained RL approach for partially observable settings, which uses a stochastic latent variable model combined with a safety critic.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|safe_reinforcement_learning_from_pixels_using_a_stochastic_latent_representation	/pdf/d23d89f2185376366872d2d18efe81c6248775c3.pdf
aNiem36virV	6113	Revisiting and Improving FGSM Adversarial Training	['Small-scale features', 'FGSM adversarial training', 'Catastrophic overfitting']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|revisiting_and_improving_fgsm_adversarial_training	/pdf/f1a77a6b334554d719ae1343dee9c2101b79f46f.pdf
whsWWPAUkwR	6114	Cross-Window Self-Training via Context Variations from Sparsely-Labeled Time Series	['semi-supervised learning', 'time series', 'pseudo labeling']		Applications (eg, speech processing, computer vision, NLP)	anonymous|crosswindow_selftraining_via_context_variations_from_sparselylabeled_time_series	/pdf/8ea342fd141a5888da9cbd70b3b61f92f20688d1.pdf
4oLK1_k71Tz	6118	Mid-Vision Feedback for Convolutional Neural Networks	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|midvision_feedback_for_convolutional_neural_networks	/pdf/d4a42a5bb08ab24c22a61a81b93129c1877f6f23.pdf
JKFSUPa70W6M	6119	Don’t Bet on Sparsity: Designing Brain-inspired Distance-preserving Encoder	['Orthogonal attention', 'Lipschitz', 'Entropic Transformer']		Deep Learning and representational learning	anonymous|dont_bet_on_sparsity_designing_braininspired_distancepreserving_encoder	/pdf/fce3151cacf87f1d2d11eda3da4754d275c68b68.pdf
kIo_C6QmMOM	6120	Coupled Multiwavelet Operator Learning for Coupled Differential Equations	['Neural operators', 'coupled differential equations', 'multiwavelet transform', 'partial differential equations']	We propose a novel coupled multiwavelet operator learning scheme for efficiently solving coupled differential equations.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|coupled_multiwavelet_operator_learning_for_coupled_differential_equations	/pdf/d88e8acd68220278c010819b169a68e98879f03e.pdf
Pk_di2bPAop	6121	On the Adversarial Robustness against Natural Weather Perturbations	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_adversarial_robustness_against_natural_weather_perturbations	/pdf/d64fc92ee3a8327e1cd0fca6b98ac47f204548bb.pdf
rpWw6Ki2b5s	6122	Therbligs in Action: Video Understanding through Motion Primitives	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|therbligs_in_action_video_understanding_through_motion_primitives	/pdf/25a47794975c5514646fb1a079e6bab5e262b562.pdf
JZMR727O29	6123	Backpropagation through Combinatorial Algorithms: Identity with Projection Works	['combinatorial optimization', 'deep learning', 'representation learning', 'gradient descent', 'backpropagation', 'argmin differentiation', 'deep graph matching', 'retrieval']	We propose a simple alternative for differentiating through combinatorial solvers with linear objectives, that is on par with SoTA, has no hyperparameters, and is more robust to perturbations.	Deep Learning and representational learning	anonymous|backpropagation_through_combinatorial_algorithms_identity_with_projection_works	/pdf/ab45d6bb523d6e5da04f5fbb9eb3f7ef576430eb.pdf
swEskiem99	6124	Feature selection and low test error in shallow low-rotation ReLU networks	['gradient descent', 'gradient flow', 'margin maximization', 'test error', 'neural collapse', 'generalization']	This work establishes low test error of gradient methods on two-layer ReLU networks with standard initialization, in three regimes where key sets of weights rotate little, making use of margins as the core analysis technique.	Deep Learning and representational learning	anonymous|feature_selection_and_low_test_error_in_shallow_lowrotation_relu_networks	/pdf/8571e56a52c25f00a3664957e717069013105130.pdf
mdERENskoo1	6125	Generalization to translation shifts in object detection: a study in architectures and augmentations	['OOD generalization', 'beyond accuracy', 'empirical study']	Data augmentations and architecture are complementary ways of incorporating inductive bias about desired robustness/invariances	Deep Learning and representational learning	anonymous|generalization_to_translation_shifts_in_object_detection_a_study_in_architectures_and_augmentations	/pdf/f2259f160bd90607f463a1687a2a28d5fae0ea6a.pdf
8Tr3v4ueNd7	6127	Exphormer: Scaling Graph Transformers with Expander Graphs	['Graph neural networks', 'Transformers']	We show how to use expander graphs to devise sparse graph transformers that are powerful and scalable.	Deep Learning and representational learning	anonymous|exphormer_scaling_graph_transformers_with_expander_graphs	/pdf/25fc1cbb8df95f09036d941c5908d78b110f0695.pdf
IC8LwiOLKFr	6128	Some Practical Concerns and Solutions for Using Pretrained Representation in Industrial Systems	['Representation Learning', 'Stability', 'Generalization', 'Convergence', 'Predictability', 'Industry Application']	We investigate some practical concerns and solutions for using pretrained representation in industrial systems.	Deep Learning and representational learning	anonymous|some_practical_concerns_and_solutions_for_using_pretrained_representation_in_industrial_systems	/pdf/30591d673ed32b3770d4a53d32e687b824e88eaf.pdf
2QzNuaRHn4Z	6129	Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts	['Robustness', 'Distribution shift', 'Group Shift']	Robustness to group shifts without training group annotations can be achieved with a constrained form of DRO.	Deep Learning and representational learning	anonymous|bitrateconstrained_dro_beyond_worst_case_robustness_to_unknown_group_shifts	/pdf/30573c11ec9dd3f2b6ab7dbe8c5b2478c4848b1c.pdf
vJVIUTwohv	6130	Offline Reinforcement Learning via Weighted $f$-divergence	['Offline Reinforcement Learning', 'Stationary Distribution Correction Estimation']	We propose a DICE algorithm with weighted f-divergence regularization for offline RL, which enables state-action dependent regularization.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_reinforcement_learning_via_weighted_fdivergence	/pdf/efaa925439ea64fa6789b82db159415bb99e1bd8.pdf
xKYlWJaLFi	6135	MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers	['Multi-task Pre-training', 'Dense Retrieval']		Applications (eg, speech processing, computer vision, NLP)	anonymous|master_multitask_pretrained_bottlenecked_masked_autoencoders_are_better_dense_retrievers	/pdf/d52dd406d22f22e955b687115defdd426fb27863.pdf
raSbs1AFoX3	6137	On the convergence of SGD under the over-parameter setting	['SGD', 'over-parameter', 'almost surely convergence', 'global optimum convergence']	We show that SGD converges to the global optimum with probability 1 and provide a asymptotic convergence rate	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|on_the_convergence_of_sgd_under_the_overparameter_setting	/pdf/a0cc2c9f40433b6570a1e2ce9e1c20a280129910.pdf
zfiYcbeQkH	6140	SciRepEval: A Multi-Format Benchmark for Scientific Document Representations	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|scirepeval_a_multiformat_benchmark_for_scientific_document_representations	/pdf/008cae8748c4fee5f883dc30d1e27559eb0ba480.pdf
SVl1w1u3InX	6141	CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement	['self-boost refinement', 'complex answers', 'autoregressive generation']	CASR improves left-to-right autoregressive generation without heuristic intermediate sequences for complex answers via self-boost refinement	Generative models	anonymous|casr_generating_complex_sequences_with_autoregressive_selfboost_refinement	/pdf/95dd7d2c3b6f8a951c7277b54caa185c9e44c86c.pdf
GKsNIC_mQRG	6143	Emergence of Exploration in Policy Gradient Reinforcement Learning via Resetting	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|emergence_of_exploration_in_policy_gradient_reinforcement_learning_via_resetting	/pdf/af1e8e9b71683c93937fcf4578bfc6e14d0bb84c.pdf
6ruVLB727MC	6145	UL2: Unifying Language Learning Paradigms	['language models', 'pretraining', 'transformers']	How to train a language model properly	Deep Learning and representational learning	anonymous|ul2_unifying_language_learning_paradigms	/pdf/5f82dea887dd2379f58936df0661935f51ec9246.pdf
Vf2DK1Ol0ed	6146	A Benchmark Dataset for Learning from Label Proportions	['Learning from Label Proportions', 'Benchmark Dataset', 'LLP']	A Benchmark based on Criteo Kaggle CTR dataset for Learning from Label Proportions	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|a_benchmark_dataset_for_learning_from_label_proportions	/pdf/091a6ae3959a706a0135d23c9032fbae501e415d.pdf
d8mr8lKIZ3n	6147	Arbitrary Virtual Try-On Network: Characteristics Representation and Trade-off between Body and Clothing	['Deep Learning', 'Virtual Try-on', 'Generative Adversarial Networks', 'Artificial Intelligence in Fashion']	We develop a special 2D virtual try-on network for cross-category try on task, e.g. long sleeves<->short sleeves or long pants<->skirts, since the limb may be exposed or hidden in such case.	Deep Learning and representational learning	anonymous|arbitrary_virtual_tryon_network_characteristics_representation_and_tradeoff_between_body_and_clothing	/pdf/17e2e36a00fbe3a27219988cef1ee1078d5f46e4.pdf
KyoVpYvWWnK	6148	Efficient Certified Training and Robustness Verification of Neural ODEs	['Neural ODEs', 'Adversarial Robustness', 'Certified Robustness', 'Robustness Verification', 'Certified Training']	We enable certified training and scalable robustness verification of neural ODEs.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|efficient_certified_training_and_robustness_verification_of_neural_odes	/pdf/b0875aee0265ab11adf5ae239b57568e6c6690f5.pdf
u6KhE9fapjX	6149	CAT: Collaborative Adversarial Training	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|cat_collaborative_adversarial_training	/pdf/8272e453b0c16212ae37b32a3d796298cdcf7333.pdf
MT1Pcdo8sGG	6152	Automatically Answering and Generating Machine Learning Final Exams	[]		Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|automatically_answering_and_generating_machine_learning_final_exams	/pdf/3b81ac82a6abda4ae875dee2bd1407d40e6ef501.pdf
HtAfbHa7LAL	6153	MA-BERT: Towards Matrix Arithmetic-only BERT Inference by Eliminating Complex Non-linear Functions	['BERT', 'Efficient inference', 'Matrix arithmetic-only', 'Eleminate non-linear functions']	MA-BERT completely eliminates the complex non-linear functions in BERT and achieves matrix arithmetic-only operation with trivial ReLU, which could benefit inference on both general computing units and accelerator designs for edge applications	Deep Learning and representational learning	anonymous|mabert_towards_matrix_arithmeticonly_bert_inference_by_eliminating_complex_nonlinear_functions	/pdf/a1328d5eaf0894c3fa7fca6583c78d2dd7ecbb11.pdf
Tl8OmiibP99	6154	Improving Differentiable Neural Architecture Search by Encouraging Transferability	[]		Deep Learning and representational learning	anonymous|improving_differentiable_neural_architecture_search_by_encouraging_transferability	/pdf/bfaed547b247ffb91fbb682994617e8035394026.pdf
afrUI9hkUJM	6157	Oscillation Neural Ordinary Differential Equations	['Neural Ordinary Differential Equations', 'Continuous Deep Learning']	Oscillation Neural Ordinary Differential Equations	Deep Learning and representational learning	anonymous|oscillation_neural_ordinary_differential_equations	/pdf/3bb90bfdfe776f3fab3d0754fd3c167dd3ccda73.pdf
067CGykiZTS	6160	Scaling Up Probabilistic Circuits by Latent Variable Distillation	[]		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|scaling_up_probabilistic_circuits_by_latent_variable_distillation	/pdf/8c5f86574b54b7f2365d42fe78d1875d7e10927b.pdf
bxtzk6Wfrpo	6163	Mirror Training for Input Convex Neural Network	['input convex neural network', 'convex optimization', 'representation', 'recurrent neural network', 'hosting capacity']		Optimization (eg, convex and non-convex optimization)	anonymous|mirror_training_for_input_convex_neural_network	/pdf/57822eedb6968242236b48f91607f48b86bf37b4.pdf
3TduOwfFNoy	6166	Contextualized Generative Retrieval	['NLP', 'Information Retrieval']	By utilizing contextualized token embeddings in generative retrieval, it can utilize both the parametric space of the model and the non-parametric space of contextualized embeddings.	Applications (eg, speech processing, computer vision, NLP)	anonymous|contextualized_generative_retrieval	/pdf/3a090f438777fda4d2e2fc813d8d7ab88ba54b36.pdf
tyZ1ChGZIKO	6167	Selective Frequency Network for Image Restoration	['Image restoration', 'Frequency domain', 'Frequency selection']	We propose a novel network to recover the most useful frequency component for image restoration via frequency selection.	Applications (eg, speech processing, computer vision, NLP)	anonymous|selective_frequency_network_for_image_restoration	/pdf/cfac4f72a029de4e15e79614f747377f52c0c439.pdf
lmumJ2pC0JB	6169	Sharp Convergence Analysis of Gradient Descent for Deep Linear Neural Networks	['deep linear neural networks', 'non-convex optimization', 'gradient descent', 'initialization']	In deep linear neural networks, we obtain sharp rates for gradient descent to converge to a global optimum.	General Machine Learning (ie none of the above)	anonymous|sharp_convergence_analysis_of_gradient_descent_for_deep_linear_neural_networks	/pdf/91b3c79aaf68ab4cb68b1a7d723f684e73d866d2.pdf
jYv81Ai6ztO	6172	Theoretical Study of Provably Efficient Offline Reinforcement Learning with Trajectory-Wise Reward	['RL theory', 'offline RL', 'trajectory-wise reward']	This paper studies the theory of offline RL with trajectory-wise reward	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|theoretical_study_of_provably_efficient_offline_reinforcement_learning_with_trajectorywise_reward	/pdf/d659267f10f24afc591a3276462faa9641c8e0a3.pdf
wZiE_S2362V	6173	Contrastive Learning of Molecular Representation with Fragmented Views	['Molecule representation learning']	We propose a contrastive learning method for molecular representation with fragmented views.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|contrastive_learning_of_molecular_representation_with_fragmented_views	/pdf/2fa1b2176370d847b92bb06e79d261bc4501ffbc.pdf
4bCsX2K0KuR	6174	FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation	['retrieval augmented generation', 'KILT', 'Fusion-in-Decoder', 'efficiency']	We increase the efficiency of FID with FiD-Light including a source pointing workflow for effective retrieval augmented generation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|fidlight_efficient_and_effective_retrievalaugmented_text_generation	/pdf/598201cde37cd088716f8496b7f4dd31f8264492.pdf
3i_7H3phuy3	6175	Incompatibility between Deterministic Policy and Generative Adversarial Imitation Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|incompatibility_between_deterministic_policy_and_generative_adversarial_imitation_learning	/pdf/c9c7be21ab69612240d6f289acef7dd929c5ad9f.pdf
Rn8u4MYgeNJ	6179	Mitigating the Limitations of Multimodal VAEs with Coordination-Based Approach	['mutlimodal learning', 'deep generative models']		Generative models	anonymous|mitigating_the_limitations_of_multimodal_vaes_with_coordinationbased_approach	/pdf/277bf87997b88576a8fa7d506d573481b00f862e.pdf
paGvsrl4Ntr	6182	Transfer NAS with Meta-learned Bayesian Surrogates	[]		Deep Learning and representational learning	anonymous|transfer_nas_with_metalearned_bayesian_surrogates	/pdf/4b5c3dda5c09eeaf64fee15b8901174e211b3ad4.pdf
BLsM6WymMo6	6183	SRBGCN: Tangent space-Free Lorentz Transformations for Graph Feature Learning	['fully hyperbolic network', 'Lorentz transformations', 'boost and rotation', 'graph convolutional networks', 'hyperbolic rotations']	This work introduces a fully hyperbolic network that uses direct Lorentz transformations to learn the features directly on the manifold.	Deep Learning and representational learning	anonymous|srbgcn_tangent_spacefree_lorentz_transformations_for_graph_feature_learning	/pdf/fac1a62b269d6f1c8e9afcfd1bf9b69ca6756cef.pdf
fGG6vHp3W9W	6184	Hierarchical Abstraction for Combinatorial Generalization in Object Rearrangement	['objects', 'combinatorial generalization', 'abstraction', 'rearrangement', 'slots', 'binding', 'hierarchy', 'compositionality', 'symmetry', 'independence', 'graph search']	We demonstrate how to generalize over a combinatorially large space of rearrangement tasks from only pixel observations by constructing from video demonstrations a factorized transition graph over entity state transitions that we use for control.	Deep Learning and representational learning	anonymous|hierarchical_abstraction_for_combinatorial_generalization_in_object_rearrangement	/pdf/8173372aeb107ebefa2a4b8fabd8f20d93360034.pdf
h9O0wsmL-cT	6186	Regression with Label Differential Privacy	['label differential privacy', 'regression']	We present a new label differentially private algorithm for training regression models.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|regression_with_label_differential_privacy	/pdf/028e9de3bc6608d2897966b0d27f30d4c69b1a32.pdf
mcJvCys7DX7	6187	Counterfactual Generation Under Confounding	['counterfactual', 'confounding', 'cycleGAN', 'classification']	We propose a counterfactual data augmentation to improve the performance of a classifier when the data is spuriously correlated	Deep Learning and representational learning	anonymous|counterfactual_generation_under_confounding	/pdf/49390399d9e85ef45bc97b2dc6c2f134025a5a3e.pdf
eCIVFDVxvAx	6188	Label Similarity Aware Contrastive Learning	['Contrastive Learning', 'Supervised Learning', 'Representation Learning']	Label similarity aware contrastive learning builds better representation space and improves downstream performance via optimizing alignment and uniformity.	Deep Learning and representational learning	anonymous|label_similarity_aware_contrastive_learning	/pdf/194b65dc77a8cae98dad729379e74c87b540f8af.pdf
7oFuxtJtUMH	6189	Certified Training: Small Boxes are All You Need	['Certified Training', 'Certified Robustness', 'Adversarial Robustness', 'Robustness Verification']	We propose a novel certified training method based on propagating small input regions, establishing a new state of the art for certified accuracy.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|certified_training_small_boxes_are_all_you_need	/pdf/8561df9fc3e9bdd20e04c6cb786f68a302cf329c.pdf
M2unceRvqhh	6190	Learning with Logical Constraints but without Shortcut Satisfaction	['training with logical constraints', 'logical formula encoding', 'variational learning', 'stochastic gradient descent ascent']		Deep Learning and representational learning	anonymous|learning_with_logical_constraints_but_without_shortcut_satisfaction	/pdf/e1100c4db9e6516216bff54a8592a4ec9419a244.pdf
-zw8zmeIt7M	6192	Efficiently Meta-Learning for Robust Deep Networks without Prior Unbiased Set	['Robust deep learning', 'Noisy Label', 'Meta-learning', 'KD']	We present an efficiently meta-learning approach, which eliminates the dependence on additional unbiased data and reduces the optimization complexity of recent meta-learning based method	General Machine Learning (ie none of the above)	anonymous|efficiently_metalearning_for_robust_deep_networks_without_prior_unbiased_set	/pdf/e2c9968e04c4550ddbc7a78434e9937d99c61c40.pdf
No6QvMxdQMo	6194	SELCOR: Self-Correction for Weakly Supervised Learning	['Weakly Supervised Learning', 'Label Noise', 'Self-Training']	We propose a self-training based method to reduce noise in weak labels for weakly supervised learning.	Unsupervised and Self-supervised learning	anonymous|selcor_selfcorrection_for_weakly_supervised_learning	/pdf/ac3152274dc637081b28ba0905010935fd22c6c2.pdf
yKbprarjc5B	6195	Leveraging Large Language Models for Multiple Choice Question Answering	['NLP', 'language models', 'multiple choice question answering', 'symbol binding', 'GPT-3', 'Codex']	Large language models that can effectively associate multiple choice answer options with symbols can be prompted in a way that yields dramatically improved performance on multiple choice question answering tasks.	Applications (eg, speech processing, computer vision, NLP)	anonymous|leveraging_large_language_models_for_multiple_choice_question_answering	/pdf/de8dabb82a2a7649f2eba36a85954c2cb0d612cd.pdf
UHPva3PuKLN	6196	On Information Maximisation in Multi-View Self-Supervised Learning	['multi-view Self-supervised Learning', 'Information Theory']	 	Unsupervised and Self-supervised learning	anonymous|on_information_maximisation_in_multiview_selfsupervised_learning	/pdf/454b6905b0981b00ddfdc04227049196d0fa5e04.pdf
w48XN5HwpV8	6198	On the Existence of a Trojaned Twin Model	['Backdoor Attack', 'Trojan Attack']	A mathematical model for backdoor attack, show the existence of a trojaned twin model of a clean model	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_existence_of_a_trojaned_twin_model	/pdf/3d4aab551a10ec53991cec22c18736340be90470.pdf
jZfksUBb3Zz	6200	Multi Task Learning of Different Class Label Representations for Stronger Models	['Label Representation', 'Image Classification', 'Representation Learning', 'Multi-Task Learning']	We present a new way of representing class labels, and train a network to recognize them as an auxiliary task, leading to stronger models.	Deep Learning and representational learning	anonymous|multi_task_learning_of_different_class_label_representations_for_stronger_models	/pdf/d059a82aad9f1b6dea2684eb26cccd5796c6d604.pdf
UxqUgchwXkK	6201	Fast Nonlinear Vector Quantile Regression	['optimal transport', 'quantile regression', 'vector quantiles', 'uncertainty quantification', 'multi-output regression', 'conformal prediction', 'software']	We extend Vector Quantile Regression to support non-linear specification, while ensuring monotonicity and scaling to millions of samples.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|fast_nonlinear_vector_quantile_regression	/pdf/0d551391621901efcd1bcba793d2c7722250f930.pdf
O5rKg7IRQIO	6202	Guarded Policy Optimization with Imperfect Online Demonstrations	['reinforcement learning', 'guarded policy optimization', 'imperfect demonstrations', 'shared control', 'metadrive simulator']	Introducing a new policy optimization method exploiting imperfect online demonstrations from a guardian policy.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|guarded_policy_optimization_with_imperfect_online_demonstrations	/pdf/8f2f8213db05c6eb82cd3c759c2b901810f8aa5d.pdf
GGItImF9oG5	6203	Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?	[]	Your model is pretty cool, but does it scale? Let's find out. 	Deep Learning and representational learning	anonymous|scaling_laws_vs_model_architectures_how_does_inductive_bias_influence_scaling	/pdf/0a9d8f8625c4e8d98ba14d0f70d0cfec72880d80.pdf
l2vPa8gwBuA	6204	One-Step Estimator for Permuted Sparse Recovery	[]		Optimization (eg, convex and non-convex optimization)	anonymous|onestep_estimator_for_permuted_sparse_recovery	/pdf/23a6c7fd6e2b1c2195157d67f9c3799fb84a51b8.pdf
-94tJCOo7OM	6206	MCTransformer: Combining Transformers And Monte-Carlo Tree Search For Offline Reinforcement Learning	['Transformer', 'Monte Carlo Tree Search', 'Offline Reinforcement Learning', 'SameGame']	A novel approach for sequential decision making using reinforcement learning by combining MCTS and transformers.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|mctransformer_combining_transformers_and_montecarlo_tree_search_for_offline_reinforcement_learning	/pdf/d74cba6946dd95a739af4d64352774540e5dff99.pdf
p48GR3rwtxf	6207	Neural Representations in Multi-Task Learning guided by Task-Dependent Contexts	['Learning Representations', 'Neural Geometry', 'Context-Dependent Decision Making', 'Attention Mechanisms']	We investigate neural representations learned by multi-task architectures focusing on task-switching networks that use task-dependent contexts.	Deep Learning and representational learning	anonymous|neural_representations_in_multitask_learning_guided_by_taskdependent_contexts	/pdf/d2b8a3d5c550769c1d89e055c57a3d2b4690da19.pdf
2jcvy1htS_r	6209	A Hierarchical Bayesian Approach to Federated Learning	['Federated Learning', 'Bayesian Methods', 'Probabilistic Models']	We propose a novel hierarchical Bayesian approach to Federated learning (FL) where the block-coordinate descent solution to the variational inference leads to a viable algorithm for FL with proved convergence and generalisation guarantee.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|a_hierarchical_bayesian_approach_to_federated_learning	/pdf/3ce8f19be99ead38d4f55cf069c491eb0c8d1981.pdf
NI7StoWHJPT	6210	Improving the Calibration of Fine-tuned Language Models via Denoising Variational Auto-Encoders	[]		Deep Learning and representational learning	anonymous|improving_the_calibration_of_finetuned_language_models_via_denoising_variational_autoencoders	/pdf/9ba1c83e4908a7a68b0d7f41c2f81f154b504beb.pdf
cB4N3G5udUS	6212	RandProx: Primal-Dual Optimization Algorithms with Randomized Proximal Updates	['optimization', 'randomized algorithm', 'stochastic algorithm', 'proximal splitting', 'proximity operator']		Optimization (eg, convex and non-convex optimization)	anonymous|randprox_primaldual_optimization_algorithms_with_randomized_proximal_updates	/pdf/fbe1863822207621f860a2b30b9a11deca4b5e1c.pdf
-4DiyBMgv9m	6214	Identifying Phase Transition Thresholds of Permuted Linear Regression via Message Passing	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|identifying_phase_transition_thresholds_of_permuted_linear_regression_via_message_passing	/pdf/922f8c68ece0fa54603e677d69cabb25d49219a1.pdf
z0_V5O9cmNw	6215	Learning in temporally structured environments	['1/f noise', 'Kalman filter', 'neural network', 'learning theory', 'optimizers']	Models that learn at multiple timescales perform well in tasks with complex temporal structure	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|learning_in_temporally_structured_environments	/pdf/bd7c220a686a42c7b6a157ec9ea986482c81dc85.pdf
TZixgYj-oqI	6216	Offline imitation learning by controlling the effective planning horizon	['imitation learning', 'offline imitation learning', 'supplementary offline dataset']	We fix the problem that previous IL algorithms don't work with a low discount factor, and show that offline IL can be solved with the proposed fix and lowering the discount factor.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|offline_imitation_learning_by_controlling_the_effective_planning_horizon	/pdf/17bf0f6425f51b764c3ae7fdb2accc5d8af50636.pdf
5YHaMHg2Bfa	6217	SGD Through the Lens of Kolmogorov Complexity	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|sgd_through_the_lens_of_kolmogorov_complexity	/pdf/bcdb85524b4fa04d50fd6c60bde5feba43d85554.pdf
qSCHRL8b96S	6218	PTUnifier: Pseudo Tokens as Paradigm Unifiers in Medical Vision-and-Language Pre-training	['medical analysis', 'vision-and-language', 'multi-modal learning']	This paper proposes a simple approach to extract generic representations from medical images and texts, which can be applied to a broad range of medical tasks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|ptunifier_pseudo_tokens_as_paradigm_unifiers_in_medical_visionandlanguage_pretraining	/pdf/743621768182dbb5eedc53432473dadcfa14bd64.pdf
bnkvnbGEXnc	6220	Deep Equilibrium Non-Autoregressive Sequence Learning	['deep equilibrium model', 'non-autoregressive sequence-to-sequence']		Applications (eg, speech processing, computer vision, NLP)	anonymous|deep_equilibrium_nonautoregressive_sequence_learning	/pdf/8971614712336f714a39ce7c74fc0ec3f9f84800.pdf
pRCMXcfdihq	6221	Protein Sequence and Structure Co-Design with Equivariant Translation	['protein design', 'sequence structure co-design', 'equivariant translation', 'geometric deep learning']	A novel framework for protein sequence and structure co-design, which translates proteins in the joint sequence-structure space in an iterative and end-to-end manner.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|protein_sequence_and_structure_codesign_with_equivariant_translation	/pdf/c8dec4b09ff2735022470fe2f18c7c95f590eea3.pdf
rmoMvptXK7M	6226	Gray-Box Gaussian Processes for Automated Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|graybox_gaussian_processes_for_automated_reinforcement_learning	/pdf/5433cf015e1fc44aca552d82a273594c64d509ac.pdf
odI2OpMFq-D	6227	Optimizing Data-Flow in Binary Neural Networks	['Binary', 'Networks', 'Quantization', '1-bit']	A method to speed-up Binary Neural Networks removing floating-point computation	Deep Learning and representational learning	anonymous|optimizing_dataflow_in_binary_neural_networks	/pdf/a9ea37dc3d4fbb37dd18c3942b3d4c2b4399a0d9.pdf
FHZUqgxIBYn	6228	Opportunistic Actor-Critic (OPAC) with Clipped Triple Q-learning	['Model-free Deep RL', 'Actor-Critic', 'Estimation Bias', 'Continuous Control']	OPAC achieves higher average rewards than relevant baselines and mitigates the underestimation bias with the help of Clipped Triple Q-learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|opportunistic_actorcritic_opac_with_clipped_triple_qlearning	/pdf/160835fa3b9b00f5217dcb65dba54dabdf3adbf0.pdf
FkRMv-mlSTy	6230	Adaptive Computation with Elastic Input Sequence	['Adaptive computation', 'dynamic allocation of computation budget.']	We present a new perspective for embattling dynamic allocation of computation budget to different inputs via introducing elasticity to the input length.	Deep Learning and representational learning	anonymous|adaptive_computation_with_elastic_input_sequence	/pdf/c8ec776959490d1b2dbb1e4a1c4f1955862a8b31.pdf
MIy9IfYlecR	6231	Learning Test Time Augmentation with Cascade Loss Prediction	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_test_time_augmentation_with_cascade_loss_prediction	/pdf/e902e846020e4c615f296ebeff709d79a3667621.pdf
JpbLyEI5EwW	6233	Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data 	['implicit bias', 'gradient descent', 'gradient flow', 'neural networks']		Deep Learning and representational learning	anonymous|implicit_bias_in_leaky_relu_networks_trained_on_highdimensional_data	/pdf/5954e0304f284c0e6a1dfb3a095810f0c2f78199.pdf
aMbzoO5go4r	6234	Deconfounded Noisy Labels Learning	['Noisy labels learning', 'image classification', 'causal inference.']	Explicitly deconfound noisy label learning with causal adjustment, which eliminates the spurious correlation between labels and background representation and preserves true causal effect between labels and foreground representation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|deconfounded_noisy_labels_learning	/pdf/9733bf494ce89b32cdf5dd9646b8d2fad696fefc.pdf
CBfYffLqWqb	6235	Evolving Populations of Diverse RL Agents with MAP-Elites	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|evolving_populations_of_diverse_rl_agents_with_mapelites	/pdf/874212cdb64b0accf92f09684f51dc7b826b4bb4.pdf
JmC_Tld3v-f	6236	Individual Privacy Accounting with Gaussian Differential Privacy	['differential privacy', 'gaussian differential privacy', 'fully adaptive compositions', 'privacy accounting', 'individual privacy loss']	Accurate privacy analysis of fully adaptive compositions using Gaussian differential privacy	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|individual_privacy_accounting_with_gaussian_differential_privacy	/pdf/095d60203c0c6f12b65b91c1c49771e6cf9ea050.pdf
WHlt5tLz12T	6237	LiftedCL: Lifting Contrastive Learning for Human-Centric Perception	['contrastive learning', 'human-centric perception']	We present LiftedCL for self-supervised learning, which improves contrastive learning by leveraging 3D human structure information to learn 3D-aware human-centric representations.	Unsupervised and Self-supervised learning	anonymous|liftedcl_lifting_contrastive_learning_for_humancentric_perception	/pdf/438907ee27cdd971d0517b3f4c368b2069602026.pdf
by_KjUv-7YC	6238	Text2Model: Model Induction for Zero-shot Generalization Using Task Descriptions	['zero-shot learning', 'vision and language']	Produce a model for a classification task described in text at inference time without training; using equivariant hypernetworks	Deep Learning and representational learning	anonymous|text2model_model_induction_for_zeroshot_generalization_using_task_descriptions	/pdf/43c743af22ca9538ca068e9a533228ca69fd4414.pdf
9gRIOMVLCiH	6241	Toward Learning Geometric Eigen-Lengths Crucial for Robotic Fitting Tasks	['Visual Representation Learning', 'Shape Understanding']	We formulate a novel learning problem and explore learning frameworks to discover useful low-dimensional yet sufficient geometric eigen-lengths for fitting tasks.	Deep Learning and representational learning	anonymous|toward_learning_geometric_eigenlengths_crucial_for_robotic_fitting_tasks	/pdf/b51bbbc72158292caf009835c784f2d61060ad88.pdf
Gkbxt7ThQxU	6242	Explicitly Maintaining Diverse Playing Styles in Self-Play	['Reinforcement learning', 'evolutionary algorithm', 'self-play', 'diverse playing styles', 'high skill levels']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|explicitly_maintaining_diverse_playing_styles_in_selfplay	/pdf/85425bf169c716a88d25cd203e5713ab024a7db4.pdf
YPKBIILy-Kt	6247	Confidence-Based Feature Imputation for Graphs with Partially Known Features	['Graph neural networks', 'Graphs', 'Missing features']	For graphs with missing features, we define a novel concept of confidence and propose a pseudo-confidence-based feature imputation (PCFI) scheme.	Deep Learning and representational learning	anonymous|confidencebased_feature_imputation_for_graphs_with_partially_known_features	/pdf/557d6fea043cb025c5d2142c1c59531ce5f68c34.pdf
PfPrnKDtvIG	6250	Multi-Agent Reinforcement Learning with Shared Resources for Inventory Management	['Multi-Agent Reinforcement Learning', 'Inventory Mangement']	We propose a scalable and effective method to control a large number of agents for inventory management.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|multiagent_reinforcement_learning_with_shared_resources_for_inventory_management	/pdf/a057d061dce08b6196f98519eeb910da2526caad.pdf
_i0-12XqVJZ	6251	Asynchronous Distributed Bilevel Optimization	[]		Optimization (eg, convex and non-convex optimization)	anonymous|asynchronous_distributed_bilevel_optimization	/pdf/f6e8742f2c064095ebafee62883e5f3bd191226d.pdf
Opcegzztjay	6252	Causal Explanations of Structural Causal Models	['explanatory interactive learning', 'explainable artificial intelligence', 'causal explanations', 'structural causal models', 'user study']	As a step towards causal XIL, we propose a solution to the lack of truly causal explanations from existing methods.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|causal_explanations_of_structural_causal_models	/pdf/68f99cdcbe3d67ca042985eb44fb947a252be739.pdf
xOPd5QO_5RT	6253	Generalizable Multi-Relational Graph Representation Learning:  A Message Intervention Approach	['Multi-Relational Graph', 'Causal Inference', 'Representation Learning', 'Graph Neural Network']	A message intervention method for learning generalizable multi-relational graph representations	Deep Learning and representational learning	anonymous|generalizable_multirelational_graph_representation_learning_a_message_intervention_approach	/pdf/255644c9dee71e168941ff9a1afc5ab649533749.pdf
-SBZ8c356Oc	6254	Improving Adversarial Robustness by Putting More Regularizations on Less Robust Samples	['Adversarial Training', 'Adversarial Attack', 'Robust Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|improving_adversarial_robustness_by_putting_more_regularizations_on_less_robust_samples	/pdf/c84018b26cde8b7e4e75bb8c9f3b8d22f14b6295.pdf
uV1A7jemwS8	6256	GM-VAE: Representation Learning with VAE on Gaussian Manifold	['VAE', 'Representation learning', 'Hyperbolic space', 'Distribution on Riemannian manifold', 'Information geometry']	We propose a Gaussian manifold VAE whose latent space consists of diagonal Gaussians and a stable distribution over the space, by using information geometry. 	Deep Learning and representational learning	anonymous|gmvae_representation_learning_with_vae_on_gaussian_manifold	/pdf/a15f495223abc7167fcc4d8fb503520f1c0a30ab.pdf
_JScUk9TBUn	6257	Uniform-in-time propagation of chaos for the mean field gradient Langevin dynamics	['Neural network optimization', 'mean-field regime', 'interacting particle system', 'propagation of chaos']		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|uniformintime_propagation_of_chaos_for_the_mean_field_gradient_langevin_dynamics	/pdf/1ab8d35a0ce8bf28ea4f728e4f1636e275e3cae0.pdf
mNk7mgWZcJa	6258	Scrunch: Preventing sensitive property inference through privacy-preserving representation learning	['privacy', 'machine learning as a service', 'center loss']	A system, based on the center loss function, to produce private machine learning data exchange for machine learning as a service scenarios	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|scrunch_preventing_sensitive_property_inference_through_privacypreserving_representation_learning	/pdf/ab1ee750f80ebe40048f0b61baea95e0a6a468c1.pdf
FzKeidp3qnB	6260	Learning Layered Implicit Model for 3D Avatar Clothing Representation	['Geometric Representation', '3D Cloth', 'Human Body', 'Implicit Surface']	We present a novel 3D cloth represention, i.e., a neural implicit surface model conditioned on volumetric SMPL prior, to capture realistic clothes from raw scans.	Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_layered_implicit_model_for_3d_avatar_clothing_representation	/pdf/0844a0154542aa5df79ec04fcc1a33fb265027da.pdf
FhYkgzYNMQ7	6261	On Representation Learning in the First Layer of Deep CNNs and the Dynamics of Gradient Descent	[]		Deep Learning and representational learning	anonymous|on_representation_learning_in_the_first_layer_of_deep_cnns_and_the_dynamics_of_gradient_descent	/pdf/be692845144f60da2b8bb9ad52330571b5457259.pdf
6BHlZgyPOZY	6262	Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|neuroevolution_is_a_competitive_alternative_to_reinforcement_learning_for_skill_discovery	/pdf/a17060081443a48352632833b54ea297b77abced.pdf
T6NIgvKRb7b	6263	Denoising Differential Privacy in Split Learning	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|denoising_differential_privacy_in_split_learning	/pdf/3c75540cb3e6312cf637667d52db6ce609c9268f.pdf
6s5HaPx6ndR	6264	Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration	['eye-tracking', 'transformers', 'self-attention', 'code exploration', 'source code', 'neural models of code']	We compare how developers and GPT-like language models navigate snippets of source code.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|extracting_meaningful_attention_on_source_code_an_empirical_study_of_developer_and_neural_model_code_exploration	/pdf/376f6c58b8ffe7493924ef82c9acb3dcdbede6c7.pdf
5iibKv7Wk8W	6267	Mixture of Basis for Interpretable Continual Learning with Distribution Shifts	['continual learning', 'lifelong learning', 'distribution shift', 'interpretable learning', 'semi-supervised learning']	We develop a novel continual learning algorithm, Mixture of Basis models (MoB), that constructs a dynamic, task-dependent, mixture of interpretable models that outperforms other continual learning algorithms on several, diverse problem domains.	Deep Learning and representational learning	anonymous|mixture_of_basis_for_interpretable_continual_learning_with_distribution_shifts	/pdf/14b57db2ac799a4b9ae1ee79cb374c7f19f311bd.pdf
9pA3oXBwYh7	6269	Towards biologically plausible Dreaming and Planning	['Reinforcement Learning', 'Model based', 'Biologically Plausible']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|towards_biologically_plausible_dreaming_and_planning	/pdf/fb51a9a71d3de1574503bd9794077610ff6e3515.pdf
6apN9AQ-3fN	6272	Distance VS. Coordinate: Distance Based Embedding Improves Model Generalization for Routing Problems	['routing problems', 'travelling salesman problem', 'combinatorial optimization', 'pickup and delivery', 'embedding']	Distance based embedding is a better choice for routing problems, compared to coordinate based embedding.	Deep Learning and representational learning	anonymous|distance_vs_coordinate_distance_based_embedding_improves_model_generalization_for_routing_problems	/pdf/38fe12d316a1646460d951450e7cad85c0cb8a58.pdf
n1bLgxHW6jW	6273	Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation	['zeroth-order optimization', 'derivative estimation', 'finite difference']		Optimization (eg, convex and non-convex optimization)	anonymous|zerothorder_optimization_with_trajectoryinformed_derivative_estimation	/pdf/e899abaae31a4a6fffe169cb6082a2ed234f54f1.pdf
vNrmEgfGIg3	6275	Filtered Semi-Markov CRF	['Structured prediction', 'Text segmentation', 'Named Entity Recognition']		Applications (eg, speech processing, computer vision, NLP)	anonymous|filtered_semimarkov_crf	/pdf/37aa2172a3280cacc9f777a8d993ded299eb274b.pdf
krcFYSfcbhx	6276	Exploiting Personalized Invariance for Better Out-of-distribution Generalization in Federated Learning	['Federated Learning', 'Out-of-distribution Generalization', 'Non-IID', 'Personalization', 'Invariant Learning']	We are the first to consider the challenging out-of-distribution generalization problem under Non-IID federated learning setting and propose the novel concept of personalized invariance and method to handle it.	Deep Learning and representational learning	anonymous|exploiting_personalized_invariance_for_better_outofdistribution_generalization_in_federated_learning	/pdf/3bd617d36661d2ce66542102a39436d4dfa9d3c4.pdf
dqZ_GFn7Nuh	6277	AUTOMATIC CURRICULUM FOR UNSUPERVISED REIN- FORCEMENT LEARNING	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|automatic_curriculum_for_unsupervised_rein_forcement_learning	/pdf/23ba8c23843769fe85abcadf531b5074849fc24c.pdf
iEE0MadUaZh	6279	Help Me Explore: Combining Autotelic and Social Learning via Active Goal Queries	['Exploration', 'Teachability', 'Autotelism', 'Social Interaction', 'Curriculum Learning']	We propose to blend individual and socially-guided skill learning in multi-goal environments with a new interaction protocol named Help Me Explore in which the agent chooses to seek external help for exploration or autonomously learn to master goals.	General Machine Learning (ie none of the above)	anonymous|help_me_explore_combining_autotelic_and_social_learning_via_active_goal_queries	/pdf/a5a3954f5e22c2330f5e3ec01ace179fa96215f4.pdf
yBOlJNIX0jN	6280	Farsighter: Efficient Multi-step Exploration for Deep Reinforcement Learning	[]		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|farsighter_efficient_multistep_exploration_for_deep_reinforcement_learning	/pdf/49e00675e7194a238bd2b7102865a4f2993cddbe.pdf
VBTJqqWjxMv	6281	A Message Passing Perspective on Learning Dynamics of Contrastive Learning	[]		Unsupervised and Self-supervised learning	anonymous|a_message_passing_perspective_on_learning_dynamics_of_contrastive_learning	/pdf/42a30e867ea7b6fa74c2c960e5014e62af6ceea9.pdf
HlRfoQDDj-V	6282	Proximal Validation Protocol	[]		General Machine Learning (ie none of the above)	anonymous|proximal_validation_protocol	/pdf/922372d10a1ff76197d5e9962f85fc492ad1786d.pdf
9Y0P3YoERSy	6283	The GANfather: Controllable generation of malicious activity to expose detection weaknesses and improve defence systems.	[]		Generative models	anonymous|the_ganfather_controllable_generation_of_malicious_activity_to_expose_detection_weaknesses_and_improve_defence_systems	/pdf/3c31cac529f04062bb9677a37b136a4ff6beebcf.pdf
IlkQffBxiC7	6284	Breaking Large Language Model-based Code Generation	['large language models', 'code generation', 'controlled generation', 'attacks', 'reliability', 'reinforcement learning']	We present BreaC, a novel method for breaking large language model-based code generators such that they excessively generate erroneous code.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|breaking_large_language_modelbased_code_generation	/pdf/da54ad28785cfe8a33b83ca1f03d007f39088cef.pdf
OhjGzRE5N6o	6286	Protein Sequence Design in a Latent Space via Model-based Reinforcement Learning	['Biological sequence design', 'Model-based reinforcement learning', 'Protein design', 'Representation learning']	This study investigates why many model-based biological sequence design methods produce results that empirically fail and proposes a novel optimization process that can efficiently traverse a latent representation space instead of the sequence space.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|protein_sequence_design_in_a_latent_space_via_modelbased_reinforcement_learning	/pdf/76b43ba9fd2e31a41d09b3c66f8c8f6eae63f23f.pdf
P63GxgD7LIl	6290	TransFool: An Adversarial Attack against Neural Machine Translation Models	['Adversarial attack', 'deep neural network', 'language model', 'natural language processing', 'neural machine translation', 'robstness.']	We propose TransFool to build adversarial attacks against neural machine translation systems, which are fluent sentences and semantically similar to the original sentence, but highly degrade the translation quality. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|transfool_an_adversarial_attack_against_neural_machine_translation_models	/pdf/b659ef6c777ddc085954d84c6f4008c7df6c2514.pdf
FmpRQpQLs5J	6292	Model-based Unknown Input Estimation via Partially Observable Markov Decision Processes	['unknown input estimation', 'partially observable markov decision process', 'model-based reinforcement learning', 'model predictive control', 'cross-entropy method', 'dynamics modeling']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|modelbased_unknown_input_estimation_via_partially_observable_markov_decision_processes	/pdf/c401ca4eea82a11cff1666a858f21b1122981850.pdf
_q7A0m3vXH0	6294	Geometrically regularized autoencoders for non-Euclidean data	['autoencoders', 'Riemannian geometry', 'non-Euclidean data', 'regularization', 'score estimation']	We propose geometrically regularized autoencoders for non-Euclidean data and discuss their various use cases.	Deep Learning and representational learning	anonymous|geometrically_regularized_autoencoders_for_noneuclidean_data	/pdf/6c15e3a7518e9a9df11dc0747662a4a0548a5d86.pdf
oiwXWPDTyNk	6296	Concept-level Debugging of Part-Prototype Networks	['explainability', 'debugging', 'self-explainable networks', 'part-prototype networks', 'concept-based models']	A novel and human-friendly concept-level debugger for part-prototype networks.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|conceptlevel_debugging_of_partprototype_networks	/pdf/257ae22acf2ce099323cdf84237184fbac82cc13.pdf
tcHwiu6CJ_B	6298	MEDOE: A Multi-Expert Decoder and Output Ensemble Framework for Long-tailed Semantic Segmentation	['semantic segmentation', 'long-tailed distribution']	We proposed MEDOE framework to address the long-tailed distribution in semantic segmentation	Deep Learning and representational learning	anonymous|medoe_a_multiexpert_decoder_and_output_ensemble_framework_for_longtailed_semantic_segmentation	/pdf/4b62b1d2579cde86e59d6336f5c2104767d0a682.pdf
dC31wEs-hsV	6299	Versatile Energy-Based Models for High Energy Physics	['Generative modeling', 'Energy-based models', 'Out-of-distribution detection']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|versatile_energybased_models_for_high_energy_physics	/pdf/aace536619f661436137ac864a3d11c207ab3865.pdf
FLr9RRqbwB-	6300	Batch Normalization and Bounded Activation Functions	['Batch Normalization', 'Activation Functions', 'Saturation', 'Sparsity']	With bounded activation functions, using batch normalization after activation functions is better because of asymmetric saturation and sparsity. 	Deep Learning and representational learning	anonymous|batch_normalization_and_bounded_activation_functions	/pdf/3e6199df247b71f0a5462071f2ed2f4640e92830.pdf
KNSRDB-clPX	6301	Improving Protein Interaction Prediction using Pretrained Structure Embedding	['pretrianing', 'protein', 'PPI']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|improving_protein_interaction_prediction_using_pretrained_structure_embedding	/pdf/adc1d5a74d5234b5cde555ff54d989ee284b42c3.pdf
dXmWWc7GHVU	6302	Contrastive Representation Learning for Multi-scale Spatial Scenes	[]		Deep Learning and representational learning	anonymous|contrastive_representation_learning_for_multiscale_spatial_scenes	/pdf/b3ebca4492c899287ab933be3447c2d11d080a1a.pdf
hZ2H2Ps5dp6	6305	What's in a name? The Influence of Personal Names on Spatial Reasoning in BLOOM Large Language Models	['BLOOM', 'Bias', 'Large Language Model']	BLOOM models are susceptible to undesirable variations in reasoning ability depending on the choice of personal names even though the reasoning task does not depend on the choice of names.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|whats_in_a_name_the_influence_of_personal_names_on_spatial_reasoning_in_bloom_large_language_models	/pdf/c44f372d1561af9d0f23e33c36a8c3688e695c3b.pdf
5T80c_5NSbV	6306	A sparse, fast, and stable representation for multiparameter topological data analysis	['Topological Data Analysis', 'Algebraic Topology', 'Persistent Homology', 'Kernel Methods']	In this article, we provide a general framework for representing multiparameter persistent homology with stability guarantees.	Deep Learning and representational learning	anonymous|a_sparse_fast_and_stable_representation_for_multiparameter_topological_data_analysis	/pdf/651abda59a7cebcd0886f43847917200cf5ab9f3.pdf
jevY-DtiZTR	6308	Mole-BERT: Rethinking Pre-training Graph Neural Networks for Molecules	['graph neural networks']	We explain the negative transfer in molecular graph pre-training and develop two novel pre-training strategies to alleviate this issue.	Deep Learning and representational learning	anonymous|molebert_rethinking_pretraining_graph_neural_networks_for_molecules	/pdf/434800247b82a028eed68a1e35bfd476a5dcf49a.pdf
j1HyTEWHTT	6309	Face reconstruction from facial templates by learning latent space of a generator network	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|face_reconstruction_from_facial_templates_by_learning_latent_space_of_a_generator_network	/pdf/b87ec02a8bfbd124ab77d71d02fddf1b6a36d7db.pdf
oL2uVCVlyf	6312	When and Why Is Pretraining Object-Centric Representations Good for Reinforcement Learning?	['object-centric representation', 'reinforcement learning']		Deep Learning and representational learning	anonymous|when_and_why_is_pretraining_objectcentric_representations_good_for_reinforcement_learning	/pdf/ae2bb181153acb3baac81a6d98f4fe85f0b3fe1e.pdf
d5U-bPKPde	6313	Group-Disentangling Conditional Shift	['group disentanglement', 'variational autoencoders', 'conditional shift']	A VAE-based model that can group-disentangle data under conditional shift, evaluated on fair comparisons between student test scores.	Unsupervised and Self-supervised learning	anonymous|groupdisentangling_conditional_shift	/pdf/c6d8466367b05558ee180537afddeab9025e949f.pdf
ashgrQnYsm	6316	MBrain: A Multi-channel Self-Supervised Learning Framework for Brain Signals	['brain signals', 'self-supervised learning', 'multi-channel time series', 'seizure detection']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|mbrain_a_multichannel_selfsupervised_learning_framework_for_brain_signals	/pdf/7d9897c19d4521d3f485537d3193f545675fdea3.pdf
l6CpxixmUg	6317	Modeling content creator incentives on algorithm-curated platforms	['Nash equilibria', 'producer incentives', 'attention monetizing platforms', 'recommenders', 'differentiable games', 'exposure game']	Algorithmic choices in modern recommenders may have significant and unexpected effects on content creator incentives.	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|modeling_content_creator_incentives_on_algorithmcurated_platforms	/pdf/d06719fa1029140b0d8702966b9e91dfbd9a70fb.pdf
ueEMZjY9WiM	6319	Compression-aware Training of Neural Networks using Frank-Wolfe	['compression aware', 'neural network', 'frank-wolfe', 'pruning']		Optimization (eg, convex and non-convex optimization)	anonymous|compressionaware_training_of_neural_networks_using_frankwolfe	/pdf/1c2e81ce8b3a79dd480cf4bb09df18814081df68.pdf
KL6i1IdwQ6z	6320	xTrimoDock: Cross-Modal Transformer for Multi-Chain Protein Docking	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|xtrimodock_crossmodal_transformer_for_multichain_protein_docking	/pdf/b542f327a376299f7cf8fe6130b1212ade4a1017.pdf
xfqDe72zh41	6321	Actionable Neural Representations: Grid Cells from Minimal Constraints	['Grid Cells', 'Representation Theory', 'Theoretical Neuroscience', 'Normative Models']	We study a novel definition of an optimal representation of structured spaces, and show that it can be used to derive the brain's grid cells and their perturbations normatively.  	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|actionable_neural_representations_grid_cells_from_minimal_constraints	/pdf/de3c857e6a33e2b22413a4c5da34d77c7122a84a.pdf
eZN8nUXAVO7	6322	FedGC: An Accurate and Efficient Federated Learning under Gradient Constraint for Heterogeneous Data	['Federated Learning', 'Non-IID data']	An accurate and efficient Federated Learning method is proposed to improve the performance on Non-IID data by mitigating catastrophic forgetting at clients and effectively aggregating clients’ knowledge at server, while reducing local training time.	Deep Learning and representational learning	anonymous|fedgc_an_accurate_and_efficient_federated_learning_under_gradient_constraint_for_heterogeneous_data	/pdf/22df531185b359dc4d436956eecf11c436bc6ac3.pdf
j7MnZOwaQ__	6323	UiTTa: Online Test-Time Adaptation by User Interaction	['Test-time Adaptation', 'Human-AI Interaction', 'Model Robustness', 'Distribution Shift']	We explore test-time adaptation from model-user interaction. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|uitta_online_testtime_adaptation_by_user_interaction	/pdf/ba006ef91d2f711097c7bd0977d95a0d6e3d3268.pdf
3c13LptpIph	6324	Behavior Proximal Policy Optimization 	['Offline Reinforcement Learning', 'Monotonic Policy Improvement']	 We propose Behavior Proximal Policy Optimization (BPPO), which bases on on-policy method (PPO) and effectively solves offline RL without any extra constraint or regularization introduced. 	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|behavior_proximal_policy_optimization	/pdf/cf6e2a87489f93bad25ac806676ae68656792de7.pdf
UazgYBMS9-W	6325	Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study	['Natural Language Processing', 'Probing Study']		Applications (eg, speech processing, computer vision, NLP)	anonymous|can_bert_refrain_from_forgetting_on_sequential_tasks_a_probing_study	/pdf/b93c80eaabc7cb7c731f5c252a98fc10c76bb145.pdf
dyifcA9UuRo	6326	Neural Probabilistic Logic Programming in Discrete-Continuous Domains	['neural-symbolic AI', 'logic', 'probability', 'neural networks', 'probabilistic logic programming', 'neuro-symbolic integration', 'learning and reasoning']	DeepSeaProbLog: a neural probabilistic logic programming language with discrete and continuous random variables.	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|neural_probabilistic_logic_programming_in_discretecontinuous_domains	/pdf/0467c4d9a2a599f32b175652bbb4f2a85117f1c2.pdf
SEcSahl0Ql	6328	Iterative Circuit Repair Against Formal Specifications	['sequential circuits', 'repair', 'synthesis', 'transformer']	We present a deep learning approach for repairing sequential circuits against formal specifications given in linear-time temporal logic (LTL).	Applications (eg, speech processing, computer vision, NLP)	anonymous|iterative_circuit_repair_against_formal_specifications	/pdf/74e4dd16bf820b343a00387c2706528a102766d8.pdf
i8AnfJYMvz	6329	Beyond Reward: Offline Preference-guided Policy Optimization	['offline reinforcement learning', 'preference-based reinforcement learning', 'hindsight information matching', 'preference-guided policy optimization']	We propose an end-to-end offline preference-based reinforcement learning formulation that directly optimizes the policy by preference supervision without learning a separate reward function.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|beyond_reward_offline_preferenceguided_policy_optimization	/pdf/a304af0759c11a56d8b3f9ee53b96d456aaaeb29.pdf
BdcfKgE9dhF	6331	Robust Training through Adversarially Selected Data Subsets	['Subset selection', 'Robust learning']	Develops robust learning strategy where a subset of instances are selectively chosen for perturbation and the selection strategy is never revealed to the learner.	General Machine Learning (ie none of the above)	anonymous|robust_training_through_adversarially_selected_data_subsets	/pdf/4d2115728caab0ef99919d61011f968576a2ecc8.pdf
LNpMtk15AS4	6333	Boosting Causal Discovery via Adaptive Sample Reweighting	['Causal Structure Learning', 'Score-based Causal Discovery', 'Adaptive Sample Reweighting']	Automatically learn the adaptive weights for each observation to boost score-based causal discovery performance. 	General Machine Learning (ie none of the above)	anonymous|boosting_causal_discovery_via_adaptive_sample_reweighting	/pdf/51314d2fc3b7a6fd854d288372ab98cb6b26a5a3.pdf
Lgp4Y2Tor34	6334	Smooth image-to-image translations with latent space interpolations	['image-to-image translation', 'GANs', 'mixup', 'latent spaces interpolation']	We are regularizing the latent spaces to have super smooth image-to-image translations. We also created a metric to quantitatively measure how smooth the translations.	Generative models	anonymous|smooth_imagetoimage_translations_with_latent_space_interpolations	/pdf/184032fcc7ad691ec932fad7c29ee2ec78d96a35.pdf
mnVf1W6ipGm	6335	Unveiling the sampling density in non-uniform geometric graphs	['graph neural network', 'graph representation learning', 'spectral method', 'non-uniform sampling', 'geometric graph', 'graphon']	We introduce geometric graphs with hubs, an effective model for real-world graphs, and retrieve the sampling density by which those graphs are sampled from continuous latent spaces, to achieve various tasks.	Deep Learning and representational learning	anonymous|unveiling_the_sampling_density_in_nonuniform_geometric_graphs	/pdf/5fe0b1231ed18018628abb1090ba7f4ec7228186.pdf
Z2oC6xxaWPL	6337	Light and Accurate: Neural Architecture Search via Two Constant Shared Weights Initialisations	['neural architecture search', 'zero-cost', 'machine learning']	Zero-cost neural architecture search with two forward passes: no gradients, no labels, any architecture type, high accuracy.	General Machine Learning (ie none of the above)	anonymous|light_and_accurate_neural_architecture_search_via_two_constant_shared_weights_initialisations	/pdf/e0a191af3074e47d002f5f7a5f1c45b64edc451e.pdf
gvOSQjGTtxj	6338	Deep autoregressive density nets vs neural ensembles for model-based offline reinforcement learning	['Offline reinforcement learning', 'batch reinforcement learning', 'ensemble', 'autoregressive', 'D4RL', 'model-based']	We show in model-based offline reinforcement learning a better performance can be obtained with a single well-calibrated autoregressive system model than with the usual ensembles.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|deep_autoregressive_density_nets_vs_neural_ensembles_for_modelbased_offline_reinforcement_learning	/pdf/c0b676e01a44fda52acb1140953f26352ed965da.pdf
kqHkCVS7wbj	6339	Decision S4: Efficient Sequence-Based RL via State Spaces Layers	['Sequential RL', 'S4', 'Decision transformers']	Replacing transformers with state-space layers for RL modeling. Also extended to on-policy training.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|decision_s4_efficient_sequencebased_rl_via_state_spaces_layers	/pdf/d4215a2e852dfcfc212f44f78d591b6d23436587.pdf
8zsK9lbna9L	6342	RephraseTTS: Dynamic Length Text based Speech Insertion with Speaker Style Transfer	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|rephrasetts_dynamic_length_text_based_speech_insertion_with_speaker_style_transfer	/pdf/35ff3082cb65f28b7b7de5572b8fd160823eddd8.pdf
pvgEL1yS3Ql	6346	Cross-Layer Retrospective Retrieving via Layer Attention	['Layer Attention', 'Recurrent Layer Attention', 'Layer Interaction', 'CNNs', 'Vision Transformers', 'Vision Networks']	A multi-head recurrent layer attention mechanism is proposed to retrieve query-related information from previous layers.	Deep Learning and representational learning	anonymous|crosslayer_retrospective_retrieving_via_layer_attention	/pdf/5291eb517cb2a6a9c32315619277312965f753f7.pdf
WP0zFLrO01	6349	Convergence Rate of Primal-Dual Approach to Constrained Reinforcement Learning with Softmax Policy	['Constrained Reinforcement Learning', 'Constrained Markov Decision Process']	We propose a primal-dual policy gradient approach to solve constrained reinforcement learning problems, and show it needs iteration complexity.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|convergence_rate_of_primaldual_approach_to_constrained_reinforcement_learning_with_softmax_policy	/pdf/a6f7da62bd8b38e288d327a9cd88ac7027ec41ce.pdf
75O7S_L4oY	6350	Learning Group Importance using the Differentiable Hypergeometric Distribution	['hypergeometric distribution', 'weakly-supervised learning', 'reparameterization trick', 'group importance', 'variational clustering', 'gumbel softmax']	We propose the differentiable hypergeometric distribution and show the advantage of explicitly learning subset sizes.	Deep Learning and representational learning	anonymous|learning_group_importance_using_the_differentiable_hypergeometric_distribution	/pdf/41bb7a5599e1d27d2b3912d07bd5195363091013.pdf
bjPPypbLre	6351	Making Substitute Models More Bayesian Can Enhance Transferability of Adversarial Examples	['Adversarial Examples', 'Black-box Attacks', 'Adversarial Transferability']		Deep Learning and representational learning	anonymous|making_substitute_models_more_bayesian_can_enhance_transferability_of_adversarial_examples	/pdf/23bb8d0f281f12443096b99dd534c82589c9e171.pdf
ngV1BPp6xDc	6353	Grounded Contrastive Learning for Open-world Semantic Segmentation	['open-world semantic segmentation', 'zero-shot segmentation']	We propose a novel open-world segmentation framework using image-text pairs, which optimizes text-region alignment explicitly.	Applications (eg, speech processing, computer vision, NLP)	anonymous|grounded_contrastive_learning_for_openworld_semantic_segmentation	/pdf/3e047886f6a529ddd56e9fd1b2e10740ddbfe28d.pdf
pcBJT4bgbpH	6356	Attention Flows for General Transformers	['transformer', 'explanations', 'attention flow', 'shapley value']	We formalize and generalize a method to construct a flow network out of the attention values of Transformer models to compute how much an input token influences a model's prediction.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|attention_flows_for_general_transformers	/pdf/856b9edd10a128b8bf6928a5ef34cf3fcbfdf3b8.pdf
688hNNMigVX	6357	Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering	['Automated Feature Engineering', 'Reinforcement Learning', 'Tabular Data', 'Data-Driven', 'Pre-Training']	We propose a data-driven automated feature engineering framework Fetch.	General Machine Learning (ie none of the above)	anonymous|learning_a_datadriven_policy_network_for_pretraining_automated_feature_engineering	/pdf/e74b444f8e160c99840ef1a7ba4559e53cfb61a7.pdf
05ff9BRSMzE	6358	Gandalf : Data Augmentation is all you need for Extreme Classification	['Extreme Classification', 'Data Augmentation', 'Search and Recommendation']		Deep Learning and representational learning	anonymous|gandalf_data_augmentation_is_all_you_need_for_extreme_classification	/pdf/abd30c644772dec9e1418ecef679e117d4673060.pdf
7HSHJQwkna0	6359	Learn Together, Stop Apart: An Inclusive Approach To Early Stopping	['ensemble', 'boosting', 'regularization', 'clusterization']	We propose a new scheme to GB pruning based on adaptive stops for different data regions	General Machine Learning (ie none of the above)	anonymous|learn_together_stop_apart_an_inclusive_approach_to_early_stopping	/pdf/c990b31f35c4035ad422fc06c0145215ef4ff697.pdf
TN9gQ4x0Ep3	6362	Don’t fear the unlabelled: safe semi-supervised learning via debiasing	['Semi-supervised learning', 'deep learning', 'empirical risk minimisation', 'control variate', 'variance reduction', 'asymptotic statistics']	We propose a slight modification of most common semi-supervised learning methods to make them safe by debiasing their risk estimate. In particular, we apply it successfully to Fixmatch.	Unsupervised and Self-supervised learning	anonymous|dont_fear_the_unlabelled_safe_semisupervised_learning_via_debiasing	/pdf/7ad565f4db757eee2158c1944c014a475714d7e6.pdf
-hMNEMgT8Wd	6363	RG: OUT-OF-DISTRIBUTION DETECTION WITH REACTIVATE GRADNORM	['OOD detection', 'Uncertainty Learning']	The information of joint feature space and output space improves the performance of OOD detection.	General Machine Learning (ie none of the above)	anonymous|rg_outofdistribution_detection_with_reactivate_gradnorm	/pdf/d4398d8fafc7de5ca196b1d8ee879cddfd847465.pdf
70-hEqC4Wo8	6364	Accelerating spiking neural network training using the $d$-block model	['spiking neural networks', 'accelerated training', 'stochastic refractory period', 'stochastic recurrent conductance latency']	We propose a new SNN model which obtains accelerated training and state-of-the-art performance across various neuromorphic datasets without the need of any regularisation and using less spikes compared to standard SNNs.	General Machine Learning (ie none of the above)	anonymous|accelerating_spiking_neural_network_training_using_the_dblock_model	/pdf/7a8b0b8c0e35775482d9a53133241b2610590b74.pdf
diOVflNRZnG	6365	Curvature Informed Furthest Point Sampling	['dowsampling', 'point cloud', 'curvature informed', 'shape completion', 'segmentation', 'furthest point sampling']	An extension of furthest point sampling algorithm that takes curvature information into consideration	Deep Learning and representational learning	anonymous|curvature_informed_furthest_point_sampling	/pdf/3be7e499a76369afc7b2f5d052f1f000aec19d6d.pdf
w47MhmAsbzs	6367	Enabling Equation Learning with the Bayesian Model Evidence via systematic $R^2$-elimination	['coefficient of determination', 'Bayesian model evidence', 'model selection', 'Equation Learning']	A pseudo-brute-force model selection strategy using R-squared and Bayesian model evidence that efficiently works for Equation Learning.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|enabling_equation_learning_with_the_bayesian_model_evidence_via_systematic_r^2elimination	/pdf/3a57c933e89f54e251febee70e1af46e7d5c4527.pdf
dpuAkczrTOt	6368	Meta-Learning the Inductive Biases of Simple Neural Circuits	['Inductive Bias', 'Generalisation', 'Meta-Learning', 'Spiking Neural Network', 'Neuroscience']	We meta-learn functions that networks of interest find easy to generalise, characterising their inductive bias; we suggest this as a method for interpreting and understanding network function.	General Machine Learning (ie none of the above)	anonymous|metalearning_the_inductive_biases_of_simple_neural_circuits	/pdf/e4a8d475c4b30a21d68ff2a11e33059ff885ca30.pdf
r3-aLHxn2nB	6370	CLEP: Exploiting Edge Partitioning for Graph Contrastive Learning	['Graph Contrastive Learning']		Unsupervised and Self-supervised learning	anonymous|clep_exploiting_edge_partitioning_for_graph_contrastive_learning	/pdf/45819f7393df32ae20835a5265dd83adc72f281c.pdf
mN43JdXmYMs	6372	Moment Distributionally Robust Probabilistic Supervised Learning	['probabilistic supervised learning', 'distributionally robust optimization', 'proper scoring rules']	We propose a distributionally robust learning approach for predicting conditional label distributions in probabilistic supervised learning.	General Machine Learning (ie none of the above)	anonymous|moment_distributionally_robust_probabilistic_supervised_learning	/pdf/aeee21470192eaa2586e8e5753e1786422f0a4a4.pdf
47DzlkyH3dM	6373	Variational Learning ISTA	['compressed sensing', 'LISTA', 'variational models', 'inverse problems']		Deep Learning and representational learning	anonymous|variational_learning_ista	/pdf/be716f0f90bbada6062ace84b5150131fe6fe42a.pdf
lKXcMB9tOFD	6374	Improved Gradient Descent Optimization Algorithm based on Inverse Model-Parameter Difference	['Deep learning', 'Neural Networks', 'Optimization algorithm', 'Adaptive learning-rate', 'Stochastic Gradient Descent']	A new approach to gradient descent optimization in which learning-rate for each model-parameter is adjusted inversely proportional to the displacement of corresponding model-parameter from preceding iteration.	Deep Learning and representational learning	anonymous|improved_gradient_descent_optimization_algorithm_based_on_inverse_modelparameter_difference	/pdf/15b22408ca36d0073a6ef0f8c7c15bf85b7e83a3.pdf
FEAIArDldTA	6375	Improved Training of Physics-Informed Neural Networks with Model Ensembles	['Label propagation', 'Model ensembles', 'Partial differential equations', 'Physics-informed neural networks']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|improved_training_of_physicsinformed_neural_networks_with_model_ensembles	/pdf/6c2df36d98b57ae452e79b5022372554abc5130f.pdf
L6CKiPH3hI	6376	Enriching Online Knowledge Distillation with Specialist Ensemble	['Online knowledge distillation', 'Label prior shift', 'Ensemble learning']	Online knowledge distillation with an ensemble of specialized teachers that are explicitly estimated for each imbalanced label prior.	Deep Learning and representational learning	anonymous|enriching_online_knowledge_distillation_with_specialist_ensemble	/pdf/106df6de1286d3194dedbfc7ce5741b204d1f47b.pdf
j8s-BRxXST	6378	A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration	['language model', 'contrastive learning', 'repetition', 'degeneration']	To tackle the repetitive degeneration problem of neural autoregressive language models, we propose a token-level contrastive learning objective that penalizes incorrectly repeating tokens.	Generative models	anonymous|a_simple_contrastive_learning_objective_for_alleviating_neural_text_degeneration	/pdf/bce10df55e9f2c18afc84cc87a1e4fafb557c949.pdf
18XzeuYZh_	6379	Online Bias Correction for Task-Free Continual Learning	['Task-Free Continual Learning']		General Machine Learning (ie none of the above)	anonymous|online_bias_correction_for_taskfree_continual_learning	/pdf/606d334ebafd117461e9a5ded1474c785434ddc8.pdf
Wac06sAkHk	6380	Simulating Task-Free Continual Learning Streams From Existing Datasets	['Task-Free Continual Learning']		General Machine Learning (ie none of the above)	anonymous|simulating_taskfree_continual_learning_streams_from_existing_datasets	/pdf/e99c1c435b09d6fa223846a98772bd6af92f046c.pdf
-UsbRlXzMG	6381	How (Un)Fair is Text Summarization?	['Natural language processing', 'Summarization', 'Fairness']	We show that machine learning based summarizers exhibit bias toward different groups and are very sensitive to document structure.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|how_unfair_is_text_summarization	/pdf/ac1c5e90aab0d31e4505c9adf213936e78f30ecf.pdf
rer10Bb-9Qn	6387	Pseudo-Differential Integral Operator for Learning Solution Operators of Partial Differential Equations	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pseudodifferential_integral_operator_for_learning_solution_operators_of_partial_differential_equations	/pdf/e43d87c04546f1bd7678bd5046b309aca93181ff.pdf
F8OUxtWEQRi	6388	Kinship Representation Learning with Face Componential Relation	['kinship recognition', 'attention', 'contrastive learning']	We achieve the SOTA kinship recognition performance by the learning face componential relation with contrastive learning.	Applications (eg, speech processing, computer vision, NLP)	anonymous|kinship_representation_learning_with_face_componential_relation	/pdf/2f9e723fd8d9099b4f95962b7752764235f7557a.pdf
x-mXzBgCX3a	6390	FairGBM: Gradient Boosting with Fairness Constraints	['fairness', 'gradient boosting', 'constrained optimization', 'tabular data']	A novel fairness-aware method based on constrained optimization for Gradient Boosting models, that can match state-of-the-art fairness and performance while training 10x faster.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fairgbm_gradient_boosting_with_fairness_constraints	/pdf/1dac27135307c77d3c2474767e653ea708063b5f.pdf
m3DmIL7wHDW	6393	The guide and the explorer: smart agents for resource-limited iterated batch reinforcement learning	['Model-based reinforcement learning', 'Dyna', 'exploration', 'planning', 'offline', 'growing batch', 'iterated batch']	Smart agents for resource-limited iterated batch reinforcement learning	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|the_guide_and_the_explorer_smart_agents_for_resourcelimited_iterated_batch_reinforcement_learning	/pdf/5a26cf59fe9dcf00c28bfdb2d9e10bf54a6e2818.pdf
7bcrAxy00Jw	6394	Improve distance metric learning by learning positions of class centers	['distance metric learning', 'skewed mean function']		Deep Learning and representational learning	anonymous|improve_distance_metric_learning_by_learning_positions_of_class_centers	/pdf/087cc9907dd431278eccc7cda292cbe29cab8c5c.pdf
HqVp0rNC8jn	6395	Learning Geometric Representations of Interactive Objects	['Representation Learning', 'Interaction', 'Equivariance']	We propose a representation learning framework that extracts from observations the geometric state of both an agent and an object the agent interacts with.	Deep Learning and representational learning	anonymous|learning_geometric_representations_of_interactive_objects	/pdf/050f824cc2dfdff6c08516fae0fc651ac2a0e6a7.pdf
MW0hjtzYRkW	6396	RISC-V MICROARCHITECTURE EXPLORATION VIA REINFORCEMENT LEARNING	['Design Space Exploration', 'Reinforcement Learning']	Microarchitecture design space exploration via reinforcement learning for RISC-V processors	Applications (eg, speech processing, computer vision, NLP)	anonymous|riscv_microarchitecture_exploration_via_reinforcement_learning	/pdf/fee44df9c838f0bcffee0beaebac1c997ee5134d.pdf
wRdGz0ZWYHF	6400	Rethinking Metric Based Contrastive Learning Method’s Generalization Capability	[]		Unsupervised and Self-supervised learning	anonymous|rethinking_metric_based_contrastive_learning_methods_generalization_capability	/pdf/749e999cfadefd9fc3601a898bf367166b777ac5.pdf
rwetAifrs16	6401	Incremental Predictive Coding: A Parallel and Fully Automatic Learning Algorithm	['Cognitive Science', 'deep learning', 'predictive coding']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|incremental_predictive_coding_a_parallel_and_fully_automatic_learning_algorithm	/pdf/05a8eaf8e22ca5a51cf78336a5d2cb5b36fa2b9b.pdf
CcXTudu9bvu	6402	DELTA: Diverse Client Sampling for Fasting Federated Learning	['federated learning', 'client sampling']	We propose a unbiased sampling method that characterizes the impact of client diversity and local variance, and provide a complete theoretical proof and experimental verification.	Optimization (eg, convex and non-convex optimization)	anonymous|delta_diverse_client_sampling_for_fasting_federated_learning	/pdf/232f89bd3671245e1ec43a134f303183c39c88bf.pdf
ywAjQw-spmY	6404	Formal Specifications from Natural Language	['language models', 'natural language', 'formal specifications', 'first-order logic', 'temporal logic', 'regular expressions']	We study the generalization abilities of language models when translating natural language into formal specifications with complex semantics.	Applications (eg, speech processing, computer vision, NLP)	anonymous|formal_specifications_from_natural_language	/pdf/108d15156cc503f6c3eb5ce053e7d7a5b88f243b.pdf
Y1J29OryQg	6408	Causal Inference for Knowledge Graph Completion	['Causal Inference', 'Knowledge Graph Completion']	We propose causal KGC models to alleviate the issues by leveraging causal inference framework.	Applications (eg, speech processing, computer vision, NLP)	anonymous|causal_inference_for_knowledge_graph_completion	/pdf/1db19a07fc713ba2d6c0747c28e5839528f98048.pdf
fyD8adDrXo	6410	HyPHEN: A Hybrid Packing Method and Optimizations for Homomorphic Encryption-Based Neural Network 	['Private Inference', 'Homomorphic Encryption', 'PPML']	Efficient convolution algorithms for private inference based on fully homomorphic encryption	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|hyphen_a_hybrid_packing_method_and_optimizations_for_homomorphic_encryptionbased_neural_network	/pdf/89f2d2eec0d1f0dbdd59921cf708847f0b100378.pdf
4F1gvduDeL	6412	Few-Shot Domain Adaptation For End-to-End Communication	['domain adaptation', 'end-to-end communication', 'autoencoders', 'Gaussian mixtures', 'mixture density networks', 'few-shot', 'wireless channel']	We propose a sample-efficient domain adaptation method for the autoencoder based end-to-end communication problem	Applications (eg, speech processing, computer vision, NLP)	anonymous|fewshot_domain_adaptation_for_endtoend_communication	/pdf/a0faea89aea7aec7076b54aa2a612c6891600a7e.pdf
1BEoYnjZVV	6413	Geometry Problem Solving based on Counterfactual Evolutionary Reasoning	['Counterfactual Reasoning', 'Geometry Problem Solving', 'Symbolic Reasoning']	A new method using counterfactual evolutionary reasoning for geometry problem solving	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|geometry_problem_solving_based_on_counterfactual_evolutionary_reasoning	/pdf/47948a56b44c8f903981e23a66c274dac8ae1cb4.pdf
UPwzqPOs4-	6414	Probing for Correlations of Causal Facts: Large Language Models and Causality	['large language models', 'empirical analysis', 'causal facts']	"We hypothesize that LLMs exploit correlations between the questions on causal relations with their expected (or ""right"") causal answers."	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|probing_for_correlations_of_causal_facts_large_language_models_and_causality	/pdf/a040f82e8781f81c8204b93159e838ee696973dd.pdf
GX0uI5T8kd	6415	Self-Supervised Off-Policy Ranking via Crowd Layer	['off-policy ranking', 'policy representation learning', 'reinforcement learning']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|selfsupervised_offpolicy_ranking_via_crowd_layer	/pdf/bf84e1d5ace8219d3eb6ee9c737350a4ffe59302.pdf
8foynpwwRb	6416	Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning	['Optimization', 'Sharpness-aware Training', 'Computation Efficiency.']	We propose a randomized training policy, called randomized sharpness-aware training, for boosting the compuation efficiency in sharpness-aware training.	Optimization (eg, convex and non-convex optimization)	anonymous|randomized_sharpnessaware_training_for_boosting_computational_efficiency_in_deep_learning	/pdf/33e627e47d0326c2874616ba29443931604a4965.pdf
b5M2oNm3nA	6417	Supervised Q-Learning can be a Strong Baseline for Continuous Control	['Zeroth-Order Method', 'Continuous Control', 'Supervised Optimization']	We propose to use Zeroth-Order supervised policy optimization based on Q-learning as alternative to policy gradient in continuous control tasks.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|supervised_qlearning_can_be_a_strong_baseline_for_continuous_control	/pdf/e2d3a59c3e7e8f99f7d5a71f2c18ef93b674057b.pdf
me09xlTmm8	6427	Transport with Support: Data-Conditional Diffusion Bridges	['diffusion models', 'optimal transport', 'particle filtering', 'stochastic control', 'sequential Monte Carlo']	Conditioning diffusion Schrödinger bridges on intermediate sparse observations via particle filtering	Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|transport_with_support_dataconditional_diffusion_bridges	/pdf/bd0388da4164ff7d6d9d878d4f309465b2663f04.pdf
fQejLClfsw	6428	SWRM: Similarity Window Reweighting and Margins for Long-Tailed Recognition	['Long-tailed recognition', 'class re-balancing', 'reweighting', 'logit adjustment']		Applications (eg, speech processing, computer vision, NLP)	anonymous|swrm_similarity_window_reweighting_and_margins_for_longtailed_recognition	/pdf/b62c29e59268e8310af276964debd9ed021ba091.pdf
htL4UZ344nF	6429	CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code	['source code processing', 'tokenization', 'byte-pair encoding']		Applications (eg, speech processing, computer vision, NLP)	anonymous|codebpe_investigating_subtokenization_options_for_large_language_model_pretraining_on_source_code	/pdf/41d351940f007234285b23b581ce2c0235433744.pdf
-M0TNnyWFT5	6431	Task-Aware Information Routing from Common Representation Space in Lifelong Learning	['Continual learning', 'Lifelong learning', 'Representation learning', 'Global workspace theory', 'Task-specific attention']	A continual learning method that entails task-attention modules to capture task-specific information from the common representation space	Deep Learning and representational learning	anonymous|taskaware_information_routing_from_common_representation_space_in_lifelong_learning	/pdf/7fea74ad7729e28eaa795825b792c7ecadfc570d.pdf
cUX2psP06OL	6433	Manipulating Multi-agent Navigation Task via Emergent Communications	[]		Deep Learning and representational learning	anonymous|manipulating_multiagent_navigation_task_via_emergent_communications	/pdf/d70649372bd87da4adf9b8567b48ce6ae8b653ef.pdf
O_er9uNktN	6435	Cross-utterance Conditioned Coherent Speech Editing via Biased Training and Entire Inference	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|crossutterance_conditioned_coherent_speech_editing_via_biased_training_and_entire_inference	/pdf/7c66e6fcd61f62cd8f152fe05fb87cf5bbd636cf.pdf
eDLwjKmtYFt	6438	EquiMod: An Equivariance Module to Improve Self-Supervised Learning	['Representation learning', 'Self-supervised learning', 'Contrastive learning', 'Equivariance']	We propose a generic equivariance module that structures the learned latent space by learning to predict the displacement in the embedding space caused by augmentations; we show that it improves the representation of usual self-supervised methods.	Deep Learning and representational learning	anonymous|equimod_an_equivariance_module_to_improve_selfsupervised_learning	/pdf/60a169291453be0a6d1bf2e0c8691a195a6127b8.pdf
-4HJSA3Y2vg	6439	MolBART: Generative Masked Language Models for Molecular Representations	['representation learning', 'machine learning for chemistry', 'self-supervised learning', 'molecular representations']	We develop self-supervised representations of molecules using generative masked language models that set state-of-the-art for many chemical property and reaction prediction tasks and implicitly learn features and substructures important in chemistry	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|molbart_generative_masked_language_models_for_molecular_representations	/pdf/119b672290146d984c6229eefa346588a5cf02f0.pdf
5WOIluv9Xop	6440	HOW SAMPLING AFFECTS TRAINING: AN EFFECTIVE SAMPLING THEORY STUDY FOR LONG-TAILED IMAGE CLASSIFICATION	[]		Deep Learning and representational learning	anonymous|how_sampling_affects_training_an_effective_sampling_theory_study_for_longtailed_image_classification	/pdf/5061b4734d8106279a7df77c1c371b783e126e4e.pdf
mmFtinp4wQ_	6443	Thresholded Lexicographic Ordered Multi-Objective Reinforcement Learning	['Reinforcement Learning', 'Lexicographic Ordered Multi-Objectives']	We investigate reinforcement learning for thresholded lexicographic ordered multi-objective settings.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|thresholded_lexicographic_ordered_multiobjective_reinforcement_learning	/pdf/0d701d74dc5033fd7e827cfe06d1b5154be7cd50.pdf
F5Cj26wfiu	6445	xTrimoABFold: Improving Antibody Structure Prediction without Multiple Sequence Alignments 	['Protein structure prediction', 'antibody structure prediction', 'amino acid sequence', 'homologous structure']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|xtrimoabfold_improving_antibody_structure_prediction_without_multiple_sequence_alignments	/pdf/db25cb65c8ef32a617564ec43ad1a30470ae4619.pdf
jkMT2AtccX	6446	Learning Representations for Reinforcement Learning with Hierarchical Forward Models	['Reinforcement learning', 'Representation learning', 'Continuous control']	Hierarchical forward models that predict at varying temporal coarseness and learn to communicate lead to more informative representations and better downstream control.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|learning_representations_for_reinforcement_learning_with_hierarchical_forward_models	/pdf/a13d636c71a5ca5fcf88bfa3e4b9187b0aa0d74c.pdf
WVZQa2QYJN	6448	RuDar: Weather Radar Dataset for Precipitation Nowcasting with Geographical and Seasonal Variability	['precipitation nowcasting', 'weather forecasting', 'weather radar', 'benchmark']	Weather radar dataset with benchmarks for nowcasting (next frame prediction) tasks with seasonal and geographical dependencies	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|rudar_weather_radar_dataset_for_precipitation_nowcasting_with_geographical_and_seasonal_variability	/pdf/4174b7650f19c431247ed816378752f521806a65.pdf
kL67fyKb6A	6450	Online black-box adaptation to label-shift in the presence of conditional-shift	['label-shift', 'online', 'black-box', 'adaptation', 'Bayesian']	Learning hyper-parameters on an OOD validation set can improve online black-box adaptation to label-shift when there is also conditional-shift in deployment	General Machine Learning (ie none of the above)	anonymous|online_blackbox_adaptation_to_labelshift_in_the_presence_of_conditionalshift	/pdf/98bca2739bc24ea714e500cde408395e9afa82a9.pdf
loc3CUXeuzH	6456	Graph Spline Networks for Efficient Continuous Simulation of Dynamical Systems	['Graph', 'Spline Collocation Method', 'Graph Neural Networks', 'Simulation', 'Partial Differential Equations', 'PDEs', 'Physics', 'Scientific Computing']	We propose a novel model to exploit the synergy between graph neural networks and orthogonal spline collocation to accelerate learned simulations of physical systems by interpolating solutions of graph neural networks.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|graph_spline_networks_for_efficient_continuous_simulation_of_dynamical_systems	/pdf/27d0bafc77c6e25d6d730a255a35fc2bc368a473.pdf
BDjGGZk9yz	6460	Supervised Random Feature Regression via Projection Pursuit	['Random Feature', 'multi-kernel', 'projection pursuit', 'semi-parametric regression', 'neural networks']		Unsupervised and Self-supervised learning	anonymous|supervised_random_feature_regression_via_projection_pursuit	/pdf/3ab06ee9ce85788c655c90e5b72f783423f1d60f.pdf
JIptuwnqwn	6461	Quantized Disentangled Representations for Object-Centric Visual Tasks	['quantised representation', 'disentangled representation', 'object-centric task']	We propose quantised disentangled representations that demonstrate state-of-the art performace in set prediction tasks mong a class of object-centric methods.	Deep Learning and representational learning	anonymous|quantized_disentangled_representations_for_objectcentric_visual_tasks	/pdf/255cbf9178283a4bf8e1513b31f45021a195176d.pdf
oJpVVGXu9i	6462	Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning	['Differential Privacy', 'Representation Learning', 'Federated Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|share_your_representation_only_guaranteed_improvement_of_the_privacyutility_tradeoff_in_federated_learning	/pdf/59d1e816cc49dfd2c55f9b4132dd37331e66dc78.pdf
VPX0ln_YoG	6464	Loss Adapted Plasticity: Learning From Data With Unreliable Sources	['Data Sources', 'Unreliable Data', 'Noisy Data', 'Noisy Labels']	To learn from reliable and unreliable data sources, this paper demonstrates a technique that can be applied to any gradient descent optimiser: Update model weights as a function of the perceived reliability of data sources within a wider data set.	Deep Learning and representational learning	anonymous|loss_adapted_plasticity_learning_from_data_with_unreliable_sources	/pdf/df1e473cd0992a4f6f90ca217debe550c13c7989.pdf
X5ZMzRYqUjB	6465	On the Certification of Classifiers for Outperforming Human Annotators	['Evaluation theory', 'Oracle accuracy', 'Superhuman classifier']	A theory for estimating the performance of a classifier by comparing with human annotators, even when the humans are inferior to the classifier.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|on_the_certification_of_classifiers_for_outperforming_human_annotators	/pdf/18a0e858c1a2bf457b2ca3c8bc036b507921be9d.pdf
o3Q4m8jg4BR	6466	LS-IQ: Implicit Reward Regularization for Inverse Reinforcement Learning	['Inverse Reinforcement Learning', 'Imitation Learning', 'Reward Regularization', 'Deep Reinforcement Learning']	We propose a novel perspective on implicit L2 reward regularization for inverse reinforcement learning.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|lsiq_implicit_reward_regularization_for_inverse_reinforcement_learning	/pdf/99a90f10e67e2a6272b43e24f859af1c9eb4c766.pdf
_GcWoi0SQm	6467	Free Bits: Platform-Aware Latency Optimization of Mixed-Precision Neural Networks for Edge Deployment	['Edge AI', 'TinyML', 'Mixed-Precision Quantization']	By combining differentiable precision search with platform-aware heuristics, we can reduce end-to-end latency of DNNS running on microcontrollers by up to 29.2%.	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|free_bits_platformaware_latency_optimization_of_mixedprecision_neural_networks_for_edge_deployment	/pdf/6c1c5ccc42d70fac6dae65ce2ee9d2f924828296.pdf
3WYtm7UzsR	6472	Towards scalable and non-IID robust Hierarchical Federated Learning via Label-driven Knowledge Aggregator	['Federated Learning', 'Knowledge Distillation', 'non-IID']	We propose a Hierarchical FL framework to divide and conquer non-IID group-by-group	Deep Learning and representational learning	anonymous|towards_scalable_and_noniid_robust_hierarchical_federated_learning_via_labeldriven_knowledge_aggregator	/pdf/1fd4f6983c2bb88065927ff2eeb76cf55e723a8c.pdf
P_48ZG7ySK	6473	Learning with Non-Uniform Label Noise: A Cluster-Dependent Semi-Supervised Approach	['Non-uniform label noise', 'Cluster-dependent sample selection mechanism', 'Semi-supervised training.']	For the robust learning with non-uniform label noise, we propose a cluster-dependent sample selection algorithm followed by a semi-supervised training mechanism.	Deep Learning and representational learning	anonymous|learning_with_nonuniform_label_noise_a_clusterdependent_semisupervised_approach	/pdf/f2604ccd695c49e7c1f9849d3e79b187751a3804.pdf
HGsoe1wmRW5	6477	Pocket-specific 3D Molecule Generation by Fragment-based Autoregressive Diffusion Models	['3D molecule generation', 'drug design', 'protein binding pocket', 'generative model', 'diffusion model']	Using fragment-based autoregressive diffusion model to generate 3D molecules for protein binding pockets	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|pocketspecific_3d_molecule_generation_by_fragmentbased_autoregressive_diffusion_models	/pdf/7415cd617a3b5d3020e785fe11fb2d376adac328.pdf
tPKKXeW33YU	6480	WiNeRT: Towards Neural Ray Tracing for Wireless Channel Modelling and Differentiable Simulations	['neural rendering', 'wireless', 'ray tracing', 'nerf']	Neural wireless ray tracer	Applications (eg, speech processing, computer vision, NLP)	anonymous|winert_towards_neural_ray_tracing_for_wireless_channel_modelling_and_differentiable_simulations	/pdf/534be669699d513e6146394fb77e72ad7e056632.pdf
AqX3oSbzyQ1	6481	Object-Centric Learning with Slot Mixture Models	['object-centric task', 'gaussian mixture model', 'slot attention']	We propose to use Gaussian Mixture Model to represent slots in object-centric tasks, which leads to a more expressive slots representation and the state-of-the-art results in the set property prediction task.	Deep Learning and representational learning	anonymous|objectcentric_learning_with_slot_mixture_models	/pdf/64a1262560cebe62fa6b2e4feea963f14a1a06b3.pdf
r9fX833CsuN	6485	Curriculum-based Co-design of Morphology and Control of Voxel-based Soft Robots	['Artificial Life', 'Brain-body Co-design', 'Robotics', 'Modular Soft Robots']	Curriculum-based Co-design of Morphology and Control of Voxel-based Soft Robots	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|curriculumbased_codesign_of_morphology_and_control_of_voxelbased_soft_robots	/pdf/243938292b1dc42570947ff647682e03d4e5ab7b.pdf
8XfHh4XSQ0Q	6490	Adaptive Block-wise Learning for Knowledge Distillation	['Knowledge distillation', 'Local error signals', 'Bilevel optimization']		Deep Learning and representational learning	anonymous|adaptive_blockwise_learning_for_knowledge_distillation	/pdf/b038b8f9e35e55033f9ea16ac393892b6e31c337.pdf
dNmkN_z72P4	6492	Towards Performance-maximizing Network Pruning via Global Channel Attention	['Channle Pruning', 'Global Attention', 'Deep Neural Networks', 'Model Compression']	GlobalPrun is a static channel pruning method which utilizes advantages from both static and dynamic methods via global channel attention, achieving much higher compression rates and better accuracy.	Deep Learning and representational learning	anonymous|towards_performancemaximizing_network_pruning_via_global_channel_attention	/pdf/f1f6582250e93559253bf65618083c83268be64a.pdf
wSysC6I_S0z	6493	A Hybrid Framework for Generating A Country-scale Synthetic Population	['Synthetic Data', 'Synthetic Population', 'Agent-based Modelling', 'Statistical Methods', 'Machine Learning']	This paper provides a hybrid framework to generate country-scale synthetic population and also provides metrics to assess the quality of our population.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|a_hybrid_framework_for_generating_a_countryscale_synthetic_population	/pdf/aedd7b0c17e8e9aa3d3d031e86630122585f9127.pdf
8Ygoj2IeXfW	6494	Diversity Boosted Learning for Domain Generalization with a Large Number of Domains	['Domain Generalization', 'Spurious Correlation']	We propose a novel sampling framework to efficiently sample the most informative domains and data points to help train robust models against two kinds of spurious correlations in Domain Generalization field.	Deep Learning and representational learning	anonymous|diversity_boosted_learning_for_domain_generalization_with_a_large_number_of_domains	/pdf/f75b97ede849c6db45fb5c77cfe11dcbe3ece6c8.pdf
ejR4E1jaH9k	6495	Solving stochastic weak Minty variational inequalities without increasing batch size	['Variational inequalities', 'stochastic first-order methods', 'nonconvex-nonconcave', 'minimax']	Weak MVIs can be solved with only stochastic feedback using extragradient-like algorithms by introducing a bias-correction term	Optimization (eg, convex and non-convex optimization)	anonymous|solving_stochastic_weak_minty_variational_inequalities_without_increasing_batch_size	/pdf/bdf3ca0748ce380f6aa3be355783419c8ab3f923.pdf
17RDXeF-skZ	6496	Doing Fast Adaptation Fast: Conditionally Independent Deep Ensembles for Distribution Shifts	['deep ensemble', 'diverse ensemble', 'shortcut learning', 'spurious correlations', 'conditional mutual information']		Deep Learning and representational learning	anonymous|doing_fast_adaptation_fast_conditionally_independent_deep_ensembles_for_distribution_shifts	/pdf/1ef722a5b2e1130fecdbd6dceec0e1ddf5cd9cff.pdf
tORS9qGBNpT	6498	Distributed Least Square Ranking with Random Features	['least square ranking', 'distributed learning', 'learning theory', 'random features']	We study the statistical properties of pairwise ranking using distributed learning and random features, establish the convergence rate in probability, and demonstrate the power of the proposed methods via numerical experiments.	General Machine Learning (ie none of the above)	anonymous|distributed_least_square_ranking_with_random_features	/pdf/3511b749f8e23baa7a205ef0391bdf31de7dd8d1.pdf
gHwpv9pSEP2	6500	FLOP: Tasks for Fitness Landscapes Of Protein families using sequence- and structure-based representations	['protein engineering', 'representation learning', 'generalization', 'benchmark', 'enzyme engineering', 'protein structure', 'protein language model']	Novel benchmark dataset for exploration of single family protein fitness landscapes for protein engineering	Infrastructure (eg, datasets, competitions, implementations, libraries)	anonymous|flop_tasks_for_fitness_landscapes_of_protein_families_using_sequence_and_structurebased_representations	/pdf/e9739c891235ed69d1c1db54b409672ca5e08f85.pdf
pW_jGk1D_Ww	6502	Disentangled Feature Swapping Augmentation for Weakly Supervised Semantic Segmentation	['Weakly Supervised Semantic Segmentation', 'Data Augmentation', 'Feature Disentanglement']	We propose a novel feature augmentation for weakly supervised semantic segmentation to prevent the classifier from being biased by misleading correlation.	Applications (eg, speech processing, computer vision, NLP)	anonymous|disentangled_feature_swapping_augmentation_for_weakly_supervised_semantic_segmentation	/pdf/fc8531f69a25e5383916ceb64c3c83da7f9bde8a.pdf
zygzt8QFsV	6505	Partial Output Norm: Mitigating the Model Output Blow-up Effect of Cross Entropy Loss 	[]		General Machine Learning (ie none of the above)	anonymous|partial_output_norm_mitigating_the_model_output_blowup_effect_of_cross_entropy_loss	/pdf/fc7c50857a5f39289162c49225cd431980111418.pdf
1FsdIfRngtw	6510	Rethinking the Value of Prompt Learning for Vision-Language Models	['Prompt Tuning', 'Visual-Language Pre-training']		Deep Learning and representational learning	anonymous|rethinking_the_value_of_prompt_learning_for_visionlanguage_models	/pdf/f2bab646f102f7ef92d6fd0603cd4a5b3f4ac631.pdf
gNI4_85Cyve	6511	QAID: Question Answering Inspired Few-shot Intent Detection	['Intent Detection', 'Question Answering', 'Contrastive Learning', 'Passage Retrieval']	Our method achieve SOTA results on few-shot intent detection by combining Question-Answering architecture, Contrastive Learning techniques and use of the intent name as answer. 	Deep Learning and representational learning	anonymous|qaid_question_answering_inspired_fewshot_intent_detection	/pdf/2984ab8594ec83d48171561fd7e7c85767c39b0c.pdf
cZM4iZmxzR7	6512	Simple Spectral Graph Convolution from an Optimization Perspective	['Graph Convolution', 'Graph Fourier Transformation', 'Unsupervised Learning']	We define a learnable and unsupervised graph convolution framework as self-representation on graph.	Deep Learning and representational learning	anonymous|simple_spectral_graph_convolution_from_an_optimization_perspective	/pdf/4dfec7b41fd7e6502bbccc24b2cb1a405d85029f.pdf
0z_cXcu1N6o	6514	Transformer needs NMDA receptor nonlinearity for long-term memory	['NMDAR', 'hippocampus', 'transformer', 'memory']		Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|transformer_needs_nmda_receptor_nonlinearity_for_longterm_memory	/pdf/d0214912554a6e498767104618b6b9de3e6f1a8a.pdf
EgJ0PbRPkCW	6515	Joint Representations of Text and Knowledge Graphs for Retrieval and Evaluation	['Representation learning', 'Text generation', 'Knowledge bases', 'Evaluation']	We learn joint representations for knowledge base elements and corresponding text, which allows to perform retrieval and referenceless adequacy evaluation	Deep Learning and representational learning	anonymous|joint_representations_of_text_and_knowledge_graphs_for_retrieval_and_evaluation	/pdf/c632edbf35d654ca305a02d46428cd0b0e507f0c.pdf
pgJp7rDc_hk	6516	Coreset for Rational Functions	['Coreset', 'Auto-regression', 'rational functions', 'non-convex optimization']		Optimization (eg, convex and non-convex optimization)	anonymous|coreset_for_rational_functions	/pdf/a32e912f000d7aa233e256e2c6fd81d27138d96c.pdf
hChYEyebNm1	6518	Gradient-Based Transfer Learning	['meta-learning', 'gradient-based meta-learning', 'transfer learning', 'representation learning']	We formulate transfer learning as a meta-learning problem and extend current gradient-based meta-learning methods to this setting. 	Deep Learning and representational learning	anonymous|gradientbased_transfer_learning	/pdf/041fdb929c8bcc579a246ecda14cc8bb9abac37d.pdf
ULzyv9M1j5	6520	Transformer-based model for symbolic regression via joint supervised learning	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|transformerbased_model_for_symbolic_regression_via_joint_supervised_learning	/pdf/b0edca4ba8c4dc4ee4753c3a218a2fbab8027e17.pdf
a-bD9-0ycs0	6522	Latent Linear ODEs with Neural Kalman Filtering for Irregular Time Series Forecasting	['Time Series Forecasting', 'Neural ODE', 'Kalman Filter', 'Koopman Operator', 'Missing Values']		Deep Learning and representational learning	anonymous|latent_linear_odes_with_neural_kalman_filtering_for_irregular_time_series_forecasting	/pdf/c48c0d9c5389ecab0650d9039f11a47231ea14fd.pdf
9D5FH6LFbRu	6526	Functional Risk Minimization	['learning framework', 'theory', 'meta-learning', 'supervised learning']	We propose to model uncertainty in function space rather than output space. We derive a learning framework, with experimental results, and show connections to recent theory on over-paramterized generalization.	Deep Learning and representational learning	anonymous|functional_risk_minimization	/pdf/a1f2610c888d4f1edb6be34815f1891ef35359f6.pdf
UPQualDj1oo	6527	Machine Learning from Explanations	['model explanations', 'trustworthy machine learning', 'explainable ai', 'interpretable machine learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|machine_learning_from_explanations	/pdf/38dd9169c18cb8bdb2728eb8959ac67b8a040276.pdf
MjikLUwiB3M	6528	Towards a Complete Theory of Neural Networks with Few Neurons	['theory of neural networks', 'non-convex landscapes', 'critical manifolds', 'gradient flow dynamics']	We analytically study the landscapes of neural networks with a few neurons, shedding light on how the neurons move following gradient flow. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|towards_a_complete_theory_of_neural_networks_with_few_neurons	/pdf/bd204b0c5259348c1743039482ded0196acd5440.pdf
1Wo0vqaZ8WJ	6530	Let Offline RL Flow: Training Conservative Agents in the Latent Space of Normalizing Flow	['Offline Reinforcement Learning', 'Normalizing Flows']	Latent-Variable Policy Optimization for Offline RL based on Normalizing Flows (outperforms both PLAS and LAPO)	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|let_offline_rl_flow_training_conservative_agents_in_the_latent_space_of_normalizing_flow	/pdf/4e7393a98430e6de246334dceae4244b8cd9205e.pdf
0OlEBibFa_g	6532	"Detecting Out-of-Distribution Data with Semi-supervised Graph “Feature"" Networks"	[]		Deep Learning and representational learning	anonymous|detecting_outofdistribution_data_with_semisupervised_graph_feature_networks	/pdf/c8b3ebaa02e559c99c8d9a0a22cd7cbe9c7c146f.pdf
pWVASryOyFw	6533	Learning Uncertainty for Unknown Domains with Zero-Target-Assumption	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_uncertainty_for_unknown_domains_with_zerotargetassumption	/pdf/660457ddfcc0af8abfff7ed8fc24d314ca032b28.pdf
eGWEfaW-5Yt	6534	PPAT: Progressive Graph Pairwise Attention Network for Event Causality Identification	['Event causality identification', 'graph neural network', 'natural language processing']	We propose PPAT for event causality identification, which reasons inter-sentence event causality based on intra-sentence event causality and outperforms all previous methods.	Applications (eg, speech processing, computer vision, NLP)	anonymous|ppat_progressive_graph_pairwise_attention_network_for_event_causality_identification	/pdf/6004c846038f2eb8ed0a83a5965a2e9ef320777b.pdf
Rn50hCOX9XX	6535	Gene finding revisited: improved robustness through structured decoding from learning embeddings	['gene finding', 'graphical model', 'gene prediction', 'gene splicing', 'conditional random fields', 'structured decoding', 'DNA', 'learned embeddings']	Improving the robustness of predicting the exact coding sequences of genomes by combining deep learning with a graphical model encoding gene structure. 	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|gene_finding_revisited_improved_robustness_through_structured_decoding_from_learning_embeddings	/pdf/ab31d4ef3ae64c779f0cf7a7fc93104063767acf.pdf
zUXBrqXQ1g6	6536	Cultivation of Digital Diagnosis from Medical Images: Radiomics	['Radiomics', 'MRI', 'CT', 'Medical Imaging', 'Diagnosis']		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|cultivation_of_digital_diagnosis_from_medical_images_radiomics	/pdf/635e4a41adfd85ab9f96d25ca0e6efa6437ce68d.pdf
Jdj0fZhswJC	6539	Convergence is Not Enough: Average-Case Performance of No-Regret Learning Dynamics	['q-replicator dynamics', 'potential games', 'average price of anarchy', 'learning']	Beyond convergence, average case metrics rely on regions of attraction to compare the performance of different dynamics in multi-agent games. 	Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|convergence_is_not_enough_averagecase_performance_of_noregret_learning_dynamics	/pdf/4f6ae13cdd5e3c513ef35dfba5a7abcf34c134c3.pdf
jREF4bkfi_S	6542	Mini-batch $k$-means terminates within $O(d/\epsilon)$ iterations	[]		Theory (eg, control theory, learning theory, algorithmic game theory)	anonymous|minibatch_kmeans_terminates_within_od\epsilon_iterations	/pdf/c81b55ea515d9c2ab67c74ca7560b8964d3a8c75.pdf
BO5_Lm7iD_	6545	Social Network Structure Shapes Innovation: Experience-sharing in RL with SAPIENS	['collective innovation', 'social network', 'multi-agent model', 'collective dynamics', 'communication topology', 'collective cognition']	We show that a group's ability to collectively solve tasks depends on the social network structure that determines who shares information with whom, with dynamically changing structures performing best..	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|social_network_structure_shapes_innovation_experiencesharing_in_rl_with_sapiens	/pdf/00752af6a35f86330798294e6ff814df9a107147.pdf
Xj9V-stmIcO	6546	Proper Scoring Rules for Survival Analysis	['scoring rules', 'survival analysis', 'time-to-event analysis']	Theoretical analysis of scoring rules for survival analysis.	General Machine Learning (ie none of the above)	anonymous|proper_scoring_rules_for_survival_analysis	/pdf/301c2598a7cfae7f0f30b655a35b0622387261d6.pdf
gZYbGIpFYpA	6548	Learning to Perturb for Contrastive Learning of Unsupervised Sentence Representations	['Unsupervised Sentence Representations', 'Contrastive Learning']		Applications (eg, speech processing, computer vision, NLP)	anonymous|learning_to_perturb_for_contrastive_learning_of_unsupervised_sentence_representations	/pdf/f102eca491f16d4800a9887c46d74489dbc19c68.pdf
N_g8TT9Cy7f	6549	Generating Intuitive Fairness Specifications for Natural Language Processing	['Individual Fairness', 'Style Transfer', 'NLP', 'Crowdsourcing', 'Human Evaluation']	We provide new methods for generating individual fairness specifications for NLP based on LLMs and validate them in a human study. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|generating_intuitive_fairness_specifications_for_natural_language_processing	/pdf/26811fba098a3ae6afec63cf9df8dc938da56bb0.pdf
7YfHla7IxBJ	6550	Encoding Recurrence into Transformers	['Recurrent models', 'Transformers', 'sample efficiency', 'gated mechanism']	We propose a new module to encode the recurrent dynamics of an RNN layer into Transformers and higher sample efficiency can be achieved.	Deep Learning and representational learning	anonymous|encoding_recurrence_into_transformers	/pdf/c677ad4a2683aeb88c14d6279b744fd4f3e074ae.pdf
HTJE5Krui0g	6551	Softened Symbol Grounding for Neuro-symbolic Systems	['neuro-symbolic learning', 'symbol grounding problem', 'projection-based sampling']		Deep Learning and representational learning	anonymous|softened_symbol_grounding_for_neurosymbolic_systems	/pdf/faec52dcd3582c3d92f7f4e778c223e9bb143b76.pdf
yqe0BZeN_xH	6553	SwinZS3: Zero-Shot Semantic Segmentation with a Swin Transformer	['zero shot semantic segmentation', 'deep learning', 'transformer']		Deep Learning and representational learning	anonymous|swinzs3_zeroshot_semantic_segmentation_with_a_swin_transformer	/pdf/b0c2ac0d1dfce7acabe315a89cd09b3400118f6d.pdf
TZG_XsO4x6y	6556	Long-horizon video prediction using a dynamic latent hierarchy	['long-term video prediction', 'hierarchical generative model', 'spatiotemporal disentaglement', 'event-based model']	Hierarchical generative model for long-horizon video prediction	Generative models	anonymous|longhorizon_video_prediction_using_a_dynamic_latent_hierarchy	/pdf/2692c2463873f531ac0604487b99398f9bd042bf.pdf
QN_VgTeOYGl	6558	Data Leakage in Tabular Federated Learning	['federated learning', 'tabular data', 'data leakage attacks', 'gradient inversion']	We introduce a novel data leakage atack on FL for tabular data.	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|data_leakage_in_tabular_federated_learning	/pdf/f12c3c883d65b7173caa03111c39ccc99e6d8a9d.pdf
3uDXZZLBAwd	6560	Deep Reinforcement Learning based Insight Selection Policy	['recommender', 'insight', 'reinforcement learning', 'behavior change support system', 'health coaching', 'lifestyle simulator', 'Gaussian mixture modeling']		Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|deep_reinforcement_learning_based_insight_selection_policy	/pdf/bb3c94000ef7597bd29e1e371a58007578adbdd8.pdf
s6l6ks1iooc	6569	Towards Robust Online Dialogue Response Generation	[]		Applications (eg, speech processing, computer vision, NLP)	anonymous|towards_robust_online_dialogue_response_generation	/pdf/51848724d8021f68be8db4781829073ec9f1e39e.pdf
pGR2gNO5c4p	6575	NeuralStagger: accelerating physics constrained neural PDE solver with spatial-temporal decomposition	[]		Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|neuralstagger_accelerating_physics_constrained_neural_pde_solver_with_spatialtemporal_decomposition	/pdf/8c64616e9b066b3540cd1144aedf273fc0c2d183.pdf
IQM-3_Tzldw	6577	Learning to aggregate: A parameterized aggregator to debias aggregation for cross-device federated learning	['Federated learning']	Our idea is to learn an aggregator to debias aggregation to calibrate and control the direction of aggregated parameters to deal with both client drift and period drift.	Deep Learning and representational learning	anonymous|learning_to_aggregate_a_parameterized_aggregator_to_debias_aggregation_for_crossdevice_federated_learning	/pdf/6bad3008665ed39aee60079bbdd470a4d6c0a04f.pdf
KNL8KSH7b_F	6578	UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers	['Multimodal Model', 'Model Compression', 'Vision-Language Transformers']	For the first time, we propose a multimodal compression approach UPop for vision-language Transformers from the perspective of pruning.	Deep Learning and representational learning	anonymous|upop_unified_and_progressive_pruning_for_compressing_visionlanguage_transformers	/pdf/0cb357ad4303a2e9101f41b03a72fcee55883250.pdf
91efl6aSU2d	6580	Dual-Domain Diffusion Based Progressive Style Rendering towards Semantic Structure Preservation	[]		Generative models	anonymous|dualdomain_diffusion_based_progressive_style_rendering_towards_semantic_structure_preservation	/pdf/41f1ee94074f8071f4994e631f025b05c649a8be.pdf
NOKUQ9JMohJ	6584	ONLINE RESTLESS BANDITS WITH UNOBSERVED STATES	['Thompson Sampling', 'Explore-Then-Commit', 'online restless bandit']	We propose TSEETC to slove the restless bandits with unknown transition kernels,unknown reward functions and unobserved states.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|online_restless_bandits_with_unobserved_states	/pdf/8817c2f27cfd98e186b7768c42dcdf073ad63ee7.pdf
vzdrgR2nomD	6591	FARE: Provably Fair Representation Learning	['fairness', 'fair representation learning']	We present the first provable fair representation learning method. 	Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|fare_provably_fair_representation_learning	/pdf/7924f400e6af28aa2b9f38f0e0e18473afc3a0fd.pdf
Vx6G9W5M4sQ	6592	pFedKT: Personalized Federated Learning via Knowledge Transfer	['Personalized Federated Learning', 'Knowledge Transfer', 'Local Hypernetwork', 'Contrastive Learning']		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|pfedkt_personalized_federated_learning_via_knowledge_transfer	/pdf/fd51349deb64ac0d27637aa49b07cd49025731fc.pdf
6iEoTr-jeB7	6593	Learning Continuous Normalizing Flows For Faster Convergence To Target Distribution via Ascent Regularizations	['normalizing flows', 'gradient flows', 'density estimation', 'unbiased sampling', 'variational inference']		Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)	anonymous|learning_continuous_normalizing_flows_for_faster_convergence_to_target_distribution_via_ascent_regularizations	/pdf/a96e6e9e4a114c3a72550dc771488a8a3790a94f.pdf
9Zx6tTcX0SE	6598	A Study of Biologically Plausible Neural Network: the Role and Interactions of Brain-Inspired Mechanisms in Continual Learning	"['Continual Learning', 'Catastrophic Forgetting', 'Brain-inspired Mechanisms', 'Active Dendrites', ""Dale's Principle"", 'Hebbian Learning', 'Sparsity']"	a comprehensive study on the role and interactions of different mechanisms inspired by the brain including sparse non-overlapping representations, Hebbian learning, synaptic consolidation, and replay of past activations	Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)	anonymous|a_study_of_biologically_plausible_neural_network_the_role_and_interactions_of_braininspired_mechanisms_in_continual_learning	/pdf/bffb14021d64e4b61b09f3a9a1884b44ac354595.pdf
I3HCE7Ro78H	6599	Adversarial Training descends without descent: Finding actual descent directions based on Danskin's theorem	['Adversarial Training', 'Adversarial Examples', 'non-convex optimization', 'robustness']	There is a subtle bug in the theory behind PGD. We show how to correct it and that it matters in practice	Optimization (eg, convex and non-convex optimization)	anonymous|adversarial_training_descends_without_descent_finding_actual_descent_directions_based_on_danskins_theorem	/pdf/a964cd69256714b4ad85c932d0e6e27d8fa171fd.pdf
sZI1Oj9KBKy	6601	TVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning	['Structured pruning', 'model compression']	We use the total variation distance between the class conditional distributions of filter outputs for structured pruning of neural networks.	Deep Learning and representational learning	anonymous|tvsprune_pruning_nondiscriminative_filters_via_total_variation_separability_of_intermediate_representations_without_fine_tuning	/pdf/ecc7dfcce63f2d2c89f092ebc1ea450fcc96e573.pdf
mhnHqRqcjYU	6603	DFPC: Data flow driven pruning of coupled channels without data.	['Pruning', 'Data Free', 'Model Compression']	We propose a novel data-free algorithm to accelerate neural networks via pruning coupled channels.	Deep Learning and representational learning	anonymous|dfpc_data_flow_driven_pruning_of_coupled_channels_without_data	/pdf/55db83e926f940361b1f96359cd90eb9e5461681.pdf
tmIiMPl4IPa	6610	Factorized Fourier Neural Operators	['fourier transform', 'fourier operators', 'pde', 'navier stokes']	An efficient and scalable neural PDE solver using Fourier transform.	Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )	anonymous|factorized_fourier_neural_operators	/pdf/f165fba1a61fac089a88a6f600dafa6100768f5c.pdf
N3kGYG3ZcTi	6611	Suppression helps: Lateral Inhibition-inspired Convolutional Neural Network for Image Classification	['Lateral Inhibition', 'Convolutional Neural Networks']	Improving feature learning with lateral inhibition	Deep Learning and representational learning	anonymous|suppression_helps_lateral_inhibitioninspired_convolutional_neural_network_for_image_classification	/pdf/fe61792a0bdac18c97e72754f6fd250b79e65ffc.pdf
RUzSobdYy0V	6620	Quantifying and Mitigating the Impact of Label Errors on Model Disparity Metrics	[]		Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)	anonymous|quantifying_and_mitigating_the_impact_of_label_errors_on_model_disparity_metrics	/pdf/fa20300b4f58971f6a0663a5cb2c8efd17fe6240.pdf
kRvZ2PcsxjJj	6623	Quantum reinforcement learning 	['quantum reinforcement learning', 'multi-agent', 'quantum technology', 'control optimization', 'quantum circuit']	A review and implementation of quantum reinforcement learning. We used QRL to train several game agents, and finally predicted and looked forward to future applications and trends.	Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)	anonymous|quantum_reinforcement_learning	/pdf/bd1412beeb070314478ba69a52979cd9d7057106.pdf
